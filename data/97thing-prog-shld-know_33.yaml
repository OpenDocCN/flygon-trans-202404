- en: Floating-point Numbers Aren't Real
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 浮点数不是真实的
- en: Floating-point Numbers Aren't Real
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 浮点数不是真实的
- en: Floating-point numbers are not "real numbers" in the mathematical sense, even
    though they are called *real* in some programming languages, such as Pascal and
    Fortran. Real numbers have infinite precision and are therefore continuous and
    non-lossy; floating-point numbers have limited precision, so they are finite,
    and they resemble "badly-behaved" integers, because they're not evenly spaced
    throughout their range.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 浮点数在数学意义上不是“实数”，尽管在某些编程语言中（如Pascal和Fortran）它们被称为*实数*。实数具有无限的精度，因此是连续的和非丢失的；浮点数具有有限的精度，因此它们是有限的，它们类似于“表现不佳的”整数，因为它们在其范围内不是均匀分布的。
- en: To illustrate, assign 2147483647 (the largest signed 32-bit integer) to a 32-bit
    float variable (x, say), and print it. You'll see 2147483648\. Now print `x -
    64`. Still 2147483648\. Now print `x - 65` and you'll get 2147483520! Why? Because
    the spacing between adjacent floats in that range is 128, and floating-point operations
    round to the nearest floating-point number.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，将 2147483647（最大的32位有符号整数）赋值给一个32位浮点变量（比如说x），然后打印它。你会看到2147483648。现在打印`x
    - 64`。仍然是2147483648。现在打印`x - 65`，你会得到2147483520！为什么？因为在这个范围内相邻浮点数之间的间隔是128，浮点运算会四舍五入到最近的浮点数。
- en: 'IEEE floating-point numbers are fixed-precision numbers based on base-two scientific
    notation: 1.d[1]d[2]...d[p-1] × 2^e, where *p* is the precision (24 for float,
    53 for double). The spacing between two consecutive numbers is 2^(1-p+e), which
    can be safely approximated by ε|x|, where ε is the *machine epsilon* (2^(1-p)).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE浮点数是基于二进制科学计数法的固定精度数字：1.d[1]d[2]...d[p-1] × 2^e，其中*p*是精度（float为24，double为53）。两个连续数字之间的间距是2^(1-p+e)，可以安全地近似为ε|x|，其中ε是*机器精度*（2^(1-p)）。
- en: Knowing the spacing in the neighborhood of a floating-point number can help
    you avoid classic numerical blunders. For example, if you're performing an iterative
    calculation, such as searching for the root of an equation, there's no sense in
    asking for greater precision than the number system can give in the neighborhood
    of the answer. Make sure that the tolerance you request is no smaller than the
    spacing there; otherwise you'll loop forever.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 了解浮点数周围的间距可以帮助您避免经典的数值错误。例如，如果您正在执行迭代计算，比如搜索方程的根，那么在答案附近要求比数字系统能给出的精度更高是没有意义的。确保您请求的容差不小于那里的间距；否则你会无限循环。
- en: Since floating-point numbers are approximations of real numbers, there is inevitably
    a little error present. This error, called *roundoff*, can lead to surprising
    results. When you subtract nearly equal numbers, for example, the most significant
    digits cancel each other out, so what was the least significant digit (where the
    roundoff error resides) gets promoted to the most significant position in the
    floating-point result, essentially contaminating any further related computations
    (a phenomenon known as *smearing*). You need to look closely at your algorithms
    to prevent such *catastrophic cancellation*. To illustrate, consider solving the
    equation *x² - 100000x + 1 = 0* with the quadratic formula. Since the operands
    in the expression *-b + sqrt(b² - 4)* are nearly equal in magnitude, you can instead
    compute the root *r[1] = -b + sqrt(b² - 4)*, and then obtain *r[2] = 1/r[1]*,
    since for any quadratic equation, ax2 + bx + c = 0, the roots satisfy *r[1]r[2]
    = c/a*.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 由于浮点数是实数的近似值，难免存在一些误差。这种误差称为*舍入误差*，可能导致意想不到的结果。例如，当你减去几乎相等的数字时，最显著的数字会相互抵消，所以舍入误差存在的最低有效位会提升到浮点结果的最显著位置，从而污染任何进一步相关的计算（这种现象称为*涂抹*）。你需要仔细检查你的算法，以防止这种*灾难性的抵消*。举个例子，考虑用求根公式解方程*x²
    - 100000x + 1 = 0*。由于表达式*-b + sqrt(b² - 4)*中的操作数几乎相等，你可以计算根*r[1] = -b + sqrt(b²
    - 4)*，然后得到*r[2] = 1/r[1]*，因为对于任何二次方程，ax2 + bx + c = 0，根满足*r[1]r[2] = c/a*。
- en: 'Smearing can occur in even more subtle ways. Suppose a library naively computes
    *e^x* by the formula *1 + x + x²/2 + x³/3! + ...*. This works fine for positive
    *x*, but consider what happens when *x* is a large negative number. The even-powered
    terms result in large positive numbers, and subtracting the odd-powered magnitudes
    will not even affect the result. The problem here is that the roundoff in the
    large, positive terms is in a digit position of much greater significance than
    the true answer. The answer diverges toward positive infinity! The solution here
    is also simple: for negative *x*, compute *e^x = 1/e^(|x|)*.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 即使更微妙的方式也可能发生涂抹。假设一个库通过公式*1 + x + x²/2 + x³/3! + ...*天真地计算*e^x*。对于正数*x*，这样做没问题，但是当*x*是一个很大的负数时会发生什么呢？偶次幂会产生很大的正数，而减去奇次幂的量甚至不会影响结果。问题在于，大正数的舍入值位于远比真实答案更为重要的数字位置。答案会朝着正无穷发散！解决方法也很简单：对于负数*x*，计算*e^x
    = 1/e^(|x|)*。
- en: It should go without saying that you shouldn't use floating-point numbers for
    financial applications — that's what decimal classes in languages like Python
    and C# are for. Floating-point numbers are intended for efficient scientific computation.
    But efficiency is worthless without accuracy, so remember the source of rounding
    errors and code accordingly!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 应该不言而喻，你不应该在金融应用中使用浮点数 —— 这就是像 Python 和 C# 这样的语言中的十进制类存在的原因。浮点数旨在进行高效的科学计算。但是效率没有准确性就毫无价值，所以请记住舍入误差的来源，并相应地编写代码！
- en: By [Chuck Allison](http://programmer.97things.oreilly.com/wiki/index.php/Chuck_Allison)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：[查克·艾利森](http://programmer.97things.oreilly.com/wiki/index.php/Chuck_Allison)
