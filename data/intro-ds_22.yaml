- en: '[Map](data_mining_map.htm) > [Data Science](data_mining.htm) > [Predicting
    the Future](predicting_the_future.htm) > [Modeling](modeling.htm) > [Classification](classification.htm)/[Regression](regression.htm)
    > Artificial Neural Network'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '[映射](data_mining_map.htm) > [数据科学](data_mining.htm) > [预测未来](predicting_the_future.htm)
    > [建模](modeling.htm) > [分类](classification.htm)/[回归](regression.htm) > 人工神经网络'
- en: Artificial Neural Network
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: An artificial neutral network (**ANN**) is a system that is based on the biological
    neural network, such as the brain. The brain has approximately 100 billion neurons,
    which communicate through electro-chemical signals. The neurons are connected
    through junctions called synapses. Each neuron receives thousands of connections
    with other neurons, constantly receiving incoming signals to reach the cell body.
    If the resulting sum of the signals surpasses a certain threshold, a response
    is sent through the axon. The ANN attempts to recreate the computational mirror
    of the biological neural network, although it is not comparable since the number
    and complexity of neurons and the used in a biological neural network is many
    times more than those in an artificial neutral network.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络（**ANN**）是基于生物神经网络的系统，例如大脑。大脑约有1000亿个神经元，它们通过电化学信号进行通信。神经元通过称为突触的连接连接在一起。每个神经元与其他神经元建立数千个连接，不断接收传入信号以达到细胞体。如果信号的总和超过一定的阈值，则通过轴突发送响应。人工神经网络试图重新创建生物神经网络的计算镜像，尽管它不可比较，因为生物神经网络中的神经元数量和复杂性以及使用的次数比人工神经网络中的多得多。
- en: '![](../Images/3bc37b190a0fddf8c97fa0e19348c650.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3bc37b190a0fddf8c97fa0e19348c650.jpg)'
- en: 'An ANN is comprised of a network of artificial neurons (also known as "nodes").
    These nodes are connected to each other, and the strength of their connections
    to one another is assigned a value based on their strength: inhibition (maximum
    being -1.0) or excitation (maximum being +1.0). If the value of the connection
    is high, then it indicates that there is a strong connection. Within each node''s
    design, a transfer function is built in. There are three types of neurons in an
    ANN, **input nodes**, **hidden nodes**, and **output nodes**.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络由一组人工神经元（也称为“节点”）组成。这些节点彼此连接，它们之间的连接强度根据其强度分配一个值：抑制（最大值为-1.0）或兴奋（最大值为+1.0）。如果连接的值很高，则表示存在很强的连接。在每个节点的设计中，内置了一个传递函数。人工神经网络中有三种类型的神经元，即**输入节点**、**隐藏节点**和**输出节点**。
- en: '![](../Images/38a7b1aad71ea24d0e9a5cfa61833627.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38a7b1aad71ea24d0e9a5cfa61833627.jpg)'
- en: The input nodes take in information, in the form which can be numerically expressed.
    The information is presented as activation values, where each node is given a
    number, the higher the number, the greater the activation. This information is
    then passed throughout the network. Based on the connection strengths (**weights**),
    inhibition or excitation, and transfer functions, the activation value is passed
    from node to node. Each of the nodes sums the activation values it receives; it
    then modifies the value based on its transfer function. The activation flows through
    the network, through hidden layers, until it reaches the output nodes. The output
    nodes then reflect the input in a meaningful way to the outside world. The difference
    between predicted value and actual value (error) will be propagated backward by
    apportioning them to each node's weights according to the amount of this error
    the node is responsible for (e.g., [gradient descent algorithm](gradient_descent.htm)).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 输入节点接收信息，其形式可以用数字表示。信息以激活值的形式呈现，其中每个节点都被赋予一个数字，数字越高，激活越强。然后将此信息传递到整个网络中。基于连接强度（**权重**）、抑制或兴奋以及传递函数，激活值从一个节点传递到另一个节点。每个节点对其接收的激活值求和；然后根据其传递函数修改该值。激活值通过网络流动，穿过隐藏层，直到到达输出节点。然后，输出节点以对外部世界有意义的方式反映输入。预测值与实际值之间的差异（错误）将通过根据节点对此错误的负责程度将其分配给每个节点的权重而向后传播（例如，[梯度下降算法](gradient_descent.htm)）。
- en: '![](../Images/39405304bf2994968032432a87ed48f5.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39405304bf2994968032432a87ed48f5.jpg)'
- en: '**Transfer (Activation) Functions**'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**传递（激活）函数**'
- en: The transfer function translates the input signals to output signals. Four types
    of transfer functions are commonly used, Unit step (threshold), sigmoid, piecewise
    linear, and Gaussian.  **Unit step (threshold)**The output is set at one of two
    levels, depending on whether the total input is greater than or less than some
    threshold value.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 传递函数将输入信号转换为输出信号。常用的四种传递函数类型是单位阶跃（阈值）、Sigmoid、分段线性和高斯。
- en: '![](../Images/8cd5d7873ac35d5f96c404a0b04f79cd.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cd5d7873ac35d5f96c404a0b04f79cd.jpg)'
- en: '**Sigmoid**The sigmoid function consists of 2 functions, *logistic* and *tangential*.
    The values of logistic function range from 0 and 1 and -1 to +1 for tangential
    function.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sigmoid**Sigmoid函数由两个函数组成，*逻辑*和*切线*。逻辑函数的值范围在0和1之间，切线函数的值范围在-1到+1之间。'
- en: '![](../Images/6db5fcf324f044f7229014ca4504c5e9.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6db5fcf324f044f7229014ca4504c5e9.jpg)'
- en: '**Piecewise Linear **The output is proportional to the total weighted output.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**分段线性**输出与总加权输出成比例。'
- en: '![](../Images/071f402bb31b4d22b06170e1f409c5ae.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/071f402bb31b4d22b06170e1f409c5ae.jpg)'
- en: '**Gaussian**Gaussian functions are bell-shaped curves that are continuous.
    The node output (high/low) is interpreted in terms of class membership (1/0),
    depending on how close the net input is to a chosen value of average.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯**高斯函数是连续的钟形曲线。节点输出（高/低）根据输入与选择的平均值的接近程度来解释类成员资格（1/0）。'
- en: '![](../Images/27bc9ccc416ab2a23634c8dc00256020.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27bc9ccc416ab2a23634c8dc00256020.jpg)'
- en: '**Linear** Like a linear regression, a linear activation function transforms
    the weighted sum inputs of the neuron to an output using a linear function.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性**像线性回归一样，线性激活函数将神经元的加权和输入转换为输出，使用线性函数。'
- en: '![](../Images/4f697e4f0109680bb1d7c1b68e8b637f.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f697e4f0109680bb1d7c1b68e8b637f.jpg)'
- en: '**Algorithm**'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**算法**'
- en: There are different types of neural networks, but they are generally classified
    into feed-forward and feed-back networks. A **feed-forward network** is a non-recurrent
    network which contains inputs, outputs, and hidden layers; the signals can only
    travel in one direction. Input data is passed onto a layer of processing elements
    where it performs calculations. Each processing element makes its computation
    based upon a weighted sum of its inputs. The new calculated values then become
    the new input values that feed the next layer. This process continues until it
    has gone through all the layers and determines the output. A threshold transfer
    function is sometimes used to quantify the output of a neuron in the output layer.
    Feed-forward networks include [Perceptron](artificial_neural_network_bkp.htm)
    (linear and non-linear) and [Radial Basis Function](artificial_neural_network_rbf.htm)
    networks. Feed-forward networks are often used in data mining. A **feed-back network**
    has feed-back paths meaning they can have signals traveling in both directions
    using loops. All possible connections between neurons are allowed. Since loops
    are present in this type of network, it becomes a non-linear dynamic system which
    changes continuously until it reaches a state of equilibrium. Feed-back networks
    are often used in associative memories and optimization problems where the network
    looks for the best arrangement of interconnected factors.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络有不同类型，但通常分为前馈和反馈网络。**前馈网络**是一种非递归网络，包含输入、输出和隐藏层；信号只能单向传输。输入数据传递到一层处理元素，进行计算。每个处理元素根据其输入的加权和进行计算。新计算的值然后成为下一层的新输入值。这个过程一直持续，直到通过所有层并确定输出。有时会使用阈值传递函数来量化输出层神经元的输出。前馈网络包括[感知器](artificial_neural_network_bkp.htm)（线性和非线性）和[径向基函数](artificial_neural_network_rbf.htm)网络。前馈网络经常用于数据挖掘。**反馈网络**具有反馈路径，意味着可以使用循环双向传输信号。允许神经元之间的所有可能连接。由于这种网络中存在循环，它变成一个非线性动态系统，不断变化直到达到平衡状态。反馈网络经常用于联想记忆和优化问题，其中网络寻找相互关联因素的最佳排列。
