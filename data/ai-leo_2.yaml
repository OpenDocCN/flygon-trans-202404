- en: Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: Introduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Machine learning is all about using your computer to "learn" how to deal with
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习就是利用你的计算机来“学习”如何处理
- en: problems without “programming". (It’s a branch of artificial intelligence)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 无需“编程”就能解决问题。（这是人工智能的一个分支）
- en: We take some data, train a model on that data, and use the trained model to
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取一些数据，对该数据进行模型训练，并使用训练好的模型来
- en: make predictions on new data. Basically is a way to make the computer create
    a
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在新数据上做出预测。基本上是一种让计算机创建一个的方法
- en: program that gives some output with a known input and that latter give a intelligent
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 给出已知输入并后来给出智能输出的程序
- en: output to a different but similar input.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 输出到一个不同但相似的输入。
- en: We need machine learning on cases that would be difficult to program by hand
    all
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要机器学习来解决一些难以手动编程的情况
- en: possible variants of a classification/prediction problem
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 分类/预测问题的可能变体
- en: 'The basic Idea of Machine Learning is to make the computer learn something
    from the data. Machine learning comes in two flavors:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的基本思想是让计算机从数据中学到东西。机器学习有两种味道：
- en: 'Supervised Learning: You give to the computer some pairs of inputs/outputs,
    so in the future new when new inputs are presented you have an intelligent output.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习：你给计算机一些输入/输出对，这样在未来当新输入被呈现时，你就有了一个智能的输出。
- en: 'Unsupervised Learning: You let the computer learn from the data itself without
    showing what is the expected output.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习：你让计算机从数据本身学习，而不告诉它期望的输出是什么。
- en: '![](supervised_unsupervised.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](supervised_unsupervised.png)'
- en: Examples of Supervised Learning
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习示例
- en: '* * *'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Image Classification: Your train with images/labels. Then on the future when
    you give a new image expecting that the computer will recognise the new object
    (Classification)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像分类：你用图像/标签进行训练。然后在将来，当你提供一个新的图像时，期望计算机能够识别新对象（分类）。
- en: 'Market Prediction: You train the computer with historical market data, and
    ask the computer to predict the new price on the future (Regression)'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 市场预测：你用历史市场数据训练计算机，并要求计算机预测未来的价格（回归）
- en: '![](Classification_Regression.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](Classification_Regression.png)'
- en: Examples of Unsupervised Learning
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习示例
- en: '* * *'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Clustering: You ask the computer to separate similar data on clusters, this
    is essential in research and science.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚类：你让计算机将相似的数据分开成簇，这在研究和科学中至关重要。
- en: 'High Dimension Visualisation: Use the computer to help us visualise high dimension
    data.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高维可视化：利用计算机帮助我们可视化高维数据。
- en: 'Generative Models: After a model capture the probability distribution of your
    input data, it will be able to generate more data. This is very useful to make
    your classifier more robust.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成模型：当一个模型捕获了输入数据的概率分布后，它就能够生成更多的数据。这对于使你的分类器更加稳健非常有用。
- en: '![](TSNE.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](TSNE.png)'
- en: '![](GenerativeModel.PNG)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](GenerativeModel.PNG)'
- en: Features
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征
- en: '* * *'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Imagine the following problem, you are working on a system that should classify
    if a tumour is benign or malign, at a first moment the only information that you
    have to decide is the tumour size. We can see the your training data distribution
    bellow. Observe that the characteristic (or feature) tumour size does not seems
    to be alone a good indicator to decide if the tumour is malignant or benign.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下以下问题，你正在处理一个系统，应该对肿瘤是良性还是恶性进行分类，在最初的时候，你决定的唯一信息是肿瘤的大小。我们可以看到下面的训练数据分布。注意，特征（或特征）肿瘤大小似乎不是一个单独的良性或恶性肿瘤的良好指标。
- en: '![](Features1.PNG)'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_IMG
  zh: '![](Features1.PNG)'
- en: Now consider that we add one more feature to the problem (Age).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑我们向问题中添加一个特征（年龄）。
- en: '![](Features2.PNG)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](Features2.PNG)'
- en: The intuition is that with more features that are relevant to the problem that
    you want to classify, you will make your system more robust. Complex systems like
    this one could have up to thousand of features. One question that you may ask
    is how can I determine the features that are relevant to my problem. Also which
    algorithm to use best to tackle infinite amount of features, for example Support
    Vector machines have mathematical tricks that allow a very large number of features.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 直觉是，通过增加与你想要分类的问题相关的更多特征，你将使你的系统更加稳健。像这样的复杂系统可能有上千个特征。你可能会问的一个问题是，我如何确定与我的问题相关的特征。还有哪种算法最适合处理无限数量的特征，例如支持向量机有数学技巧允许处理非常大量的特征。
- en: Training
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: '* * *'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The idea is to give a set of inputs and it's expected outputs, so after training
    we will have a model (hypothesis) that will then map new data to one of the categories
    trained.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 思路是提供一组输入及其预期输出，因此训练后我们将得到一个模型（假设），然后将新数据映射到训练的类别之一。
- en: '![](Workflow1.PNG)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](Workflow1.PNG)'
- en: 'Ex: Imagine that you give a set of images and the following categories, duck
    or not duck, the idea is that after training you can get an image of a duck from
    internet and the model should say "duck"'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：想象一下，你提供一组图像和以下类别，鸭子或非鸭子，想法是在训练后，你可以从互联网上获取一幅鸭子的图像，模型应该说“鸭子”。
- en: '![](DuckNoDuck.PNG)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](DuckNoDuck.PNG)'
- en: Bag of tricks
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技巧包
- en: There are a lot of different machine learning algorithms, on this book we will
    concentrate more on neural networks, but there is no one single best algorithm
    it all depends on the problem that you need to solve, the amount of data available.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多不同的机器学习算法，在本书中我们将更专注于神经网络，但没有一个单一最佳算法，一切取决于你需要解决的问题，可用的数据量。
- en: '![](CompareAlgos.png)![](ListAlgos.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](CompareAlgos.png)![](ListAlgos.png)'
- en: The Basic Recipe
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本配方
- en: This is the super simple recipe (maybe cover 50%), we will explain the “how”
    later but this gives some hint on how to think when dealing with a machine learning
    problem.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是超级简单的配方（可能覆盖50%），我们稍后会解释“如何”，但这给出了在处理机器学习问题时如何思考的一些提示。
- en: First check if your model works well on the training data, and if not make the
    model more complex (Deeper, or more neurons)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先检查你的模型在训练数据上表现如何，如果不好，让模型更复杂（更深或更多神经元）。
- en: If yes then test on the “test” data, if not you overfit, and the most reliable
    way to cure overfit is to get more data (Putting the test data on the train data
    does not count)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是，则在“测试”数据上进行测试，如果不是，你过拟合了，治愈过拟合的最可靠方法是获得更多数据（将测试数据放入训练数据中不算）
- en: By the way the biggest public image dataset (imagenet) is not big enough to
    the 1000 classes imagenet competition
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，最大的公共图像数据集（imagenet）对于1000类imagenet竞赛来说还不够大
- en: '![](BasicRecipe.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](BasicRecipe.png)'
- en: Next Chapter
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: On the next chapter we will learn the basics of Linear Algebra needed on artificial
    intelligence.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习人工智能所需的线性代数基础知识。
- en: Linear Algebra
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性代数
- en: Introduction
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Linear Algebra is a omit important topic to understand, a lot of deep learning
    algorithms use it, so this chapter will teach the topics needed to understand
    what will come next.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数是一个非常重要的主题，很多深度学习算法都在使用它，因此本章将教授理解接下来内容所需的主题。
- en: Scalars, Vectors and Matrices
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标量、向量和矩阵
- en: '* * *'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Scalars: A single number'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标量：一个单一的数字
- en: 'Vector: Array of numbers, where each element is identified by an single index'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量：一组数字的数组，其中每个元素由单个索引标识
- en: 'Matrix: Is a 2D array of numbers, bellow we have a (2-row)X(3-col) matrix.
    On matrix a single element is identified by two indexes instead of one'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵：是一个数字的2D数组，下面是一个（2行）X（3列）矩阵。在矩阵中，一个单独的元素由两个索引而不是一个索引标识。
- en: '![](scalar-vector-matrix.gif)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](scalar-vector-matrix.gif)'
- en: '![](enter-the-matrix-10-638.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](enter-the-matrix-10-638.jpg)'
- en: Here we show how to create them on matlab and python(numpy)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们展示如何在matlab和python（numpy）中创建它们
- en: '![](MatlabSimpleMatrix.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](MatlabSimpleMatrix.png)'
- en: '![](PythonSimpleMatrix.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](PythonSimpleMatrix.png)'
- en: Matrix Operations
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵运算
- en: Here we will show the important operations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们将展示重要的操作。
- en: Transpose
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转置
- en: '* * *'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you have an image(2d matrix) and multiply with a rotation matrix, you will
    have a rotated image. Now if you multiply this rotated image with the transpose
    of the rotation matrix, the image will be "un-rotated"
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一幅图像（2D矩阵）并与一个旋转矩阵相乘，你将得到一个旋转后的图像。现在如果你将这个旋转后的图像与旋转矩阵的转置相乘，图像将被“取消旋转”。
- en: Basically transpose a matrix is to swap it's rows and cols. Or rotate the matrix
    around it's main diagonal.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，转置一个矩阵是交换它的行和列。或者围绕其主对角线旋转矩阵。
- en: '![](MatrixTranspose.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](MatrixTranspose.jpg)'
- en: '![](TransposeAnim.gif)![](Transpose2.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](TransposeAnim.gif)![](Transpose2.png)'
- en: Addition/Subtraction
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加法/减法
- en: '* * *'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Basically we add 2 matrices by adding each element with the other. Both matrices
    need to have same dimension
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们通过将每个元素与另一个元素相加来添加2个矩阵。两个矩阵需要具有相同的维度。
- en: '![](matrix-addition.gif)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](matrix-addition.gif)'
- en: '![](matrix-subtraction.gif)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](matrix-subtraction.gif)'
- en: Multiply by scalar
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 乘以标量
- en: '* * *'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Multiply all elements of the matrix by a scalar
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 将矩阵的所有元素乘以一个标量
- en: '![](matrix-multiply-constant.gif)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](matrix-multiply-constant.gif)'
- en: Matrix Multiplication
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 矩阵乘法
- en: '* * *'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The matrix product of an n×m matrix with an m×ℓ matrix is an n×ℓ matrix. The
    (i,j) entry of the matrix product AB is the dot product of the ith row of A with
    the jth column of B.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: n×m 矩阵与 m×ℓ 矩阵的矩阵积是一个 n×ℓ 矩阵。矩阵积 AB 的（i，j）条目是矩阵 A 的第 i 行与矩阵 B 的第 j 列的点积。
- en: The number of columns on the first matrix must match the number of rows on the
    second matrix. The result will be another matrix or a scalar with dimensions defined
    by the rows of the first matrix and columns of the second matrix.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个矩阵的列数必须与第二个矩阵的行数匹配。结果将是另一个矩阵或由第一个矩阵的行和第二个矩阵的列定义的标量。
- en: '![](MatrixMultiplication_Check.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](MatrixMultiplication_Check.png)'
- en: Basically the operation is to "dot product" each row of the first matrix(k)
    with each column of the second matrix(m).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，操作是将第一个矩阵（k）的每一行与第二个矩阵（m）的每一列进行“点乘”。
- en: '![](MatrixMultplyMovement.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](MatrixMultplyMovement.png)'
- en: Some examples
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一些例子
- en: '![](MatrixMultiplication_Example.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](MatrixMultiplication_Example.png)'
- en: '![](Matrix_Multiply_0.gif)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](Matrix_Multiply_0.gif)'
- en: '![](Matrix_Multiply_1.gif)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](Matrix_Multiply_1.gif)'
- en: '![](Matrix_Multiply_2.gif)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](Matrix_Multiply_2.gif)'
- en: Commutative property
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交换律
- en: Matrix multiplication is not always commutative ![](bcbe2544.png), but the dot
    product between 2 vectors is commutative, ![](b7244efc.png).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法不总是交换的 ![](bcbe2544.png)，但两个向量的点积是交换的，![](b7244efc.png)。
- en: Types of Matrix
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵的类型
- en: '* * *'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: There are some special matrices that are interesting to know.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些特殊的矩阵是有趣的。
- en: 'Identity: If you multiply a matrix B by the identity matrix you will have the
    matrix B as result, the diagonal of the identity matrix is filled with ones, all
    the rest are zeros.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单位矩阵：如果你用单位矩阵乘以一个矩阵 B，你将得到矩阵 B 作为结果，单位矩阵的对角线填满了 1，其余全部填满了 0。
- en: 'Inverse: Used on matrix division and to solve linear systems.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逆：用于矩阵除法和解线性系统。
- en: '![](matrix-identity.gif)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](matrix-identity.gif)'
- en: Tensors
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量
- en: '* * *'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Sometimes we need to organize information with more than 2 dimensions, we called
    tensor an n-dimension array.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们需要用多于 2 个维度来组织信息，我们将 n 维数组称为张量。
- en: For example an 1d tensor is a vector, a 2d tensor is a matrix, a 3d tensor is
    a 3d tensor is a cube, and a 4d tensor is an vector of cubes, a 5d tensor is a
    matrix of cubes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个 1 维张量是一个向量，一个 2 维张量是一个矩阵，一个 3 维张量是一个立方体，一个 4 维张量是一个立方体的向量，一个 5 维张量是一个立方体的矩阵。
- en: '![](Tensor_2.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](Tensor_2.png)'
- en: '![](Tensor_1.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](Tensor_1.png)'
- en: Practical example
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际例子
- en: Here we will show to use matrix multiplication to implement a linear classifier.
    Don't care now about what linear classifier does, just pay attention that we use
    linear algebra do solve it.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们将展示如何使用矩阵乘法来实现线性分类器。现在不用担心线性分类器的作用是什么，只要注意我们使用线性代数来解决它即可。
- en: '![](Linear_1.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](Linear_1.jpg)'
- en: Merging the weights and bias (bias trick) to solve the linear classification
    as a single matrix multiplication
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 将权重和偏置（偏置技巧）合并以解决线性分类问题作为单个矩阵乘法
- en: '![](BiasTrick.jpeg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](BiasTrick.jpeg)'
- en: On Matlab
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Matlab
- en: '![](MatlabLinearClassifer.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](MatlabLinearClassifer.png)'
- en: On Python
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python
- en: '![](PythonLinearClassifer.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](PythonLinearClassifer.png)'
- en: Next Chapter
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: The next chapter we will learn about Linear Classification.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习线性分类。
- en: Supervised Learning
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有监督学习
- en: Introduction
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'In this chapter we will learn about Supervised learning as well as talk a bit
    about Cost Functions and Gradient descent. Also we will learn about 2 simple algorithms:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习有监督学习，同时稍微谈一下成本函数和梯度下降。我们还将学习两个简单的算法：
- en: Linear Regression (for Regression)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归（用于回归）
- en: Logistic Regression (for Classification)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归（用于分类）
- en: The first thing to learn about supervised learning is that every sample data
    point x has an expected output or label y, in other words your training is composed
    of ![](1241931f.png) pairs.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 关于有监督学习的第一件事是，每个样本数据点 x 都有一个预期输出或标签 y，换句话说，你的训练由 ![](1241931f.png) 对组成。
- en: 'For example consider the table below:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 例如考虑下表：
- en: '| Size in feet (x) | Price (y) |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 尺寸（x） | 价格（y） |'
- en: '| --- | --- |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 2104 | 460 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 2104 | 460 |'
- en: '| 1416 | 232 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 1416 | 232 |'
- en: '| 1534 | 315 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 1534 | 315 |'
- en: '| 852 | 178 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 852 | 178 |'
- en: This table (or training set) shows the sizes of houses along with their price.
    So a house of size 2104 feet costs 460\.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表（或训练集）显示了房屋尺寸以及它们的价格。所以一个尺寸为 2104 平方英尺的房子价格是 460 美元。
- en: 'The idea is that we could use data like this to create models that can predict
    some outcome (ie: Price) from different inputs (ie: Size in feet).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 思路是我们可以使用这样的数据来创建能够从不同输入（即：尺寸）预测某种结果（即：价格）的模型。
- en: Linear Regression
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性回归
- en: '* * *'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Regression is about returning a continuous scalar number from some input. The
    model or hypothesis that we will learn will predict a value following a linear
    rule. However sometimes a linear model is not enough to capture the underlying
    nature of your data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是关于从某些输入返回连续的标量数的。我们将学习的模型或假设将按线性规则预测一个值。然而，有时一个线性模型不足以捕捉数据的潜在特性。
- en: '![](LinearRegExample.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](LinearRegExample.png)'
- en: 'Hypothesis:'
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 假设：
- en: Basically linear regression trys to create a line ![](e8e26b41.png), that fits
    the data on training, e.g.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，线性回归试图创建一条线，以适应训练数据，例如：
- en: '![](af468600.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](af468600.png)'
- en: '![](83f7d33e.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](83f7d33e.png)'
- en: The whole idea of supervised learning is that we try to learn the best parameters
    (theta in this case) from our training set.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的整个思想是，我们尝试从我们的训练集中学习最佳参数（在这种情况下是 theta）。
- en: Cost Function
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成本函数
- en: Before we talk about how to learn the parameters (also called weights) of our
    hypothesis we need to know how to evaluate if our current set of weights are already
    doing a good job. The function that does this job is called Loss or Cost function.
    Basically it will return a scalar value between 0(No error) and infinity (Really
    bad).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论如何学习假设的参数（也称为权重）之前，我们需要知道如何评估我们当前的权重是否已经做得很好。执行这项工作的函数称为损失函数或成本函数。基本上它将返回一个介于
    0（无误差）和无穷大（非常糟糕）之间的标量值。
- en: 'An example of such a function is given below:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这样一个函数的示例如下：
- en: '![](6e23d77c.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](6e23d77c.png)'
- en: where
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: 'm: Number of items in your dataset (i): i-th element of your dataset y: Label(expected
    value) in dataset'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'm: 数据集中的项数（i）：数据集中的第 i 个元素 y：数据集中的标签（期望值）'
- en: This paticular cost function is called mean-squared error loss, and is actually
    very useful for regression problems.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的成本函数称为均方误差损失，实际上对于回归问题非常有用。
- en: During training we want to minimise our loss by continually changing the theta
    parameters. Another nice feature of this paticular function is that it is a convex
    function so it is guaranteed to have no more than one minimum, which will also
    be it's global minimum. This makes it easier for us to optimise.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们希望通过不断改变 theta 参数来最小化我们的损失。这个特定函数的另一个好处是它是一个凸函数，因此保证不会有多于一个最小值，这也将是它的全局最小值。这使得我们更容易优化。
- en: 'Our task is therefor to find:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务是找到：
- en: '![](738d7cd7.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](738d7cd7.png)'
- en: Gradient descent
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度下降
- en: '* * *'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Gradient descent is a simple algorithm that will try to find the local minimum
    of a function. We use gradient descent to minimise our loss function. One important
    feature to observe on gradient descent is that it will more often than not get
    stuck into the first local minimum that it encounters. However there is no guarantee
    that this local minimum it finds is the best (global) one.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种简单的算法，它会试图找到函数的局部最小值。我们使用梯度下降来最小化我们的损失函数。梯度下降的一个重要特征是，它往往会陷入它遇到的第一个局部最小值中。然而，并不能保证它找到的这个局部最小值是最好（全局）的。
- en: '![](GradDecAlgo.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](GradDecAlgo.png)'
- en: The gradient descent needs the first derivative of the function that you want
    to minimise. So if we want to minimise some function by changing parameters, you
    need to derive this function with respect to these parameters.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降需要你想要最小化的函数的一阶导数。所以，如果我们想通过改变参数来最小化某个函数，你需要针对这些参数对这个函数进行求导。
- en: One thing to note is as this algorithm will execute on all samples in your training
    set it does not scale well for bigger datasets.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，由于此算法将在训练集中的所有样本上执行，因此对于更大的数据集来说，它不会很好地扩展。
- en: Simple example
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单的例子
- en: 'Bellow we have some simple implementation in matlab that uses gradient descent
    to minimise the following function:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个简单的在 Matlab 中使用梯度下降来最小化以下函数的实现：
- en: '![](cc7a762a.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](cc7a762a.png)'
- en: 'It''s derivative with respect to x is:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 它相对于 x 的导数是：
- en: '![](e1c43b85.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](e1c43b85.png)'
- en: 'The code to find at what point our local minimum occurs is as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 找到我们的局部最小值出现的点的代码如下所示：
- en: '[PRE0]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Gradient descent for linear regression
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性回归的梯度下降
- en: In order to use gradient descent for linear regression you need to calculate
    the derivative of it's loss (means squared error) with respect to it's parameters.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用梯度下降进行线性回归，你需要计算它的损失（均方误差）相对于它的参数的导数。
- en: 'This derivative will be:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个导数将会是：
- en: '![](5c0d652.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](5c0d652.png)'
- en: Logistic Regression
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: '* * *'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The name may sound confusing but actually Logistic Regression is simply all
    about classification. For instance consider the example below where we want to
    classify 2 classes: x''s and o''s. Now our output y will have two possible values
    [0,1].'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 名字可能听起来让人困惑，但实际上 Logistic 回归只是关于分类的一切。例如，考虑下面的例子，我们想要对 2 类进行分类：x 和 o。现在我们的输出
    y 将有两个可能的值 [0,1]。
- en: Normally we do not use Logistic Regression if we have a large number of features
    (e.g. more than 100 features).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，如果我们有大量特征（例如超过 100 个特征），我们就不使用 Logistic 回归。
- en: '![](Image%20%5b5%5d.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](Image%20%5b5%5d.png)'
- en: Hypothesis
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 假设
- en: Our hypothesis is almost the same compared to the linear regression however
    the difference is that now we use a function that will force our output to give
    ![](e640a3a9.png)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的假设与线性回归几乎相同，然而区别在于现在我们使用一个函数来强制我们的输出给出 ![](e640a3a9.png)
- en: '![](7c76275d.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](7c76275d.png)'
- en: where
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '![](f5fb1593.png) is the logistic or sigmoid function, therefore'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '![](f5fb1593.png) 是逻辑或 Sigmoid 函数，因此'
- en: '![](9f0ba3d5.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](9f0ba3d5.png)'
- en: Here the sigmoid function will convert a scalar number to some probability between
    0 and 1.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 Sigmoid 函数将一个标量数转换为介于 0 和 1 之间的概率。
- en: Cost function for classification
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类的成本函数
- en: When dealing with classification problems, we should use a different cost/loss
    function. A good candidate for classification is the cross-entropy cost function.
    By the way this function can be found by using the Maximum Likelihood estimation
    method.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 处理分类问题时，我们应该使用不同的成本/损失函数。用于分类的一个好选择是交叉熵成本函数。顺便说一句，通过使用最大似然估计方法可以找到这个函数。
- en: 'The cross-entropy cost function is:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵成本函数是：
- en: '![](a5d0adaa.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](a5d0adaa.png)'
- en: Again our objective is to find the best parameter theta that minimize this function,
    so to use gradient descent we need to calculate the derivative of this function
    with respect to theta
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们的目标是找到最小化这个函数的最佳参数 theta，因此为了使用梯度下降，我们需要计算这个函数相对于 theta 的导数
- en: '![](5c0d652.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](5c0d652.png)'
- en: One cool thing to note is that the derivative is the same as the derivative
    from linear regression.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的一个很酷的事情是，导数与线性回归的导数相同。
- en: Overfitting (Variance) and Underfitting (Bias)
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过拟合（方差）和欠拟合（偏差）
- en: The main idea of training in machine learning is to let the computer learn the
    underlying structure of the training set and not just the specific training set
    that it sees. If it does not learn the underlying structure and instead learns
    just the structure of the training samples then we say our model has overfit.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中训练的主要思想是让计算机学习训练集的潜在结构，而不仅仅是它所见到的具体训练集。如果它没有学习到潜在结构，而是只学习到了训练样本的结构，那么我们就说我们的模型过拟合了。
- en: 'We can tell overfitting has occured when our model has a very good accuracy
    on the training set (e.g.: 99.99%) but does not perform that well on the test
    set (e.g.: 60%).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的模型在训练集上有非常高的准确率（例如：99.99%），但在测试集上表现不佳（例如：60%）时，我们可以判断出现了过拟合。
- en: This basically occurs when your model is too complex in relation to the available
    data, and/or you don't have enough data to capture the underlying data pattern.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的模型过于复杂相对于可用数据时，或者你没有足够的数据来捕捉潜在的数据模式时，基本上就会发生这种情况。
- en: The opposite of this problem is called Underfitting, basically it happens when
    your model is too simple to capture the concept given in the training set.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的相反称为欠拟合，基本上是指当你的模型过于简单而无法捕捉训练集中给定的概念时发生的。
- en: 'Some graphical examples of these problems are shown below:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的一些图形示例如下：
- en: '**Left:** Underfit'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**左侧：** 欠拟合'
- en: '**Middle:** Perfect'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**中间：** 完美'
- en: '**Right:** Overfit'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**右侧：** 过拟合'
- en: '![](UnderOverFit.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](UnderOverFit.jpg)'
- en: Solving Overfitting
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决过拟合
- en: Get more data
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取更多数据
- en: Use regularisation
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则化
- en: Check other model architectures
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查其他模型架构
- en: Solving Underfitting
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决欠拟合
- en: Add more layers or more parameters
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加更多层或更多参数
- en: Check other architectures
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查其他架构
- en: Regularization
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化
- en: '* * *'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: It's a method that helps overfitting by forcing your hypothesis parameters to
    have nice small values and to force your model to use all the available parameters.
    To use regularization you just need to add an extra term to your cost/loss function
    during training. Below we have an example of the Mean squared error loss function
    with an added regularization term.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种通过强制假设参数具有良好小值并迫使模型使用所有可用参数来帮助过拟合的方法。要使用正则化，你只需在训练过程中向你的成本/损失函数中添加一个额外的项。下面我们有一个带有额外正则化项的均方误差损失函数的示例。
- en: '![](80fcd243.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](80fcd243.png)'
- en: Also the regularized version of the cross-entropy loss function
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 还有交叉熵损失函数的正则化版本
- en: '![](185df188.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](185df188.png)'
- en: This term will basically multiply by ![](41d912dc.png) all parameters ![](5a7fef68.png)
    from your hypothesis
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项基本上将通过![](41d912dc.png)将你的假设的所有参数![](5a7fef68.png)相乘。
- en: Normally we don't need to regularise the bias term of our hypothesis.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不需要对我们假设的偏差项进行正则化。
- en: During gradient descent you also need to calculate the derivative of those terms.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在梯度下降期间，您还需要计算这些项的导数。
- en: Intuition
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 直觉
- en: You can imagine that besides forcing the weights to have lower values, the regularisation
    will also spread the "concept" across more weights. One way to think about what
    happens when we regularise is shown below.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象，除了强制权重具有较低的值之外，正则化还将把“概念”分散到更多的权重上。当我们进行正则化时，可以通过以下方式来思考会发生什么。
- en: For our input x we can have 2 weight vectors w1 or w2\. When we multiply our
    input with our weight vector we will get the same output of 1 for each. However
    the weight vector w2 is a better choice of weight vector as this will look at
    more of our input x compared to w1 which only looks at one value of x.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的输入x，我们可以有2个权重向量w1或w2。当我们用我们的权重向量乘以我们的输入时，我们将得到每个输出的相同输出1。然而，权重向量w2是更好的权重向量选择，因为它将查看我们的输入x的更多内容，而w1只查看x的一个值。
- en: '![](cadca0ba.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](cadca0ba.png)'
- en: In practice this might reduce performance on our training set but will improve
    generalisation and thus performance when testing.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，这可能会降低我们训练集的性能，但会提高泛化性，从而在测试时提高性能。
- en: Non-Linear Hypothesis
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非线性假设
- en: '* * *'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Sometimes our hypothesis needs to have non-linear terms to be able to predict
    more complex classification/regression problems. We can for instance use Logistic
    Regression with quadratic terms to capture this complexity. As mentioned earlier
    this does not scale well for large number of features.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们的假设需要具有非线性项，以便能够预测更复杂的分类/回归问题。例如，我们可以使用具有二次项的逻辑回归来捕捉这种复杂性。正如前面提到的，这对于特征数量较多的情况不具备良好的可扩展性。
- en: '![](NonLinearFeatures.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](NonLinearFeatures.png)'
- en: For instance if we would like to classify a 100x100 grayscale image using logistic
    regression we would need 50 million parameters to include the quadratic terms.
    Training with this number of features will need at least 10x more images (500
    millions) to avoid overfitting. Also the computational cost will be really high.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想要使用逻辑回归对一个100x100的灰度图像进行分类，我们将需要5000万个参数来包括二次项。使用这么多特征进行训练将至少需要10倍的图像（5亿）。此外，计算成本将非常高。
- en: In the next chapters we will learn other algorithms that scale better for bigger
    number of features.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习其他更适合具有更多特征的算法。
- en: Local minimas
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局部最小值
- en: '* * *'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As we increase the number of parameters on our model our loss function will
    start to find multiple local minima. This can be a problem for training because
    the gradient descent can get stuck in one of them.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们增加模型的参数数量时，我们的损失函数将开始找到多个局部最小值。这对于训练来说可能是一个问题，因为梯度下降可能会陷入其中一个最小值中。
- en: '![](sgd_stuck.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](sgd_stuck.png)'
- en: 'Actually some recent papers also try to prove that some of the methods used
    today (ie: Deep Neural networks) the local-minima is actually really close to
    the global minima, so you don''t need to care about using a Convex loss or about
    getting stuck in a local-minima.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，一些最近的论文还试图证明今天使用的某些方法（例如：深度神经网络）的局部最小值实际上非常接近全局最小值，因此您不需要关心使用凸损失或者陷入局部最小值的问题。
- en: '![](DeeperLocalMinimas.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](DeeperLocalMinimas.jpg)'
- en: Neural Networks
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络
- en: Introduction
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Family of models that takes a very “loose” inspiration from the brain, used
    to approximate functions that depends on a large number of inputs. (Is a very
    good Pattern recognition model).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 一族模型，其灵感来源于大脑，用于近似取决于大量输入的函数。（是一个非常好的模式识别模型）。
- en: Neural networks are examples of Non-Linear hypothesis, where the model can learn
    to classify much more complex relations. Also it scale better than Logistic Regression
    for large number of features.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是非线性假设的示例，模型可以学习分类更复杂的关系。而且它对于具有大量特征的情况比逻辑回归更具可扩展性。
- en: 'It''s formed by artificial neurons, where those neurons are organised in layers.
    We have 3 types of layers:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 它由人工神经元形成，其中这些神经元被组织成层。我们有3种类型的层：
- en: Input layer
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入层
- en: Hidden layers
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏层
- en: Output layer
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出层
- en: We classify the neural networks from their number of hidden layers and how they
    connect, for instance the network above have 2 hidden layers. Also if the neural
    network has/or not loops we can classify them as Recurrent or Feed-forward neural
    networks.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从隐藏层数量以及它们的连接方式来对神经网络进行分类，例如上面的网络有2个隐藏层。此外，如果神经网络有/没有循环，我们可以将它们分类为循环或前馈神经网络。
- en: Neural networks from more than 2 hidden layers can be considered a deep neural
    network. The advantage of using more deep neural networks is that more complex
    patterns can be recognised.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 具有超过2个隐藏层的神经网络可以被认为是深度神经网络。使用更深层的神经网络的优势在于可以识别更复杂的模式。
- en: '![](neuralnetworks.png)'
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_IMG
  zh: '![](neuralnetworks.png)'
- en: Bellow we have an example of a 2 layer feed forward artificial neural network.
    Imagine that the connections between neurons are the parameters that will be learned
    during training. On this example Layer L1 will be the input layer, L2/L3 the hidden
    layer and L4 the output layer
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们有一个两层前馈人工神经网络的示例。想象一下神经元之间的连接是训练期间将要学习的参数。在这个例子中，层L1将是输入层，L2/L3是隐藏层，L4是输出层。
- en: '![](NeuralNetwork.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](NeuralNetwork.png)'
- en: Brain Differences
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大脑差异
- en: '* * *'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Now wait before you start thinking that you can just create a huge neural network
    and call strong AI, there are some few points to remember:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在你开始认为你可以创建一个巨大的神经网络并称之为强人工智能之前，请等一等，有一些要记住的要点：
- en: 'Just a list:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 列个清单：
- en: The artificial neuron fires totally different than the brain
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工神经元的激活方式与大脑完全不同
- en: A human brain has 100 billion neurons and 100 trillion connections (synapses)
    and operates on 20 watts(enough to run a dim light bulb) - in comparison the biggest
    neural network have 10 million neurons and 1 billion connections on 16,000 CPUs
    (about 3 million watts)
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类大脑有1000亿个神经元和100万亿个连接（突触），并且以20瓦的功率运行（足以点亮一个暗淡的灯泡）- 相比之下，最大的神经网络有1000万个神经元和10亿个连接，需要16000个CPU（约300万瓦）
- en: The brain is limited to 5 types of input data from the 5 senses.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大脑仅限于来自5种感官的5种类型的输入数据。
- en: Children do not learn what a cow is by reviewing 100,000 pictures labelled “cow”
    and “not cow”, but this is how machine learning works.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 孩子们并不是通过审阅10万张标有“牛”的图片和“非牛”的图片来学习什么是牛的，但这就是机器学习的工作原理。
- en: Probably we don't learn by calculating the partial derivative of each neuron
    related to our initial concept. (By the way we don't know how we learn)
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或许我们并不是通过计算与我们最初概念相关的每个神经元的偏导数来学习。（顺便说一句，我们不知道我们是如何学习的）
- en: Real Neuron
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 真实神经元
- en: '![](neuron.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](neuron.png)'
- en: Artificial Neuron
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工神经元
- en: '* * *'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](neuron_model.jpeg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](neuron_model.jpeg)'
- en: The single artificial neuron will do a dot product between w and x, then add
    a bias, the result is passed to an activation function that will add some non-linearity.
    The neural network will be formed by those artificial neurons.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 单个人工神经元将对w和x进行点积，然后添加一个偏置，结果传递给一个激活函数，该函数将添加一些非线性。神经网络将由这些人工神经元组成。
- en: The non-linearity will allow different variations of an object of the same class
    to be learned separately. Which is a different behaviour compared to the linear
    classifier that tries to learn all different variations of the same class on a
    single set of weights. More neurons and more layers is always better but it will
    need more data to train.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性将允许学习同一类别的不同变化的不同版本。这与试图在单一权重集上学习同一类别的所有不同变化的线性分类器的行为不同。更多的神经元和更多的层总是更好的，但需要更多的数据来训练。
- en: Each layer learn a concept, from it's previous layer. So it's better to have
    deeper neural networks than a wide one. (Took 20 years to discover this)
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层从它的前一层学习一个概念。因此，拥有更深层的神经网络比拥有更宽的神经网络更好。（花了20年的时间才发现这一点）
- en: Activation Functions
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活函数
- en: '* * *'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: After the neuron do the dot product between it's inputs and weights, it also
    apply a non-linearity on this result. This non-linear function is called Activation
    Function.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经元对其输入和权重执行点积后，它还会在这个结果上应用一个非线性。这个非线性函数称为激活函数。
- en: On the past the popular choice for activation functions were the sigmoid and
    tanh. Recently it was observed the ReLU layers has better response for deep neural
    networks, due to a problem called vanishing gradient. So you can consider using
    only ReLU neurons.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，激活函数的流行选择是Sigmoid和tanh。最近观察到ReLU层对深度神经网络有更好的响应，这是由于一个称为梯度消失的问题。因此，您可以考虑只使用ReLU神经元。
- en: '![](ffa45100.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](ffa45100.png)'
- en: '![](ActivationFunctions.PNG)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](ActivationFunctions.PNG)'
- en: Example of simple network
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单网络的示例
- en: Consider the Neural network bellow with 1 hidden layer, 3 input neurons, 3 hidden
    neurons and one output neuron.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑下面具有 1 个隐藏层、3 个输入神经元、3 个隐藏神经元和一个输出神经元的神经网络。
- en: '![](SimpleANN.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](SimpleANN.png)'
- en: We can define all the operation that this network will do as follows.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义该网络将执行的所有操作如下。
- en: '![](2c729b18.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](2c729b18.png)'
- en: Here ![](9d409d72.png) means the activation(output) of the first neuron of layer
    2 (hidden layer on this case). The first layer, (input layer) can be considered
    as ![](3d270619.png) and it's values are just the input vector.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 ![](9d409d72.png) 表示第 2 层（在本例中为隐藏层）第一个神经元的激活（输出）。第一层（输入层）可以被视为 ![](3d270619.png)，它的值只是输入向量。
- en: 'Consider the connections between each layer as a matrix of parameters. Consider
    those matrices as the connections between layers. On this case we have to matrices:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 将每一层之间的连接视为参数矩阵。将这些矩阵视为层之间的连接。在这种情况下，我们有两个矩阵：
- en: '![](afc31031.png): Map the layer 1 to layer 2 (Input and Hidden layer)'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![](afc31031.png)：将第 1 层映射到第 2 层（输入层和隐藏层）'
- en: '![](e286ad01.png): Map layer 2 to to layer 2 (Hidden and output layer)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![](e286ad01.png)：将第 2 层映射到第 2 层（隐藏层和输出层）'
- en: 'Also you consider the dimensions of ![](afc31031.png) as [number of neurons
    on layer 2] x [Number of neurons layer 1 +1]. In other words:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 还要考虑 ![](afc31031.png) 的维度，作为 [第 2 层的神经元数量] x [第 1 层的神经元数量 + 1]。换句话说：
- en: '![](2fa47a1a.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](2fa47a1a.png)'
- en: 'Where:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![](a72adc56.png): Number of neurons on next layer'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '![](a72adc56.png)：下一层的神经元数量'
- en: '![](e8716ce7.png): Number of neurons on the current layer + 1'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '![](e8716ce7.png)：当前层的神经元数量 + 1'
- en: Notice that this is only true if we consider to add the bias as part of our
    weight matrices, this could depend from implementation to implementation.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，只有在我们考虑将偏置添加为权重矩阵的一部分时，这才成立，这可能因实现而异。
- en: Why is better than Logistic Regression
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么比 logistic 回归更好
- en: '* * *'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Consider that the neural network as a cascaded chain of logistic regression,
    where the input of each layer is the output of the previous one. Another way to
    think on this is that each layer learn a concept with the output of the previous
    layer.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 将神经网络视为一系列级联的 logistic 回归，其中每一层的输入是前一层的输出。另一种思考方式是，每一层学习了前一层输出的一个概念。
- en: '![](DeepConcept.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](DeepConcept.png)'
- en: This is nice because the layer does not need to learn the whole concept at once,
    but actually build a chain of features that build that knowledge.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，因为层不需要一次性学习整个概念，而实际上是构建了一个构建该知识的特征链。
- en: Vectorized Implementation
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量化实现
- en: '* * *'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: You can calculate the output of the whole layer ![](af123120.png)as a matrix
    multiplication followed by a element-wise activation function. This has the advantage
    of performance, considering that you are using tools like Matlab, Numpy, or also
    if you are implementing on hardware.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以计算整个层的输出 ![](af123120.png) 作为矩阵乘法，然后是逐元素激活函数。这具有性能上的优势，考虑到你在使用像 Matlab、Numpy
    这样的工具，或者如果你正在硬件上实现。
- en: The mechanism of calculating the output of each layer with the output of the
    previous layer, from the beginning(input layer) to it's end(output layer) is called
    forward propagation.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 计算从开始（输入层）到结束（输出层）的每一层的输出与前一层的输出的机制被称为前向传播。
- en: '![](ForwardPropagation.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](ForwardPropagation.png)'
- en: 'To better understanding let''s break the activation of some layer as following:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解，让我们将某些层的激活拆分如下：
- en: '![](b1457857.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![](b1457857.png)'
- en: So using this formulas you can calculate the activation of each layer.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用这些公式，你可以计算每一层的激活。
- en: Multiple class problems
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类问题
- en: '* * *'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On the multi-class classification problem you need to allocate one neuron for
    each class, than during training you provide a one-hot vector for each one of
    your desired class. This is somehow easier than the logistic regression one-vs-all
    training.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类别分类问题中，你需要为每个类别分配一个神经元，然后在训练过程中，为每个期望的类别提供一个独热向量。这在某种程度上比 logistic 回归的一对一训练更容易。
- en: '![](MultiClassProb.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![](MultiClassProb.png)'
- en: Cost function (Classification)
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本函数（分类）
- en: '* * *'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The cost function of neural networks, it''s a little more complicated than
    the logistic regression. So for classification on Neural networks we should use:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的成本函数，比 logistic 回归要复杂一些。因此，对于神经网络的分类，我们应该使用：
- en: '![](6a7b9836.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](6a7b9836.png)'
- en: 'Where:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: 'L: Number of layers'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L：层数
- en: 'm: Dataset size'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: m：数据集大小
- en: 'K: Number of classes'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K：类别数
- en: '![](bd75c77e.png): Number of neurons (not counting bias) from layer l'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](bd75c77e.png)：第 l 层的神经元数量（不包括偏置）'
- en: 'During training we need to calculate the partial derivative of this cost function
    with respect to each parameter on your neural network. Actually what we need to
    compute is:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练期间，我们需要计算神经网络上每个参数的此成本函数的偏导数。实际上，我们需要计算的是：
- en: The loss itself (Forward-propagation)
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失本身（前向传播）
- en: The derivative of the loss w.r.t each parameter (Back-propagation)
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失相对于每个参数的导数（反向传播）
- en: Backpropagation
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播
- en: '* * *'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Backpropagation it's an efficient algorithm that helps you calculate the derivative
    of the cost function with respect to each parameter of the neural network. The
    name backpropagation comes from the fact that now we start calculating errors
    from all your neurons from the output layer to the input layer direction. After
    those errors are calculated we simply multiply them by the activation calculated
    during forward propagation.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播是一种有效的算法，可以帮助您计算神经网络每个参数的成本函数的导数。反向传播这个名字来自于现在我们从输出层向输入层方向开始计算所有神经元的错误。这些错误计算完成后，我们只需将它们与前向传播期间计算的激活相乘即可。
- en: '![](BackPropNeuralNet.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![](BackPropNeuralNet.png)'
- en: Doing the backpropagation (Vectorized)
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进行反向传播（矢量化）
- en: As mentioned the backpropagation will flow on the reverse order iterating from
    the last layer. So starting from the output layer we calculate the output layer
    error.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，反向传播将按照相反的顺序流动，从最后一层开始迭代。所以从输出层开始，我们计算输出层的错误。
- en: The "error values" for the last layer are simply the differences of our actual
    results in the last layer and the correct outputs in y.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一层的“误差值”简单地是最后一层中我们的实际结果与 y 中的正确输出的差异。
- en: '![](c4959933.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](c4959933.png)'
- en: Where
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '![](72faac05.png): Expected output from training'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](72faac05.png)：训练的期望输出'
- en: '![](7ace1459.png): Network output/activation of the last L layer'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](7ace1459.png)：网络输出/最后 L 层的激活'
- en: For all other layers (layers before the last layer until the input)
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有其他层（从最后一层之前的层到输入层）
- en: '![](4c4e4cd5.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![](4c4e4cd5.png)'
- en: Where
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '![](70fbe2a7.png): Error of layer l'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](70fbe2a7.png)：第 l 层的错误'
- en: '![](7b18f6d2.png): Derivative of activation function'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](7b18f6d2.png)：激活函数的导数'
- en: '![](7893cf17.png): Pre-activation of layer l'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](7893cf17.png)：第 l 层的预激活'
- en: '.*: Element wise multiplication'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: .*：逐元素相乘
- en: 'After all errors(delta) are calculated we need to actually calculate the derivative
    of the loss, which is the product of the error times the activation of each respective
    neuron:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 计算完所有误差（delta）之后，我们需要实际计算损失的导数，即每个相应神经元的误差与激活的乘积：
- en: '![](9c286de2.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![](9c286de2.png)'
- en: Now we're ignoring the regularisation term.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们忽略正则化项。
- en: Complete algorithm
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整算法
- en: Bellow we describe the whole procedure in pseudo-code
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们用伪代码描述整个过程
- en: '![](AlgoBackProp.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![](AlgoBackProp.png)'
- en: Gradient Checking
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度检查
- en: '* * *'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'In order to verify if your backpropagation code is right we can estimate the
    gradient, using other algorithm, unfortunately we cannot use this algorithm in
    practice because it will make the training slow, but we can use to compare it''s
    results with the backpropagation. Basically we will calculate numerically the
    derivative of the loss with respect to each parameter by calculating the loss
    and adding a small perturbation (ie: ![](2af86d7a.png)) to each parameter one
    at a time.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证您的反向传播代码是否正确，我们可以使用其他算法来估计梯度，不幸的是，我们不能在实践中使用此算法，因为它会使训练变慢，但我们可以用它来比较其结果与反向传播。基本上，我们将通过分别对每个参数添加一个小扰动（即：![](2af86d7a.png)）来数值计算损失相对于每个参数的导数。
- en: '![](GradientCheck.jpg)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](GradientCheck.jpg)'
- en: '![](1151abb.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![](1151abb.png)'
- en: Actually you will compare this gradient with the output of the backpropagation
    ![](d94e9f68.png).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，您将比较此梯度与反向传播的输出！[](d94e9f68.png)。
- en: Again this will be really slow because we need to calculate the loss again with
    this small perturbation twice for each parameter.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 再次说明，这将非常缓慢，因为我们需要为每个参数计算两次带有此小扰动的损失。
- en: For example suppose that you have 3 parameters ![](75a959e9.png)
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您有 3 个参数！[](75a959e9.png)
- en: '![](c1fe604b.png)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![](c1fe604b.png)'
- en: '![](765311e0.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![](765311e0.png)'
- en: '![](62de42ed.png)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![](62de42ed.png)'
- en: Weights initialization
  id: totrans-349
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 权重初始化
- en: '* * *'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The way that you initialize your network parameters is also important, you cannot
    for instance initialize all your weights to zero, normally you want to initialize
    them with small random values on the range ![](3ab3a524.png) but somehow also
    take into account that you don't want to have some sort of symmetry of the random
    values between layers.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化网络参数的方式也很重要，例如你不能将所有权重初始化为零，通常你希望将它们初始化为在范围 ![](3ab3a524.png) 内的小随机值，但同时也要考虑到你不希望在层之间具有某种随机值的对称性。
- en: '[PRE1]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: What we can see from the code above is that we create random numbers independently
    for each layer, and all of them in between the range ![](3ab3a524.png)
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的代码中可以看出，我们独立为每一层创建随机数，而且它们都在范围内 ![](3ab3a524.png)
- en: Training steps
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练步骤
- en: '* * *'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now just to list the steps required to train a neural network. Here we mention
    the term epoch which means a complete pass intro all elements of your training
    set. Actually you repeat your training set over and over because the weights don't
    completely learn a concept in a single epoch.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在只需列出训练神经网络所需的步骤。在这里我们提到时期这个术语，它意味着对你的训练集中的所有元素进行完整的遍历。实际上，你一遍又一遍地重复你的训练集，因为权重不会在一个时期内完全学会一个概念。
- en: Initialize weights randomly
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机初始化权重
- en: For each epoch
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个时期
- en: Do the forward propagation
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行正向传播
- en: Calculate loss
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算损失
- en: Do the backward propagation
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行反向传播
- en: Update weights with Gradient descent (Optionally use gradient checking to verify
    backpropagation)
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用梯度下降更新权重（可选使用梯度检查来验证反向传播）
- en: Go to step 2 until you finish all epochs
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到步骤2，直到完成所有时期
- en: Training/Validation/Test data
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练/验证/测试数据
- en: '* * *'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Some good practices to create your dataset for training your hypothesis models
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 一些创建用于训练假设模型的数据集的良好实践
- en: Collect as many data as possible
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集尽可能多的数据
- en: Merge/Shuffle all this data
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并/洗牌所有这些数据
- en: Divide this dataset into train(60%)/validation(20%)/test(20%) set
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这个数据集分成训练（60%）/验证（20%）/测试（20%）集
- en: Avoid having test from a different distribution of your train/validation
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 避免测试来自不同分布的训练/验证
- en: Use the validation set to tune your model (Number of layers/neurons)
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用验证集来调整你的模型（层数/神经元数量）
- en: Check overall performance with the test set
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试集检查整体性能
- en: When we say to use the validation set it means that we're going to change parameters
    of our model and check which one get better results on this validation set, don't
    touch your training set. If you are having bad results on your test set consider
    getting more data, and verify if your train/test/val come from the same distribution.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说要使用验证集时，意味着我们将更改模型的参数，并检查哪一个在这个验证集上获得更好的结果，不要触摸你的训练集。如果你在测试集上的结果不好，请考虑获取更多数据，并验证你的训练/测试/验证是否来自相同的分布。
- en: Effects of deep neural networks
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度神经网络的影响
- en: '* * *'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As mentioned earlier having deeper and bigger neural networks is always better
    in terms of recognition performance, but some problems also arise with more complex
    models.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，拥有更深层次和更大规模的神经网络在识别性能方面总是更好的，但是更复杂的模型也会带来一些问题。
- en: Deeper and more complex neural networks, need more data to train (10x number
    of parameters)
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更深层次和更复杂的神经网络，需要更多数据来训练（参数数量的10倍）
- en: Over-fit can become a problem so do regularization (Dropout, L2 regularization)
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过拟合可能会成为问题，因此进行正则化（Dropout、L2正则化）
- en: Prediction time will increase.
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测时间将会增加。
- en: Neural networks as computation graphs
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络作为计算图
- en: '* * *'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In order to calculate the back-propagation, it's easier if you start representing
    your hypothesis as computation graphs. Also in next chapters we use different
    types of layers working together, so to simplify development consider the neural
    networks as computation graphs. The idea is that if you provide for each node
    of your graph the forward/backward implementation, the back propagation becomes
    much more easier.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算反向传播，如果你开始将你的假设表示为计算图，那会更容易。另外，在接下来的章节中，我们将使用不同类型的层一起工作，所以为了简化开发，请将神经网络视为计算图。这个想法是，如果你为你的图的每个节点提供正向/反向实现，那么反向传播就会变得更容易。
- en: '![](NeuralNetworkGraph.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![](NeuralNetworkGraph.png)'
- en: Linear Classification
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性分类
- en: Introduction
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: A linear classifier does classification decision based on the value of a linear
    combination of the characteristics. Imagine that the linear classifier will merge
    into it's weights all the characteristics that define a particular class. (Like
    merge all samples of the class cars together)
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 线性分类器根据特征的线性组合的值做出分类决策。想象一下，线性分类器将在其权重中合并定义特定类的所有特征。（就像将类别为汽车的所有样本合并在一起）
- en: This type of classifier works better when the problem is linear separable.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 当问题是线性可分时，这种类型的分类器效果更好。
- en: '![](linear_vs_nonlinear_problems.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![](linear_vs_nonlinear_problems.png)'
- en: '![](bffbeee2.png)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![](bffbeee2.png)'
- en: '![](pixelspaceLinear.jpeg)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![](pixelspaceLinear.jpeg)'
- en: The weight matrix will have one row for every class that needs to be classified,
    and one column for ever element(feature) of x.On the picture above each line will
    be represented by a row in our weight matrix.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 权重矩阵将为需要分类的每个类别具有一行，并且对于 x 的每个元素（特征）都具有一列。在上面的图片中，每一行都将由我们的权重矩阵中的一行表示。
- en: Weight and Bias Effect
  id: totrans-393
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 权重和偏置的影响
- en: '* * *'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The effect of changing the weight will change the line angle, while changing
    the bias, will move the line left/right
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 改变权重的效果将改变线的角度，而改变偏置将使线左右移动
- en: Parametric Approach
  id: totrans-396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参数化方法
- en: '* * *'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](ParametricModel.jpg)'
  id: totrans-398
  prefs:
  - PREF_H3
  type: TYPE_IMG
  zh: '![](ParametricModel.jpg)'
- en: 'The idea is that out hypothesis/model has parameters, that will aid the mapping
    between the input vector to a specific class score. The parametric model has two
    important components:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 思想是我们的假设/模型具有参数，这些参数将有助于将输入向量映射到特定类得分。参数模型有两个重要组成部分：
- en: 'Score Function: Is a function ![](647cc9bd.png) that will map our raw input
    vector to a score vector'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评分函数：是一个函数 ![](647cc9bd.png)，将我们的原始输入向量映射到一个评分向量
- en: 'Loss Function: Quantifies how well our current set of weights maps some input
    x to a expected output y, the loss function is used during training time.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失函数：衡量我们当前权重集合将一些输入 x 映射到期望输出 y 的程度，损失函数在训练时使用。
- en: On this approach, the training phase will find us a set of parameters that will
    change the hypothesis/model to map some input, to some of the output class.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，训练阶段将为我们找到一组参数，这些参数将改变假设/模型以将某些输入映射到某些输出类。
- en: During the training phase, which consist as a optimisation problem, the weights
    (W) and bias (b) are the only thing that we can change.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练阶段，即优化问题，权重 (W) 和偏置 (b) 是我们唯一可以改变的东西。
- en: '![](Linear_Classification.png)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![](Linear_Classification.png)'
- en: 'Now some topics that are important on the diagram above:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 现在上面图表中一些重要的主题：
- en: The input image x is stretched to a single dimension vector, this loose spatial
    information
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入图像 x 被拉伸为单维向量，这会丢失空间信息
- en: The weight matrix will have one column for every element on the input
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 权重矩阵将为每个输入元素具有一列
- en: The weight matrix will have one row for every element of the output (on this
    case 3 labels)
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 权重矩阵将为每个输出元素（在本例中为 3 个标签）的每个元素都有一行。
- en: The bias will have one row for every element of the output (on this case 3 labels)
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 偏置将为每个输出元素（在本例中为 3 个标签）的每个元素都有一行。
- en: The loss will receive the current scores and the expected output for it's current
    input X
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 损失函数将接收当前分数和其当前输入 X 的期望输出
- en: 'Consider each row of W a kind of pattern match for a specified class. The score
    for each class is calculated by doing a inner product between the input vector
    X and the specific row for that class. Ex:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 将 W 的每一行视为针对指定类的一种模式匹配。每个类别的分数通过对输入向量 X 和该类别的特定行进行内积计算得出。例如：
- en: '![](3bab8058.png)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![](3bab8058.png)'
- en: Example on Matlab
  id: totrans-413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Matlab 上的示例
- en: '* * *'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](calc_scores_matlab.PNG)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![](calc_scores_matlab.PNG)'
- en: The image bellow reshape back the weights to an image, we can see by this image
    that the training try to compress on each row of W all the variants of the same
    class. (Check the horse with 2 heads)
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像将权重重塑回图像，我们可以通过这个图像看到训练尝试将同一类的所有变体压缩在 W 的每一行上。（查看有 2 个头的马）
- en: '![](LinearTemplate.png)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
  zh: '![](LinearTemplate.png)'
- en: Bias trick
  id: totrans-418
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏置技巧
- en: '* * *'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Some learning libraries implementations, does a trick to consider the bias as
    part of the weight matrix, the advantage of this approach is that we can solve
    the linear classification with a single matrix multiplication.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 一些学习库的实现会做一个技巧来将偏置视为权重矩阵的一部分，这种方法的优势在于我们可以通过单次矩阵乘法解决线性分类问题。
- en: '![](8124c541.png)'
  id: totrans-421
  prefs: []
  type: TYPE_IMG
  zh: '![](8124c541.png)'
- en: '![](Bias_Trick.jpg)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![](Bias_Trick.jpg)'
- en: Basically you add an extra row at the end of the input vector, and concatenate
    a column on the W matrix.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，你需要在输入向量的末尾添加一行，并在 W 矩阵上连接一列。
- en: Input and Features
  id: totrans-424
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入和特征
- en: '* * *'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The input vector sometimes called feature vector, is your input data that is
    sent to the classifier. As the linear classifier does not handle non-linear problems,
    it is the responsibility of the engineer, process this data and present it in
    a form that is separable to the classifier.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 输入向量有时被称为特征向量，是发送到分类器的输入数据。由于线性分类器不能处理非线性问题，因此工程师的责任是处理这些数据并以分类器可分离的形式呈现它。
- en: The best case scenario is that you have a large number of features, and each
    of them has a high correlation to the desired output and low correlation between
    thems
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的情况是你有很多特征，每个特征与所需输出具有高相关性，而它们之间的相关性很低
- en: Loss Function
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失函数
- en: Introduction
  id: totrans-429
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As mention earlier the Loss/Cost functions are mathematical functions that will
    answer how well your classifier is doing it's job with the current set of parameters
    (Weights and Bias). One important step on supervised learning is the choice of
    the right loss function for the job/task.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，损失/成本函数是数学函数，它将回答你的分类器在当前参数（权重和偏差）下工作得有多好。在监督学习中，选择正确的损失函数是至关重要的一步。
- en: Model Optimization
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型优化
- en: Model Optimization
  id: totrans-433
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型优化
- en: Introduction
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Machine learning models learn by updating it's parameters (weights and biases)
    towards the direction of the correct classification.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型通过更新其参数（权重和偏差）来学习，朝着正确分类的方向。
- en: Basic structure of a learning model
  id: totrans-437
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习模型的基本结构
- en: '* * *'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On the picture bellow we will show the basic blocks of a machine learning model
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图片中，我们将展示机器学习模型的基本组成部分
- en: '![](MachineLearningModel.png)'
  id: totrans-440
  prefs: []
  type: TYPE_IMG
  zh: '![](MachineLearningModel.png)'
- en: On this picture we can detect the following components
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 在这张图片上，我们可以发现以下组件
- en: 'Training dataset: Basically a high speed disk containing your training data'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练数据集：基本上是一个包含您的训练数据的高速磁盘
- en: 'Batch of samples: A list of pairs (X,Y), consisting on inputs, expected outputs,
    for example X can be a image and Y the label "cat"'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 样本批次：一个由（X，Y）对组成的列表，包括输入和期望输出，例如X可以是一张图片，Y是标签“猫”
- en: 'Parameters: Set of parameters used by your model layers, to map X to Y'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数：由您的模型层使用的一组参数，将X映射到Y
- en: 'Model: Set of computing layers that transform an input X and weights W, into
    a score (probable Y)'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型：一组计算层，将输入X和权重W转换为一个得分（可能的Y）
- en: 'Loss function: Responsible to say how far our score is from the ideal response
    Y, the output of the loss function is a scalar. Another way is also to consider
    that the loss function say how bad is your current set of parameters W.'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 损失函数：负责表明我们的分数距离理想响应Y有多远，损失函数的输出是一个标量。另一种方式也是考虑损失函数表明您当前的参数W有多糟糕。
- en: What we will do?
  id: totrans-447
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们将做什么？
- en: '* * *'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Basically we need an algorithm that will change our weight and biases, in order
    to minimize our loss function.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们需要一种算法来改变我们的权重和偏差，以便最小化我们的损失函数。
- en: The Loss function
  id: totrans-450
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 损失函数
- en: '* * *'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: You can imagine the loss function here as a place with some mountains, and your
    objective is to find it's vale (lowest) place. Your only instrument is the gadget
    that returns your altitude (loss). You need to find out which direction to take.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象这里的损失函数就像一个有些山的地方，你的目标是找到它的低谷（最低）处。你唯一的工具是返回你的海拔高度（损失）的小玩意儿。你需要找出应该走哪个方向。
- en: '![](LossAlps.png)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![](LossAlps.png)'
- en: 'Here we can also observe two things:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们还可以观察到两件事：
- en: You have more than one value (Local minima)
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你有超过一个值（局部最小值）
- en: Depending where you landed you probably find one instead of the other (Importance
    of weight initialization)
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取决于你降落在哪里，你可能会找到一个而不是另一个（权重初始化的重要性）
- en: Which direction to take (Gradient descent)
  id: totrans-457
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要采取哪个方向（梯度下降）
- en: '* * *'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We can use calculus to discover which direction to take, for instance if we
    follow the derivative of the loss function, we can guarantee that we always go
    down. This is done just by subtracting the current set of weights by derivative
    of the loss function evaluated at that point.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用微积分来发现应该采取的方向，例如，如果我们遵循损失函数的导数，我们可以保证我们总是朝着下降的方向前进。这只需将当前的权重集减去该点处的损失函数的导数即可完成。
- en: '![](ddc9caec.png)'
  id: totrans-460
  prefs: []
  type: TYPE_IMG
  zh: '![](ddc9caec.png)'
- en: On multiple dimensions we have a vector of partial derivatives, which we call
    gradient.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个维度上，我们有一个偏导数的向量，我们称之为梯度。
- en: 'Observe that we multiply the gradient by a factor ![](c9b9fa39.png) (step-size,
    learning-rate), that is normally a small value ex: 0.001'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将梯度乘以一个因子![](c9b9fa39.png)（步长，学习速率），通常是一个小值，例如：0.001
- en: Simple Example
  id: totrans-463
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单示例
- en: To illustrate the gradient descent method let's follow a simple case in 1D.
    Consider the initial weight (-1.5)
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明梯度下降方法，让我们按照一维中的一个简单情况来进行。考虑初始权重（-1.5）
- en: '![](474e08d1.png)'
  id: totrans-465
  prefs: []
  type: TYPE_IMG
  zh: '![](474e08d1.png)'
- en: '![](gradDescentAnim.gif)'
  id: totrans-466
  prefs: []
  type: TYPE_IMG
  zh: '![](gradDescentAnim.gif)'
- en: On Matlab
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Matlab 上
- en: '![](GradientDescentMatCode.png)'
  id: totrans-468
  prefs: []
  type: TYPE_IMG
  zh: '![](GradientDescentMatCode.png)'
- en: We can observe that after we use calculus do find the derivative of the loss
    function, we just needed to evaluate it with the current weight. After that we
    just take the evaluated value from the current weight.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，在使用微积分找到损失函数的导数之后，我们只需要用当前权重评估它。之后，我们只需从当前权重中取得评估值。
- en: Learning rate to big
  id: totrans-470
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习率过大
- en: '* * *'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Using a big learning rate can accelerate convergence, but could also make the
    gradient descent oscillate and diverge.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大的学习率可以加速收敛，但也可能使梯度下降振荡并发散。
- en: '![](BigGradientDescent.gif)'
  id: totrans-473
  prefs: []
  type: TYPE_IMG
  zh: '![](BigGradientDescent.gif)'
- en: Numerical Gradient
  id: totrans-474
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数值梯度
- en: '* * *'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Slow method to evaluate the gradient, but we can use it to verify if our code
    is right
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 评估梯度的慢方法，但我们可以用它来验证我们的代码是否正确
- en: Mini Batch Gradient Descent
  id: totrans-477
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小批量梯度下降
- en: '* * *'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](loss.jpeg)'
  id: totrans-479
  prefs: []
  type: TYPE_IMG
  zh: '![](loss.jpeg)'
- en: Instead of running through all the training set to calculate the loss, then
    do gradient descent, we can do in a small (batch) portions. This leads to similar
    results and compute faster. Normally the min-batch size is dependent of the GPU
    memory.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 不是运行整个训练集来计算损失，然后进行梯度下降，我们可以分成小的（批量）部分来做。这导致类似的结果并且计算更快。通常，小批量大小取决于 GPU 内存。
- en: If you analyze your loss decay over time the full-batch version is less noisy
    but much more difficult to compute.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你分析随时间衰减的损失，完全批量版本更少噪音但更难计算。
- en: If your mini-batch size goes to 1, which means you compute the gradient descent
    for each sample. On this case we have the Stochastic Gradient Descent.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的小批量大小变为 1，这意味着你为每个样本计算梯度下降。在这种情况下，我们有随机梯度下降。
- en: This is relatively less common to see because in practice due to vectorized
    code optimizations it can be computationally much more efficient to evaluate the
    gradient for 100 examples, than the gradient for one example 100 times.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 这相对较少见，因为在实践中，由于矢量化代码优化，评估 100 个示例的梯度通常比 100 次评估一个示例的梯度更加高效。
- en: Effects of learning rate on loss
  id: totrans-484
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习速率对损失的影响
- en: Actually what people do is to choose a high (but not so high) learning rate,
    then decay with time.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上人们做的是选择一个较高（但不是太高）的学习速率，然后随时间衰减。
- en: '![](learningrates.jpeg)'
  id: totrans-486
  prefs: []
  type: TYPE_IMG
  zh: '![](learningrates.jpeg)'
- en: 'Here are 2 ways to decay the learning rate with time while training:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两种训练过程中随时间衰减学习率的方法：
- en: Divide the learning rate (![](efff0667.png)) by 2 every x epochs
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 每 x 个周期将学习速率（![](efff0667.png)）减半
- en: '![](c36c0e20.png), where t is time and k is the decay parameter'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '![](c36c0e20.png)，其中 t 是时间，k 是衰减参数'
- en: '![](4480a80c.png), where t is the time and k the decay parameter'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '![](4480a80c.png)，其中 t 是时间，k 是衰减参数'
- en: Other algorithms
  id: totrans-491
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他算法
- en: 'The gradient descent is the simplest idea to do model optimization. There are
    a few other nice algorithms to try when thinking about model optimization:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是进行模型优化的最简单的方法。在考虑模型优化时，还有一些不错的算法可以尝试：
- en: Stochastic Gradient descent
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机梯度下降
- en: Stochastic Gradient descent with momentum (Very popular)
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有动量的随机梯度下降（非常流行）
- en: Nag
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nag
- en: Adagrad
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adagrad
- en: Adam (Very good because you need to take less care about learning rate)
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adam（非常好，因为你不需要太在意学习速率）
- en: rmsprop
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: rmsprop
- en: '![](OtherOptimizers.gif)'
  id: totrans-499
  prefs: []
  type: TYPE_IMG
  zh: '![](OtherOptimizers.gif)'
- en: Next Chapter
  id: totrans-500
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: Now what we need is a way to get the gradient vector of our model, next chapter
    we will talk about back-propagation.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要一种方法来获取我们模型的梯度向量，下一章我们将讨论反向传播。
- en: Backpropagation
  id: totrans-502
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向传播
- en: Back-propagation
  id: totrans-503
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向传播
- en: Introduction
  id: totrans-504
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Backpropagation is an algorithm that calculate the partial derivative of every
    node on your model (ex: Convnet, Neural network). Those partial derivatives are
    going to be used during the training phase of your model, where a loss function
    states how much far your are from the correct result. This error is propagated
    backward from the model output back to it''s first layers. The backpropagation
    is more easily implemented if you structure your model as a computational graph.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播是一种计算模型中每个节点（例如：Convnet，神经网络）的偏导数的算法。这些偏导数将在模型的训练阶段中使用，其中损失函数说明了您与正确结果相差多少。这个错误是从模型输出向后传播到它的第一层。如果您将模型结构化为计算图，则反向传播更容易实现。
- en: '![](Circuit1.png)'
  id: totrans-507
  prefs: []
  type: TYPE_IMG
  zh: '![](Circuit1.png)'
- en: The most important thing to have in mind here is how to calculate the forward
    propagation of each block and it's gradient. Actually most of the deep learning
    libraries code is about implementing those gates forward/backward code.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最重要的事情是如何计算每个块的前向传播及其梯度。实际上，大多数深度学习库的代码都是关于实现这些门的前向/后向代码。
- en: Basic blocks
  id: totrans-509
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本块
- en: Some examples of basic blocks are, add, multiply, exp, max. All we need to do
    is observe their forward and backward calculation
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 一些基本块的示例包括加法、乘法、指数、最大值。我们所需要做的就是观察它们的前向和后向计算。
- en: '* * *'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](SumGate.png)'
  id: totrans-512
  prefs: []
  type: TYPE_IMG
  zh: '![](SumGate.png)'
- en: '![](MulGate.png)'
  id: totrans-513
  prefs: []
  type: TYPE_IMG
  zh: '![](MulGate.png)'
- en: '![](MaxGate.png)'
  id: totrans-514
  prefs: []
  type: TYPE_IMG
  zh: '![](MaxGate.png)'
- en: '![](GradientBranches.png)'
  id: totrans-515
  prefs: []
  type: TYPE_IMG
  zh: '![](GradientBranches.png)'
- en: Some other derivatives
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 其他一些导数
- en: '![](2c1d1490.png)'
  id: totrans-517
  prefs: []
  type: TYPE_IMG
  zh: '![](2c1d1490.png)'
- en: Observe that we output 2 gradients because we have 2 inputs... Also observe
    that we need to save (cache) on memory the previous inputs.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们输出了 2 个梯度，因为我们有 2 个输入... 还要注意我们需要将先前的输入保存在内存中。
- en: Chain Rule
  id: totrans-519
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 链式法则
- en: '* * *'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Imagine that you have an output y, that is function of g, which is function
    of f, which is function of x. If you want to know how much g will change with
    a small change on dx (dg/dx), we use the chain rule. Chain rule is a formula for
    computing the derivative of the composition of two or more functions.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有一个输出 y，它是 g 的函数，而 g 是 f 的函数，而 f 是 x 的函数。如果你想知道 g 在 dx 上的微小变化（dg/dx），我们使用链式法则。链式法则是计算两个或更多函数组合的导数的公式。
- en: '![](ChainRule1.png)'
  id: totrans-522
  prefs: []
  type: TYPE_IMG
  zh: '![](ChainRule1.png)'
- en: The chain rule is the work horse of back-propagation, so it's important to understand
    it now. On the picture bellow we get a node f(x,y) that compute some function
    with two inputs x,y and output z. Now on the right side, we have this same node
    receiving from somewhere (loss function) a gradient dL/dz which means. "How much
    L will change with a small change on z". As the node has 2 inputs it will have
    2 gradients. One showing how L will a small change dx and the other showing how
    L will change with a small change (dz)
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 链式法则是反向传播的主要工作，因此现在理解它很重要。在下面的图片中，我们有一个节点 f(x,y)，它计算具有两个输入 x、y 和输出 z 的某个函数。现在在右边，我们有这个相同的节点从某处（损失函数）接收一个梯度
    dL/dz，这意味着。“L 会随着 z 的微小变化而改变多少”。由于节点有 2 个输入，它将有 2 个梯度。一个显示 L 如何随着 dx 的微小变化而变化，另一个显示
    L 如何随着 dz 的微小变化而变化。
- en: '![](chainrule_example.PNG) In order to calculate the gradients we need the
    input dL/dz (dout), and the derivative of the function f(x,y), at that particular
    input, then we just multiply them. Also we need the previous cached input, saved
    during forward propagation.'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '![](chainrule_example.PNG) 为了计算梯度，我们需要输入的 dL/dz（dout），以及在该特定输入处的函数 f(x,y) 的导数，然后我们只需将它们相乘。同时，我们需要在前向传播期间保存的先前缓存的输入。'
- en: Gates Implementation
  id: totrans-525
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 门的实现
- en: '* * *'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Observe bellow the implementation of the multiply and add gate on python
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 下面观察 python 上乘法和加法门的实现
- en: '![](PythonCircuits.png)'
  id: totrans-528
  prefs: []
  type: TYPE_IMG
  zh: '![](PythonCircuits.png)'
- en: Step by step example
  id: totrans-529
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逐步示例
- en: '* * *'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: With what we learn so far, let's calculate the partial derivatives of some graphs
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们迄今所学，让我们计算一些图的偏导数
- en: Simple example
  id: totrans-532
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单示例
- en: Here we have a graph for the function ![](9e90bd2.png)
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个函数的图表 ![](9e90bd2.png)
- en: '![](SimpleGraph.png)'
  id: totrans-534
  prefs: []
  type: TYPE_IMG
  zh: '![](SimpleGraph.png)'
- en: Start from output node f, and consider that the gradient of f related to some
    criteria is 1 (dout)
  id: totrans-535
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输出节点 f 开始，并考虑 f 相对于某些标准的梯度为 1（dout）
- en: dq=(dout(1) * z), which is -4 (How the output will change with a change in q)
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: dq=(dout(1) * z)，这是 -4（输出将如何随着 q 的变化而变化）
- en: dz=(dout(1) * q), which is 3 (How the output will change with a change in z)
  id: totrans-537
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: dz=(dout(1) * q)，这是 3（输出将如何随着 z 的变化而变化）
- en: The sum gate distribute it's input gradients, so dx=-4, dy=-4 (How the output
    will change with x,z)
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总和门分配了它的输入梯度，所以 dx=-4，dy=-4（输出将如何随着 x，z 的变化而变化）
- en: Perceptron with 2 inputs
  id: totrans-539
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有 2 个输入的感知机
- en: This following graph represent the forward propagation of a simple 2 inputs,
    neural network with one output layer with sigmoid activation.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表表示一个简单的 2 输入、具有 sigmoid 激活的输出层的神经网络的前向传播。
- en: '![](6fcb84f4.png)'
  id: totrans-541
  prefs: []
  type: TYPE_IMG
  zh: '![](6fcb84f4.png)'
- en: '![](SimplePerceptron.png)'
  id: totrans-542
  prefs: []
  type: TYPE_IMG
  zh: '![](SimplePerceptron.png)'
- en: '![](StepByStepExample.png)'
  id: totrans-543
  prefs: []
  type: TYPE_IMG
  zh: '![](StepByStepExample.png)'
- en: Start from the output node, considering that or error(dout) is 1
  id: totrans-544
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输出节点开始，考虑到我们的误差(dout)是 1
- en: The gradient of the input of the 1/x will be -1/(1.37^2), -0.53
  id: totrans-545
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1/x 输入的梯度将是 -1/(1.37^2)，-0.53
- en: The increment node does not change the gradient on it's input, so it will be
    (-0.53 * 1), -0.53
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增量节点不会改变其输入的梯度，因此它将是 (-0.53 * 1)，-0.53
- en: The exp node input gradient will be (exp(-1(cached input)) * -0.53), -0.2
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: exp 节点的输入梯度将是 (exp(-1(缓存输入)) * -0.53)，-0.2
- en: The negative gain node will be it's input gradient (-1 * -0.2), 0.2
  id: totrans-548
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 负增益节点将是其输入梯度（-1 * -0.2），0.2
- en: The sum node will distribute the gradients, so, dw2=0.2, and the sum node also
    0.2
  id: totrans-549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总和节点将分配梯度，因此 dw2=0.2，并且总和节点也为 0.2
- en: The sum node again distribute the gradients so again 0.2
  id: totrans-550
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总和节点再次分配梯度，因此再次为 0.2
- en: dw0 will be (0.2 * -1), -0.2
  id: totrans-551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: dw0 将是 (0.2 * -1)，-0.2
- en: dx0 will be (0.2 * 2). 0.4
  id: totrans-552
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: dx0 将是 (0.2 * 2)。0.4
- en: Next Chapter
  id: totrans-553
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: Next chapter we will learn about Feature Scaling.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习关于特征缩放的内容。
- en: Feature Scaling
  id: totrans-555
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征缩放
- en: Feature Scaling
  id: totrans-556
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征缩放
- en: Introduction
  id: totrans-557
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In order to make the life of gradient descent algorithms easier, there are some
    techniques that can be applied to your data on training/test phase. If the features
    ![](bddfd27d.png) on your input vector ![](761426bc.png), are out of scale your
    loss space ![](42a195a9.png) will be somehow stretched. This will make the gradient
    descent convergence harder, or at least slower.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使梯度下降算法的生活更加轻松，可以在训练/测试阶段对数据应用一些技术。如果输入向量 ![](bddfd27d.png) 中的特征不成比例，那么你的损失空间
    ![](42a195a9.png) 将会在某种程度上被拉伸。这将使梯度下降的收敛更加困难，或者至少更慢。
- en: On the example bellow your input X has 2 features (house size, and number of
    bedrooms). The problem is that house size feature range from 0...2000, while number
    of bedrooms range from 0...5.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，你的输入 X 有 2 个特征（房屋大小和卧室数量）。问题是房屋大小特征范围为 0...2000，而卧室数量范围为 0...5。
- en: '![](FeatureScaling.jpg)'
  id: totrans-561
  prefs: []
  type: TYPE_IMG
  zh: '![](FeatureScaling.jpg)'
- en: Centralize data and normalize
  id: totrans-562
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据中心化和归一化
- en: '* * *'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](PreProcessing.jpeg)'
  id: totrans-564
  prefs: []
  type: TYPE_IMG
  zh: '![](PreProcessing.jpeg)'
- en: 'Bellow we will pre-process our input data to fix the following problems:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们将对我们的输入数据进行预处理，以解决以下问题：
- en: Data not centered around zero
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据未围绕零中心化
- en: Features out of scale
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征不成比例
- en: Consider your input data ![](e84a970b.png), where N is the number of samples
    on your input data (batch size) and D the dimensions (On the previous example
    D is 2, size house, num bedrooms).
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑你的输入数据 ![](e84a970b.png)，其中 N 是你的输入数据样本数（批量大小），D 是维度（在前面的示例中，D 是 2，房屋大小，卧室数量）。
- en: The first thing to do is to subtract the mean value of the input data, this
    will centralize the data dispersion around zero
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要做的是减去输入数据的均值，这将使数据的分散围绕零中心化
- en: '![](b53e5544.png)'
  id: totrans-570
  prefs: []
  type: TYPE_IMG
  zh: '![](b53e5544.png)'
- en: On prediction phase is common to store this mean value to be subtracted from
    a test example. On the case of image classification, it's also common to store
    a mean image created from a batch of images on the training-set, or the mean value
    from every channel.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测阶段，通常会存储这个均值以便从测试样本中减去。在图像分类的情况下，通常会存储从训练集的一批图像创建的均值图像，或者每个通道的均值。
- en: After your data is centralized around zero, you can make all features have the
    same range by dividing X by it's standard deviation.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的数据围绕零中心化后，你可以通过将 X 除以它的标准差来使所有特征具有相同的范围。
- en: '![](8008dab6.png)'
  id: totrans-573
  prefs: []
  type: TYPE_IMG
  zh: '![](8008dab6.png)'
- en: Again this operation fix our first, problem, because all features will range
    similarly. But this should be used if somehow you know that your features have
    the same "weight". On the case of image classification for example all pixels
    have the same range (0..255) and a pixel alone has no bigger meaning (weight)
    than the other, so just mean subtraction should suffice for image classification.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，这个操作解决了我们的第一个问题，因为所有的特征将会有相似的范围。但是如果你知道你的特征具有相同的“重要性”，那么应该使用这个方法。例如，在图像分类的情况下，所有的像素都具有相同的范围
    (0..255)，一个像素本身并没有比其他像素更重要，因此仅需进行均值减法就足够了。
- en: 'Common mistake:'
  id: totrans-575
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见错误：
- en: '* * *'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: An important point to make about the preprocessing is that any preprocessing
    statistics (e.g. the data mean) must only be computed on the training data, and
    then applied to the validation / test data. Computing the mean and subtracting
    it from every image across the entire dataset and then splitting the data into
    train/val/test splits would be a mistake. Instead, the mean must be computed only
    over the training data and then subtracted equally from all splits (train/val/test).
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 关于预处理的一个重要观点是，任何预处理统计数据（例如数据均值）必须仅在训练数据上计算，然后应用于验证/测试数据。计算数据均值并从整个数据集中的每个图像中减去它，然后将数据分割成训练/验证/测试集是错误的。相反，均值必须仅在训练数据上计算，然后平均减去所有分割（训练/验证/测试）的数据。
- en: Next Chapter
  id: totrans-578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: Next chapter we will learn about Neural Networks.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习神经网络。
- en: Model Initialization
  id: totrans-580
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型初始化
- en: Model Initialization
  id: totrans-581
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型初始化
- en: Introduction
  id: totrans-582
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: One important topic we should learn before we start training our models, is
    about the weight initialization. Bad weight initialization, can lead to a "never
    convergence training" or a slow training.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始训练模型之前，我们应该学习的一个重要主题是权重初始化。糟糕的权重初始化可能导致“永不收敛的训练”或训练缓慢。
- en: Weight matrix format
  id: totrans-585
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 权重矩阵格式
- en: '* * *'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'As observed on previous chapters, the weight matrix has the following format:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前几章观察到的，权重矩阵具有以下格式：
- en: '![](9e63ed7d.png)'
  id: totrans-588
  prefs: []
  type: TYPE_IMG
  zh: '![](9e63ed7d.png)'
- en: 'Consider the number of outputs ![](64649e57.png), as rows and the number of
    inputs ![](5f0028c.png) as columns. You could also consider another format:'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 将输出数量![](64649e57.png)视为行数，将输入数量![](5f0028c.png)视为列数。您还可以考虑另一种格式：
- en: '![](109a7901.png)'
  id: totrans-590
  prefs: []
  type: TYPE_IMG
  zh: '![](109a7901.png)'
- en: Here ![](64649e57.png) as columns and ![](5f0028c.png) as rows.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 这里![](64649e57.png)作为列，![](5f0028c.png)作为行。
- en: The whole point is that our weights is going to be a 2d matrix function of ![](5f0028c.png)
    and ![](64649e57.png)
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于我们的权重将是一个关于![](5f0028c.png)和![](64649e57.png)的二维矩阵函数
- en: Initialize all to zero
  id: totrans-593
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全部初始化为零
- en: '* * *'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you initialize your weights to zero, your gradient descent will never converge
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将权重初始化为零，您的梯度下降将永远不会收敛
- en: '![](all_zeros_initialization.png)'
  id: totrans-596
  prefs: []
  type: TYPE_IMG
  zh: '![](all_zeros_initialization.png)'
- en: Initialize with small values
  id: totrans-597
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用小值初始化
- en: '* * *'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'A better idea is to initialize your weights with values close to zero (but
    not zero), ie: 0.01'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的方法是用接近零的值（但不是零）初始化权重，即：0.01。
- en: '![](9979e35b.png)'
  id: totrans-600
  prefs: []
  type: TYPE_IMG
  zh: '![](9979e35b.png)'
- en: Here randn gives random data with zero mean, unit standard deviation. ![](20895e70.png)
    are the number of input and outputs. The 0.01 term will keep the random weights
    small and close to zero.
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 这里randn给出了均值为零，单位标准差的随机数据。![](20895e70.png)是输入和输出的数量。0.01项将保持随机权重较小且接近于零。
- en: '![](matlab_randn.png)'
  id: totrans-602
  prefs: []
  type: TYPE_IMG
  zh: '![](matlab_randn.png)'
- en: The problem with the previous way to do initialization is that the variance
    of the outputs will grow with the number of inputs. To solve this issue we can
    divide the random term by the square root of the number of inputs.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 以前进行初始化的问题是输出的方差会随着输入数量的增加而增加。要解决这个问题，我们可以将随机项除以输入数量的平方根。
- en: '![](fc90afec.png)'
  id: totrans-604
  prefs: []
  type: TYPE_IMG
  zh: '![](fc90afec.png)'
- en: '![](xavier_inits.png)'
  id: totrans-605
  prefs: []
  type: TYPE_IMG
  zh: '![](xavier_inits.png)'
- en: Now it seems that we don't have dead neurons, the only problem with this approach
    is to use it with Relu neurons.
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看来我们没有死神经元，这种方法的唯一问题是将其用于Relu神经元。
- en: '![](xavier_inits_relu.png)'
  id: totrans-607
  prefs: []
  type: TYPE_IMG
  zh: '![](xavier_inits_relu.png)'
- en: To solve this just add a simple (divide by 2) term....
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决这个问题，只需添加一个简单的（除以2）项....
- en: '![](20772a44.png)'
  id: totrans-609
  prefs: []
  type: TYPE_IMG
  zh: '![](20772a44.png)'
- en: '![](xavier_inits_relu_fix.png)'
  id: totrans-610
  prefs: []
  type: TYPE_IMG
  zh: '![](xavier_inits_relu_fix.png)'
- en: So use this second form to initialize Relu layers.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 所以使用这种第二种形式来初始化Relu层。
- en: Bath Norm layer
  id: totrans-612
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批归一化层
- en: '* * *'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On future chapters we're going to learn a technique that make your model more
    resilient to specific initialization.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的章节中，我们将学习一种使您的模型对特定初始化更具弹性的技术。
- en: Next chapter
  id: totrans-615
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Next chapter we start talk about convolutions.
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们开始谈论卷积。
- en: Recurrent Neural Networks
  id: totrans-618
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: Recurrent Neural Networks
  id: totrans-619
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: Introduction
  id: totrans-620
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On previous forward neural networks, our output was a function between the current
    input and a set of weights. On recurrent neural networks(RNN), the previous network
    state is also influence the output, so recurrent neural networks also have a "notion
    of time". This effect by a loop on the layer output to it's input.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 在以前的前向神经网络中，我们的输出是当前输入和一组权重之间的函数。在循环神经网络(RNN)中，先前的网络状态也会影响输出，因此循环神经网络也具有“时间概念”。这通过将层输出循环到其输入来实现。
- en: '![](recurrent.jpg)'
  id: totrans-623
  prefs: []
  type: TYPE_IMG
  zh: '![](recurrent.jpg)'
- en: In other words, the RNN will be a function with inputs ![](2683a688.png) (input
    vector) and previous state ![](93d89ee3.png). The new state will be ![](22b53607.png).
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，RNN将是一个具有输入![](2683a688.png)（输入向量）和上一个状态![](93d89ee3.png)的函数。新状态将是![](22b53607.png)。
- en: The recurrent function, ![](d9cebfcd.png), will be fixed after training and
    used to every time step.
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 递归函数![](d9cebfcd.png)在训练后将被固定，并用于每个时间步。
- en: Recurrent Neural Networks are the best model for regression, because it take
    into account past values.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络是回归的最佳模型，因为它考虑了过去的值。
- en: RNN are computation "Turing Machines" which means, with the correct set of weights
    it can compute anything, imagine this weights as a program.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: RNN是计算“图灵机”，这意味着，通过正确的权重集，它可以计算任何东西，想象这些权重就像一个程序。
- en: Just to not let you too overconfident on RNN, there is no automatic back-propagation
    algorithms, that will find this "perfect set of weights".
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 只是为了不让你对RNN过于自信，没有自动的反向传播算法，可以找到这个“完美的权重集”。
- en: 'Bellow we have a simple implementation of RNN recurrent function: (Vanilla
    version)'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是RNN循环函数的简单实现：（基础版本）
- en: '![](13091812.png)'
  id: totrans-630
  prefs: []
  type: TYPE_IMG
  zh: '![](13091812.png)'
- en: 'The code that calculate up to the next state ![](22b53607.png) looks like this:'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 计算到下一个状态的代码如下：![](22b53607.png)
- en: '[PRE2]'
  id: totrans-632
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Observe that in our case of RNN we are now more interested on the next state,
    ![](22b53607.png) not exactly the output, ![](4d21efaf.png)
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在我们的RNN案例中，我们现在更感兴趣的是下一个状态，![](22b53607.png) 而不是确切的输出，![](4d21efaf.png)
- en: Before we start let's just make explicit how to backpropagate the tanh block.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，让我们明确如何反向传播tanh块。
- en: '![](tanhBlock.png)'
  id: totrans-635
  prefs: []
  type: TYPE_IMG
  zh: '![](tanhBlock.png)'
- en: Now we can do the backpropagation step (For one single time-step)
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进行反向传播步骤（对于单个时间步）
- en: '[PRE3]'
  id: totrans-637
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A point to be noted is that the same function ![](4c48cbdd.png) and the same
    set of parameters will be applied to every time-step.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，相同的函数![](4c48cbdd.png) 和相同的参数集将应用于每个时间步。
- en: '![](RecurrentNeuralNetwork.png)'
  id: totrans-639
  prefs: []
  type: TYPE_IMG
  zh: '![](RecurrentNeuralNetwork.png)'
- en: A good initialization for the RNN states ![](22b53607.png) is zero. Again this
    is just the initial RNN state not it's weights.
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: RNN状态的良好初始化为零。再次强调，这只是初始RNN状态，而不是其权重。
- en: These looping feature on RNNs can be confusing first but actually you can think
    as a normal neural network repeated(unrolled) multiple times. The number of times
    that you unroll can be consider how far in the past the network will remember.
    In other words each time is a time-step.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: RNN中的这种循环特性一开始可能会让人困惑，但实际上你可以将其看作是一个正常的神经网络多次重复（展开）。你展开的次数可以被认为是网络将记住多久以前的内容。换句话说，每次都是一个时间步。
- en: '![](RNN_Unrolling.png)'
  id: totrans-642
  prefs: []
  type: TYPE_IMG
  zh: '![](RNN_Unrolling.png)'
- en: Forward and backward propagation on each time-step
  id: totrans-643
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每个时间步上的前向和后向传播
- en: From the previous examples we presented code for forward and backpropagation
    for one time-step only. As presented before the RNN are unroled for each time-step
    (finite). Now we present how to do the forward propagation for each time-step.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的例子中，我们仅为一个时间步呈现了前向和反向传播的代码。如前所述，RNN被展开到每个时间步（有限）。现在我们展示如何为每个时间步进行前向传播。
- en: '[PRE4]'
  id: totrans-645
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-646
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Bellow we show a diagram that present the multiple ways that you could use a
    recurrent neural network compared to the forward networks. Consider the inputs
    the red blocks, and the outputs the blue blocks.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们展示了一个图表，展示了与前向网络相比，您可以使用递归神经网络的多种方式。将红色块视为输入，蓝色块视为输出。
- en: '![](Recurrent_Forward.jpeg)'
  id: totrans-648
  prefs: []
  type: TYPE_IMG
  zh: '![](Recurrent_Forward.jpeg)'
- en: 'One to one: Normal Forward network, ie: Image on the input, label on the output'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一对一：正常的前向网络，即：输入为图像，输出为标签
- en: 'One to many(RNN): (Image captioning) Image in, words describing the scene out
    (CNN regions detected + RNN)'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一对多（RNN）：（图像字幕）输入为图像，输出为描述场景的单词（CNN检测到的区域 + RNN）
- en: 'Many to one(RNN): (Sentiment Analysis) Words on a phrase on the input, sentiment
    on the output (Good/Bad) product.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多对一（RNN）：（情感分析）输入为短语中的单词，输出为情感（好/坏）产品。
- en: 'Many to many(RNN): (Translation), Words on English phrase on input, Portuguese
    on output.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多对多（RNN）：（翻译）输入为英语短语中的单词，输出为葡萄牙语。
- en: 'Many to many(RNN): (Video Classification) Video in, description of video on
    output.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多对多（RNN）：（视��分类）视频输入，视频描述输出。
- en: Stacking RNNs
  id: totrans-654
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 堆叠RNN
- en: '* * *'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Bellow we describe how we add "depth" to RNN and also how to unroll RNNs to
    deal with time.
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们描述如何为RNN添加“深度”，以及如何展开RNN以处理时间。
- en: Observe that the output of the RNNs are feed to deeper layers, while the state
    is feed for dealing with past states.
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，RNN的输出被馈送到更深层，而状态被馈送以处理过去的状态。
- en: '![](RNN_Stacking.png)'
  id: totrans-658
  prefs: []
  type: TYPE_IMG
  zh: '![](RNN_Stacking.png)'
- en: Simple regression example
  id: totrans-659
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单的回归示例
- en: Here we present a simple case where we want the RNN to complete the word, we
    give to the network the characters h,e,l,l , our vocabulary here is [h,e,l,o].
    Observe that after we input the first 'h' the network want's to output the wrong
    answer (right is on green), but near the end, after the second 'l' it want's to
    output the right answer 'o'. Here the order that the characters come in does matter.
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们展示了一个简单的案例，我们希望RNN完成单词，我们向网络提供字符h,e,l,l，我们的词汇表是[h,e,l,o]。请注意，在我们输入第一个'h'后，网络想要输出错误答案（正确答案在绿色上），但接近末尾，在第二个'l'后，它想要输出正确答案'o'。在这里，字符的顺序确实很重要。
- en: '![](RNNSampleWithDict.png)'
  id: totrans-661
  prefs: []
  type: TYPE_IMG
  zh: '![](RNNSampleWithDict.png)'
- en: Describing images
  id: totrans-662
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 描述图像
- en: '* * *'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you connect a convolution neural network, with pre-trained RNN. The RNN will
    be able to describe what it "see" on the image.
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将卷积神经网络与预训练的 RNN 连接起来。RNN 将能够描述它在图像上“看到”的内容。
- en: '![](CNN_RNN.png)'
  id: totrans-665
  prefs: []
  type: TYPE_IMG
  zh: '![](CNN_RNN.png)'
- en: 'Basically we get a pre-trained CNN (ie: VGG) and connect the second-to-last
    FC layer and connect to a RNN. After this you train the whole thing end-to-end.'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上我们得到一个预训练的 CNN（例如：VGG），连接到倒数第二个全连接层，然后连接到一个 RNN。之后你可以端对端地训练整个模型。
- en: '![](CNN_RNN_2.png)'
  id: totrans-667
  prefs: []
  type: TYPE_IMG
  zh: '![](CNN_RNN_2.png)'
- en: Long Short Term Memory networks(LSTM)
  id: totrans-668
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 长短期记忆网络（LSTM）
- en: '* * *'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: LSTM provides a different recurrent formula ![](d9cebfcd.png), it's more powefull
    thanvanilla RNN, due to it's complex ![](d9cebfcd.png) that add "residual information"
    to the next state instead of just transforming each state. Imagine LSTM are the
    "residual" version of RNNs.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM 提供了一个不同的循环公式 ![](d9cebfcd.png)，它比普通 RNN 更强大，因为它的复杂性 ![](d9cebfcd.png) 会将“残余信息”添加到下一个状态，而不仅仅是转换每个状态。想象一下
    LSTM 是 RNN 的“残余”版本。
- en: In other words LSTM suffer much less from vanishing gradients than normal RNNs.
    Remember that the plus gates distribute the gradients.
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，LSTM 比普通 RNN 更少受到梯度消失的影响。记住加法门会分配梯度。
- en: So by suffering less from vanishing gradients, the LSTMs can remember much more
    in the past. So from now just use LSTMs when you think about RNN.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，由于梯度消失的问题较少，LSTM 可以记住更多的过去信息。所以从现在开始，当你考虑 RNN 时只使用 LSTM。
- en: '![](residual_RNN.png)'
  id: totrans-673
  prefs: []
  type: TYPE_IMG
  zh: '![](residual_RNN.png)'
- en: Observe from the animation bellow how hast the gradients on the RNN disappear
    compared to LSTM.
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: 从下面的动画中观察 RNN 上的梯度消失与 LSTM 相比是多么快。
- en: '![](rnn_LSTM_gradient.gif)'
  id: totrans-675
  prefs: []
  type: TYPE_IMG
  zh: '![](rnn_LSTM_gradient.gif)'
- en: The vanishing problem can be solved with LSTM, but another problem that can
    happen with all recurrent neural network is the exploding gradient problem.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度消失问题可以通过 LSTM 解决，但所有循环神经网络可能遇到的另一个问题是梯度爆炸问题。
- en: To fix the exploding gradient problem, people normally do a gradient clipping,
    that will allow only a maximum gradient value.
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决梯度爆炸问题，人们通常会进行梯度裁剪，这将只允许最大梯度值。
- en: This highway for the gradients is called Cell-State, so one difference compared
    to the RNN that has only the state flowing, on LSTM we have states and the cell
    state.
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用于梯度传递的通道被称为细胞状态，因此与只有状态流动的 RNN 相比，LSTM 有状态和细胞状态的区别。
- en: '![](Flow_LSTM_RNN.png)'
  id: totrans-679
  prefs: []
  type: TYPE_IMG
  zh: '![](Flow_LSTM_RNN.png)'
- en: LSTM Gate
  id: totrans-680
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LSTM 门
- en: Doing a zoom on the LSTM gate. This also improves how to do the backpropagation.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 对 LSTM 门进行放大。这也改善了反向传播的方法。
- en: '![](LSTMBlockDiagram.png)'
  id: totrans-682
  prefs: []
  type: TYPE_IMG
  zh: '![](LSTMBlockDiagram.png)'
- en: Code for lstm forward propagation for one time-step
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 用于一个时间步的 LSTM 前向传播的代码
- en: '[PRE6]'
  id: totrans-684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now the backward propagation for one time-step
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是一个时间步的反向传播
- en: '[PRE7]'
  id: totrans-686
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Deep Learning
  id: totrans-687
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习
- en: Introduction
  id: totrans-688
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](DLPic.png)'
  id: totrans-690
  prefs: []
  type: TYPE_IMG
  zh: '![](DLPic.png)'
- en: Deep learning is a branch of machine learning based on a set of algorithms that
    learn to represent the data. Bellow we list the most popular ones.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是基于一组算法的机器学习分支，这些算法学习表示数据。下面我们列出最流行的算法。
- en: Convolutional Neural Networks
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Deep Belief Networks
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度信念网络
- en: Deep Auto-Encoders
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度自动编码器
- en: Recurrent Neural Networks (LSTM)
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环神经网络（LSTM）
- en: One of the promises of deep learning is that they will substitute hand-crafted
    feature extraction. The idea is that they will "learn" the best features needed
    to represent the given data.
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的一个承诺是它们将取代手工制作的特征提取。其想法是它们将“学习”表示给定数据所需的最佳特征。
- en: '![](DeepLearning.png)'
  id: totrans-697
  prefs: []
  type: TYPE_IMG
  zh: '![](DeepLearning.png)'
- en: Layers and layers
  id: totrans-698
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 层层叠加
- en: '* * *'
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Deep learning models are formed by multiple layers. On the context of artificial
    neural networks the multi layer perceptron (MLP) with more than 2 hidden layers
    is already a Deep Model.
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型由多个层组成。在人工神经网络的背景下，具有超过 2 个隐藏层的多层感知器（MLP）已经是一个深度模型。
- en: As a rule of thumb deeper models will perform better than shallow models, the
    problem is that more deep you go more data, you will need to avoid over-fitting.
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个经验法则，深度模型的表现会比浅层模型更好，问题在于你深入的层数越多，你就需要更多的数据来避免过拟合。
- en: '![](DeepLearningModel.png)'
  id: totrans-702
  prefs: []
  type: TYPE_IMG
  zh: '![](DeepLearningModel.png)'
- en: Layer types
  id: totrans-703
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 层类型
- en: Here we list some of the most used layers
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了一些最常用的层
- en: Convolution layer
  id: totrans-705
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卷积层
- en: Pooling Layer
  id: totrans-706
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 池化层
- en: Dropout Layer
  id: totrans-707
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 丢弃层
- en: Batch normalization layer
  id: totrans-708
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 批量归一化层
- en: Fully Connected layer
  id: totrans-709
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 全连接层
- en: Relu, Tanh, sigmoid layer
  id: totrans-710
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Relu、Tanh、sigmoid 层
- en: Softmax, Cross Entropy, SVM, Euclidean (Loss layers)
  id: totrans-711
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Softmax、交叉熵、SVM、欧几里得（损失层）
- en: Avoid over-fitting
  id: totrans-712
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免过拟合
- en: '* * *'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Besides getting more data, there are some techniques used to combat over-fitting,
    here is a list of the most common ones:'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 除了获取更多数据，还有一些用于对抗过拟合的技术，以下是最常见的一些：
- en: Dropout
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 辍学
- en: Regularization
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正规化
- en: Data Augmentation
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据增强
- en: Dropout
  id: totrans-718
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 辍学
- en: It's a technique that randomly turns off some neurons from the fully connected
    layer during training.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种在训练期间随机关闭一些全连接层神经元的技术。
- en: '![](Dropout.png)'
  id: totrans-720
  prefs: []
  type: TYPE_IMG
  zh: '![](Dropout.png)'
- en: The dropout forces the fully connected layers to learn the same concept in different
    ways
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 辍学强制全连接层以不同的方式学习相同的概念
- en: Regularization
  id: totrans-722
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正规化
- en: dasdaasdasadasdad
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: dasdaasdasadasdad
- en: Data Augmentation
  id: totrans-724
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据增强
- en: Synthetically create new training examples by applying some transformations
    on the input data. For examples fliping images. During Imagenet Competition, Alex
    Krizhevesky (Alexnet) used data augmentation of a factor of 2048, where each class
    on imagenet has 1000 elements.
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对输入数据应用一些变换来合成新的训练样本。例如翻转图像。在Imagenet比赛中，Alex Krizhevesky（Alexnet）使用了2048倍的数据增强，其中每个Imagenet类别有1000个元素。
- en: '![](Augmentation1.png)![](Augmentation2.png)'
  id: totrans-726
  prefs: []
  type: TYPE_IMG
  zh: '![](Augmentation1.png)![](Augmentation2.png)'
- en: '![](Augmentation3.png)'
  id: totrans-727
  prefs: []
  type: TYPE_IMG
  zh: '![](Augmentation3.png)'
- en: Automatic Hierarchical representation
  id: totrans-728
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动分层表示
- en: The idea is to let the learning algorithm to find the best representation that
    it can for every layer starting from the inputs to the more deepest ones.
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: 思想是让学习算法从输入到更深层逐层找到最佳表示。
- en: The shallow layers learn to represent data on it's simpler form and deepest
    layers learn to represent the data with the concepts learned from the previous
    ones.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 浅层学习以更简单的形式表示数据，最深层学习以从前一层学到的概念表示数据。
- en: '![](HieararchicalRepresentation.png)'
  id: totrans-731
  prefs: []
  type: TYPE_IMG
  zh: '![](HieararchicalRepresentation.png)'
- en: '![](DBN_Faces.png)'
  id: totrans-732
  prefs: []
  type: TYPE_IMG
  zh: '![](DBN_Faces.png)'
- en: Old vs New
  id: totrans-733
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 老 vs 新
- en: '* * *'
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Actually the only new thing is the usage of something that will learn how to
    represent the data (feature selection) automatically and based on the dataset
    given. Is not about saying that SVM or decision trees are bad, actually some people
    use SVMs at the end of the deep neural network to do classificaion.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，唯一的新东西是使用某种东西自动学习如何表示数据（特征选择），并基于给定的数据集。不是说SVM或决策树不好，事实上有些人在深度神经网络的最后使用SVM来进行分类。
- en: The only point is that the feature selection can be easily adapted to new data.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的问题是特征选择可以很容易地适应新数据。
- en: The biggest advantage on this is that if your problem get more complex you just
    make your model "deeper" and get more data (a lot) to train to your new problem.
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的最大优势是，如果您的问题变得更加复杂，您只需使您的模型变得更加“深入”，并获得更多（大量）数据来训练您的新问题。
- en: Some guys from Deep Learning
  id: totrans-738
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习中的一些人
- en: '* * *'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](SomeGuysMachineLearning.png)'
  id: totrans-740
  prefs: []
  type: TYPE_IMG
  zh: '![](SomeGuysMachineLearning.png)'
- en: Next Chapter
  id: totrans-741
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: Next chapter we will learn about Convolution Neural Networks.
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习卷积神经网络。
- en: Convolution
  id: totrans-743
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积
- en: Convolution
  id: totrans-744
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积
- en: Introduction
  id: totrans-745
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Convolution is a mathematical operation that does the integral of the product
    of 2 functions(signals), with one of the signals flipped. For example bellow we
    convolve 2 signals f(t) and g(t).
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是一种数学运算，对两个函数（信号）的积进行积分，其中一个信号被翻转。例如，下面我们对两个信号 f(t) 和 g(t) 进行卷积。
- en: '![](Conv1.png)'
  id: totrans-748
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv1.png)'
- en: So the first thing to do is to flip (180 degrees) the signal g, then slide the
    flipped g over f, multiplying and accumulating all it's values.
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 所以要做的第一件事是翻转（180度）信号 g，然后将翻转的 g 滑动到 f 上，乘以并累积所有它的值。
- en: The order that you convolve the signals does not matter for the end result,
    so conv(a,b)==conv(b,a)
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 对信号进行卷积的顺序对最终结果没有影响，因此 conv(a,b)==conv(b,a)
- en: On this case consider that the blue signal ![](6003a9f8.png) is our input signal
    and ![](e5429842.png) our kernel, the term kernel is used when you use convolutions
    to filter signals.
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，考虑到蓝色信号 ![](6003a9f8.png) 是我们的输入信号， ![](e5429842.png) 是我们的卷积核，当您使用卷积来过滤信号时，术语卷积核就会被使用。
- en: Output signal size 1D
  id: totrans-752
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输出信号大小1D
- en: 'On the case of 1d convolution the output size is calculated like this:'
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: 1维卷积的情况下，输出大小的计算方法如下：
- en: '![](f8e75e8d.png)'
  id: totrans-754
  prefs: []
  type: TYPE_IMG
  zh: '![](f8e75e8d.png)'
- en: Application of convolutions
  id: totrans-755
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积的应用
- en: People use convolution on signal processing for the following use cases
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: 人们在信号处理中使用卷积的用例如下
- en: Filter Signals (1d audio, 2d image processing)
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤信号（1维音频，2维图像处理）
- en: Check how much a signal is correlated to another
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个信号与另一个信号的相关性有多大
- en: Find patterns on signals
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在信号中找到模式
- en: Simple example in matlab and python(numpy)
  id: totrans-760
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab和Python（numpy）的简单示例
- en: Bellow we convolve to signals x = (0,1,2,3,4) with w = (1,-1,2).
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们将信号 x = (0,1,2,3,4) 与 w = (1,-1,2) 进行卷积。
- en: '![](SimpleConv.png)'
  id: totrans-762
  prefs: []
  type: TYPE_IMG
  zh: '![](SimpleConv.png)'
- en: '![](Convolve1d_Python.png)'
  id: totrans-763
  prefs: []
  type: TYPE_IMG
  zh: '![](Convolve1d_Python.png)'
- en: Doing by hand
  id: totrans-764
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 手动操作
- en: To understand better then concept of convolution let's do the example above
    by hand. Basically we're going to convolve 2 signals (x,w). The first thing is
    to flip W horizontally (Or rotate to left 180 degrees)
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解卷积的概念，让我们手动做上面的例子。基本上我们将对 2 个信号 (x, w) 进行卷积。第一件事是水平翻转 W（或向左旋转 180 度）
- en: '![](Conv1_ManualStart.png)'
  id: totrans-766
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv1_ManualStart.png)'
- en: After that we need to slide the flipped W over the input X
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: 之后我们需要将翻转的 W 滑动到输入 X 上
- en: '![](Conv1d_Manual.png)'
  id: totrans-768
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv1d_Manual.png)'
- en: Observe that on steps 3,4,5 the flipped window is completely inside the input
    signal. Those results are called 'valid'. The cases where the flipped window is
    not fully inside the input window(X), we can consider to be zero, or calculate
    what is possible to be calculated, ex on step 1 we multiply 1 by zero, and the
    rest is simply ignored.
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到在步骤 3、4、5 中，翻转的窗口完全位于输入信号内。这些结果被称为“有效”。当翻转的窗口没有完全位于输入窗口(X)内时，我们可以考虑为零，或者计算可能计算的内容，例如在步骤
    1 中，我们将 1 乘以零，其余部分被简单地忽略。
- en: Input padding
  id: totrans-770
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入填充
- en: In order to keep the convolution result size the same size as the input, and
    to avoid an effect called circular convolution, we pad the signal with zeros.
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持卷积结果的大小与输入大小相同，并避免称为循环卷积的效果，我们用零填充信号。
- en: 'Where you put the zeros depends on what you want to do, ie: on the 1d case
    you can concatenate them on the end, but on 2d is normally around the original
    signal'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: 将零放在哪里取决于你想要做什么，即：在 1d 情况下，你可以将它们连接在末尾，但在 2d 情况下通常是在原始信号周围。
- en: '![](zeroPadding_0.png)'
  id: totrans-773
  prefs: []
  type: TYPE_IMG
  zh: '![](zeroPadding_0.png)'
- en: '![](zeroPadding.png)'
  id: totrans-774
  prefs: []
  type: TYPE_IMG
  zh: '![](zeroPadding.png)'
- en: 'On matlab you can use the command padarray to pad the input:'
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 在 matlab 中，你可以使用 padarray 命令来填充输入：
- en: '[PRE8]'
  id: totrans-776
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Transforming convolution to computation graph
  id: totrans-777
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将卷积转换为计算图
- en: In order to calculate partial derivatives of every node inputs and parameters,
    it's easier to transform it to a computational graph. Here I'm going to transform
    the previous 1d convolution, but this can be extended to 2d convolution as well.
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算每个节点输入和参数的偏导数，将其转换为计算图会更容易。这里我将转换之前的 1d 卷积，但这也可以扩展到 2d 卷积。
- en: '![](Conv1d_Manual_symbolic.png)'
  id: totrans-779
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv1d_Manual_symbolic.png)'
- en: Here our graph will be created on the valid cases where the flipped kernel(weights)
    will be fully inserted on our input window.
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们的图将在翻转的卷积核（权重）完全插入到我们的输入窗口的有效情况下创建。
- en: '![](Simple_1d_Conv_graph.png)'
  id: totrans-781
  prefs: []
  type: TYPE_IMG
  zh: '![](Simple_1d_Conv_graph.png)'
- en: We're going to use this graph in the future to infer the gradients of the inputs
    (x) and weights (w) of the convolution layer
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在未来使用这个图来推断卷积层的输入 (x) 和权重 (w) 的梯度
- en: 2d Convolution
  id: totrans-783
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2d 卷积
- en: '* * *'
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Extending to the second dimension, 2d convolutions are used on image filters,
    and when you would like to find a specific patch on image.
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展到第二维，2d 卷积用于图像滤波器，以及当你想要在图像上找到特定的补丁时。
- en: '![](Conv2dUsage1.png)'
  id: totrans-786
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv2dUsage1.png)'
- en: '![](PatternMatch.png)'
  id: totrans-787
  prefs: []
  type: TYPE_IMG
  zh: '![](PatternMatch.png)'
- en: Matlab and python examples
  id: totrans-788
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab 和 python 示例
- en: '![](MatlabConv2_Example.png)'
  id: totrans-789
  prefs: []
  type: TYPE_IMG
  zh: '![](MatlabConv2_Example.png)'
- en: Doing by hand
  id: totrans-790
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 手动操作
- en: First we should flip the kernel, then slide the kernel on the input signal.
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们应该翻转卷积核，然后将卷积核滑动到输入信号上。
- en: Before doing this operation by hand check out the animation showing how this
    sliding works
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动操作之前，看看展示滑动如何工作的动画
- en: '![](Convolution_schematic.gif)'
  id: totrans-793
  prefs: []
  type: TYPE_IMG
  zh: '![](Convolution_schematic.gif)'
- en: '![](Conv2d_Manual.png)'
  id: totrans-794
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv2d_Manual.png)'
- en: Stride
  id: totrans-795
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步幅
- en: By default when we're doing convolution we move our window one pixel at a time
    (stride=1), but some times in convolutional neural networks we move more than
    one pixel. Strides of 2 are used on pooling layers.
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，当我们进行卷积时，我们每次移动一个像素的窗口（步幅=1），但有时在卷积神经网络中我们会移动多个像素。步幅为 2 用于池化层。
- en: Observe that bellow the red window is moving much more than one pixel time.
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到在红色窗口下方移动的比一个像素时间更多。
- en: '![](Pooling_schematic.gif)'
  id: totrans-798
  prefs: []
  type: TYPE_IMG
  zh: '![](Pooling_schematic.gif)'
- en: Output size for 2d
  id: totrans-799
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2d 的输出大小
- en: 'If we consider the padding and stride, the output size of convolution is defined
    as:'
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: 如果考虑填充和步幅，卷积的输出大小定义为：
- en: '![](200d3e57.png)'
  id: totrans-801
  prefs: []
  type: TYPE_IMG
  zh: '![](200d3e57.png)'
- en: F is the size of the kernel, normally we use square kernels, so F is both the
    width and height of the kernel
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: F 是卷积核的大小，通常我们使用方形卷积核，因此 F 既是卷积核的宽度又是高度
- en: Implementing convolution operation
  id: totrans-803
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现卷积操作
- en: '* * *'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The example bellow will convolve a 5x5x3 (WxHx3) input, with a conv layer with
    the following parameters Stride=2, Pad=1, F=3(3x3 kernel), and K=2 (two filters).
    Our input has 3 channels, so we need a 3x3x3 kernel weight. We have 2 filters
    (K=2) so we have 2 output activation (3x3x2). Calculating the output size we have:
    (5 - 3 + 2)/2 + 1 = 3'
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的例子将用一个5x5x3（WxHx3）输入进行卷积，使用以下参数的卷积层 Stride=2, Pad=1, F=3（3x3内核），和 K=2（两个滤波器）。我们的输入有3个通道，所以我们需要一个3x3x3的内核权重。我们有2个滤波器（K=2），所以我们有2个输出激活（3x3x2）。计算输出大小我们有：(5
    - 3 + 2)/2 + 1 = 3
- en: '![](Conv_Example.png)'
  id: totrans-806
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv_Example.png)'
- en: So basically we need to calculate 2 convolutions, one for each 3x3x3 filter
    (w0,w1), and remembering to add the bias.
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基本上我们需要计算2个卷积，一个用于每个3x3x3滤波器（w0，w1），并记得添加偏差。
- en: '![](Conv_Vanilla_1.png)'
  id: totrans-808
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv_Vanilla_1.png)'
- en: The code bellow (vanilla version) cannot be used on real life, because it will
    be slow. Usually deep learning libraries do the convolution as a matrix multiplication,
    using im2col/col2im.
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码（基础版本）不能在实际生活中使用，因为它会很慢。通常，深度学习库会将卷积作为矩阵乘法进行，使用im2col/col2im。
- en: '[PRE9]'
  id: totrans-810
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Next Chapter
  id: totrans-811
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: Next chapter we will learn about Deep Learning.
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习有关深度学习的内容。
- en: Convolutional Neural Networks
  id: totrans-813
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Convolutional Neural Networks
  id: totrans-814
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: '* * *'
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](ConvnetDiagram.png)'
  id: totrans-816
  prefs: []
  type: TYPE_IMG
  zh: '![](ConvnetDiagram.png)'
- en: '![](Conv_Relu_pool_FC.png)'
  id: totrans-817
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv_Relu_pool_FC.png)'
- en: Introduction
  id: totrans-818
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: A CNN is composed of layers that filters(convolve) the inputs to get usefull
    information. These convolutional layers have parameters(kernel) that are learned
    so that these filters are adjusted automatically to extract the most useful information
    for the task at hand without feature selection. CNN are better to work with images.
    Normal Neural networks does not fit well on image classification problems
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: CNN由过滤器（卷积）输入组成，以获取有用信息。这些卷积层有参数（内核），可以学习这些过滤器，使得这些过滤器自动调整以从手头的任务中提取最有用的信息，而不需要特征选择。CNN更适合处理图像。普通神经网络不太适合图像分类问题
- en: Comparison of Normal Neural network
  id: totrans-821
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 普通神经网络的比较
- en: '* * *'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On normal neural networks, we need to convert the image to a single 1d vector
    ![](49e0430d.png),then send this data to a hidden layer which is fully connected.
    On this scenario each neuron will have ![](51d4cd80.png) parameters per neuron.
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 在普通神经网络中，我们需要将图像转换为单个1d向量 ![](49e0430d.png)，然后将这些数据发送到完全连接的隐藏层。在这种情况下，每个神经元将每个神经元具有
    ![](51d4cd80.png) 参数。
- en: '![](WeightSharing.png)'
  id: totrans-824
  prefs: []
  type: TYPE_IMG
  zh: '![](WeightSharing.png)'
- en: Common architecture
  id: totrans-825
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见的架构
- en: '* * *'
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Normally the pattern [CONV->ReLU->Pool->CONV->ReLU->Pool->FC->Softmax_loss(during
    train)] is quite commom.
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: 通常模式 [CONV->ReLU->Pool->CONV->ReLU->Pool->FC->Softmax_loss(在训练期间)] 是相当常见的。
- en: '![](Common_CNN_Arch.png)'
  id: totrans-828
  prefs: []
  type: TYPE_IMG
  zh: '![](Common_CNN_Arch.png)'
- en: Main actor the convolution layer
  id: totrans-829
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要演员卷积层
- en: The most important operation on the convolutional neural network are the convolution
    layers, imagine a 32x32x3 image if we convolve this image with a 5x5x3 (The filter
    depth must have the same depth as the input), the result will be an activation
    map 28x28x1.
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络中最重要的操作是卷积层，想象一下一个32x32x3图像，如果我们将这个图像与一个5x5x3卷积（滤波器的深度必须与输入的深度相同）卷积，结果将是一个激活地图28x28x1。
- en: '![](ezgif.com-optimize.gif)'
  id: totrans-831
  prefs: []
  type: TYPE_IMG
  zh: '![](ezgif.com-optimize.gif)'
- en: The filter will look for a particular thing on all the image, this means that
    it will look for a pattern in the whole image with just one filter.
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤器将在整个图像中寻找特定的东西，这意味着它将在整个图像中寻找一个模式，只需要一个滤波器。
- en: '![](Conv11.PNG)'
  id: totrans-833
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv11.PNG)'
- en: Now consider that we want our convolution layer to look for 6 different things.
    On this case our convolution layer will have 6 5x5x3 filters. Each one looking
    for a particular pattern on the image.
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑我们希望我们的卷积层查找6个不同的东西。在这种情况下，我们的卷积层将有6个5x5x3滤波器。每一个都在图像上寻找一个特定的模式。
- en: '![](Conv2.PNG)'
  id: totrans-835
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv2.PNG)'
- en: By the way the convolution by itself is a linear operation, if we don't want
    to suffer from the same problem of the linear classifers we need to add at the
    end of the convolution layer a non-linear layer. (Normally a Relu)
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，卷积本身是一种线性操作，如果我们不想遭受线性分类器的相同问题，我们需要在卷积层末尾添加一个非线性层。（通常是Relu）
- en: Another important point of using convolution as pattern match is that the position
    where the thing that we want to search on the image is irrelevant. On the case
    of neural networks the model/hypothesis will learn an object on the exact location
    where the object is located during training.
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: 使用卷积作为模式匹配的另一个重要点是，我们要在图像上搜索的物体的位置是无关紧要的。在神经网络的情况下，模型/假设将在训练期间物体所在的确切位置学习一个对象。
- en: Convolution layer Hyper parameters
  id: totrans-838
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层超参数
- en: '* * *'
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Those are the parameters that are used to configure a convolution layer
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是用于配置卷积层的参数
- en: 'Kernel size(K): Small is better (But if is on the first layer, takes a lot
    of memory)'
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核大小（K）：越小越好（但如果是在第一层，会占用大量内存）
- en: 'Stride(S): How many pixels the kernel window will slide (Normally 1, in conv
    layers, and 2 on pooling layers)'
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步幅（S）：核窗口将滑动的像素数（通常为1，在卷积层中，池化层为2）
- en: 'Zero Padding(pad): Put zeros on the image border to allow the conv output size
    be the same as the input size (F=1, PAD=0; F=3, PAD=1; F=5, PAD=2; F=7, PAD=3)'
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零填充（pad）：在图像边界上放置零以使卷积输出大小与输入大小相同（F=1，PAD=0；F=3，PAD=1；F=5，PAD=2；F=7，PAD=3）
- en: 'Number of filters(F): Number of patterns that the conv layer will look for.'
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滤波器数量（F）：卷积层将寻找的模式数量。
- en: Output size
  id: totrans-845
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出大小
- en: 'By default the convolution output will always have a result smaller than the
    input. To avoid this behaviour we need to use padding. To calculate the convolution
    output (activation map) size we need this formula:'
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，卷积输出将始终比输入小。要避免这种行为，我们需要使用填充。要计算卷积输出（激活图）大小，我们需要使用以下公式：
- en: '![](36938e90.png)'
  id: totrans-847
  prefs: []
  type: TYPE_IMG
  zh: '![](36938e90.png)'
- en: '![](b60caaa0.png)'
  id: totrans-848
  prefs: []
  type: TYPE_IMG
  zh: '![](b60caaa0.png)'
- en: Vizualizing convolution
  id: totrans-849
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化卷积
- en: Here we will see some examples of the convolution window sliding on the input
    image and change some of it's hyper parameters.
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们将看到一些示例，演示卷积窗口在输入图像上滑动并更改一些超参数。
- en: Convolution with no padding and stride of 1
  id: totrans-851
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 不带填充且步幅为1的卷积
- en: Here we have a input 4x4 convolved with a filter 3x3 (K=3) with stride (S=1)
    and padding (pad=0)
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们有一个输入4x4与一个滤波器3x3（K=3）卷积，步幅（S=1）和填充（pad=0）
- en: '![](no_padding_no_strides.gif)'
  id: totrans-853
  prefs: []
  type: TYPE_IMG
  zh: '![](no_padding_no_strides.gif)'
- en: Convolution with padding and stride of 1
  id: totrans-854
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 带填充和步幅为1的卷积
- en: Now we have an input 5x5 convolved with a filter 3x3 (k=3) with stride (S=1)
    and padding (pad=1). On some libraries there is a feature that always calculate
    the right amount of padding to keep the output spatial dimensions the "same" as
    the input dimensions.
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个输入5x5与一个滤波器3x3（k=3）卷积，步幅（S=1）和填充（pad=1）。在某些库中，有一个功能总是计算正确数量的填充以保持输出空间维度与输入维度“相同”。
- en: '![](same_padding_no_strides.gif)'
  id: totrans-856
  prefs: []
  type: TYPE_IMG
  zh: '![](same_padding_no_strides.gif)'
- en: Number of parameters(weights)
  id: totrans-857
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数数量（权重）
- en: '* * *'
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Here we show how to calculate the number of parameters used by one convolution
    layer. We will illustrate with a simple example:'
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们展示了如何计算一个卷积层使用的参数数量。我们将用一个简单的例子加以说明：
- en: 'Input: 32x32x3, 32x32 RGB image'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：32x32x3，32x32 RGB 图像
- en: 'CONV: Kernel(F):5x5, Stride:1, Pad:2, numFilters:10'
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: CONV：核（F）：5x5，步幅：1，填充：2，滤波器数量：10
- en: '![](edc7a412.png)'
  id: totrans-862
  prefs: []
  type: TYPE_IMG
  zh: '![](edc7a412.png)'
- en: You can omit the "+1" parameter (Bias), to simplify calculations.
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以省略“+1”参数（偏置），以简化计算。
- en: Amount of memory
  id: totrans-864
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存量
- en: '* * *'
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here we show how to calculate the amount of memory needed on the convolution
    layer.
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们展示了如何计算卷积层所需的内存量。
- en: 'Input: 32x32x3, 32x32 RGB image'
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：32x32x3，32x32 RGB 图像
- en: 'CONV: Kernel(F):5x5, Stride:1, Pad:2, numFilters:10, as we use padding our
    output volume will be 32x32x10, so the ammount of memory in bytes is: 10240 bytes'
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: CONV：核（F）：5x5，步幅：1，填充：2，滤波器数量：10，由于我们使用填充，所以我们的输出体积将是32x32x10，因此内存量为：10240字节
- en: So the amount of memory is basically just the product of the dimensions of the
    output volume which is a 4d tensor.
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，内存量基本上只是输出体积尺寸的维度乘积，它是一个4维张量。
- en: '![](41e9054c.png)'
  id: totrans-870
  prefs: []
  type: TYPE_IMG
  zh: '![](41e9054c.png)'
- en: 'Where:'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![](e768559f.png): Output batch size'
  id: totrans-872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](e768559f.png)：输出批量大小'
- en: '![](48a9667f.png): The outpt volume or on the case of convolution the number
    of filters'
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](48a9667f.png)：输出体积或在卷积情况下滤波器的数量'
- en: '![](fdb9624c.png): The height of the output activation map'
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](fdb9624c.png)：输出激活图的高度'
- en: '![](6b7ff93.png): The width of the output activation map'
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](6b7ff93.png)：输出激活图的宽度'
- en: 1x1 Convolution
  id: totrans-876
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1x1卷积
- en: '* * *'
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This type if convolution is normally used to adapt depths, by merging them,
    without changing the spatial information.
  id: totrans-878
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的卷积通常用于调整深度，通过合并它们而不改变空间信息。
- en: Substituting Big convolutions
  id: totrans-879
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替换大卷积
- en: '* * *'
  id: totrans-880
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here we explain what is the effect of cascading several small convolutions,
    on the diagram bellow we have 2 3x3 convolution layers. If you start from the
    second layer on the right, one neuron on the second layer, has a 3x3 receptive
    field, and each neuron on the first layer create a 5x5 receptive field on the
    input.
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们解释了级联几个小卷积的效果，在下面的图表中，我们有2个3x3卷积层。如果从最右边的第二层开始，第二层上的一个神经元具有3x3的感受野，而第一层上的每个神经元在输入上创建一个5x5的感受野。
- en: So in simpler words cascading can be used to represent bigger ones.
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: 所以简单地说，级联可以用来表示更大的卷积。
- en: '![](CascadingConvolutions.png)'
  id: totrans-883
  prefs: []
  type: TYPE_IMG
  zh: '![](CascadingConvolutions.png)'
- en: The new trend on new successful models is to use smaller convolutions, for example
    a 7x7 convolution can be substituted with 3 3x3 convolutions with the same depth.
    This substitution cannot be done on the first conv layer due to the depth mismatch
    between the first conv layer and the input file depth (Unless if your first layer
    has only 3 filters).
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: 新成功模型的新趋势是使用更小的卷积，例如，一个 7x7 卷积可以被同样深度的 3 个 3x3 卷积替代。由于第一个卷积层和输入文件深度之间的深度不匹配（除非您的第一层只有
    3 个滤波器），因此无法在第一卷积层上进行此替换。
- en: '![](ConvLayer.png)'
  id: totrans-885
  prefs: []
  type: TYPE_IMG
  zh: '![](ConvLayer.png)'
- en: On the diagram above we substitute one 7x7 convolution by 3 3x3 convolutions,
    observe that between them we have relu layers, so we have more non-linearities.
    Also we have less weights and multiply-add operations so it will be faster to
    compute.
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，我们用 3 个 3x3 卷积代替了一个 7x7 卷积，注意它们之间有 relu 层，所以我们有更多的非线性。此外，我们有更少的权重和乘加操作，所以计算速度会更快。
- en: Calculating the substitution of a 7x7 convolution
  id: totrans-887
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算 7x7 卷积的替换
- en: 'Imagine a 7x7 convolution, with C filters, being used on a input volume WxHxC
    we can calculate the number of weights as:'
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，一个 7x7 卷积，有 C 个滤波器，被用在一个输入体积 WxHxC 上，我们可以计算权重的数量为：
- en: '![](d1009d9b.png)'
  id: totrans-889
  prefs: []
  type: TYPE_IMG
  zh: '![](d1009d9b.png)'
- en: Now if we use 3 3x3 convolutions with C filters, we would have
  id: totrans-890
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果我们使用 3 个带有 C 个滤波器的 3x3 卷积，我们会得到
- en: '![](f12a1879.png)'
  id: totrans-891
  prefs: []
  type: TYPE_IMG
  zh: '![](f12a1879.png)'
- en: We still have less parameters, as we need to use Relu between the layers to
    break the linearity (otherwise the conv layers in cascade will appear as a single
    3x3 layer) we have more non-linearity, less parameters, and more performance.
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然有更少的参数，因为我们需要在层之间使用 Relu 打破线性（否则级联的卷积层将表现为单个 3x3 层），我们有更多的非线性，更少的参数和更好的性能。
- en: Substitution on the first layer
  id: totrans-893
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对第一层的替换
- en: '* * *'
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As mentioned before, we cannot substitute large convolutions on the first layer.
    Actually small convolutions on the first layer cause a memory consume explosion.
  id: totrans-895
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们不能在第一层上替换大的卷积。事实上，第一层上的小卷积会导致内存消耗的激增。
- en: To illustrate the problem let's compare the first layer of a convolution neural
    network as been 3x3 with 64 filters and stride of 1 and the same depth with 7x7
    and stride of 2, consider the image size to be 256x256x3.
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明问题，让我们比较一个卷积神经网络的第一层，一个是 3x3 的，有 64 个滤波器，步幅为 1，另一个是深度相同，但是是 7x7 的，步幅为 2，考虑图像大小为
    256x256x3。
- en: '![](6843150f.png)'
  id: totrans-897
  prefs: []
  type: TYPE_IMG
  zh: '![](6843150f.png)'
- en: 'TODO: How the stride and convolution size affect the memory consumption'
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: TODO：步幅和卷积大小如何影响内存消耗
- en: Continuing on 3x3 substitution (Bottleneck)
  id: totrans-899
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 继续进行 3x3 替换（瓶颈）
- en: '* * *'
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: It's also possible to simplify the 3x3 convolution with a mechanism called bottleneck.
    This again will have the same representation of a normal 3x3 convolution but with
    less parameters, and more non-linearities.
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以通过称为瓶颈的机制简化 3x3 卷积。这将再次以普通 3x3 卷积的方式表示，但参数较少，非线性更多。
- en: Observe that the substitution is made on the 3x3 convolution that has the same
    depth as the previous layer (On this case 50x50x64)
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，替换是在与上一层相同深度的 3x3 卷积上进行的（在这种情况下是 50x50x64）
- en: '![](Conv_Bottleneck.png)'
  id: totrans-903
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv_Bottleneck.png)'
- en: Here we calculate how much parameters we use on the bottleneck, remember that
    on 3x3 is ![](3251489b.png)
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们计算了我们在瓶颈上使用了多少参数，记住，在 3x3 上是![](3251489b.png)
- en: '![](Botleneck_Calc.PNG)'
  id: totrans-905
  prefs: []
  type: TYPE_IMG
  zh: '![](Botleneck_Calc.PNG)'
- en: So the bottleneck uses ![](b94f9821.png), which is less.
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 因此瓶颈使用的是![](b94f9821.png)，这个值较小。
- en: The bottleneck is also used on microsoft residual network.
  id: totrans-907
  prefs: []
  type: TYPE_NORMAL
  zh: 瓶颈也被用在微软的残差网络中。
- en: '![](ResnetBottleneck.jpg)'
  id: totrans-908
  prefs: []
  type: TYPE_IMG
  zh: '![](ResnetBottleneck.jpg)'
- en: Another option to break 3x3xC convolutions is to use 1x3xC, then 3x1xC, this
    has been used on residual googlenet inception layer.
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: 打破 3x3xC 卷积的另一个选择是使用 1x3xC，然后是 3x1xC，这在残差 googlenet inception 层中已经被使用。
- en: '![](Subs_3x3.PNG)'
  id: totrans-910
  prefs: []
  type: TYPE_IMG
  zh: '![](Subs_3x3.PNG)'
- en: '![](NewInception.PNG)'
  id: totrans-911
  prefs: []
  type: TYPE_IMG
  zh: '![](NewInception.PNG)'
- en: FC -> Conv Layer Conversion
  id: totrans-912
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FC -> 卷积层转换
- en: '* * *'
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: It's possible to convert Fully connected layers to convolution layers and vice-versa,
    but we are more interest on the FC->Conv conversion. This is done to improve performance.
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: 完全连接的层和卷积层之间可以相互转换，但我们更感兴趣的是 FC->Conv 转换。这是为了提高性能。
- en: 'For example imagine a FC layer with output K=4096 and input 7x7x512, the conversion
    would be:'
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一个 FC 层，输出 K=4096 和输入 7x7x512，转换将是：
- en: 'CONV: Kernel:7x7, Pad:0, Stride:1, numFilters:4096.'
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
  zh: CONV：Kernel:7x7，Pad:0，Stride:1，numFilters:4096。
- en: 'Using the 2d convolution formula size: ![](26d0dd.png), which will be 1x1x4096.'
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 2D 卷积公式大小：![](26d0dd.png)，将是 1x1x4096。
- en: 'In resume what you gain by converting the FC layers to convolution:'
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，将 FC 层转换为卷积层所获得的好处：
- en: 'Performance: It''s faster to compute due to the weight sharing'
  id: totrans-919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能：由于权重共享，计算速度更快
- en: You can use images larger than the ones that you trained, without changing nothing
  id: totrans-920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用比您训练的图像更大的图像，而不需要更改任何内容
- en: You will be able to detect 2 objects on the same image (If you use a bigger
    image) your final output will be bigger then a single row vector.
  id: totrans-921
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您将能够在同一图像上检测到2个对象（如果您使用更大的图像），您的最终输出将比单个行向量更大。
- en: '![](MultipleCharacters.gif)'
  id: totrans-922
  prefs: []
  type: TYPE_IMG
  zh: '![](MultipleCharacters.gif)'
- en: Next Chapter
  id: totrans-923
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: Next chapter we will learn about Fully Connected layers.
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习关于全连接层的知识。
- en: Fully Connected Layer
  id: totrans-925
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全连接层
- en: Fully Connected Layer
  id: totrans-926
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全连接层
- en: Introduction
  id: totrans-927
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This chapter will explain how to implement in matlab and python the fully connected
    layer, including the forward and back-propagation.
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将解释如何在 matlab 和 python 中实现全连接层，包括前向传播和反向传播。
- en: '![](FullyConnectedLayer.png)'
  id: totrans-930
  prefs: []
  type: TYPE_IMG
  zh: '![](FullyConnectedLayer.png)'
- en: 'First consider the fully connected layer as a black box with the following
    properties: On the forward propagation'
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
  zh: 首先将全连接层视为具有以下特性的黑匣子：在前向传播中
- en: Has 3 inputs (Input signal, Weights, Bias)
  id: totrans-932
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有3个输入（输入信号，权重，偏置）
- en: Has 1 output
  id: totrans-933
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有1个输出
- en: On the back propagation
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播中
- en: Has 1 input (dout) which has the same size as output
  id: totrans-935
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有1个输入（dout），与输出大小相同
- en: Has 3 (dx,dw,db) outputs, that has the same size as the inputs
  id: totrans-936
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有3个（dx，dw，db）输出，与输入的大小相同
- en: Neural network point of view
  id: totrans-937
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从神经网络的角度来看
- en: '* * *'
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](FC_Layer_NN.png)'
  id: totrans-939
  prefs: []
  type: TYPE_IMG
  zh: '![](FC_Layer_NN.png)'
- en: 'Just by looking the diagram we can infer the outputs:'
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: 仅通过查看图表，我们就可以推断出输出：
- en: '![](ce09aba1.png)'
  id: totrans-941
  prefs: []
  type: TYPE_IMG
  zh: '![](ce09aba1.png)'
- en: 'Now vectorizing (put on matrix form): (Observe 2 possible versions)'
  id: totrans-942
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进行向量化（转换为矩阵形式）：（观察2种可能的版本）
- en: '![](9e63ed7d.png)'
  id: totrans-943
  prefs: []
  type: TYPE_IMG
  zh: '![](9e63ed7d.png)'
- en: Depending on the format that you choose to represent W attention to this because
    it can be confusing.
  id: totrans-944
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您选择表示 W 的格式，要注意这一点，因为可能会令人困惑。
- en: 'For example if we choose X to be a column vector, our matrix multiplication
    must be:'
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们选择 X 为列向量，则我们的矩阵乘法必须是：
- en: '![](109a7901.png)'
  id: totrans-946
  prefs: []
  type: TYPE_IMG
  zh: '![](109a7901.png)'
- en: Computation graph point of view
  id: totrans-947
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从计算图的角度来看
- en: '* * *'
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In order to discover how each input influence the output (backpropagation) is
    better to represent the algorithm as a computation graph.
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: 为了发现每个输入如何影响输出（反向传播），最好将算法表示为计算图。
- en: '![](Graph_Fully_Connected_Layer.png)'
  id: totrans-950
  prefs: []
  type: TYPE_IMG
  zh: '![](Graph_Fully_Connected_Layer.png)'
- en: Now for the backpropagation let's focus in one of the graphs, and apply what
    we learned so far on backpropagation.
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对于反向传播，让我们专注于其中一个图表，并应用到目前为止学到的关于反向传播的知识。
- en: '![](Graph_Fully_Connected_Layer_Backprop.png)'
  id: totrans-952
  prefs: []
  type: TYPE_IMG
  zh: '![](Graph_Fully_Connected_Layer_Backprop.png)'
- en: Summarizing the calculation for the first output (y1), consider a global error
    L(loss) and ![](6b7d96f4.png)
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: 总结计算第一个输出（y1），考虑全局误差 L（损失）和 ![](6b7d96f4.png)
- en: '![](a0d260d8.png)'
  id: totrans-954
  prefs: []
  type: TYPE_IMG
  zh: '![](a0d260d8.png)'
- en: '![](3f51c64e.png)'
  id: totrans-955
  prefs: []
  type: TYPE_IMG
  zh: '![](3f51c64e.png)'
- en: '![](34f8377a.png)'
  id: totrans-956
  prefs: []
  type: TYPE_IMG
  zh: '![](34f8377a.png)'
- en: Also extending to the second output (y2)
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: 还扩展到第二个输出（y2）
- en: '![](c78583bb.png)'
  id: totrans-958
  prefs: []
  type: TYPE_IMG
  zh: '![](c78583bb.png)'
- en: '![](468a2295.png)'
  id: totrans-959
  prefs: []
  type: TYPE_IMG
  zh: '![](468a2295.png)'
- en: '![](51bc5114.png)'
  id: totrans-960
  prefs: []
  type: TYPE_IMG
  zh: '![](51bc5114.png)'
- en: 'Merging the results, for dx:'
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: 合并结果，对于 dx：
- en: '![](d269dc97.png)'
  id: totrans-962
  prefs: []
  type: TYPE_IMG
  zh: '![](d269dc97.png)'
- en: On the matrix form
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: 在矩阵形式中
- en: '![](7f5d0677.png), or ![](3fe949c9.png).'
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: '![](7f5d0677.png)，或者 ![](3fe949c9.png)。'
- en: Depending on the format that you choose to represent X (as a row or column vector),
    attention to this because it can be confusing.
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您选择表示 X（作为行向量或列向量）的格式，要注意这一点，因为可能会令人困惑。
- en: 'Now for dW It''s important to not that every gradient has the same dimension
    as it''s original value, for instance dW has the same dimension as W, in other
    words:'
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对于 dW，重要的是要注意每个梯度与其原始值具有相同的维度，例如 dW 与 W 具有相同的维度，换句话说：
- en: '![](db7dc2ed.png)'
  id: totrans-967
  prefs: []
  type: TYPE_IMG
  zh: '![](db7dc2ed.png)'
- en: '![](fca2e763.png)'
  id: totrans-968
  prefs: []
  type: TYPE_IMG
  zh: '![](fca2e763.png)'
- en: And dB ![](c88de6e2.png)
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 dB ![](c88de6e2.png)
- en: Expanding for bigger batches
  id: totrans-970
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展为更大的批次
- en: '* * *'
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: All the examples so far, deal with single elements on the input, but normally
    we deal with much more than one example at a time. For instance on GPUs is common
    to have batches of 256 images at the same time. The trick is to represent the
    input signal as a 2d matrix [NxD] where N is the batch size and D the dimensions
    of the input signal. So if you consider the CIFAR dataset where each digit is
    a 28x28x1 (grayscale) image D will be 784, so if we have 10 digits on the same
    batch our input will be [10x784].
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有的例子都处理了输入中的单个元素，但通常我们一次处理的例子远远不止一个。例如，在GPU上同时处理256张图像是很常见的。关键是将输入信号表示为一个2d矩阵[NxD]，其中N是批量大小，D是输入信号的维度。因此，如果考虑CIFAR数据集，其中每个数字是一个28x28x1（灰度）图像，D将是784，所以如果我们在同一个批次中有10个数字，我们的输入将是[10x784]。
- en: 'For the sake of argument, let''s consider our previous samples where the vector
    X was represented like ![](8a28794f.png), if we want to have a batch of 4 elements
    we will have:'
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: 为了论证起见，让我们考虑之前的样本，其中向量X被表示为 ![](8a28794f.png)，如果我们想要有一个包含4个元素的批次，我们将有：
- en: '![](4ffc17e6.png)'
  id: totrans-974
  prefs: []
  type: TYPE_IMG
  zh: '![](4ffc17e6.png)'
- en: In this case W must be represented in a way that support this matrix multiplication,
    so depending how it was created it may need to be transposed
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，W必须以支持这种矩阵乘法的方式表示，因此取决于它是如何创建的，可能需要转置
- en: '![](eaba624a.png)'
  id: totrans-976
  prefs: []
  type: TYPE_IMG
  zh: '![](eaba624a.png)'
- en: 'Continuing the forward propagation will be computed as:'
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
  zh: 继续进行前向传播的计算如下：
- en: '![](3c17fe53.png)'
  id: totrans-978
  prefs: []
  type: TYPE_IMG
  zh: '![](3c17fe53.png)'
- en: One point to observe here is that the bias has repeated 4 times to accommodate
    the product X.W that in this case will generate a matrix [4x2]. On matlab the
    command "repmat" does the job. On python it does automatically.
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的一点是，偏置重复了4次以适应在这种情况下生成一个矩阵[4x2]的乘积X.W。在matlab中，命令"repmat"可以完成这项工作。在python中则会自动完成。
- en: '![](MatlabRepmat.PNG)'
  id: totrans-980
  prefs: []
  type: TYPE_IMG
  zh: '![](MatlabRepmat.PNG)'
- en: Using Symbolic engine
  id: totrans-981
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用符号引擎
- en: '* * *'
  id: totrans-982
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Before jumping to implementation is good to verify the operations on Matlab
    or Python (sympy) symbolic engine. This will help visualize and explore the results
    before acutally coding the functions.
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
  zh: 在跳入实现之前，最好在matlab或python（sympy）符号引擎上验证操作。这将有助于在实际编写函数之前可视化和探索结果。
- en: Symbolic forward propagation on Matlab
  id: totrans-984
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab上的符号前向传播
- en: '* * *'
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here after we defined the variables which will be symbolic, we create the matrix
    W,X,b then calculate ![](c5476bc3.png), compare the final result with what we
    calculated before.
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们定义了将是符号的变量之后，我们创建矩阵W、X、b，然后计算 ![](c5476bc3.png)，将最终结果与我们之前计算的结果进行比较。
- en: '![](SymbForwardMatlab.PNG)'
  id: totrans-987
  prefs: []
  type: TYPE_IMG
  zh: '![](SymbForwardMatlab.PNG)'
- en: Symbolic backward propagation on Matlab
  id: totrans-988
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab上的符号反向传播
- en: '* * *'
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now we also confirm the backward propagation formulas. Observe the function
    "latex" that convert an expression to latex on matlab
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们也确认了反向传播的公式。注意函数"latex"将一个表达式转换为matlab上的latex
- en: '![](SymbBackwardMatlab.PNG) Here I''ve just copy and paste the latex result
    of dW or " ![](a06dcfa1.png) " from matlab'
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: '![](SymbBackwardMatlab.PNG) 这里我只是复制并粘贴了来自matlab的dW或" ![](a06dcfa1.png) "的latex结果'
- en: '![](d485c17d.png)'
  id: totrans-992
  prefs: []
  type: TYPE_IMG
  zh: '![](d485c17d.png)'
- en: Input Tensor
  id: totrans-993
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入张量
- en: '* * *'
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our library will be handling images, and most of the time we will be handling
    matrix operations on hundreds of images at the same time. So we must find a way
    to represent them, here we will represent batch of images as a 4d tensor, or an
    array of 3d matrices. Bellow we have a batch of 4 rgb images (width:160, height:120).
    We're going to load them on matlab/python and organize them one a 4d matrix
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的库将处理图像，并且大部分时间我们将同时处理数百张图像的矩阵操作。因此，我们必须找到一种表示它们的方法，在这里我们将批量图像表示为一个4d张量，或者是一个3d矩阵的数组。下面是一个包含4个rgb图像（宽度：160，高度：120）的批量。我们将在matlab/python中加载它们并将它们组织成一个4d矩阵
- en: '![](ImgsBatch.png)'
  id: totrans-996
  prefs: []
  type: TYPE_IMG
  zh: '![](ImgsBatch.png)'
- en: Observe that in matlab the image becomes a matrix 120x160x3\. Our tensor will
    be 120x160x3x4 ![](MatlabLoadImages.png)
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在matlab中，图像变成了一个矩阵120x160x3。我们的张量将是120x160x3x4 ![](MatlabLoadImages.png)
- en: On Python before we store the image on the tensor we do a transpose to convert
    out image 120x160x3 to 3x120x160, then to store on a tensor 4x3x120x160
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，在将图像存储到张量之前，我们进行了转置，将我们的图像120x160x3转换为3x120x160，然后存储到一个张量4x3x120x160中
- en: '![](PythonLoadImages.png)'
  id: totrans-999
  prefs: []
  type: TYPE_IMG
  zh: '![](PythonLoadImages.png)'
- en: Python Implementation
  id: totrans-1000
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python实现
- en: Forward Propagation
  id: totrans-1001
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 前向传播
- en: '* * *'
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Python_FC_Forward.png)'
  id: totrans-1003
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_FC_Forward.png)'
- en: Backward Propagation
  id: totrans-1004
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反向传播
- en: '* * *'
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Python_FC_Backward.png)'
  id: totrans-1006
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_FC_Backward.png)'
- en: Matlab Implementation
  id: totrans-1007
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Matlab实现
- en: '* * *'
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: One special point to pay attention is the way that matlab represent high-dimension
    arrays in contrast with matlab. Also another point that may cause confusion is
    the fact that matlab represent data on col-major order and numpy on row-major
    order.
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
  zh: 要特别注意 Matlab 与 Python 在表示高维数组方面的方式。还有一个可能会引起混淆的点是，Matlab 将数据表示为列主序，而 numpy 则为行主序。
- en: '![](Row_Col_Major.jpg)'
  id: totrans-1010
  prefs: []
  type: TYPE_IMG
  zh: '![](Row_Col_Major.jpg)'
- en: Multidimensional arrays in python and matlab
  id: totrans-1011
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 和 Matlab 中的多维数组
- en: '* * *'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](MultiMatlabArray.png)'
  id: totrans-1013
  prefs: []
  type: TYPE_IMG
  zh: '![](MultiMatlabArray.png)'
- en: One difference on how matlab and python represent multidimensional arrays must
    be noticed. We want to create a 4 channel matrix 2x3\. So in matlab you need to
    create a array (2,3,4) and on python it need to be (4,2,3)
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: 必须注意 Matlab 和 Python 表示多维数组的一点差异。我们想要创建一个 2x3 的 4 通道矩阵。因此，在 Matlab 中，您需要创建一个数组
    (2,3,4)，在 Python 中，它需要是 (4,2,3)。
- en: '![](Matlab_MultiDim.png)'
  id: totrans-1015
  prefs: []
  type: TYPE_IMG
  zh: '![](Matlab_MultiDim.png)'
- en: Matlab Reshape order
  id: totrans-1016
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab 重塑顺序
- en: '* * *'
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As mentioned before matlab will run the command reshape one column at a time,
    so if you want to change this behavior you need to transpose first the input matrix.
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，Matlab 将按列一次重塑一列，因此如果您想更改此行为，您需要首先转置输入矩阵。
- en: '![](Matlab_Reshape.png)'
  id: totrans-1019
  prefs: []
  type: TYPE_IMG
  zh: '![](Matlab_Reshape.png)'
- en: If you are dealing with more than 2 dimensions you need to use the "permute"
    command to transpose. Now on Python the default of the reshape command is one
    row at a time, or if you want you can also change the order (This options does
    not exist in matlab)
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您处理的是多于 2 个维度的情况，您需要使用 "permute" 命令进行转置。现在在 Python 中，reshape 命令的默认值是一次一行，或者如果您愿意，您也可以更改顺序（在
    Matlab 中不存在此选项）。
- en: '![](Python_Reshape.png)'
  id: totrans-1021
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_Reshape.png)'
- en: 'Bellow we have a reshape on the row-major order as a new function:'
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们将按行主序重塑为一个新函数：
- en: '![](Matlab_reshape_row.png)'
  id: totrans-1023
  prefs: []
  type: TYPE_IMG
  zh: '![](Matlab_reshape_row.png)'
- en: 'The other option would be to avoid this permutation reshape is to have the
    weight matrix on a different order and calculate the forward propagation like
    this:'
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
  zh: 避免这种排列重塑的另一种选择是将权重矩阵放在不同的顺序上，并像这样计算前向传播：
- en: '![](20ffcef4.png)'
  id: totrans-1025
  prefs: []
  type: TYPE_IMG
  zh: '![](20ffcef4.png)'
- en: With x as a column vector and the weights organized row-wise, on the example
    that is presented we keep using the same order as the python example.
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
  zh: 当 x 作为列向量而权重按行组织时，在所展示的例子中，我们保持与 Python 示例相同的顺序。
- en: Forward Propagation
  id: totrans-1027
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 前向传播
- en: '* * *'
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Matlab_Forward.png)'
  id: totrans-1029
  prefs: []
  type: TYPE_IMG
  zh: '![](Matlab_Forward.png)'
- en: Backward Propagation
  id: totrans-1030
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反向传播
- en: '* * *'
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Matlab_Backward.png)'
  id: totrans-1032
  prefs: []
  type: TYPE_IMG
  zh: '![](Matlab_Backward.png)'
- en: Next Chapter
  id: totrans-1033
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Next chapter we will learn about Relu layers
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习关于 ReLU 层的内容
- en: Relu Layer
  id: totrans-1036
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ReLU 层
- en: Rectified-Linear unit Layer
  id: totrans-1037
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整流线性单元层
- en: Introduction
  id: totrans-1038
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We will start this chapter explaining how to implement in Python/Matlab the
    ReLU layer.
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从解释如何在 Python/Matlab 中实现 ReLU 层开始。
- en: '![](ReluLayer.png)'
  id: totrans-1041
  prefs: []
  type: TYPE_IMG
  zh: '![](ReluLayer.png)'
- en: In simple words, the ReLU layer will apply the function ![](13304fde.png) in
    all elements on a input tensor, without changing it's spatial or depth information.
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，ReLU 层将在输入张量的所有元素上应用函数 ![](13304fde.png)，而不改变其空间或深度信息。
- en: '![](ReluMatlabSimpleExample.png) ![](Relu.jpeg)'
  id: totrans-1043
  prefs: []
  type: TYPE_IMG
  zh: '![](ReluMatlabSimpleExample.png) ![](Relu.jpeg)'
- en: From the picture above, observe that all positive elements remain unchanged
    while the negatives become zero. Also the spatial information and depth are the
    same.
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: 从上图可以看出，所有正元素保持不变，而负元素变为零。同时空间信息和深度信息保持不变。
- en: 'Thinking about neural networks, it''s just a new type of Activation function,
    but with the following features:'
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑神经网络，这只是一种新型的激活函数，但具有以下特征：
- en: Easy to compute (forward/backward propagation)
  id: totrans-1046
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容易计算（前向/反向传播）
- en: Suffer much less from vanishing gradient on deep models
  id: totrans-1047
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在深度模型上遭受的梯度消失要少得多
- en: A bad point is that they can irreversibly die if you use a big learning rate
  id: totrans-1048
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不好的一点是，如果你使用较大的学习率，它们可能会不可逆地死亡。
- en: Forward propagation
  id: totrans-1049
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向传播
- en: '* * *'
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Change all negative elements to zero while retaining the value of the positive
    elements. No spatial/depth information is changed.
  id: totrans-1051
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有负元素更改为零，同时保留正元素的值。不改变空间/深度信息。
- en: Python forward propagation
  id: totrans-1052
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 前向传播
- en: '* * *'
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Python_forward_relu.png)'
  id: totrans-1054
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_forward_relu.png)'
- en: Matlab forward propagation
  id: totrans-1055
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab 前向传播
- en: '* * *'
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Backward propagation
  id: totrans-1057
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播
- en: '* * *'
  id: totrans-1058
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Basically we're just applying the max(0,x) function to every ![](bbe484e5.png)
    input element. From the back-propagation chapter we can notice that the gradient
    dx will be zero if the element ![](aa4b6abf.png)is negative or ![](8166a298.png)
    if the element is positive.
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们只是对每个 ![](bbe484e5.png) 输入元素应用 max(0,x) 函数。从反向传播章节我们可以注意到，如果元素 ![](aa4b6abf.png)
    是负数，则梯度 dx 为零，如果元素为正数，则梯度为 ![](8166a298.png)。
- en: '![](ReluGraph.png)'
  id: totrans-1060
  prefs: []
  type: TYPE_IMG
  zh: '![](ReluGraph.png)'
- en: Python backward propagation
  id: totrans-1061
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 反向传播
- en: '* * *'
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Python_ReLU_Backward_Propagation.png)'
  id: totrans-1063
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_ReLU_Backward_Propagation.png)'
- en: Next Chapter
  id: totrans-1064
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Next chapter we will learn about Dropout layers
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习关于丢弃层的内容
- en: Dropout Layer
  id: totrans-1067
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 丢弃层
- en: Dropout Layer
  id: totrans-1068
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 丢弃层
- en: Introduction
  id: totrans-1069
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: '* * *'
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Dropout is a technique used to improve over-fit on neural networks, you should
    use Dropout along with other techniques like L2 Regularization.
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Dropout 是一种用于改善神经网络过拟合的技术，你应该与其他技术（如 L2 正则化）一起使用 Dropout。
- en: '![](DropoutLayers.png)'
  id: totrans-1072
  prefs: []
  type: TYPE_IMG
  zh: '![](DropoutLayers.png)'
- en: Bellow we have a classification error (Not including loss), observe that the
    test/validation error is smaller using dropout
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个分类错误（不包括损失），请注意使用丢弃时测试/验证错误更小。
- en: '![](With_Without_Dropout.png)'
  id: totrans-1074
  prefs: []
  type: TYPE_IMG
  zh: '![](With_Without_Dropout.png)'
- en: As other regularization techniques the use of dropout also make the training
    loss error a little worse. But that's the idea, basically we want to trade training
    performance for more generalization. Remember that's more capacity you add on
    your model (More layers, or more neurons) more prone to over-fit it becomes.
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他正则化技术一样，使用丢弃也会使训练损失略有恶化。但这就是我们想要的，基本上我们想要用训练性能换取更好的泛化性能。记住，你的模型越强大（更多层次或更多神经元），它就越容易过拟合。
- en: Bellow we have a plot showing both training, and validation loss with and without
    dropout
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们有一个绘制图，显示了带有丢弃和不带丢弃的训练和验证损失
- en: '![](dropout_loss_val_train.jpeg)'
  id: totrans-1077
  prefs: []
  type: TYPE_IMG
  zh: '![](dropout_loss_val_train.jpeg)'
- en: How it works
  id: totrans-1078
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理
- en: '* * *'
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Basically during training half of neurons on a particular layer will be deactivated.
    This improve generalization because force your layer to learn with different neurons
    the same "concept".
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，在训练期间，特定层上一半的神经元将被停用。这样做可以提高泛化能力，因为它迫使你的层使用不同的神经元来学习相同的 "概念"。
- en: During the prediction phase the dropout is deactivated.
  id: totrans-1081
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测阶段，丢弃是停用的。
- en: '![](dropout.jpeg)'
  id: totrans-1082
  prefs: []
  type: TYPE_IMG
  zh: '![](dropout.jpeg)'
- en: Where to use Dropout layers
  id: totrans-1083
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用丢弃层
- en: '* * *'
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Normally some deep learning models use Dropout on the fully connected layers,
    but is also possible to use dropout after the max-pooling layers, creating some
    kind of image noise augmentation.
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
  zh: 通常一些深度学习模型在全连接层之后使用 Dropout，但也可以在最大池化层之后使用丢弃，从而创建某种图像噪声增强。
- en: Implementation
  id: totrans-1086
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: '* * *'
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In order to implement this neuron deactivation, we create a mask(zeros and ones)
    during forward propagation. This mask is applied to the layer outputs during training
    and cached for future use on back-propagation. As explained before this dropout
    mask is used only during training.
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这种神经元停用，我们在前向传播期间创建一个掩码（零和一）。这个掩码在训练期间应用于层输出，并缓存以供未来的反向传播使用。如前所述，这个丢弃掩码仅在训练期间使用。
- en: 'On the backward propagation we''re interested on the neurons that was activated
    (we need to save mask from forward propagation). Now with those neurons selected
    we just back-propagate dout. The dropout layer has no learnable parameters, just
    it''s input (X). During back-propagation we just return "dx". In other words:
    ![](a6e8a0fe.png)'
  id: totrans-1089
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播中，我们对被激活的神经元感兴趣（我们需要保存来自前向传播的掩码）。现在，有了这些选择的神经元，我们只需反向传播 dout。丢弃层没有可学习的参数，只有它的输入（X）。在反向传播期间，我们只返回
    "dx"。换句话说：![](a6e8a0fe.png)
- en: Python Forward propagation
  id: totrans-1090
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 正向传播
- en: '* * *'
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](dropout_forward_python_code.png)'
  id: totrans-1092
  prefs: []
  type: TYPE_IMG
  zh: '![](dropout_forward_python_code.png)'
- en: Python Backward propagation
  id: totrans-1093
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 反向传播
- en: '* * *'
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](dropout_backward_python_code.png)'
  id: totrans-1095
  prefs: []
  type: TYPE_IMG
  zh: '![](dropout_backward_python_code.png)'
- en: Next Chapter
  id: totrans-1096
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1097
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Next chapter we will learn about Convolution layer
  id: totrans-1098
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习关于卷积层的内容
- en: Convolution Layer
  id: totrans-1099
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积层
- en: Convolution Layer
  id: totrans-1100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积层
- en: Introduction
  id: totrans-1101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: '* * *'
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This chapter will explain how to implement the convolution layer on python and
    matlab.
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将解释如何在 Python 和 Matlab 中实现卷积层。
- en: '![](ConvolutionLayer.png)'
  id: totrans-1104
  prefs: []
  type: TYPE_IMG
  zh: '![](ConvolutionLayer.png)'
- en: 'In simple terms the convolution layer, will apply the convolution operator
    on all images on the input tensor, and also transform the input depth to match
    the number of filters. Bellow we explain it''s parameters and signals:'
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，卷积层将在输入张量的所有图像上应用卷积运算符，并且还将转换输入深度以匹配滤波器的数量。下面我们解释它的参数和信号：
- en: 'N: Batch size (Number of images on the 4d tensor)'
  id: totrans-1106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: N：批量大小（4D 张量上的图像数量）
- en: 'F: Number of filters on the convolution layer'
  id: totrans-1107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: F：卷积层上的滤波器数量
- en: 'kW/kH: Kernel Width/Height (Normally we use square images, so kW=kH)'
  id: totrans-1108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: kW/kH：核宽度/高度（通常我们使用方形图像，所以 kW=kH）
- en: 'H/W: Image height/width (Normally H=W)'
  id: totrans-1109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H/W：图像高度/宽度（通常 H=W）
- en: 'H''/W'': Convolved image height/width (Remains the same as input if proper
    padding is used)'
  id: totrans-1110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: H'/W'：卷积后的图像高度/宽度（如果使用适当的填充，则与输入大小相同）
- en: 'Stride: Number of pixels that the convolution sliding window will travel.'
  id: totrans-1111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Stride：卷积滑动窗口将移动的像素数量。
- en: 'Padding: Zeros added to the border of the image to keep the input and output
    size the same.'
  id: totrans-1112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填充：添加到图像边界的零以保持输入和输出大小相同。
- en: 'Depth: Volume input depth (ie if the input is a RGB image depth will be 3)'
  id: totrans-1113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度：体积输入深度（如果输入是RGB图像，则深度将为3）
- en: 'Output depth: Volume output depth (same as F)'
  id: totrans-1114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出深度：体积输出深度（与 F 相同）
- en: Forward propagation
  id: totrans-1115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向传播
- en: '* * *'
  id: totrans-1116
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On the forward propagation, you must remember, that we're going to "convolve"
    each input depth with a different filter, and each filter will look for something
    different on the image.
  id: totrans-1117
  prefs: []
  type: TYPE_NORMAL
  zh: 在前向传播中，你必须记住，我们将使用不同的滤波器对每个输入深度进行“卷积”，而每个滤波器将在图像上寻找不同的内容。
- en: '![](filters_per_layer.png)'
  id: totrans-1118
  prefs: []
  type: TYPE_IMG
  zh: '![](filters_per_layer.png)'
- en: Here observe that all neurons(flash-lights) from layer 1 share the same set
    of weights, other filters will look for different patterns on the image.
  id: totrans-1119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里注意到第1层的所有神经元（闪光灯）共享相同的权重，其他滤波器将在图像上寻找不同的模式。
- en: Matlab Forward propagation
  id: totrans-1120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab 前向传播
- en: '* * *'
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Basically we can consider the previous "convn_vanilla" function on the [Convolution
    chapter](convolution_split_000.html) and apply for each depth on the input and
    output.
  id: totrans-1122
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们可以考虑之前在[卷积章节](convolution_split_000.html)中介绍的“convn_vanilla”函数，并应用于输入和输出上的每个深度。
- en: '![](Matlab_Forward_CONV.png)'
  id: totrans-1123
  prefs: []
  type: TYPE_IMG
  zh: '![](Matlab_Forward_CONV.png)'
- en: Python Forward propagation
  id: totrans-1124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 前向传播
- en: '* * *'
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The only point to observe here is that due to the way the multidimensional arrays
    are represented in python our tensors will have different order.
  id: totrans-1126
  prefs: []
  type: TYPE_NORMAL
  zh: 这里唯一需要注意的一点是，由于 Python 中多维数组的表示方式，我们的张量将具有不同的顺序。
- en: '![](Python_Forward_CONV.png)'
  id: totrans-1127
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_Forward_CONV.png)'
- en: Back-propagation
  id: totrans-1128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播
- en: '* * *'
  id: totrans-1129
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In order to derive the convolution layer back-propagation it's easier to think
    on the 1d convolution, the results will be the same for 2d.
  id: totrans-1130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了推导卷积层的反向传播，更容易考虑一维卷积，结果对于二维是相同的。
- en: So doing a 1d convolution, between a signal ![](666fe02f.png) and ![](678ee8ba.png),
    and without padding we will have ![](e271041e.png), where ![](a751091f.png). Here
    flip can be consider as a 180 degrees rotation.
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: 因此进行一维卷积，信号 ![](666fe02f.png) 和 ![](678ee8ba.png) 之间，且不使用填充，我们将得到 ![](e271041e.png)，其中
    ![](a751091f.png)。这里“flip”可以被视为180度旋转。
- en: '![](Conv1d_Manual_symbolic.png)'
  id: totrans-1132
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv1d_Manual_symbolic.png)'
- en: Now we convert all the "valid cases" to a computation graph, observe that for
    now we're adding the bias because it is used on the convolution layer.
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将所有“有效情况”转换为计算图，注意到我们现在正在添加偏差，因为它在卷积层中被使用。
- en: Observe that the graphs are basically the same as the fully connected layer,
    the only difference is that we have shared weights.
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些图表基本上与完全连接的层相同，唯一的区别在于我们有共享权重。
- en: '![](Simple_1d_Conv_Bias.png)'
  id: totrans-1135
  prefs: []
  type: TYPE_IMG
  zh: '![](Simple_1d_Conv_Bias.png)'
- en: Now changing to the back-propagation
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在转到反向传播
- en: '![](Simple_1d_Conv_Back.png)'
  id: totrans-1137
  prefs: []
  type: TYPE_IMG
  zh: '![](Simple_1d_Conv_Back.png)'
- en: If you follow the computation graphs backward, as was presented on the [Backpropagation
    chapter](backpropagation_split_000.html) we will have the following formulas for
    ![](a537b4ba.png), which means how the loss will change with the input X ![](5b05ec2e.png)
  id: totrans-1138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你沿着计算图反向进行，就像在[反向传播章节](backpropagation_split_000.html)中介绍的那样，我们将得到以下公式用于 ![](a537b4ba.png)，这意味着损失将如何随着输入
    X ![](5b05ec2e.png) 而改变
- en: 'Now consider some things:'
  id: totrans-1139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑一些事情：
- en: dX must have the same size of X, so we need padding
  id: totrans-1140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: dX 必须与 X 的大小相同，因此我们需要填充
- en: dout must have the same size of Y, which in this case is 3 (Gradient input)
  id: totrans-1141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: dout 必须与 Y 的大小相同，本例中为3（梯度输入）
- en: To save programming effort we want to calculate the gradient as a convolution
  id: totrans-1142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了节省编程工作，我们希望将梯度计算为卷积
- en: On dX gradient all elements are been multiplied by W so we're probably convolving
    W and dout
  id: totrans-1143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 dX 梯度中，所有元素都乘以 W，所以我们可能正在对 W 和 dout 进行卷积
- en: 'Following the output size rule for the 1d convolution: ![](34481da6.png) Our
    desired size is 3, our original input size is 3, and we''re going to convolve
    with the W matrix that also have 3 elements. So we need to pad our input with
    2 zeros.'
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: 根据1d卷积的输出大小规则：![](34481da6.png)我们期望的大小为3，我们的原始输入大小为3，并且我们将使用也有3个元素的W矩阵进行卷积。因此，我们需要用2个零填充我们的输入。
- en: '![](Conv1d_Backprop_dX.png)'
  id: totrans-1145
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv1d_Backprop_dX.png)'
- en: 'The convolution above implement all calculations needed for ![](a537b4ba.png),
    so in terms of convolution: ![](1af9a957.png)'
  id: totrans-1146
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的卷积实现了所有计算所需的![](a537b4ba.png)，因此在卷积方面：![](1af9a957.png)
- en: Now let's continue for ![](7086761.png), considering that they must have the
    same size as W. ![](85992f4e.png)
  id: totrans-1147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续进行![](7086761.png)，考虑到它们必须与W具有相同的大小。![](85992f4e.png)
- en: Again by just looking to the expressions that we took from the graph we can
    see that is possible to represent them as a convolution between dout and X. Also
    as the output will be 3 elements, there is no need to do padding.
  id: totrans-1148
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，只需看一下我们从图中得出的表达式，我们就可以看到可以将它们表示为dout和X之间的卷积。同样，由于输出将是3个元素，因此无需进行填充。
- en: '![](Conv1d_Backprop_dW.png)'
  id: totrans-1149
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv1d_Backprop_dW.png)'
- en: 'So in terms of convolution the calculations for ![](a06dcfa1.png) will be:
    ![](85ad1578.png) Just one point to remember, if you consider X to be the kernel,
    and dout the signal, X will be automatically flipped. ![](2bd929bc.png)'
  id: totrans-1150
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，就卷积而言，对于![](a06dcfa1.png)的计算将是：![](85ad1578.png)只需记住一点，如果您认为X是核，而dout是信号，则X将自动翻转。![](2bd929bc.png)
- en: Now for the bias, the calculation will be similar to the Fully Connected layer.
    Basically we have one bias per filter (depth) ![](ce8280a3.png)
  id: totrans-1151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对于偏置，计算将类似于完全连接的层。基本上，每个过滤器（深度）有一个偏置![](ce8280a3.png)
- en: Implementation Notes
  id: totrans-1152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施说明
- en: '* * *'
  id: totrans-1153
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Before jumping to the code some points need to be reviewed:'
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
  zh: 在跳转到代码之前，需要审查一些要点：
- en: 'If you use some parameter (ie: Stride/Pad) during forward propagation you need
    to apply them on the backward propagation.'
  id: totrans-1155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在前向传播期间使用了一些参数（例如：Stride/Pad），则需要在反向传播期间应用它们。
- en: On Python our multidimensional tensor will be "input=[N x Depth x H x W]" on
    matlab they will be "input=[H x W x Depth x N]"
  id: totrans-1156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Python中，我们的多维张量将是“input=[N x Depth x H x W]”，在matlab中它们将是“input=[H x W x Depth
    x N]”
- en: As mentioned before the gradients of a input, has the same size as the input
    itself "size(x)==size(dx)"
  id: totrans-1157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，输入的梯度与输入本身的大小相同“size(x)==size(dx)”
- en: Matlab Backward propagation
  id: totrans-1158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab反向传播
- en: '* * *'
  id: totrans-1159
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Matlab_Backward_CONV.png)'
  id: totrans-1160
  prefs: []
  type: TYPE_IMG
  zh: '![](Matlab_Backward_CONV.png)'
- en: Python Backward propagation
  id: totrans-1161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python反向传播
- en: '* * *'
  id: totrans-1162
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Python_Backward_CONV.png)'
  id: totrans-1163
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_Backward_CONV.png)'
- en: Next Chapter
  id: totrans-1164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Next chapter we will learn about Pooling layer
  id: totrans-1166
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习关于池化层
- en: Making faster
  id: totrans-1167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加速运算
- en: Making faster
  id: totrans-1168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加速运算
- en: Introduction
  id: totrans-1169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1170
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On this chapter we show a way to convert your convolution operation into a matrix
    multiplication. This has the advantage to compute faster, at the expense of more
    memory usage. We employ the **im2col** operation that will transform the input
    image or batch into a matrix, then we multiply this matrix with a reshaped version
    of our kernel. Then at the end we reshape this multiplied matrix back to an image
    with the **col2im** operation.
  id: totrans-1171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们展示了一种将卷积操作转换为矩阵乘法的方法。这样做的优点是计算速度更快，但内存使用更多。我们使用**im2col**操作，该操作将输入图像或批处理转换为矩阵，然后将此矩阵与我们的核的重新形状版本相乘。然后，在最后，我们将这个乘积矩阵重新形状回图像，使用**col2im**操作。
- en: Im2col
  id: totrans-1172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Im2col
- en: '* * *'
  id: totrans-1173
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As shown on previous source code, we use a lot for for-loops to implement the
    convolutions, while this is useful for learning purpose, it's not fast enough.
    On this section we will learn how to implement convolutions on a vectorized fashion.
  id: totrans-1174
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的源代码所示，我们使用了许多for循环来实现卷积，虽然这对学习很有用，但速度不够快。在本节中，我们将学习如何以矢量化的方式实现卷积。
- en: First, if we inspect closer the code for convolution is basically a dot-product
    between the kernel filter and the local regions selected by the moving window,
    that sample a patch with the same size as our kernel.
  id: totrans-1175
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果我们仔细检查卷积的代码，基本上是核滤波器与移动窗口选择的局部区域之间的点积，该窗口对与我们的核相同大小的补丁进行采样。
- en: What would happens if we expand all possible windows on memory and perform the
    dot product as a matrix multiplication. Answer 200x or more speedups, at the expense
    of more memory consumption.
  id: totrans-1176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将所有可能的窗口展开到内存中并将点积作为矩阵乘法执行，会发生什么。答案是200倍或更多的加速，但会增加更多的内存消耗。
- en: '![](Convolution_With_Im2col.png)'
  id: totrans-1177
  prefs: []
  type: TYPE_IMG
  zh: '![](Convolution_With_Im2col.png)'
- en: For example, if the input is [227x227x3] and it is to be convolved with 11x11x3
    filters at stride 4 and padding 0, then we would take [11x11x3] blocks of pixels
    in the input and stretch each block into a column vector of size ![](ce877a37.png)
    = 363.
  id: totrans-1178
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果输入是 [227x227x3] 并且要用 11x11x3 的滤波器进行步幅 4 和填充 0 的卷积，则会从输入中取 [11x11x3] 的像素块，并将每个块拉伸成大小为
    ![](ce877a37.png) = 363 的列向量。
- en: Calculating with input 227 with stride 4 and padding 0, gives ((227-11)/4)+1
    = 55 locations along both width and height, leading to an output matrix X_col
    of size [363 x 3025].
  id: totrans-1179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用输入 227、步幅 4 和填充 0 进行计算，得到 ((227-11)/4)+1 = 55 的宽度和高度的位置，导致输出矩阵 X_col 的大小为
    [363 x 3025]。
- en: Here every column is a stretched out receptive field (patch with depth) and
    there are 55*55 = 3025 of them in total.
  id: totrans-1180
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的每一列都是一个拉伸的感受野（深度补丁），总共有 55*55 = 3025 个。
- en: 'To summarize how we calculate the im2col output sizes:'
  id: totrans-1181
  prefs: []
  type: TYPE_NORMAL
  zh: 总结我们如何计算 im2col 输出大小：
- en: '[PRE10]'
  id: totrans-1182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The weights of the CONV layer are similarly stretched out into rows. For example,
    if there are 96 filters of size [11x11x3] this would give a matrix W_row of size
    [96 x 363], where 11x11x3=363
  id: totrans-1183
  prefs: []
  type: TYPE_NORMAL
  zh: CONV 层的权重也被拉伸成行。例如，如果有 96 个大小为 [11x11x3] 的滤波器，这将给出一个大小为 [96 x 363] 的矩阵 W_row，其中
    11x11x3=363。
- en: '![](im2col_operation.png)'
  id: totrans-1184
  prefs: []
  type: TYPE_IMG
  zh: '![](im2col_operation.png)'
- en: After the image and the kernel are converted, the convolution can be implemented
    as a simple matrix multiplication, in our case it will be W_col[96 x 363] multiplied
    by X_col[363 x 3025] resulting as a matrix [96 x 3025], that need to be reshaped
    back to [55x55x96].
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
  zh: 图像和核被转换后，卷积可以实现为简单的矩阵乘法，在我们的情况下，它将是 W_col[96 x 363] 乘以 X_col[363 x 3025] 的矩阵乘法，结果为一个矩阵
    [96 x 3025]，需要重新调整形状为 [55x55x96]。
- en: This final reshape can also be implemented as a function called col2im.
  id: totrans-1186
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的重塑也可以实现为一个名为 col2im 的函数。
- en: Notice that some implementations of im2col will have this result transposed,
    if this is the case then the order of the matrix multiplication must be changed.
  id: totrans-1187
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一些 im2col 的实现可能会得到转置的结果，如果是这种情况，则必须改变矩阵乘法的顺序。
- en: '![](Im2Col_cs231n.png)'
  id: totrans-1188
  prefs: []
  type: TYPE_IMG
  zh: '![](Im2Col_cs231n.png)'
- en: Forward graph
  id: totrans-1189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正向传播图
- en: '* * *'
  id: totrans-1190
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In order to help the usage of im2col with convolution and also to derive the
    back-propagation, let's show the convolution with im2col as a graph. Here the
    input tensor is single a 3 channel 4x4 image. That will pass to a convolution
    layer with S:1 P:0 K:2 and F:1 (Output volume).
  id: totrans-1191
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助 im2col 与卷积的使用，并推导出反向传播，让我们将 im2col 的卷积显示为一个图。这里的输入张量是一个 3 通道 4x4 图像。它将传递到一个具有
    S:1 P:0 K:2 和 F:1（输出体积）的卷积层。
- en: '![](Conv_Graph_Im2col.png)'
  id: totrans-1192
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv_Graph_Im2col.png)'
- en: Backward graph
  id: totrans-1193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反向传播图
- en: '* * *'
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Using the im2col technique the computation graph resembles the FC layer with
    the same format ![](479bdf40.png), the difference that now we have a bunch of
    reshapes, transposes and the im2col block.
  id: totrans-1195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 im2col 技术的计算图类似于具有相同格式的 FC 层 ![](479bdf40.png)，不同之处在于现在我们有一堆重塑、转置和 im2col
    块。
- en: About the reshapes and transposes during back propagation you just need to invert
    their operations using again another reshape or transpose, the only important
    thing to remember is that if you use a reshape row major during forward propagation
    you need to use a reshape row major on the backpropagation.
  id: totrans-1196
  prefs: []
  type: TYPE_NORMAL
  zh: 关于反向传播过程中的重塑和转置，你只需反转它们的操作，再次使用另一个重塑或转置即可，唯一要记住的重要事情是，如果你在正向传播中使用了行主重塑，则在反向传播中需要使用行主重塑。
- en: The only point to pay attention is the im2col backpropagation operation. The
    issue is that it cannot be implemented as a simple reshape. This is because the
    patches could actually overlap (depending on the stride), so you need to sum the
    gradients where the patches intersect.
  id: totrans-1197
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一需要注意的是 im2col 反向传播操作。问题在于它不能被实现为简单的重塑。这是因为补丁实际上可能会重叠（取决于步幅），因此你需要在补丁相交的地方求梯度的总和。
- en: '![](Conv_Graph_Im2col_Backward.png)'
  id: totrans-1198
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv_Graph_Im2col_Backward.png)'
- en: Matlab forward propagation
  id: totrans-1199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab 正向传播
- en: '* * *'
  id: totrans-1200
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[PRE11]'
  id: totrans-1201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Matlab backward propagation
  id: totrans-1202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[Matlab 反向传播](链接)'
- en: '[PRE12]'
  id: totrans-1203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Matlab im2col
  id: totrans-1204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[Matlab im2col](链接)'
- en: '* * *'
  id: totrans-1205
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[PRE13]'
  id: totrans-1206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Matlab im2col backward propagation
  id: totrans-1207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab im2col 反向传播
- en: '* * *'
  id: totrans-1208
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[PRE14]'
  id: totrans-1209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Python example for forward propagation
  id: totrans-1210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正向传播的 Python 示例
- en: '* * *'
  id: totrans-1211
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[PRE15]'
  id: totrans-1212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Python example for backward propagation
  id: totrans-1213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反向传播的 Python 示例
- en: '* * *'
  id: totrans-1214
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[PRE16]'
  id: totrans-1215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Im2col and Col2im sources in python
  id: totrans-1216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 中的 Im2col 和 Col2im 源码
- en: This implementation will receive a image on the format of a 3 dimension tensor
    [channels, rows, cols] and will create a 2d matrix on the format [rows=(new_h*new_w),
    cols=(kw*kw*C)] notice that this algorithm will output the transposed version
    of the diagram above.
  id: totrans-1217
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实现将接收一个三维张量格式的图像 [channels, rows, cols]，并创建一个二维矩阵格式的图像 [rows=(new_h*new_w),
    cols=(kw*kw*C)]，注意，此算法将输出上述图表的转置版本。
- en: '[PRE17]'
  id: totrans-1218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-1219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-1220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Smaller example
  id: totrans-1221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 较小的例子
- en: '* * *'
  id: totrans-1222
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: To make things simpler on our heads, follow the simple example of convolving
    X[3x3] with W[2x2]
  id: totrans-1223
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化我们的想法，让我们以在 X[3x3] 上卷积 W[2x2] 的简单示例为例
- en: '![](simple_im2col.png)'
  id: totrans-1224
  prefs: []
  type: TYPE_IMG
  zh: '![](simple_im2col.png)'
- en: '![](im2col_matlab_example.png)'
  id: totrans-1225
  prefs: []
  type: TYPE_IMG
  zh: '![](im2col_matlab_example.png)'
- en: Pooling Layer
  id: totrans-1226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化层
- en: Pooling Layer
  id: totrans-1227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化层
- en: Introduction
  id: totrans-1228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1229
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](MaxPoolingLayer.png)'
  id: totrans-1230
  prefs: []
  type: TYPE_IMG
  zh: '![](MaxPoolingLayer.png)'
- en: 'The pooling layer, is used to reduce the spatial dimensions, but not depth,
    on a convolution neural network, model, basically this is what you gain:'
  id: totrans-1231
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层用于减少卷积神经网络模型的空间维度，但不包括深度，基本上这就是您获得的内容：
- en: By having less spatial information you gain computation performance
  id: totrans-1232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过减少空间信息，您可以获得计算性能
- en: Less spatial information also means less parameters, so less chance to over-fit
  id: totrans-1233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更少的空间信息也意味着更少的参数，因此过度拟合的机会更少
- en: You get some translation invariance
  id: totrans-1234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您会获得一些平移不变性
- en: Some projects don't use pooling, specially when they want to "learn" some object
    specific position. Learn how to play atari games.
  id: totrans-1235
  prefs: []
  type: TYPE_NORMAL
  zh: 一些项目不使用池化，特别是当他们想要“学习”某些对象特定位置时。学会如何玩Atari游戏。
- en: On the diagram bellow we show the most common type of pooling the max-pooling
    layer, which slides a window, like a normal convolution, and get the biggest value
    on the window as the output.
  id: totrans-1236
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图表中，我们展示了最常见的池化类型，即最大池化层，它像正常的卷积一样滑动一个窗口，并将窗口中的最大值作为输出。
- en: '![](Pooling_Simple_max.png)'
  id: totrans-1237
  prefs: []
  type: TYPE_IMG
  zh: '![](Pooling_Simple_max.png)'
- en: 'The most important parameters to play:'
  id: totrans-1238
  prefs: []
  type: TYPE_NORMAL
  zh: 玩的最重要的参数：
- en: 'Input: H1 x W1 x Depth_In x N'
  id: totrans-1239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入：H1 x W1 x Depth_In x N
- en: 'Stride: Scalar that control the amount of pixels that the window slide.'
  id: totrans-1240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步幅：控制窗口滑动的像素数量的标量。
- en: 'K: Kernel size'
  id: totrans-1241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K：核大小
- en: 'Regarding it''s Output H2 x W2 x Depth_Out x N:'
  id: totrans-1242
  prefs: []
  type: TYPE_NORMAL
  zh: 关于其输出 H2 x W2 x Depth_Out x N：
- en: '![](d8085eaa.png)'
  id: totrans-1243
  prefs: []
  type: TYPE_IMG
  zh: '![](d8085eaa.png)'
- en: It's also valid to point out that there is no learnable parameters on the pooling
    layer. So it's backpropagation is simpler.
  id: totrans-1244
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得指出的是，在池化层中没有可学习的参数。 因此，它的反向传播更简单。
- en: Forward Propagation
  id: totrans-1245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正向传播
- en: '* * *'
  id: totrans-1246
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The window movement mechanism on pooling layers is the same as convolution layer,
    the only change is that we will select the biggest value on the window.
  id: totrans-1247
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层上的窗口移动机制与卷积层相同，唯一的变化是我们将选择窗口中的最大值。
- en: Python Forward propagation
  id: totrans-1248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python正向传播
- en: '* * *'
  id: totrans-1249
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Python_maxpool_forward.png)'
  id: totrans-1250
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_maxpool_forward.png)'
- en: Matlab Forward propagation
  id: totrans-1251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matlab正向传播
- en: '* * *'
  id: totrans-1252
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Backward Propagation
  id: totrans-1253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播
- en: '* * *'
  id: totrans-1254
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: From the [backpropagation chapter](backpropagation_split_000.html) we learn
    that the max node simply act as a router, giving the input gradient "dout" to
    the input that has value bigger than zero.
  id: totrans-1255
  prefs: []
  type: TYPE_NORMAL
  zh: 从[反向传播章节](backpropagation_split_000.html)中我们了解到，最大节点简单地作为一个路由器，将输入梯度“dout”给到大于零的输入。
- en: '![](MaxGate.png) You can consider that the max pooling use a series of max
    nodes, on it''s computation graph. So consider the backward propagation of the
    max pooling layer as a product between a mask containing all elements that were
    selected during the forward propagation and dout.'
  id: totrans-1256
  prefs: []
  type: TYPE_NORMAL
  zh: '![](MaxGate.png) 你可以认为最大池化使用一系列最大节点，在其计算图上。 因此，将最大池化层的反向传播视为在正向传播期间选择的所有元素的掩码与dout之间的乘积。'
- en: '![](BackPropagation_MaxPool.png)'
  id: totrans-1257
  prefs: []
  type: TYPE_IMG
  zh: '![](BackPropagation_MaxPool.png)'
- en: In other words the gradient with respect to the input of the max pooling layer
    will be a tensor make of zeros except on the places that was selected during the
    forward propagation.
  id: totrans-1258
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，相对于最大池化层输入的梯度将是一个张量，除了在正向传播期间选择的位置之外，其他地方都是零。
- en: Python Backward propagation
  id: totrans-1259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python反向传播
- en: '* * *'
  id: totrans-1260
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Python_maxpool_backward.png)'
  id: totrans-1261
  prefs: []
  type: TYPE_IMG
  zh: '![](Python_maxpool_backward.png)'
- en: Improving performance
  id: totrans-1262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提高性能
- en: '* * *'
  id: totrans-1263
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On future chapter we will learn a technique that improves the convolution performance,
    until them we will stick with the naive implementation.
  id: totrans-1264
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的章节中，我们将学习一种提高卷积性能的技术，直到那时我们将坚持使用天真的实现。
- en: Next Chapter
  id: totrans-1265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1266
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Next chapter we will learn about Batch Norm layer
  id: totrans-1267
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习关于批归一化层的知识
- en: Batch Norm layer
  id: totrans-1268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批归一化层
- en: Batch Norm layer
  id: totrans-1269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批归一化层
- en: Introduction
  id: totrans-1270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1271
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On this chapter we will learn about the batch norm layer. Previously we said
    that [feature scaling](https://www.gitbook.com/book/leonardoaraujosantos/artificial-inteligence/edit#/edit/master/feature_scaling.md)
    make the job of the gradient descent easier. Now we will extend this idea and
    normalize the activation of every Fully Connected layer or Convolution layer during
    training. This also means that while we're training we will select an batch calculate
    it's mean and standard deviation.
  id: totrans-1272
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习批归一化层。之前我们说过[特征缩放](https://www.gitbook.com/book/leonardoaraujosantos/artificial-inteligence/edit#/edit/master/feature_scaling.md)使梯度下降的工作变得更容易。现在我们将扩展这个想法，并在训练期间规范化每个全连接层或卷积层的激活。这也意味着在训练时我们将选择一个批次，计算它的均值和标准差。
- en: You can think that the batch-norm will be some kind of adaptive (or learnable)
    pre-processing block with trainable parameters. Which also means that we need
    to back-propagate them.
  id: totrans-1273
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将批归一化看作是一种自适应（或可学习的）预处理块，具有可训练参数。这也意味着我们需要反向传播它们。
- en: The original batch-norm paper can be found [here](http://arxiv.org/pdf/1502.03167v3.pdf).
  id: totrans-1274
  prefs: []
  type: TYPE_NORMAL
  zh: 原始批归一化论文可以在[这里](http://arxiv.org/pdf/1502.03167v3.pdf)找到。
- en: 'Here is the list of advantages of using Batch-Norm:'
  id: totrans-1275
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用批归一化的优点列表：
- en: Improves gradient flow, used on very deep models (Resnet need this)
  id: totrans-1276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 改善了梯度流，用于非常深的模型（Resnet 需要这个）
- en: Allow higher learning rates
  id: totrans-1277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 允许更高的学习率
- en: Reduce dependency on initialization
  id: totrans-1278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少对初始化的依赖
- en: Gives some kind of regularization (Even make Dropout less important but keep
    using it)
  id: totrans-1279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供某种形式的正则化（甚至减少了对 Dropout 的重要性但仍然使用它）
- en: As a rule of thumb if you use Dropout+BatchNorm you don't need L2 regularization
  id: totrans-1280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据经验法则，如果您使用 Dropout+批归一化，您就不需要 L2 正则化
- en: It basically force your activations (Conv,FC ouputs) to be unit standard deviation
    and zero mean.
  id: totrans-1281
  prefs: []
  type: TYPE_NORMAL
  zh: 它基本上强制您的激活（Conv，FC 输出）具有单位标准差和零均值。
- en: To each learning batch of data we apply the following normalization.
  id: totrans-1282
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个学习批数据，我们应用以下归一化。
- en: '![](f4932fb.png)'
  id: totrans-1283
  prefs: []
  type: TYPE_IMG
  zh: '![](f4932fb.png)'
- en: '![](Compute_BatchNorm.png)'
  id: totrans-1284
  prefs: []
  type: TYPE_IMG
  zh: '![](Compute_BatchNorm.png)'
- en: The output of the batch norm layer, has the ![](87a87a8c.png) are parameters.
    Those parameters will be learned to best represent your activations. Those parameters
    allows a learnable (scale and shift) factor ![](dd16f1ee.png)
  id: totrans-1285
  prefs: []
  type: TYPE_NORMAL
  zh: 批归一化层的输出，具有 ![](87a87a8c.png) 这些参数。这些参数将被学习以最佳表示您的激活。这些参数允许一个可学习的（缩放和偏移）因子 ![](dd16f1ee.png)
- en: 'Now summarizing the operations:'
  id: totrans-1286
  prefs: []
  type: TYPE_NORMAL
  zh: 现在总结操作：
- en: '![](batch_norm_fp.png)'
  id: totrans-1287
  prefs: []
  type: TYPE_IMG
  zh: '![](batch_norm_fp.png)'
- en: Here, ![](9fe1930b.png) is a small number, 1e-5.
  id: totrans-1288
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](9fe1930b.png) 是一个小数，为 1e-5。
- en: Where to use the Batch-Norm layer
  id: totrans-1289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在哪里使用批归一化层
- en: '* * *'
  id: totrans-1290
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The batch norm layer is used after linear layers (ie: FC, conv), and before
    the non-linear layers (relu). There is actually 2 batch norm implementations one
    for FC layer and the other for conv layers.'
  id: totrans-1291
  prefs: []
  type: TYPE_NORMAL
  zh: 批归一化层在线性层（即：FC、conv）之后使用，并在非线性层（relu）之前使用。实际上有两种批归一化实现，一种用于 FC 层，另一种用于 conv
    层。
- en: '![](BatchNorm_Placement.png)'
  id: totrans-1292
  prefs: []
  type: TYPE_IMG
  zh: '![](BatchNorm_Placement.png)'
- en: Test time
  id: totrans-1293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试时间
- en: '* * *'
  id: totrans-1294
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: At prediction time that batch norm works differently. The mean/std are not computed
    based on the batch. Instead, we need to build a estimate during training of the
    mean/std of the whole dataset(population) for each batch norm layer on your model.
  id: totrans-1295
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测时，批归一化的工作方式不同。均值/标准差不是基于批处理计算的。相反，我们需要在训练期间为您模型上的每个批归一化层建立整个数据集（总体）的均值/标准差的估计值。
- en: One approach to estimating the population mean and variance during training
    is to use an [exponential moving average](https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average).
  id: totrans-1296
  prefs: []
  type: TYPE_NORMAL
  zh: 估计训练期间总体均值和方差的一种方法是使用[指数移动平均](https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average)。
- en: '![](749e2654.png)'
  id: totrans-1297
  prefs: []
  type: TYPE_IMG
  zh: '![](749e2654.png)'
- en: 'Where: ![](c5ae95b1.png): Current and previous estimation ![](de87fcce.png):
    Represents the degree of weighting decrease, a constant smoothing factor between
    0 and 1 ![](c03f5ce1.png): Current value (could be mean or std) that we''re trying
    to estimate'
  id: totrans-1298
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：![](c5ae95b1.png)：当前和先前的估计 ![](de87fcce.png)：表示权重减小的程度，一个在 0 和 1 之间的常数平滑因子
    ![](c03f5ce1.png)：我们正在尝试估计的当前值（可能是均值或标准差）
- en: Normally when we implement this layer we have some kind of flag that detects
    if we're on training or testing.
  id: totrans-1299
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们实现此层时，我们会有一种标志来检测我们是在训练还是测试中。
- en: As reference we can find some tutorials with [Tensorflow](http://r2rt.com/implementing-batch-normalization-in-tensorflow.html)
    or [manually on python](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html).
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: 作为参考，我们可以找到一些关于[Tensorflow](http://r2rt.com/implementing-batch-normalization-in-tensorflow.html)或[手动在Python上](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html)的教程。
- en: Backpropagation
  id: totrans-1301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播
- en: '* * *'
  id: totrans-1302
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As mentioned earlier we need to know how to backpropagate on the batch-norm
    layer, first as we did with other layers we need to create the computation graph.
    After this step we need to calculate the derivative of each node with respect
    to it's inputs.
  id: totrans-1303
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们需要知道如何在批量归一化层上进行反向传播，首先像其他层一样，我们需要创建计算图。在这一步之后，我们需要计算每个节点相对于其输入的导数。
- en: Computation Graph
  id: totrans-1304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算图
- en: 'In order to find the partial derivatives on back-propagation is better to visualize
    the algorithm as a computation graph:'
  id: totrans-1305
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到反向传播的偏导数，最好将算法可视化为计算图：
- en: '![](batch_norm_computation_graph.png)'
  id: totrans-1306
  prefs: []
  type: TYPE_IMG
  zh: '![](batch_norm_computation_graph.png)'
- en: New nodes
  id: totrans-1307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新节点
- en: By inspecting this graph we have some new nodes (![](48a4007c.png), ![](cf0feaac.png),
    ![](f52524b5.png), ![](59e67941.png)). To simplify things you can use [Wolfram
    alpha](https://www.wolframalpha.com/) to find the derivatives. For backpropagate
    other nodes refer to the [Back-propagation chapter](https://www.gitbook.com/book/leonardoaraujosantos/artificial-inteligence/edit#/edit/master/backpropagation.md)
  id: totrans-1308
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查这个图，我们有一些新节点（![](48a4007c.png), ![](cf0feaac.png), ![](f52524b5.png), ![](59e67941.png)）。为了简化事情，您可以使用[Wolfram
    alpha](https://www.wolframalpha.com/)来找到导数。要反向传播其他节点，请参考[反向传播章节](https://www.gitbook.com/book/leonardoaraujosantos/artificial-inteligence/edit#/edit/master/backpropagation.md)
- en: '[Block 1/x](https://www.wolframalpha.com/input/?i=derivative+1%2Fx)'
  id: totrans-1309
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '[块 1/x](https://www.wolframalpha.com/input/?i=derivative+1%2Fx)'
- en: '![](BlockBackprop_1_over_x.png)'
  id: totrans-1310
  prefs: []
  type: TYPE_IMG
  zh: '![](BlockBackprop_1_over_x.png)'
- en: 'In other words:'
  id: totrans-1311
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说：
- en: '![](7b972ff1.png)'
  id: totrans-1312
  prefs: []
  type: TYPE_IMG
  zh: '![](7b972ff1.png)'
- en: 'Where: ![](b8367cc3.png) means the cached (or saved) input from the forward
    propagation. ![](9a616dbf.png) means the previous block gradient'
  id: totrans-1313
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：![](b8367cc3.png)表示来自前向传播的缓存（或保存）输入。![](9a616dbf.png)表示前一个块的梯度
- en: '[Block sqrt(x-epsilon)](https://www.wolframalpha.com/input/?i=derivative+of+sqrt(x-epsilon)'
  id: totrans-1314
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '[块 sqrt(x-epsilon)](https://www.wolframalpha.com/input/?i=derivative+of+sqrt(x-epsilon)'
- en: '![](BlockBackprop_sqrt_x.png)'
  id: totrans-1315
  prefs: []
  type: TYPE_IMG
  zh: '![](BlockBackprop_sqrt_x.png)'
- en: 'In other words:'
  id: totrans-1316
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说：
- en: '![](496a1ddb.png)'
  id: totrans-1317
  prefs: []
  type: TYPE_IMG
  zh: '![](496a1ddb.png)'
- en: 'Where: ![](b8367cc3.png): the cached (or saved) input from the forward propagation.
    ![](9a616dbf.png): the previous block gradient ![](9fe1930b.png): Some small number
    0.00005'
  id: totrans-1318
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：![](b8367cc3.png)：来自前向传播的缓存（或保存）输入。![](9a616dbf.png)：前一个块的梯度！[](9fe1930b.png)：一些小数0.00005
- en: '[Block x^2](https://www.wolframalpha.com/input/?i=derivative+of+x%5E2)'
  id: totrans-1319
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '[块 x^2](https://www.wolframalpha.com/input/?i=derivative+of+x%5E2)'
- en: '![](BlockBackprop_x2.png)'
  id: totrans-1320
  prefs: []
  type: TYPE_IMG
  zh: '![](BlockBackprop_x2.png)'
- en: 'In other words:'
  id: totrans-1321
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说：
- en: '![](5d7daa76.png)'
  id: totrans-1322
  prefs: []
  type: TYPE_IMG
  zh: '![](5d7daa76.png)'
- en: Block Summation
  id: totrans-1323
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 块求和
- en: '![](BlockBackprop_SUM.png)'
  id: totrans-1324
  prefs: []
  type: TYPE_IMG
  zh: '![](BlockBackprop_SUM.png)'
- en: Like the SUM block this block will copy the input gradient dout equally to all
    it's inputs. So for all elements in X we will divide by N and multiply by dout.
  id: totrans-1325
  prefs: []
  type: TYPE_NORMAL
  zh: 像SUM块一样，此块将把输入梯度dout等分到所有输入中。因此，对于X中的所有元素，我们将除以N并乘以dout。
- en: Implementation
  id: totrans-1326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: Python Forward Propagation
  id: totrans-1327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python前向传播
- en: '* * *'
  id: totrans-1328
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](batch_norm_fp_python.png)'
  id: totrans-1329
  prefs: []
  type: TYPE_IMG
  zh: '![](batch_norm_fp_python.png)'
- en: Python Backward Propagation
  id: totrans-1330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python反向传播
- en: '* * *'
  id: totrans-1331
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](batch_norm_bp_python.png)'
  id: totrans-1332
  prefs: []
  type: TYPE_IMG
  zh: '![](batch_norm_bp_python.png)'
- en: Next Chapter
  id: totrans-1333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1334
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Next chapter we will learn about how to optimize our model weights.
  id: totrans-1335
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章我们将学习如何优化我们的模型权重。
- en: Model Solver
  id: totrans-1336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型求解器
- en: Model Solver
  id: totrans-1337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型求解器
- en: Introduction
  id: totrans-1338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1339
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The mission of the model solver is to find the best set of parameters, that
    minimize the train/accuracy errors. On this chapter we will give a UML description
    with some piece of python/matlab code that allows you implement it yourself.
  id: totrans-1340
  prefs: []
  type: TYPE_NORMAL
  zh: 模型求解器的任务是找到最小化训练/准确性错误的最佳参数集。在本章中，我们将提供一个带有一些Python/Matlab代码片段的UML描述，让您可以自己实现它。
- en: '![](ClassDiagram.png)'
  id: totrans-1341
  prefs: []
  type: TYPE_IMG
  zh: '![](ClassDiagram.png)'
- en: 'From the UML description we can infer some information about the Solver class:'
  id: totrans-1342
  prefs: []
  type: TYPE_NORMAL
  zh: 从UML描述中，我们可以推断出有关Solver类的一些信息：
- en: It uses the training set, and has a reference to your model
  id: totrans-1343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它使用训练集，并引用您的模型
- en: 'Uses different type of optimizers(ex: SGD, ADAM, SGD with momentum)'
  id: totrans-1344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不同类型的优化器（例如：SGD、ADAM、带动量的SGD）
- en: Keep tracks of all the loss, accuracy during the training phase
  id: totrans-1345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练阶段跟踪所有损失、准确率
- en: Keep the set of parameters, that achieved best validation performance
  id: totrans-1346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保留达到最佳验证性能的参数集
- en: Usage example
  id: totrans-1347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用示例
- en: '* * *'
  id: totrans-1348
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Solver_Usage.png)'
  id: totrans-1349
  prefs: []
  type: TYPE_IMG
  zh: '![](Solver_Usage.png)'
- en: Train operation
  id: totrans-1350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练操作
- en: '* * *'
  id: totrans-1351
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'This is the method called when you actually want to start a model training,
    the methods Step, Check_Accuracy are called inside the Train method:'
  id: totrans-1352
  prefs: []
  type: TYPE_NORMAL
  zh: 当您实际上想要开始模型训练时，会调用此方法，方法 Step，Check_Accuracy 在 Train 方法内调用：
- en: Calculate number of iterations per epoch, based on number of epochs, train size,
    and batch size
  id: totrans-1353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据周期数、训练大小和批量大小计算每周期的迭代次数
- en: Call step, for each iteration
  id: totrans-1354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用步骤，对于每次迭代
- en: Decay the learning rate
  id: totrans-1355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 衰减学习率
- en: Calculate the validation accuracy
  id: totrans-1356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算验证准确性
- en: Cache the best parameters based on validation accuracy
  id: totrans-1357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据验证准确性缓存最佳参数
- en: Step operation
  id: totrans-1358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤操作
- en: '* * *'
  id: totrans-1359
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Basically during the step operation the following operations are done:'
  id: totrans-1360
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，在步骤操作期间，执行以下操作：
- en: Extract a batch from the training set.
  id: totrans-1361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从训练集中提取一个批次。
- en: Get the model loss and gradients
  id: totrans-1362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取模型损失和梯度
- en: Perform a parameter update with one of the optimizers.
  id: totrans-1363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用优化器之一执行参数更新。
- en: Check Accuracy
  id: totrans-1364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查准确性
- en: '* * *'
  id: totrans-1365
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This method basically is called at the end of each epoch. Basically it uses
    the current set of parameters, and predict the whole validation set. The objective
    is at the end get the accuracy. ![](7f8bb141.png)
  id: totrans-1366
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法基本上在每个周期结束时调用。基本上它使用当前参数集，并预测整个验证集。目标是在最后获得准确性。![](7f8bb141.png)
- en: Model loss operation
  id: totrans-1367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型损失操作
- en: '* * *'
  id: totrans-1368
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We mentioned during the "Step" operation that we get the model loss and gradients.
    This operation is implemented by the "getLoss" method. Consider the following
    basic model.
  id: totrans-1369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在“步骤”操作中提到，我们获取模型损失和梯度。此操作由 "getLoss" 方法实现。考虑以下基本模型。
- en: '![](SimpleModelLoss.png) Bellow we have the "getLoss" function for the previous
    simple model.'
  id: totrans-1370
  prefs: []
  type: TYPE_NORMAL
  zh: '![](SimpleModelLoss.png) 下面是前一个简单模型的 "getLoss" 函数。'
- en: '![](getLoss.png)'
  id: totrans-1371
  prefs: []
  type: TYPE_IMG
  zh: '![](getLoss.png)'
- en: Also bellow we have the "softmax_loss" function including "dout", ![](50803af0.png)
  id: totrans-1372
  prefs: []
  type: TYPE_NORMAL
  zh: 还在下面有 "softmax_loss" 函数，包括 "dout"，![](50803af0.png)
- en: '![](Softmax_Loss_Layer.png)'
  id: totrans-1373
  prefs: []
  type: TYPE_IMG
  zh: '![](Softmax_Loss_Layer.png)'
- en: Object Localization and Detection
  id: totrans-1374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象定位和检测
- en: Object Localization and Detection
  id: totrans-1375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象定位和检测
- en: '* * *'
  id: totrans-1376
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Introduction
  id: totrans-1377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: On this chapter we're going to learn about using convolution neural networks
    to localize and detect objects on images
  id: totrans-1378
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习使用卷积神经网络在图像上定位和检测对象
- en: '![](LocalizationDetection.png)'
  id: totrans-1379
  prefs: []
  type: TYPE_IMG
  zh: '![](LocalizationDetection.png)'
- en: RCNN
  id: totrans-1380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RCNN
- en: Fast RCNN
  id: totrans-1381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fast RCNN
- en: Faster RCNN
  id: totrans-1382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Faster RCNN
- en: Yolo
  id: totrans-1383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yolo
- en: SSD
  id: totrans-1384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSD
- en: Localize objects with regression
  id: totrans-1385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用回归定位对象
- en: Regression is about returning a number instead of a class, in our case we're
    going to return 4 numbers (x0,y0,width,height) that are related to a bounding
    box. You train this system with an image an a ground truth bounding box, and use
    L2 distance to calculate the loss between the predicted bounding box and the ground
    truth.
  id: totrans-1386
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是关于返回一个数字而不是一个类别，在我们的情况下，我们将返回 4 个数字（x0、y0、宽度、高度），这些数字与边界框相关联。您可以使用图像和真实边界框训练此系统，并使用
    L2 距离计算预测边界框和真实边界框之间的损失。
- en: '![](LocalizationRegression1.png)'
  id: totrans-1387
  prefs: []
  type: TYPE_IMG
  zh: '![](LocalizationRegression1.png)'
- en: Normally what you do is attach another fully connected layer on the last convolution
    layer
  id: totrans-1388
  prefs: []
  type: TYPE_NORMAL
  zh: 通常你要做的是在最后一个卷积层上附加另一个完全连接的层
- en: '![](LocalizationRegression2.png)'
  id: totrans-1389
  prefs: []
  type: TYPE_IMG
  zh: '![](LocalizationRegression2.png)'
- en: This will work only for one object at a time.
  id: totrans-1390
  prefs: []
  type: TYPE_NORMAL
  zh: 这只适用于一次处理一个对象。
- en: Some people attach the regression part after the last convolution (Overfeat)
    layer, while others attach after the fully connected layer (RCNN). Both works.
  id: totrans-1391
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人在最后一个卷积层（Overfeat）后附加回归部分，而其他人在完全连接的层（RCNN）后附加。两者都可以。
- en: Comparing bounding box prediction accuracy
  id: totrans-1392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较边界框预测的准确性
- en: '* * *'
  id: totrans-1393
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Basically we need to compare if the Intersect Over Union (ioU) between the prediction
    and the ground truth is bigger than some threshold (ex > 0.5)
  id: totrans-1394
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上我们需要比较预测和真实值之间的交并比（IoU）是否大于某个阈值（例如 > 0.5）
- en: '![](Intersection-over-Union-IoU-of.png)'
  id: totrans-1395
  prefs: []
  type: TYPE_IMG
  zh: '![](Intersection-over-Union-IoU-of.png)'
- en: RCNN
  id: totrans-1396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RCNN
- en: RCNN (Regions + CNN) is a method that relies on a external region proposal system.
  id: totrans-1397
  prefs: []
  type: TYPE_NORMAL
  zh: RCNN（区域 + CNN）是一种依赖外部区域提议系统的方法。
- en: '![](RCNNSimple.png)'
  id: totrans-1398
  prefs: []
  type: TYPE_IMG
  zh: '![](RCNNSimple.png)'
- en: 'The problem of RCNN is that it''s never made to be fast, for instance the steps
    to train the network are these:'
  id: totrans-1399
  prefs: []
  type: TYPE_NORMAL
  zh: RCNN 的问题在于它从未被设计为快速的，例如训练网络的步骤如下：
- en: Take a pre-trained imagenet cnn (ex Alexnet)
  id: totrans-1400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用预训练的 imagenet cnn（例如 Alexnet）
- en: Re-train the last fully connected layer with the objects that need to be detected
    + "no-object" class
  id: totrans-1401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新训练最后一个完全连接的层，与需要检测的对象 + "无对象"类
- en: Get all proposals(=~2000 p/image), resize them to match the cnn input, then
    save to disk.
  id: totrans-1402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取所有建议（约2000个/图像），调整它们的大小以匹配 cnn 输入，然后保存到磁盘。
- en: Train SVM to classify between object and background (One binary SVM for each
    class)
  id: totrans-1403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练 SVM 来对对象和背景进行分类（每个类别一个二元 SVM）
- en: 'BB Regression: Train a linear regression classifier that will output some correction
    factor'
  id: totrans-1404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 边界框回归：训练一个线性回归分类器，输出一些校正因子
- en: Step 3 Save and pre-process proposals
  id: totrans-1405
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3 保存并预处理提议
- en: '![](Step3RCNN.png)'
  id: totrans-1406
  prefs: []
  type: TYPE_IMG
  zh: '![](Step3RCNN.png)'
- en: Step 5 (Adjust bounding box)
  id: totrans-1407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 5（调整边界框）
- en: '![](Step5RCNN.png)'
  id: totrans-1408
  prefs: []
  type: TYPE_IMG
  zh: '![](Step5RCNN.png)'
- en: Fast RCNN
  id: totrans-1409
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速 RCNN
- en: The Fast RCNN method receive region proposals from some external system (Selective
    search). This proposals will sent to a layer (Roi Pooling) that will resize all
    regions with their data to a fixed size. This step is needed because the fully
    connected layer expect that all the vectors will have same size
  id: totrans-1410
  prefs: []
  type: TYPE_NORMAL
  zh: 快速 RCNN 方法从某个外部系统（选择性搜索）接收区域提议。这些提议将被发送到一个层（Roi 池化），该层将调整所有区域及其数据到固定大小。这一步骤是必要的，因为全连接层期望所有向量的大小相同。
- en: '![](Fast_RCNN.png)'
  id: totrans-1411
  prefs: []
  type: TYPE_IMG
  zh: '![](Fast_RCNN.png)'
- en: Proposals example, boxes=[r, x1, y1, x2, y2]
  id: totrans-1412
  prefs: []
  type: TYPE_NORMAL
  zh: 提议示例，boxes=[r, x1, y1, x2, y2]
- en: '![](Proposals.png)'
  id: totrans-1413
  prefs: []
  type: TYPE_IMG
  zh: '![](Proposals.png)'
- en: '![](Fast_RCnn_Caffe_LastPart.png)'
  id: totrans-1414
  prefs: []
  type: TYPE_IMG
  zh: '![](Fast_RCnn_Caffe_LastPart.png)'
- en: Still depends on some external system to give the region proposals (Selective
    search)
  id: totrans-1415
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然依赖于某个外部系统来提供区域提议（选择性搜索）
- en: Roi Pooling layer
  id: totrans-1416
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Roi 池化层
- en: '* * *'
  id: totrans-1417
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](RoiPoolingLayer.png)'
  id: totrans-1418
  prefs: []
  type: TYPE_IMG
  zh: '![](RoiPoolingLayer.png)'
- en: It's a type of max-pooling with a pool size dependent on the input, so that
    the output always has the same size. This is done because fully connected layer
    always expected the same input size.
  id: totrans-1419
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种最大池化的类型，池大小取决于输入，以便输出始终具有相同的大小。这是因为全连接层始终期望相同的输入大小。
- en: '![](RoiPoolingLayerCaffe.png)'
  id: totrans-1420
  prefs: []
  type: TYPE_IMG
  zh: '![](RoiPoolingLayerCaffe.png)'
- en: The inputs of the Roi layer will be the proposals and the last convolution layer
    activations. For example consider the following input image, and it's proposals.
  id: totrans-1421
  prefs: []
  type: TYPE_NORMAL
  zh: Roi 层的输入将是提议和最后一个卷积层的激活。例如，考虑以下输入图像及其提议。
- en: Input image
  id: totrans-1422
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像
- en: '![](InImage.png)'
  id: totrans-1423
  prefs: []
  type: TYPE_IMG
  zh: '![](InImage.png)'
- en: Two proposed regions
  id: totrans-1424
  prefs: []
  type: TYPE_NORMAL
  zh: 两个提议的区域
- en: '![](InImageRegions.png)'
  id: totrans-1425
  prefs: []
  type: TYPE_IMG
  zh: '![](InImageRegions.png)'
- en: 'Now the activations on the last convolution layer (ex: conv5)'
  id: totrans-1426
  prefs: []
  type: TYPE_NORMAL
  zh: 现在最后一个卷积层（例如：conv5）上的激活
- en: '![](Conv5_Activations.png)'
  id: totrans-1427
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv5_Activations.png)'
- en: For each convolution activation (each cell from the image above) the Roi Pooling
    layer will resize, the region proposals (in red) to the same resolution expected
    on the fully connected layer. For example consider the selected cell in green.
  id: totrans-1428
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个卷积激活（上图中的每个单元格），Roi 池化层将调整区域提议（红色）到与全连接层期望的相同分辨率。例如，考虑在绿色中选择的单元格。
- en: '![](Conv5_Activation_and_Proposals.png)'
  id: totrans-1429
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv5_Activation_and_Proposals.png)'
- en: 'Here the output will be:'
  id: totrans-1430
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的输出将是：
- en: '![](Roi_PoolingLayer1.png)'
  id: totrans-1431
  prefs: []
  type: TYPE_IMG
  zh: '![](Roi_PoolingLayer1.png)'
- en: '![](Roi_PoolingLayer2.png)'
  id: totrans-1432
  prefs: []
  type: TYPE_IMG
  zh: '![](Roi_PoolingLayer2.png)'
- en: Faster RCNN
  id: totrans-1433
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Faster RCNN
- en: '* * *'
  id: totrans-1434
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](Faster_Rcnn.png)'
  id: totrans-1435
  prefs: []
  type: TYPE_IMG
  zh: '![](Faster_Rcnn.png)'
- en: The main idea is use the last (or deep) conv layers to infer region proposals.
  id: totrans-1436
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思想是使用最后（或深层）的卷积层推断区域提议。
- en: Faster-RCNN consists of two modules.
  id: totrans-1437
  prefs: []
  type: TYPE_NORMAL
  zh: Faster-RCNN 由两个模块组成。
- en: 'RPN (Region proposals): Gives a set of rectangles based on deep convolution
    layer'
  id: totrans-1438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区域提议网络（RPN）：基于深度卷积层给出一组矩形。
- en: 'Fast-RCNN Roi Pooling layer: Classify each proposal, and refining proposal
    location'
  id: totrans-1439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速 RCNN Roi 池化层：对每个提议进行分类，并细化提议位置
- en: Region proposal Network
  id: totrans-1440
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 区域提议网络
- en: '* * *'
  id: totrans-1441
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here we break on a block diagram how Faster RCNN works.
  id: totrans-1442
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们以块图表的方式解释 Faster RCNN 的工作原理。
- en: Get a trained (ie imagenet) convolution neural network
  id: totrans-1443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取训练好的（例如 ImageNet）卷积神经网络
- en: Get feature maps from the last (or deep) convolution layer
  id: totrans-1444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从最后（或深层）卷积层获取特征映射
- en: Train a region proposal network that will decide if there is an object or not
    on the image, and also propose a box location
  id: totrans-1445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个区域提议网络，该网络将决定图像中是否存在对象，还将提出框位置
- en: Give results to a custom (python) layer
  id: totrans-1446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果提供给自定义（Python）层
- en: Give proposals to a ROI pooling layer (like Fast RCNN)
  id: totrans-1447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将提议给一个 Roi 池化层（类似于 Fast RCNN）
- en: After all proposals get reshaped to a fix size, send to a fully connected layer
    to continue the classification
  id: totrans-1448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有提议调整为固定大小后，发送到一个全连接层继续分类。
- en: '![](RegionProposalNetwork.png)'
  id: totrans-1449
  prefs: []
  type: TYPE_IMG
  zh: '![](RegionProposalNetwork.png)'
- en: '![](RPN_Network.png)'
  id: totrans-1450
  prefs: []
  type: TYPE_IMG
  zh: '![](RPN_Network.png)'
- en: How it works
  id: totrans-1451
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 工作原理
- en: Basically the RPN slides a small window (3x3) on the feature map, that classify
    what is under the window as object or not object, and also gives some bounding
    box location.
  id: totrans-1452
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，RPN 在特征图上滑动一个小窗口（3x3），对窗口下的内容进行分类为对象或非对象，并且给出一些边界框位置。
- en: For every slidding window center it creates fixed k anchor boxes, and classify
    those boxes as been object or not.
  id: totrans-1453
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个滑动窗口中心，它创建固定数量的锚定框，并将这些框分类为物体或非物体。
- en: '![](RPN_Sliding.png)'
  id: totrans-1454
  prefs: []
  type: TYPE_IMG
  zh: '![](RPN_Sliding.png)'
- en: Faster RCNN training
  id: totrans-1455
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Faster RCNN 训练
- en: On the paper, each network was trained separately, but we also can train it
    jointly. Just consider the model having 4 losses.
  id: totrans-1456
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文中，每个网络都是分开训练的，但我们也可以联合训练。只需考虑模型有4个损失。
- en: RPN Classification (Object or not object)
  id: totrans-1457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RPN分类（目标或非目标）
- en: RPN Bounding box proposal
  id: totrans-1458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RPN边界框建议
- en: Fast RCNN Classification (Normal object classification)
  id: totrans-1459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速RCNN分类（普通对象分类）
- en: Fast RCNN Bounding-box regression (Improve previous BB proposal)
  id: totrans-1460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速RCNN边界框回归（改进以前的边界框建议）
- en: '![](FasterRCNNTrain.png)'
  id: totrans-1461
  prefs: []
  type: TYPE_IMG
  zh: '![](FasterRCNNTrain.png)'
- en: Faster RCNN results
  id: totrans-1462
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Faster RCNN结果
- en: The best result now is Faster RCNN with a resnet 101 layer.
  id: totrans-1463
  prefs: []
  type: TYPE_NORMAL
  zh: 现在最好的结果是具有resnet 101层的Faster RCNN。
- en: '![](FasterRCNNSpeedComparison.png)'
  id: totrans-1464
  prefs: []
  type: TYPE_IMG
  zh: '![](FasterRCNNSpeedComparison.png)'
- en: Complete Faster RCNN diagram
  id: totrans-1465
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完整的Faster RCNN图解
- en: This diagram represents the complete structure of the Faster RCNN using VGG16,
    I've found on a github project [here](https://github.com/mitmul/chainer-faster-rcnn).
    It uses a framework called [Chainer](https://github.com/pfnet/chainer) which is
    a complete framework using only python (Sometimes cython).
  id: totrans-1466
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表示了使用VGG16的Faster RCNN的完整结构，我在一个github项目[这里](https://github.com/mitmul/chainer-faster-rcnn)找到了它。它使用了一个叫做[Chainer](https://github.com/pfnet/chainer)的框架，这是一个仅使用Python（有时使用Cython）的完整框架。
- en: '![](Faster%20R-CNN.png)'
  id: totrans-1467
  prefs:
  - PREF_H2
  type: TYPE_IMG
  zh: '![](Faster%20R-CNN.png)'
- en: Next Chapter
  id: totrans-1468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章节
- en: '* * *'
  id: totrans-1469
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On the next chapter we will discuss a different type of object detector called
    single shot detectors.
  id: totrans-1470
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章节中，我们将讨论一种称为单次检测器的不同类型的目标检测器。
- en: Single Shot Detectors
  id: totrans-1471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单次检测器
- en: Single Shot detectors
  id: totrans-1472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单次检测器
- en: '* * *'
  id: totrans-1473
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Introduction
  id: totrans-1474
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'The previous methods of object detection all share one thing in common: they
    have one part of their network dedicated to providing region proposals followed
    by a high quality classifier to classify these proposals. These methods are very
    accurate but come at a big computational cost (low frame-rate), in other words
    they are not fit to be used on embedded devices.'
  id: totrans-1475
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的目标检测方法都有一个共同点：它们的网络的一部分专门用于提供区域建议，然后是一个高质量的分类器来对这些建议进行分类。这些方法非常精确，但计算成本很高（低帧率），换句话说，它们不适合在嵌入式设备上使用。
- en: Another way of doing object detection is by combining these two tasks into one
    network. We can do this by instead of having a network produce proposals we instead
    have a set of pre defined boxes in which to look for objects.
  id: totrans-1476
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种进行目标检测的方法是将这两个任务合并到一个网络中。我们可以通过不是让一个网络生成建议，而是在一组预定义的框中查找对象来实现这一点。
- en: Using convolutional features maps from later layers of a network we run small
    conv filters over these features maps to predict class scores and bounding box
    offsets.
  id: totrans-1477
  prefs: []
  type: TYPE_NORMAL
  zh: 使用网络的后几层的卷积特征图，我们在这些特征图上运行小的卷积滤波器来预测类别得分和边界框偏移量。
- en: 'Here is the family of object detectors that follow this strategy:'
  id: totrans-1478
  prefs: []
  type: TYPE_NORMAL
  zh: 这是遵循这种策略的目标检测器家族：
- en: 'SSD: Uses different activation maps (multiple-scales) for prediction of classes
    and bounding boxes'
  id: totrans-1479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSD：使用不同的激活图（多尺度）来预测类别和边界框
- en: 'YOLO: Uses a single activation map for prediction of classes and bounding boxes'
  id: totrans-1480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YOLO：使用单个激活图来预测类别和边界框
- en: 'R-FCN(Region based Fully-Convolution Neural Networks): Like Faster Rcnn, but
    faster due to less computation ber box.'
  id: totrans-1481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R-FCN（基于区域的完全卷积神经网络）：类似于Faster Rcnn，但由于每个框的计算量更少，因此更快。
- en: 'Multibox: asdasdas'
  id: totrans-1482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Multibox：asdasdas
- en: Using these multiple scales helps to achieve a higher mAP(mean average precision)
    by being able to detect objects with different sizes on the image.
  id: totrans-1483
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些多尺度有助于通过能够检测图像上不同尺寸的对象来实现更高的mAP（平均平均精度）。
- en: Summarising the strategy of these methods
  id: totrans-1484
  prefs: []
  type: TYPE_NORMAL
  zh: 总结这些方法的策略
- en: Train a CNN with regression(box) and classification objective (loss function).
  id: totrans-1485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用回归（框）和分类目标（损失函数）来训练CNN。
- en: Use sliding window (conv) and non-maxima suppression during prediction on the
    conv feature maps (output of conv-relu)
  id: totrans-1486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在预测时在卷积特征图（conv-relu的输出）上使用滑动窗口（卷积）和非极大值抑制
- en: On this kind of detectors it is typical to have a collection of boxes overlaid
    on the image at different spatial locations, scales and aspect ratios that act
    as “anchors” (sometimes called “priors” or “default boxes”).
  id: totrans-1487
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种类型的检测器上，通常在图像上有一系列不同的空间位置、尺度和长宽比的框叠加，作为“锚点”（有时称为“先验”或“默认框”）。
- en: 'A model is then trained to make two predictions for each anchor:'
  id: totrans-1488
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，模型被训练为对每个锚点进行两个预测：
- en: A discrete class prediction for each anchor
  id: totrans-1489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个锚点的离散类别预测
- en: A continuous prediction of an offset by which the anchor needs to be shifted
    to fit the ground-truth bounding box.
  id: totrans-1490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对每个锚点连续预测一个偏移量，以适应地面实况边界框。
- en: Also the loss used on this methods are a combination of the 2 objectives, localization(regression)
    and classification.
  id: totrans-1491
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用的损失也是两个目标的组合，即定位（回归）和分类。
- en: Image Segmentation
  id: totrans-1492
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分割
- en: Image Segmentation
  id: totrans-1493
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分割
- en: Introduction
  id: totrans-1494
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1495
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now we're going to learn how to classify each pixel on the image, the idea is
    to create a map of all detected object areas on the image. Basically what we want
    is the image bellow where every pixel has a label.
  id: totrans-1496
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将学习如何对图像中的每个像素进行分类，想法是在图像上创建所有检测到的对象区域的地图。基本上，我们想要的是下面的图像，其中每个像素都有一个标签。
- en: On this chapter we're going to learn how convolutional neural networks (CNN)
    can do the job.
  id: totrans-1497
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习卷积神经网络（CNN）如何完成这项工作。
- en: '![](ImageSegmentation.PNG)'
  id: totrans-1498
  prefs: []
  type: TYPE_IMG
  zh: '![](ImageSegmentation.PNG)'
- en: Fully Convolutional network for segmentation
  id: totrans-1499
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于分割的全卷积网络
- en: '* * *'
  id: totrans-1500
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: A Fully Convolutional neural network (FCN) is a normal CNN, where the last fully
    connected layer is substituted by another convolution layer with a large "receptive
    field". The idea is to capture the global context of the scene (Tell what we have
    on the image and also give some rude location where it is).
  id: totrans-1501
  prefs: []
  type: TYPE_NORMAL
  zh: 完全卷积神经网络（FCN）是一个普通的 CNN，其中最后一个全连接层被另一个具有大“接受域”的卷积层替换。想法是捕捉场景的全局上下文（告诉我们图像上有什么，同时给出一些粗略的位置）。
- en: '![](Fully_Convolutional_Network_Semantic.PNG)'
  id: totrans-1502
  prefs: []
  type: TYPE_IMG
  zh: '![](Fully_Convolutional_Network_Semantic.PNG)'
- en: Just remember that when we convert our last fully connected (FC) layer to a
    convolutional layer we gain some form of localization if we look where we have
    more activations.
  id: totrans-1503
  prefs: []
  type: TYPE_NORMAL
  zh: 只需记住，当我们将最后一个全连接（FC）层转换为卷积层时，如果我们查看哪些位置具有更多的激活，我们会获得一些形式的定位。
- en: '![](FCN.jpg)'
  id: totrans-1504
  prefs: []
  type: TYPE_IMG
  zh: '![](FCN.jpg)'
- en: The idea is that if we choose our new last conv layer to be big enough we will
    have this localization effect scaled up to our input image size.
  id: totrans-1505
  prefs: []
  type: TYPE_NORMAL
  zh: 想法是，如果我们选择新的最后一个 conv 层足够大，我们将在我们的输入图像大小上获得这种定位效果。
- en: Conversion from normal CNN to FCN
  id: totrans-1506
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从普通 CNN 转换为 FCN
- en: '* * *'
  id: totrans-1507
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Here is how we convert a normal CNN used for classification, ie: Alexnet to
    a FCN used for segmentation.'
  id: totrans-1508
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们如何将用于分类的普通 CNN，即：Alexnet，转换为用于分割的 FCN。
- en: 'Just to remember this is how Alexnet looks like:'
  id: totrans-1509
  prefs: []
  type: TYPE_NORMAL
  zh: 只需记住这就是 Alexnet 的外观：
- en: '![](AlexNet_2.png)'
  id: totrans-1510
  prefs: []
  type: TYPE_IMG
  zh: '![](AlexNet_2.png)'
- en: Bellow is also show the parameters for each layer
  id: totrans-1511
  prefs: []
  type: TYPE_NORMAL
  zh: 下面还显示了每个层的参数
- en: '![](AlexNet_1.jpg)'
  id: totrans-1512
  prefs: []
  type: TYPE_IMG
  zh: '![](AlexNet_1.jpg)'
- en: On Alexnet the inputs are fixed to be 227x227, so all the pooling effects will
    scale down the image from 227x227 to 55x55, 27x27, 13x13, then finally a single
    row vector on the FC layers.
  id: totrans-1513
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Alexnet，输入被固定为 227x227，因此所有池化效果将使图像从 227x227 缩小到 55x55，27x27，13x13，最后是 FC
    层上的单个行向量。
- en: '![](AlexNet_0.jpg)'
  id: totrans-1514
  prefs: []
  type: TYPE_IMG
  zh: '![](AlexNet_0.jpg)'
- en: Now let's look on the steps needed to do the conversion.
  id: totrans-1515
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看执行转换所需的步骤。
- en: 1) We start with a normal CNN for classification with
  id: totrans-1516
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 我们从用于分类的普通 CNN 开始，其中
- en: '![](FCN_CONV_1.png)'
  id: totrans-1517
  prefs: []
  type: TYPE_IMG
  zh: '![](FCN_CONV_1.png)'
- en: 2) The second step is to convert all the FC layers to convolution layers 1x1
    we don't even need to change the weights at this point. (This is already a fully
    convolutional neural network). The nice property of FCN networks is that we can
    now use any image size.
  id: totrans-1518
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 第二步是将所有 FC 层转换为 1x1 卷积层，此时我们甚至不需要改变权重。（这已经是一个完全卷积神经网络）。FCN 网络的一个很好的特性是我们现在可以使用任何图像大小。
- en: '![](FCN_CONV_2.png)'
  id: totrans-1519
  prefs: []
  type: TYPE_IMG
  zh: '![](FCN_CONV_2.png)'
- en: Observe here that with a FCN we can use a different size H x N.
  id: totrans-1520
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在 FCN 中，我们可以使用不同大小的 H x N。
- en: '![](FCN_CONV_3.png)'
  id: totrans-1521
  prefs: []
  type: TYPE_IMG
  zh: '![](FCN_CONV_3.png)'
- en: 3) The last step is to use a "deconv or transposed convolution" layer to recover
    the activation positions to something meaningful related to the image size. Imagine
    that we're just scaling up the activation size to the same image size.
  id: totrans-1522
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 最后一步是使用“反卷积或转置卷积”层将激活位置恢复到与图像大小相关的有意义的东西。想象一下，我们只是将激活大小缩放到相同的图像大小。
- en: This last "upsampling" layer also have lernable parameters.
  id: totrans-1523
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最后的“上采样”层也有可学习的参数。
- en: '![](FCN_CONV_4.png)'
  id: totrans-1524
  prefs: []
  type: TYPE_IMG
  zh: '![](FCN_CONV_4.png)'
- en: 'Now with this structure we just need to find some "ground truth" and to end
    to end learning, starting from e pre-trainned network ie: Imagenet.'
  id: totrans-1525
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有了这个结构，我们只需要找到一些“地面真相”和端对端学习，从预训练网络开始，即：Imagenet。
- en: The problem with this approach is that we loose some resolution by just doing
    this because the activations were downscaled on a lot of steps.
  id: totrans-1526
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的问题在于，仅通过这样做我们会失去一些分辨率，因为激活在许多步骤上都被缩小了。
- en: '![](FirstResultFCN_No_Skips.png)'
  id: totrans-1527
  prefs: []
  type: TYPE_IMG
  zh: '![](FirstResultFCN_No_Skips.png)'
- en: To solve this problem we also get some activation from previous layers and sum
    them together. This process is called "skip" from the creators of this algorithm.
  id: totrans-1528
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们还从前几层中获得一些激活，并将它们相加。这个过程被称为这个算法的创造者所谓的“跳过”。
- en: Even today (2016) the winners on Imagenet on the Segmentation category, used
    an ensemble of FCN to win the competition.
  id: totrans-1529
  prefs: []
  type: TYPE_NORMAL
  zh: 即使今天（2016年）ImageNet分割类别的获胜者，也使用了一系列FCN来赢得比赛。
- en: Those up-sampling operations used on skip are also learn-able.
  id: totrans-1530
  prefs: []
  type: TYPE_NORMAL
  zh: 那些用于跳过的上采样操作也是可学习的。
- en: '![](Skip_Layers_FCN.png)'
  id: totrans-1531
  prefs: []
  type: TYPE_IMG
  zh: '![](Skip_Layers_FCN.png)'
- en: Bellow we show the effects of this "skip" process notice how the resolution
    of the segmentation improves after some "skips"
  id: totrans-1532
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们展示了这个“跳过”过程的效果，注意在一些“跳过”后分割的分辨率如何改善。
- en: '![](AllSkips_FCN.png)'
  id: totrans-1533
  prefs: []
  type: TYPE_IMG
  zh: '![](AllSkips_FCN.png)'
- en: '![](SkipConnections.png)'
  id: totrans-1534
  prefs: []
  type: TYPE_IMG
  zh: '![](SkipConnections.png)'
- en: Transposed convolution layer (deconvolution "bad name")
  id: totrans-1535
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转置卷积层（反卷积“坏名字”）
- en: '* * *'
  id: totrans-1536
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Basically the idea is to scale up, the scale down effect made on all previous
    layers.
  id: totrans-1537
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上的想法是放大，作用在所有先前层上的缩小效果。
- en: '![](Conv_Deconv.PNG)'
  id: totrans-1538
  prefs: []
  type: TYPE_IMG
  zh: '![](Conv_Deconv.PNG)'
- en: '![](Deconv_exp.PNG)'
  id: totrans-1539
  prefs: []
  type: TYPE_IMG
  zh: '![](Deconv_exp.PNG)'
- en: '![](animUpsampling.gif)'
  id: totrans-1540
  prefs: []
  type: TYPE_IMG
  zh: '![](animUpsampling.gif)'
- en: It has this bad name because the upsamping forward propagation is the convolution
    backpropagation and the upsampling backpropagation is the convolution forward
    propagation.
  id: totrans-1541
  prefs: []
  type: TYPE_NORMAL
  zh: 它有这个坏名字，因为上采样前向传播是卷积反向传播，而上采样反向传播是卷积前向传播。
- en: Also in caffe source code it is wrong called "deconvolution"
  id: totrans-1542
  prefs: []
  type: TYPE_NORMAL
  zh: 在caffe源代码中，它错误地被称为“deconvolution”。
- en: Extreme segmentation
  id: totrans-1543
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 极端分割
- en: '* * *'
  id: totrans-1544
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: There is another thing that we can do to avoid those "skiping" steps and also
    give better segmentation.
  id: totrans-1545
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一件事情可以做，以避免这些“跳过”步骤并提供更好的分割。
- en: '![](Deconvnet.png)'
  id: totrans-1546
  prefs: []
  type: TYPE_IMG
  zh: '![](Deconvnet.png)'
- en: This architechture is called "Deconvnet" which is basically another network
    but now with all convolution and pooling layers reversed. As you may suspect this
    is heavy, it takes 6 days to train on a TitanX. But the results are really good.
  id: totrans-1547
  prefs: []
  type: TYPE_NORMAL
  zh: 这个架构被称为“Deconvnet”，基本上是另一个网络，但现在所有的卷积和池化层都被颠倒了。正如你可能猜到的，这很重要，它需要6天的时间在TitanX上训练。但结果确实很好。
- en: Another problem is that the trainning is made in 2 stages.
  id: totrans-1548
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是训练分为2个阶段。
- en: Also Deconvnets suffer less than FCN when there are small objects on the scene.
  id: totrans-1549
  prefs: []
  type: TYPE_NORMAL
  zh: 当场景中有小物体时，Deconvnets受到的影响比FCN少。
- en: The deconvolution network output a probability map with the same size as the
    input.
  id: totrans-1550
  prefs: []
  type: TYPE_NORMAL
  zh: 反卷积网络输出一个与输入相同大小的概率图。
- en: '![](DeconvnetResults.png)'
  id: totrans-1551
  prefs: []
  type: TYPE_IMG
  zh: '![](DeconvnetResults.png)'
- en: Unpooling
  id: totrans-1552
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反池化
- en: '* * *'
  id: totrans-1553
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Besides the deconvolution layer we also need now the unpooling layer. The max-pooling
    operation is non-invertible, but we can approximate, by recording the positions
    (Max Location switches) where we located the biggest values (during normal max-pool),
    then use this positions to reconstruct the data from the layer above (on this
    case a deconvolution)
  id: totrans-1554
  prefs: []
  type: TYPE_NORMAL
  zh: 除了反卷积层之外，我们现在还需要池化层。最大池化操作是不可逆的，但我们可以通过记录位置（最大位置切换）来近似，我们记录了我们找到的最大值的位置（在正常的最大池化期间），然后使用这些位置从上面的层重构数据（在这种情况下是反卷积）。
- en: '![](UnPoolinDiagram.png)'
  id: totrans-1555
  prefs: []
  type: TYPE_IMG
  zh: '![](UnPoolinDiagram.png)'
- en: '![](Unpooling_1.png)'
  id: totrans-1556
  prefs: []
  type: TYPE_IMG
  zh: '![](Unpooling_1.png)'
- en: '![](UnpoolResults.png)'
  id: totrans-1557
  prefs: []
  type: TYPE_IMG
  zh: '![](UnpoolResults.png)'
- en: Next Chapter
  id: totrans-1558
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1559
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On the next chapter we will discuss some libraries that support deep learning
  id: totrans-1560
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论一些支持深度学习的库
- en: GoogleNet
  id: totrans-1561
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GoogleNet
- en: GoogleNet
  id: totrans-1562
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GoogleNet
- en: Introduction
  id: totrans-1563
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1564
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](GoogleNet.png)'
  id: totrans-1565
  prefs: []
  type: TYPE_IMG
  zh: '![](GoogleNet.png)'
- en: On this chapter you will learn about the googleNet (Winning architecture on
    ImageNet 2014) and it's inception layers.
  id: totrans-1566
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解到GoogleNet（2014年ImageNet获胜架构）及其初始层。
- en: '![](ImagenetTable.png)'
  id: totrans-1567
  prefs: []
  type: TYPE_IMG
  zh: '![](ImagenetTable.png)'
- en: googleNet has 22 layer, and almost 12x less parameters (So faster and less then
    Alexnet and much more accurate.
  id: totrans-1568
  prefs: []
  type: TYPE_NORMAL
  zh: googleNet有22层，参数几乎少了12倍（因此比Alexnet更快，参数比更精确。
- en: Their idea was to make a model that also could be used on a smart-phone (Keep
    calculation budget around 1.5 billion multiply-adds on prediction).
  id: totrans-1569
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的想法是制作一个也可以在智能手机上使用的模型（使预测的计算预算约为15亿乘法加法）。
- en: Inception Layer
  id: totrans-1570
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始层
- en: '* * *'
  id: totrans-1571
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The idea of the inception layer is to cover a bigger area, but also keep a fine
    resolution for small information on the images. So the idea is to convolve in
    parallel different sizes from the most accurate detailing (1x1) to a bigger one
    (5x5).
  id: totrans-1572
  prefs: []
  type: TYPE_NORMAL
  zh: 初始层的想法是覆盖更大的区域，但也保持图像上小细节的精细分辨率。因此，这个想法是并行卷积不同大小的图像，从最精确的细节（1x1）到更大的细节（5x5）。
- en: The idea is that a series of gabor filters with different sizes, will handle
    better multiple objects scales. With the advantage that all filters on the inception
    layer are learnable.
  id: totrans-1573
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是一系列具有不同尺寸的gabor滤波器将更好地处理多个对象的尺度。具有所有滤波器的优势在于，inception层上的所有滤波器都是可学习的。
- en: The most straightforward way to improve performance on deep learning is to use
    more layers and more data, googleNet use 9 inception modules. The problem is that
    more parameters also means that your model is more prone to overfit. So to avoid
    a parameter explosion on the inception layers, all bottleneck techniques are exploited.
  id: totrans-1574
  prefs: []
  type: TYPE_NORMAL
  zh: 改进深度学习性能的最直接方法是使用更多的层和更多的数据，googleNet使用了9个inception模块。问题在于，更多的参数意味着您的模型更容易过拟合。因此，为了避免inception层的参数爆炸，利用了所有的瓶颈技术。
- en: '![](Naive_Version.png)'
  id: totrans-1575
  prefs: []
  type: TYPE_IMG
  zh: '![](Naive_Version.png)'
- en: '![](InceptionModules.png)'
  id: totrans-1576
  prefs: []
  type: TYPE_IMG
  zh: '![](InceptionModules.png)'
- en: '![](inception_1x1.png)'
  id: totrans-1577
  prefs: []
  type: TYPE_IMG
  zh: '![](inception_1x1.png)'
- en: Using the bottleneck approaches we can rebuild the inception module with more
    non-linearities and less parameters. Also a max pooling layer is added to summarize
    the content of the previous layer. All the results are concatenated one after
    the other, and given to the next layer.
  id: totrans-1578
  prefs: []
  type: TYPE_NORMAL
  zh: 使用瓶颈方法，我们可以重新构建具有更多非线性和更少参数的inception模块。还添加了一个最大池化层，用于总结前一层的内容。所有结果都在一起连接，然后传递给下一层。
- en: Caffe Example
  id: totrans-1579
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Caffe 示例
- en: '* * *'
  id: totrans-1580
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Bellow we present 2 inception layers on cascade from the original googleNet.
  id: totrans-1581
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们展示了两个级联的inception层，来自原始googleNet。
- en: '![](caffe_inception.png)'
  id: totrans-1582
  prefs: []
  type: TYPE_IMG
  zh: '![](caffe_inception.png)'
- en: Residual Net
  id: totrans-1583
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 残差网络
- en: Residual Net
  id: totrans-1584
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 残差网络
- en: Introduction
  id: totrans-1585
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1586
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This chapter will present the 2016 state of the art on object classification.
    The ResidualNet it's basically a 150 deep convolution neural network made by equal
    "residual" blocks.
  id: totrans-1587
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍2016年关于目标分类的最新技术。残差网络基本上是由相同的“残差”块组成的150层深度卷积神经网络。
- en: The problem is for real deep networks (more than 30 layers), all the known techniques
    (Relu, dropout, batch-norm, etc...) are not enough to do a good end-to-end training.
    This contrast with the common "empirical proven knowledge" that deeper is better.
  id: totrans-1588
  prefs: []
  type: TYPE_NORMAL
  zh: 对于真正深度的网络（超过30层），所有已知的技术（Relu、dropout、batch-norm等）都不足以进行良好的端到端训练。这与常见的“经验证明的知识”相矛盾，即更深层次的网络效果更好。
- en: The idea of the residual network is use blocks that re-route the input, and
    add to the concept learned from the previous layer. The idea is that during learning
    the next layer will learn the concepts of the previous layer plus the input of
    that previous layer. This would work better than just learn a concept without
    a reference that was used to learn that concept.
  id: totrans-1589
  prefs: []
  type: TYPE_NORMAL
  zh: 残差网络的理念是使用重新路由输入并添加到从前一层学习到的概念的块。这个想法是，在学习过程中，下一层将学习前一层的概念以及前一层的输入。这比仅仅学习一个概念而没有用于学习该概念的参考更有效。
- en: Another way to visualize their solution is remember that the back-propagation
    of a sum node will replicate the input gradient with no degradation.
  id: totrans-1590
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化他们解决方案的另一种方式是记住，和节点的反向传播将无损地复制输入梯度。
- en: '![](residual_building_block.png)'
  id: totrans-1591
  prefs: []
  type: TYPE_IMG
  zh: '![](residual_building_block.png)'
- en: Bellow we show an example of a 34-deep residual net.
  id: totrans-1592
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们展示了一个34层深度的残差网络的示例。
- en: '![](residualnet_34.png)'
  id: totrans-1593
  prefs: []
  type: TYPE_IMG
  zh: '![](residualnet_34.png)'
- en: The ResidualNet creators proved empiricaly that it's easier to train a 34-layer
    residual compared to a 34-layer cascaded (Like VGG).
  id: totrans-1594
  prefs: []
  type: TYPE_NORMAL
  zh: 残差网络的创建者经验证明，与34层级级联（如VGG）相比，训练34层级的残差网络更容易。
- en: Observe that on the end of the residual net there is only one fully connected
    layer followed by a previous average pool.
  id: totrans-1595
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在残差网络的末端，只有一个完全连接的层，后跟先前的平均池。
- en: Residual Block
  id: totrans-1596
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 残差块
- en: '* * *'
  id: totrans-1597
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: At it's core the residual net is formed by the following structure.
  id: totrans-1598
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，残差网络由以下结构组成。
- en: '![](residual_block.png)'
  id: totrans-1599
  prefs: []
  type: TYPE_IMG
  zh: '![](residual_block.png)'
- en: Basically this jump and adder creates a path for back-propagation, allowing
    even really deep models to be trained.
  id: totrans-1600
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，这种跳跃和加法器为反向传播创建了一条路径，即使是真正深的模型也可以进行训练。
- en: As mention before the Batch-Norm block alleviate the network initialization,
    but it can be omitted for not so deep models (less than 50 layers).
  id: totrans-1601
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Batch-Norm块缓解了网络的初始化，但对于不那么深的模型（少于50层）可以省略。
- en: Again like googlenet we must use bottlenecks to avoid a parameter explosion.
  id: totrans-1602
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于googlenet，我们必须使用瓶颈来避免参数爆炸。
- en: '![](residual_bottleneck.png)'
  id: totrans-1603
  prefs: []
  type: TYPE_IMG
  zh: '![](residual_bottleneck.png)'
- en: Just to remember for the bottleneck to work the previous layer must have same
    depth.
  id: totrans-1604
  prefs: []
  type: TYPE_NORMAL
  zh: 只需记住，要使瓶颈起作用，前一层必须具有相同的深度。
- en: Caffe Example
  id: totrans-1605
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Caffe 示例
- en: '* * *'
  id: totrans-1606
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here we show 2 cascaded residual blocks form residual net, due to difficulties
    with batch-norm layers, they were omitted but still residual net gives good results.
  id: totrans-1607
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了 2 个级联的残差块组成的残差网络，由于批量规范化层的困难，它们被省略了，但残差网络仍然给出了良好的结果。
- en: '![](caffe_residual.png)'
  id: totrans-1608
  prefs: []
  type: TYPE_IMG
  zh: '![](caffe_residual.png)'
- en: Deep Learning Libraries
  id: totrans-1609
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习库
- en: Deep Learning Libraries
  id: totrans-1610
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习库
- en: Introduction
  id: totrans-1611
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Discussion, and some examples on the most common deep learning libraries:'
  id: totrans-1612
  prefs: []
  type: TYPE_NORMAL
  zh: '讨论，并对最常见的深度学习库进行一些示例:'
- en: Caffe
  id: totrans-1613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caffe
- en: Torch
  id: totrans-1614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Torch
- en: TensorFlow
  id: totrans-1615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow
- en: Theano
  id: totrans-1616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Theano
- en: CNTK
  id: totrans-1617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNTK
- en: Caffe
  id: totrans-1618
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Caffe
- en: '* * *'
  id: totrans-1619
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: One of the most basic characteristic of caffe is that is easy to train simple
    non recurrent models.
  id: totrans-1620
  prefs: []
  type: TYPE_NORMAL
  zh: Caffe 最基本的特性之一是训练简单的非递归模型很容易。
- en: 'Most cool features:'
  id: totrans-1621
  prefs: []
  type: TYPE_NORMAL
  zh: '最酷的功能:'
- en: Good Performance, allows training with multiple GPUs
  id: totrans-1622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能好，允许使用多个 GPU 进行训练
- en: Implementation for CPU and GPU
  id: totrans-1623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于 CPU 和 GPU 的实现
- en: Source code is easy to read
  id: totrans-1624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源代码易于阅读
- en: Allow layer definition in Python
  id: totrans-1625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许在 Python 中定义层
- en: Has bidings for Python and Matlab
  id: totrans-1626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有 Python 和 Matlab 绑定
- en: Allows network definition with text language (No need to write code)
  id: totrans-1627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许使用文本语言进行网络定义（不需要编写代码）
- en: Fast dataset access through LMDB
  id: totrans-1628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 LMDB 快速访问数据集
- en: Allows network vizualization
  id: totrans-1629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许网络可视化
- en: Has web interface (Digits)
  id: totrans-1630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有 Web 界面 (Digits)
- en: 'Caffe Main classes:'
  id: totrans-1631
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Caffe 主要类:'
- en: '![](CaffeOverview.jpg)'
  id: totrans-1632
  prefs: []
  type: TYPE_IMG
  zh: '![](CaffeOverview.jpg)'
- en: 'Blob: Used to store data and diffs(Derivatives)'
  id: totrans-1633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Blob: 用于存储数据和 diffs（导数）'
- en: 'Layer: Some operation that transform a bottom blob(input) to top blobs(outputs)'
  id: totrans-1634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '层: 将底部 blob（输入）转换为顶部 blob（输出）的某些操作'
- en: 'Net: Set of connected layers'
  id: totrans-1635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Net: 一组连接的层'
- en: 'Solver: Call Net forward and backward propagation, update weights using gradient
    methods (Gradient descent, SGD, adagrad, etc...)'
  id: totrans-1636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Solver: 调用 Net 前向和后向传播，使用梯度方法（梯度下降、SGD、adagrad 等...）更新权重'
- en: Caffe training/validation files
  id: totrans-1637
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Caffe 训练/验证文件
- en: path/to/image/1.jpg [label]
  id: totrans-1638
  prefs: []
  type: TYPE_NORMAL
  zh: path/to/image/1.jpg [标签]
- en: Simple example
  id: totrans-1639
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单的示例
- en: Here a logistic regression classifier. Imagine as a neural network with one
    layer and a sigmoid (cross-entropy softmax) non-linearity.
  id: totrans-1640
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个逻辑回归分类器。想象成一个具有一个层和一个 sigmoid（交叉熵 softmax）非线性的神经网络。
- en: '![](Caffe_Logistic.jpg)'
  id: totrans-1641
  prefs: []
  type: TYPE_IMG
  zh: '![](Caffe_Logistic.jpg)'
- en: '![](Caffe_Proto_Logistic.jpg)'
  id: totrans-1642
  prefs: []
  type: TYPE_IMG
  zh: '![](Caffe_Proto_Logistic.jpg)'
- en: Caffe Cons
  id: totrans-1643
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Caffe 缺点
- en: Need to write C++ / Cuda code for new layers
  id: totrans-1644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于新层需要编写 C++ / Cuda 代码
- en: Bad to write protofiles for big networks (Resnet, googlenet)
  id: totrans-1645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大型网络（Resnet、googlenet）编写 protofiles 不好
- en: Bad to experience new architectures (Mainstream version does not support Fast
    RCNN)
  id: totrans-1646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 体验新架构不好（主流版本不支持 Fast RCNN）
- en: Torch
  id: totrans-1647
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Torch
- en: '* * *'
  id: totrans-1648
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Really good for research, the problem is that use a new language called Lua.
  id: totrans-1649
  prefs: []
  type: TYPE_NORMAL
  zh: 对于研究非常好，问题在于使用了一个叫 Lua 的新语言。
- en: Torch Pros
  id: totrans-1650
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Torch 优势
- en: Flexible
  id: totrans-1651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵活
- en: Very easy source code
  id: totrans-1652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常容易的源代码
- en: Easy biding with C/C++
  id: totrans-1653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 C/C++ 的绑定很容易
- en: Web interface (Digits)
  id: totrans-1654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web 界面 (Digits)
- en: Torch Cons
  id: totrans-1655
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Torch 优势
- en: New language Lua
  id: totrans-1656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新语言 Lua
- en: Difficult to load data from directories
  id: totrans-1657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从目录加载数据困难
- en: No Matlab bidings
  id: totrans-1658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有 Matlab 绑定
- en: Less Plug and play than caffe
  id: totrans-1659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比 Caffe 更加灵活
- en: Not easy for RNN
  id: totrans-1660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 RNN 不容易
- en: Theano
  id: totrans-1661
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Theano
- en: '* * *'
  id: totrans-1662
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Theano Cons
  id: totrans-1663
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Theano 缺点
- en: More manual
  id: totrans-1664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多手动操作
- en: No matlab biding
  id: totrans-1665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有 matlab 绑定
- en: Slower than other frameworks
  id: totrans-1666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比其他框架慢
- en: No much pre-trained models
  id: totrans-1667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有太多预训练模型
- en: Tensorflow
  id: totrans-1668
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Tensorflow
- en: '* * *'
  id: totrans-1669
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Tensorflow Pros
  id: totrans-1670
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tensorflow 优势
- en: Flexible
  id: totrans-1671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵活
- en: Good for RNN
  id: totrans-1672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于 RNN
- en: Allow distributed training
  id: totrans-1673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许分布式训练
- en: Tensorboard for signal visualization
  id: totrans-1674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信号可视化的 Tensorboard
- en: Python Numpy
  id: totrans-1675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python Numpy
- en: Tensorflow Cons
  id: totrans-1676
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tensorflow 缺点
- en: Not much pre-trained models
  id: totrans-1677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有太多预训练模型
- en: No Support for new object detection features (Ex Roi pooling)
  id: totrans-1678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不支持新的目标检测功能（如 Roi 池化）
- en: No support for datasets like Caffe
  id: totrans-1679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不支持像 Caffe 那样的数据集
- en: Slower than Caffe for single GPU training
  id: totrans-1680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于单 GPU 训练比 Caffe 慢
- en: CNTK
  id: totrans-1681
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNTK
- en: '* * *'
  id: totrans-1682
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: CNTK Pros
  id: totrans-1683
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CNTK 优势
- en: Flexible
  id: totrans-1684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵活的
- en: Good for RNN
  id: totrans-1685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于 RNN
- en: Allows distributed training
  id: totrans-1686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许分布式训练
- en: CNTK Cons
  id: totrans-1687
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CNTK 缺点
- en: No visualization
  id: totrans-1688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有可视化
- en: Any error CNTK crash
  id: totrans-1689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何错误 CNTK 崩溃
- en: No simple source code to read
  id: totrans-1690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有简单的源代码可供阅读
- en: New language (ndl) to describe networks
  id: totrans-1691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的语言 (ndl) 描述网络
- en: No current matlab or python bindings
  id: totrans-1692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前没有 matlab 或 python 绑定
- en: Summary
  id: totrans-1693
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概要
- en: For research use Torch or Tensorflow (Last option Theano)
  id: totrans-1694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于研究使用 Torch 或 Tensorflow（最后选项为 Theano）
- en: For training convnets or use pre-trained models use Caffe
  id: totrans-1695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于训练卷积网络或使用预训练模型，请使用 Caffe
- en: CS231n Deep learning course summary
  id: totrans-1696
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CS231n 深度学习课程总结
- en: '![](DeepLibrariesOverview.jpg)'
  id: totrans-1697
  prefs: []
  type: TYPE_IMG
  zh: '![](DeepLibrariesOverview.jpg)'
- en: 'Get features from known model (Alexnet, Googlenet, Vgg): Use caffe'
  id: totrans-1698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从已知模型（Alexnet、Googlenet、Vgg）中获取特征：使用 Caffe
- en: 'Fine tune known models (Alexnet, Googlenet, Vgg): Use Caffe'
  id: totrans-1699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调已知模型（Alexnet、Googlenet、Vgg）：使用 Caffe
- en: 'Image Captioning: Torch or Tensorflow'
  id: totrans-1700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '图像字幕: Torch 或 Tensorflow'
- en: 'Segmentation: Caffe, Torch'
  id: totrans-1701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '分割: Caffe, Torch'
- en: 'Object Detection: Caffe with python layers, Torch (More work)'
  id: totrans-1702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标检测：Caffe with python layers，Torch（更多工作）
- en: 'Language Modelling: Torch, Theano'
  id: totrans-1703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言建模：Torch，Theano
- en: 'Implement Bath Norm: Torch, Theano or Tensorflow'
  id: totrans-1704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现Bath Norm：Torch，Theano或Tensorflow
- en: Normally Tensorflow can be used in all cased that torch can, but if you need
    to understand what a specific layer does, or if you need to create a new layer,
    use torch instead of tensorflow. Torch is preferable on those cases, because the
    layer source code is more easy to read in torch.
  id: totrans-1705
  prefs: []
  type: TYPE_NORMAL
  zh: 通常Tensorflow可以在所有情况下使用Torch，但如果您需要了解特定层的功能，或者需要创建一个新层，请使用Torch而不是Tensorflow。在这些情况下，Torch更可取，因为Torch中的层源代码更易于阅读。
- en: Next Chapter
  id: totrans-1706
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一章
- en: '* * *'
  id: totrans-1707
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On the next chapter we will discuss Distributed Learning
  id: totrans-1708
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论分布式学习
- en: Unsupervised Learning
  id: totrans-1709
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Introduction
  id: totrans-1710
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1711
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As mentioned on previous chapters, unsupervised learning is about learning information
    without the label information.
  id: totrans-1712
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前几章所述，无监督学习是指在没有标签信息的情况下学习信息。
- en: Here the term information means, "structure" for instance you would like to
    know how many groups exist in your dataset, even if you don't know what those
    groups mean.
  id: totrans-1713
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的“信息”一词指的是“结构”，例如，您想知道数据集中存在多少组，即使您不知道这些组的含义。
- en: Also we use unsupervised learning to visualize your dataset, in order to try
    to learn some insight from the data.
  id: totrans-1714
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用无监督学习来可视化您的数据集，以尝试从数据中学习一些见解。
- en: Unlabeled data example
  id: totrans-1715
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无标签数据示例
- en: '* * *'
  id: totrans-1716
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Consider the following dataset ![](750c80ea.png) (X has 2 features)
  id: totrans-1717
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下数据集！[](750c80ea.png)（X有2个特征）
- en: '![](SimpleDataUnlabeled.png)'
  id: totrans-1718
  prefs: []
  type: TYPE_IMG
  zh: '![](SimpleDataUnlabeled.png)'
- en: One type of unsupervised learning algorithm called "clustering" is used to infer
    how many distinct groups exist on your dataset.
  id: totrans-1719
  prefs: []
  type: TYPE_NORMAL
  zh: 一种称为“聚类”的无监督学习算法用于推断数据集中存在多少个不同的组。
- en: '![](SimpleDataClustered.png)'
  id: totrans-1720
  prefs: []
  type: TYPE_IMG
  zh: '![](SimpleDataClustered.png)'
- en: Here we still don't know what those groups means, but we know that there are
    4 groups that seems very distinct. On this case we choose a low dimensional dataset
    ![](6a67a3f7.png) but on real life it could be thousands of dimensions, ie ![](fe46b6da.png)
    for a grayscale 28x28 image.
  id: totrans-1721
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们仍然不知道这些组的含义，但我们知道有4个看起来非常明显的组。在这种情况下，我们选择一个低维数据集！[](6a67a3f7.png)，但在现实生活中，它可能有数千个维度，例如！[](fe46b6da.png)对于一个灰度28x28图像。
- en: Dimensionality Reduction
  id: totrans-1722
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 降维
- en: '* * *'
  id: totrans-1723
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'In order to improve classification response time (not prediction performance)
    and sometimes for visualizing your high dimension dataset (2D, 3D), we use dimesionality
    reduction techniques (ie: PCA, T-Sne).'
  id: totrans-1724
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高分类响应时间（而非预测性能），有时为了可视化您的高维数据集（2D、3D），我们使用降维技术（例如：PCA、T-Sne）。
- en: For example the [MNIST datset](http://yann.lecun.com/exdb/mnist/) is composed
    with 60,000 training examples of (0..9) digits, each one with 784 dimensions.
    This high dimensionality is due to the fact that each digit is a 28x28 grayscale
    image.
  id: totrans-1725
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[MNIST数据集](http://yann.lecun.com/exdb/mnist/)由60,000个（0..9）数字的训练示例组成，每个数字具有784个维度。这种高维度是因为每个数字都是一个28x28的灰度图像。
- en: '![](MNIST_samples.png)'
  id: totrans-1726
  prefs: []
  type: TYPE_IMG
  zh: '![](MNIST_samples.png)'
- en: It would be difficult to vizualize this dataset, so one option is to reduce
    it's dimensions to something visible on the monitor (2D,3D).
  id: totrans-1727
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个数据集进行可视化将会很困难，因此一个选择是将其维度降低到在显示器上可见的内容（2D、3D）。
- en: '![](mnist_tSNE.jpg)'
  id: totrans-1728
  prefs: []
  type: TYPE_IMG
  zh: '![](mnist_tSNE.jpg)'
- en: Here is easy to observe that a classifier could have problems to differentiate
    the digit 1 and 7.
  id: totrans-1729
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里很容易观察到分类器可能在区分数字1和7时会遇到问题。
- en: Another advantage is that this gives us some hint on how good is our current
    set of features.
  id: totrans-1730
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个优点是这给了我们一些关于当前特征集有多好的线索。
- en: Autoencoders
  id: totrans-1731
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自编码器
- en: '* * *'
  id: totrans-1732
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We can also use neural networks to do dimensionality reduction the idea is that
    we have a neural network topology that approximate the input on the output layer.
    On the middle the autoencoder has smaller layer. After training the middle layer
    has a compressed version (lossy) of the input.
  id: totrans-1733
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用神经网络进行降维，其思想是我们有一个神经网络拓扑结构，可以在输出层上近似输入。在中间，自编码器有一个较小的层。训练后，中间层具有输入的压缩版本（有损）。
- en: '![](AutoEncoder.png)'
  id: totrans-1734
  prefs: []
  type: TYPE_IMG
  zh: '![](AutoEncoder.png)'
- en: Convolution Neural network pre-train
  id: totrans-1735
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 卷积神经��络预训练
- en: As we don't need the label information to train autoencoders, we can use them
    as a pre-trainer to our convolution neural network. So in the future we can start
    your training with the weights initialized from unsupervised training.
  id: totrans-1736
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在训练自编码器时不需要标签信息，我们可以将它们用作卷积神经网络的预训练器。因此，在未来，我们可以从无监督训练初始化权重开始训练。
- en: '![](conv_autoencoder.png)'
  id: totrans-1737
  prefs: []
  type: TYPE_IMG
  zh: '![](conv_autoencoder.png)'
- en: 'Some examples of this technique can be found here:'
  id: totrans-1738
  prefs: []
  type: TYPE_NORMAL
  zh: 一些此技术的例子可以在这里找到：
- en: '[With Python](https://swarbrickjones.wordpress.com/2015/04/29/convolutional-autoencoders-in-pythontheanolasagne/)'
  id: totrans-1739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Python](https://swarbrickjones.wordpress.com/2015/04/29/convolutional-autoencoders-in-pythontheanolasagne/)'
- en: '[With Torch](https://siavashk.github.io/2016/02/22/autoencoder-imagenet/)'
  id: totrans-1740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Torch](https://siavashk.github.io/2016/02/22/autoencoder-imagenet/)'
- en: Data Manifold
  id: totrans-1741
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据流形
- en: '* * *'
  id: totrans-1742
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Manifold Learning pursuits the goal to embed data that originally lies in a
    high dimensional space in a lower dimensional space, while preserving characteristic
    properties. This is possible because for any high dimensional data to be interesting,
    it must be intrinsically low dimensional.
  id: totrans-1743
  prefs: []
  type: TYPE_NORMAL
  zh: 流形学习的目标是将原本位于高维空间中的数据嵌入到低维空间中，同时保留特征属性。这是可能的，因为对于任何有趣的高维数据来说，它必须是固有地低维的。
- en: For example, images of faces might be represented as points in a high dimensional
    space (let’s say your camera has 5MP -- so your images, considering each pixel
    consists of three values [r,g,b], lie in a 15M dimensional space), but not every
    5MP image is a face. Faces lie on a sub-manifold in this high dimensional space.
  id: totrans-1744
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，人脸图像可以表示为高维空间中的点（假设您的相机有5MP -- 所以您的图像，考虑到每个像素由三个值[r,g,b]组成，位于一个1500万维空间中），但并不是每个5MP图像都是一个人脸。人脸位于这个高维空间中的一个子流形上。
- en: A sub-manifold is locally Euclidean, i.e. if you take two very similar points,
    for example two images of identical twins they will be close on the euclidian
    space
  id: totrans-1745
  prefs: []
  type: TYPE_NORMAL
  zh: 子流形在局部上是欧几里得的，即如果你取两个非常相似的点，比如两个相同双胞胎的图像，它们在欧几里得空间中会很接近。
- en: '![](ManifoldSubspace.jpg)'
  id: totrans-1746
  prefs: []
  type: TYPE_IMG
  zh: '![](ManifoldSubspace.jpg)'
- en: For example on the dataset above we have a high dimension manifold, but the
    faces sit's on a much lower dimension space (almost euclidian). So on this subspace
    things like distance has a meaning.
  id: totrans-1747
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在上面的数据集中，我们有一个高维流形，但是人脸位于一个更低维度的空间中（几乎欧几里得）。因此，在这个子空间中，距离之类的东西是有意义的。
- en: 'With the increase of more features, the data distribution will not be linear,
    so simpler linear techniques (ex: PCA) will not be useful for dimensionality reduction.
    On those cases we need other stuff like T-Sne, Autoencoders, etc..'
  id: totrans-1748
  prefs: []
  type: TYPE_NORMAL
  zh: 随着特征数量的增加，数据分布将不是线性的，因此简单的线性技术（例如：PCA）对于降维将不再有效。在这些情况下，我们需要其他东西，如T-Sne，自动编码器等。
- en: By the way dimensionality reduction on non-linear manifolds is sometimes called
    manifold learning.
  id: totrans-1749
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，对非线性流形进行降维有时被称为流形学习。
- en: '![](LinearNonLinear.png)'
  id: totrans-1750
  prefs: []
  type: TYPE_IMG
  zh: '![](LinearNonLinear.png)'
- en: '![](ScatterPlotsMatlab.png)'
  id: totrans-1751
  prefs: []
  type: TYPE_IMG
  zh: '![](ScatterPlotsMatlab.png)'
- en: 'Bellow we have a diagram that guide you depending on the type of problem:'
  id: totrans-1752
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个根据问题类型指导您的图表：
- en: '![](DimensionalityReduction.png)'
  id: totrans-1753
  prefs: []
  type: TYPE_IMG
  zh: '![](DimensionalityReduction.png)'
- en: Here is a comparison between the T-SNE method against PCA on MNIST dataset
  id: totrans-1754
  prefs: []
  type: TYPE_NORMAL
  zh: 这是T-SNE方法与MNIST数据集上PCA方法的比较
- en: '![](PCA_TSNE.png)'
  id: totrans-1755
  prefs: []
  type: TYPE_IMG
  zh: '![](PCA_TSNE.png)'
- en: Principal Component Analysis
  id: totrans-1756
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主成分分析
- en: Principal Component Analysis
  id: totrans-1757
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主成分分析
- en: Introduction
  id: totrans-1758
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1759
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On this chapter we're going to learn about Principal Component Analysis (PCA)
    which is a tool used to make dimensionality reduction. This is usefull because
    it make the job of classifiers easier in terms of speed, or to aid data visualization.
  id: totrans-1760
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习主成分分析（PCA），这是一种用于进行降维的工具。这很有用，因为它可以使分类器在速度方面更容易，或者可以帮助数据可视化。
- en: So what are principal components then? They're the underlying structure in the
    data. They are the directions where there is the most variance on your data, the
    directions where the data is most spread out.
  id: totrans-1761
  prefs: []
  type: TYPE_NORMAL
  zh: 那么主成分是什么呢？它们是数据中的基本结构。它们是数据方差最大的方向，数据最分散的方向。
- en: The only limitation if this algorithm is that it works better only when we have
    a linear manifold.
  id: totrans-1762
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法的唯一限制是，它只在我们拥有线性流形时才能更好地工作。
- en: The PCA algorithm will try to fit a plane that minimize a projection error (sum
    of all red-line sizes)
  id: totrans-1763
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析算法将尝试拟合一个最小化投影误差的平面（所有红线大小的总和）。
- en: Imagine that the PCA will try to rotate your data looking for a angle where
    it see more variances.
  id: totrans-1764
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，主成分分析将尝试旋转你的数据，寻找一个角度，在这个角度上它看到的方差更大。
- en: '![](PCAAnimation.gif)'
  id: totrans-1765
  prefs: []
  type: TYPE_IMG
  zh: '![](PCAAnimation.gif)'
- en: As mentioned before you can use PCA when your data has a linear data manifold.
  id: totrans-1766
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，当您的数据具有线性数据流形时，可以使用PCA。
- en: '![](PCA_3d.png)'
  id: totrans-1767
  prefs: []
  type: TYPE_IMG
  zh: '![](PCA_3d.png)'
- en: But for non linear manifolds we're going to have a lot of projection errors.
  id: totrans-1768
  prefs: []
  type: TYPE_NORMAL
  zh: 但对于非线性流形，我们将有很多投影误差。
- en: '![](SwissRoll_DataManifold.png) ![](PCA_SwissRoll.png)'
  id: totrans-1769
  prefs: []
  type: TYPE_IMG
  zh: '![](SwissRoll_DataManifold.png) ![](PCA_SwissRoll.png)'
- en: Calculating PCA
  id: totrans-1770
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算PCA
- en: '* * *'
  id: totrans-1771
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Preprocess the data: ![](106312a2.png)'
  id: totrans-1772
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理数据：![](106312a2.png)
- en: 'Calculate the covariance matrix: ![](655dd0e4.png), ![](dfaeb377.png) is the
    number of elements, X is a matrix ![](ca7f258c.png) where n is experiment number
    and p the features'
  id: totrans-1773
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算协方差矩阵：![](655dd0e4.png)，![](dfaeb377.png) 是元素的数量，X 是矩阵 ![](ca7f258c.png)，其中
    n 是实验次数，p 是特征数
- en: Get the eigenvectors of the covariance matrix ![](27af2486.png), here the U
    matrix will be a nxn matrix where every column of U will be the principal components,
    if we want to reduce our data from n dimensions to k, we choose k columns from
    U.
  id: totrans-1774
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取协方差矩阵的特征向量 ![](27af2486.png)，这里 U 矩阵将是一个 nxn 矩阵，其中 U 的每一列都是主成分，如果我们想要将数据从
    n 维降到 k 维，我们从 U 中选择 k 列。
- en: The preprocessing part sometimes includes a division by the standard deviation
    of each collumn, but there are cases that this is not needed. (The mean subtraction
    is more important)
  id: totrans-1775
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理部分有时包括对每列的标准差进行除法，但有些情况下这是不需要的。（减去平均值更重要）
- en: Reducing input data
  id: totrans-1776
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少输入数据
- en: '* * *'
  id: totrans-1777
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now that we calculate our principal components, which are stored on the matrix
    U, we will reduce our input data ![](aecd381d.png) from n dimensions to k dimensions
    ![](a86cb084.png). Here k is the number of columns of U. Depending on how you
    organized the data we can have 2 different formats for Z
  id: totrans-1778
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们计算了存储在矩阵 U 中的主成分，我们将把我们的输入数据从 n 维减少到 k 维 ![](aecd381d.png)。 这里 k 是 U 的列数。
    根据数据的组织方式，我们可以有 2 种不同的 Z 格式。
- en: '![](49ca84d0.png)'
  id: totrans-1779
  prefs: []
  type: TYPE_IMG
  zh: '![](49ca84d0.png)'
- en: Get the data back
  id: totrans-1780
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 恢复数据
- en: '* * *'
  id: totrans-1781
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'To reverse the transformation we do the following: ![](a800fa4.png)'
  id: totrans-1782
  prefs: []
  type: TYPE_NORMAL
  zh: 要反转换，我们进行以下操作：![](a800fa4.png)
- en: Example in Matlab
  id: totrans-1783
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Matlab 中的示例
- en: '* * *'
  id: totrans-1784
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: To illustrate the whole process we're going to calculate the PCA from an image,
    and then restore it with less dimensions.
  id: totrans-1785
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明整个过程，我们将从图像计算 PCA，然后用更少的维度恢复它。
- en: Get some data example
  id: totrans-1786
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 获取一些数据示例
- en: '* * *'
  id: totrans-1787
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here our data is a matrix with 15 samples of 3 measurements [15x3]
  id: totrans-1788
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们的数据是一个 15 个样本的 3 个测量值的矩阵 [15x3]
- en: '![](inputData_PCA.png)'
  id: totrans-1789
  prefs: []
  type: TYPE_IMG
  zh: '![](inputData_PCA.png)'
- en: Data pre-processing
  id: totrans-1790
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据预处理
- en: '* * *'
  id: totrans-1791
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now we're going to subtract the mean of each experiment from every column, then
    divide also each element by the standard deviation of each column.
  id: totrans-1792
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将从每个实验中减去每列的平均值，然后还要将每个元素除以每列的标准差。
- en: '![](Prep_InputPCA.png)'
  id: totrans-1793
  prefs: []
  type: TYPE_IMG
  zh: '![](Prep_InputPCA.png)'
- en: mean and std will work on all columns of X
  id: totrans-1794
  prefs: []
  type: TYPE_NORMAL
  zh: 均值和标准差将应用于 X 的所有列
- en: Calculate the covariance matrix
  id: totrans-1795
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算协方差矩阵
- en: '* * *'
  id: totrans-1796
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](cov_matrix_pca.png)'
  id: totrans-1797
  prefs: []
  type: TYPE_IMG
  zh: '![](cov_matrix_pca.png)'
- en: Get the principal components
  id: totrans-1798
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 获取主成分
- en: '* * *'
  id: totrans-1799
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now we use "svd" to get the principal components, which are the eigen-vectors
    and eigen-values of the covariance matrix
  id: totrans-1800
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用 "svd" 来获取主成分，这些主成分是协方差矩阵的特征向量和特征值
- en: '![](Pca_svd.png)'
  id: totrans-1801
  prefs: []
  type: TYPE_IMG
  zh: '![](Pca_svd.png)'
- en: There are different ways to calculate the PCA, for instance matlab gives already
    a function pca or princomp, which could give different signs on the eigenvectors
    (U) but they all represent the same components.
  id: totrans-1802
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的方法来计算 PCA，例如 matlab 已经提供了一个 pca 或 princomp 函数，它们可能给出特征向量 (U) 上不同的符号，但它们都代表相同的组件。
- en: '![](other_pca.png)'
  id: totrans-1803
  prefs: []
  type: TYPE_IMG
  zh: '![](other_pca.png)'
- en: The one thing that you should pay attention is the order of the input matrix,
    because some methods to find the PCA, expect that your samples and measurements,
    are in some pre-defined order.
  id: totrans-1804
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该注意的一件事是输入矩阵的顺序，因为某些找到 PCA 的方法会期望您的样本和测量值按某种预定义的顺序排列。
- en: Recover original data
  id: totrans-1805
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 恢复原始数据
- en: '* * *'
  id: totrans-1806
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now to recover the original data we use all the components, and also reverse
    the preprocessing.
  id: totrans-1807
  prefs: []
  type: TYPE_NORMAL
  zh: 现在为了恢复原始数据，我们使用所有的组件，还要反转预处理。
- en: '![](X_Recover_PCA.png)'
  id: totrans-1808
  prefs: []
  type: TYPE_IMG
  zh: '![](X_Recover_PCA.png)'
- en: Reducing our data
  id: totrans-1809
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 减少我们的数据
- en: '* * *'
  id: totrans-1810
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Actually normally we do something before we Now that we have our principal components
    let's apply for instance k=2
  id: totrans-1811
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，通常我们会在开始之前做一些操作。现在我们有了主成分，让我们应用 k=2
- en: '![](PCA_Reduce.png)'
  id: totrans-1812
  prefs: []
  type: TYPE_IMG
  zh: '![](PCA_Reduce.png)'
- en: We can use the principal components Z to recreate the data X, but with some
    loss. The idea is that the data in Z is smaller than X, but with similar variance.
    On this case we have ![](21509b2a.png) awe could reproduce the data X_loss with
    ![](d2d11d37.png), so one dimension less.
  id: totrans-1813
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用主成分 Z 来重新创建数据 X，但会有一些损失。 思路是 Z 中的数据比 X 小，但方差相似。 在这种情况下，我们有 ![](21509b2a.png)
    我们可以用 ![](d2d11d37.png) 来复制数据 X_loss，所以维度少了一个。
- en: '![](X_loss_PCA.png)'
  id: totrans-1814
  prefs: []
  type: TYPE_IMG
  zh: '![](X_loss_PCA.png)'
- en: Using PCA on images
  id: totrans-1815
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在图像上使用 PCA
- en: '* * *'
  id: totrans-1816
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Before finish the chapter we're going to use PCA on images.
  id: totrans-1817
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束本章之前，我们将在图像上使用 PCA。
- en: '![](PCA_Image_Compression_Code.png)'
  id: totrans-1818
  prefs: []
  type: TYPE_IMG
  zh: '![](PCA_Image_Compression_Code.png)'
- en: '![](PCA_image_compression.png)'
  id: totrans-1819
  prefs: []
  type: TYPE_IMG
  zh: '![](PCA_image_compression.png)'
- en: Generative Models
  id: totrans-1820
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: Generative Models
  id: totrans-1821
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: The idea of generative models, is to be able to learn the probability distribution
    of the training set. By doing this the generative model can create more data from
    the original data. Imagine as been the perfect dataset augmentation system. So
    basically it can be used as a unsupervised way to generate samples to train other
    networks better.
  id: totrans-1822
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型的思想是能够学习训练集的概率分布。通过这样做，生成模型可以从原始数据中创建更多数据。想象一下，它是完美的数据增强系统。因此，基本上它可以作为一种无监督的方式来生成样本，以更好地训练其他网络。
- en: Basically this done by having 2 neural networks playing against each other.
  id: totrans-1823
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，这是通过让两个神经网络相互对抗来完成的。
- en: Distributed Learning
  id: totrans-1824
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式学习
- en: Introduction
  id: totrans-1825
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1826
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Learn how the training of deep models can be distributed across multiple machines.
  id: totrans-1827
  prefs: []
  type: TYPE_NORMAL
  zh: 了解如何将深度模型的训练分布到多台机器上。
- en: Map Reduce
  id: totrans-1828
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Map Reduce
- en: '* * *'
  id: totrans-1829
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Map Reduce can be described on the following steps:'
  id: totrans-1830
  prefs: []
  type: TYPE_NORMAL
  zh: Map Reduce可以描述为以下步骤：
- en: 'Split your training set, in batches (ex: divide by the number of workers on
    your farm: 4)'
  id: totrans-1831
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练集分割成批次（例如：按照你的农场工人数量划分：4）
- en: Give each machine of your farm 1/4th of the data
  id: totrans-1832
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将农场中的每台机器分配1/4的数据
- en: Perform Forward/Backward propagation, on each computer node (All nodes share
    the same model)
  id: totrans-1833
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每台计算机节点上执行前向/后向传播（所有节点共享相同的模型）
- en: Combine results of each machine and perform gradient descent
  id: totrans-1834
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并每台机器的结果并执行梯度下降
- en: Update model version on all nodes.
  id: totrans-1835
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新所有节点上的模型版本。
- en: '![](MapReduceSimple.png)'
  id: totrans-1836
  prefs: []
  type: TYPE_IMG
  zh: '![](MapReduceSimple.png)'
- en: Example Linear Regression model
  id: totrans-1837
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例线性回归模型
- en: '* * *'
  id: totrans-1838
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Consider the batch gradient descent formula, which is the gradient descent
    applied on all training set:'
  id: totrans-1839
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑批量梯度下降公式，即应用于所有训练集的梯度下降：
- en: '![](bd56965d.png)'
  id: totrans-1840
  prefs: []
  type: TYPE_IMG
  zh: '![](bd56965d.png)'
- en: 'Each machine will deal with 100 elements (After splitting the dataset), calculating
    ![](6a936391.png), then:'
  id: totrans-1841
  prefs: []
  type: TYPE_NORMAL
  zh: 每台机器将处理100个元素（在分割数据集之后），计算![](6a936391.png)，然后：
- en: '![](3bc3ebcb.png)'
  id: totrans-1842
  prefs: []
  type: TYPE_IMG
  zh: '![](3bc3ebcb.png)'
- en: Each machine is calculating the back-propagation and error for it's own split
    of data. Remember that all machines have the same copy of the model.
  id: totrans-1843
  prefs: []
  type: TYPE_NORMAL
  zh: 每台机器都在计算其自己数据分割的反向传播和误差。请记住，所有机器都有模型的相同副本。
- en: After each machine calculated their respective ![](706202b.png). Another machine
    will combine those gradients, calculate the new weights and update the model in
    all machines.
  id: totrans-1844
  prefs: []
  type: TYPE_NORMAL
  zh: 在每台机器计算出各自的![](706202b.png)后，另一台机器将合并这些梯度，计算新的权重并更新所有机器上的模型。
- en: '![](215027ae.png)'
  id: totrans-1845
  prefs: []
  type: TYPE_IMG
  zh: '![](215027ae.png)'
- en: The whole point of this procedure is to check if we can combine the calculations
    of all nodes and still make sense, in terms of the final calculation.
  id: totrans-1846
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的整个目的是检查我们是否可以合并所有节点的计算，并且仍然能够在最终计算中有意义。
- en: Who use this approach
  id: totrans-1847
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用这种方法的人
- en: '* * *'
  id: totrans-1848
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Caffe
  id: totrans-1849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caffe
- en: Torch (Parallel layer)
  id: totrans-1850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Torch（并行层）
- en: Problems
  id: totrans-1851
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题
- en: 'This approach has some problems:'
  id: totrans-1852
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法有一些问题：
- en: The complete model must fit on every machine
  id: totrans-1853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整的模型必须适合每台机器。
- en: If the model is to big it will take time to update all machines with the same
    model
  id: totrans-1854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型太大，将需要一段时间将所有机器更新为相同的模型。
- en: Split weights
  id: totrans-1855
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分割权重
- en: '* * *'
  id: totrans-1856
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Another approach whas used on google DistBelief project where they use a normal
    neural network model with weights separated between multiple machines.
  id: totrans-1857
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是在谷歌的DistBelief项目中使用的，他们使用一个普通的神经网络模型，权重分布在多台机器之间。
- en: '![](DistNeuralNetwork.png)'
  id: totrans-1858
  prefs: []
  type: TYPE_IMG
  zh: '![](DistNeuralNetwork.png)'
- en: On this approach only the weights (thick edges) that cross machines need to
    be synchronized between the workers. This technique could only be used on fully
    connected layers.
  id: totrans-1859
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，只有跨机器传递的权重（粗边）需要在工作节点之间进行同步。这种技术只能用于完全连接的层。
- en: If you mix both techniques (reference on Alexnet) paper, you do this share fully
    connected processing (Just a matrix multiplication), then when you need to the
    the convolution part, each convolution layer get one part of the batch.
  id: totrans-1860
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将两种技术（参考Alexnet论文）混合在一起，你会做到完全连接的处理（只是矩阵乘法），然后当你需要卷积部分时，每个卷积层都会得到批次的一部分。
- en: '![](AlexnetDistribution.png)'
  id: totrans-1861
  prefs: []
  type: TYPE_IMG
  zh: '![](AlexnetDistribution.png)'
- en: Google approach (old)
  id: totrans-1862
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谷歌的旧方法
- en: '* * *'
  id: totrans-1863
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](GoogleDistOldApproach.png)'
  id: totrans-1864
  prefs: []
  type: TYPE_IMG
  zh: '![](GoogleDistOldApproach.png)'
- en: Here each model replica is trained independently with pieces of data and a parameter
    server that synchronize the parameters between the workers.
  id: totrans-1865
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，每个模型副本都独立训练，使用数据片段和一个参数服务器来在工作节点之间同步参数。
- en: Google new approach
  id: totrans-1866
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谷歌的新方法
- en: '* * *'
  id: totrans-1867
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now google offer on Tensorflow some automation on choosing which strategy to
    follow depending on your work.
  id: totrans-1868
  prefs: []
  type: TYPE_NORMAL
  zh: 现在谷歌在Tensorflow上提供了一些自动化选择策略的功能，具体取决于你的工作。
- en: '![](TensorflowDistributes.png)'
  id: totrans-1869
  prefs: []
  type: TYPE_IMG
  zh: '![](TensorflowDistributes.png)'
- en: Asynchronous Stochastic Gradient Descent
  id: totrans-1870
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步随机梯度下降
- en: Methodology for usage
  id: totrans-1871
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用法方法论
- en: Introduction
  id: totrans-1872
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-1873
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This chapter will give a [recipe](https://www.youtube.com/watch?v=NKiwFF_zBu4&t=997s)
    on how to tackle Machine learning problems
  id: totrans-1874
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍如何解决机器学习问题的[配方](https://www.youtube.com/watch?v=NKiwFF_zBu4&t=997s)。
- en: 3 Step process
  id: totrans-1875
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3步骤流程
- en: Define what you need to do and how to measure(metrics) how well/bad you are
    going.
  id: totrans-1876
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义您需要做什么以及如何测量（指标）您的表现如何。
- en: Start with a very simple model (Few layers)
  id: totrans-1877
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一个非常简单的模型开始（少量层）
- en: Add more complexity when needed.
  id: totrans-1878
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在需要时增加更多复杂性。
- en: Define goals
  id: totrans-1879
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义目标
- en: Normally by being slightly better than human performance(in terms of accuracy
    or prediction time), is already enough for a good product.
  id: totrans-1880
  prefs: []
  type: TYPE_NORMAL
  zh: 通常稍微好于人类表现（以准确性或预测时间为标准），已经足够成为一个好产品。
- en: Metrics
  id: totrans-1881
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指标
- en: 'Accuracy: % of correct examples'
  id: totrans-1882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度：正确示例的百分比
- en: 'Coverage: Number of processed examples per unit of time'
  id: totrans-1883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 覆盖范围：每单位时间处理的示例数
- en: 'Precision: Number of detections that are correct'
  id: totrans-1884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精度：正确检测的数量
- en: 'Error: Amount of error'
  id: totrans-1885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误：错误量
- en: Start with simplest model
  id: totrans-1886
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从最简单的模型开始
- en: Look if available for the state-of-the-art method for solving that problem.
    If not available use the following recipe.
  id: totrans-1887
  prefs: []
  type: TYPE_NORMAL
  zh: 查看是否有解决该问题的最先进方法。 如果不可用，请使用以下配方。
- en: 'Lots of noise and now much structure(ex: House price from features like number
    of rooms,kitchen size, etc...): Don''t use deep learning'
  id: totrans-1888
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 很多噪音而现在很少结构（例如：房价来自特征如房间数量、厨房大小等）：不要使用深度学习
- en: 'Few noise but lot''s of structure (ex: Images, video, text): Use deep learning'
  id: totrans-1889
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些噪音但是很多结构（例如：图像、视频、文本）：使用深度学习
- en: 'Examples for Non-deep methods:'
  id: totrans-1890
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 非深度方法示例：
- en: Logistic Regression
  id: totrans-1891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: SVM
  id: totrans-1892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Boosted decision trees (Previous favorite "default" algorithm), used a lot in
    robotics
  id: totrans-1893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升决策树（以前的最爱“默认”算法），在机器人技术中大量使用
- en: What kind of deep
  id: totrans-1894
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 什么样的深度
- en: 'Few structure: Use only Fully-Connected layers 2-3 layers (Relu, Dropout, SGD+Momentum).
    Need at least few thousand examples per class.'
  id: totrans-1895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少量结构：只使用全连接层2-3层（Relu，Dropout，SGD+Momentum）。 每类至少需要几千个示例。
- en: 'Spatial structure: Use CONV layers (Inception/Residual, Relu, Droput, Batch-Norm,
    SGD+Momentum).'
  id: totrans-1896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间结构：使用CONV层（Inception/Residual，Relu，Droput，Batch-Norm，SGD+Momentum）。
- en: 'Sequencial structure (text, market movement): Use Recurrent networks (LSTM,
    SGD, Gradient clipping).'
  id: totrans-1897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺序结构（文本、市场走势）：使用循环网络（LSTM，SGD，梯度裁剪）。
- en: When using Residual/Inception networks start with the shallowest example possible.
  id: totrans-1898
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Residual/Inception网络时从最浅的示例开始。
- en: Solving High train errors
  id: totrans-1899
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解决高训练错误
- en: 'Do the following actions on this order:'
  id: totrans-1900
  prefs: []
  type: TYPE_NORMAL
  zh: 按以下顺序执行以下操作：
- en: Inspect for defects on the data. (Need human intervention)
  id: totrans-1901
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查数据的缺陷。 （需要人工干预）
- en: Check for software bugs on your library. (Use gradient check, it's probably
    a backprop error)
  id: totrans-1902
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查您的库中是否有软件错误。（使用梯度检查，可能是反向传播错误）
- en: Tune learning rate (Make it smaller)
  id: totrans-1903
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整学习率（使其更小）
- en: Make network deeper. (You should start with a shallow network on the beginning)
  id: totrans-1904
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使网络更深。 （您应该从最初的浅网络开始）
- en: Solving High test errors
  id: totrans-1905
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解决高测试错误
- en: 'Do the following actions on this order:'
  id: totrans-1906
  prefs: []
  type: TYPE_NORMAL
  zh: 按以下顺序执行以下操作：
- en: Do more data augmentation (Also try generative models to create more data)
  id: totrans-1907
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 做更多数据增强（也尝试生成模型来创建更多数据）
- en: Add dropout and batch-norm
  id: totrans-1908
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加丢弃和批量规范化
- en: Get more data (More data has more influence on Accuracy then anything else)
  id: totrans-1909
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取更多数据（更多数据对准确性的影响大于其他任何因素）
- en: Some trends
  id: totrans-1910
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一些趋势
- en: Following the late 2016 Andrew Ng [lecture](https://www.youtube.com/watch?v=F1ka6a13S9I&t=564s)
    these are the topics that we need to pay attention.
  id: totrans-1911
  prefs: []
  type: TYPE_NORMAL
  zh: 按照2016年底的Andrew Ng的[讲座](https://www.youtube.com/watch?v=F1ka6a13S9I&t=564s)，这些是我们需要注意的主题。
- en: 1\. Scalability
  id: totrans-1912
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1. 可扩展性
- en: Have a computing system that scale well for more data and more model complexity.
  id: totrans-1913
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个能够很好地扩展更多数据和更复杂模型的计算系统。
- en: 2\. Team
  id: totrans-1914
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2. 团队
- en: Have on your team divided with with AI people and HPC (Cuda, OpenCl, etc...).
  id: totrans-1915
  prefs: []
  type: TYPE_NORMAL
  zh: 分为AI人员和HPC（Cuda，OpenCl等）的团队。
- en: 3\. Data first
  id: totrans-1916
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3. 数据优先
- en: Data is more important than your model, always try to get more quality data
    before trying to change your model.
  id: totrans-1917
  prefs: []
  type: TYPE_NORMAL
  zh: 数据比您的模型更重要，在尝试更改模型之前，始终尝试获取更多优质数据。
- en: 4\. Data Augmentation
  id: totrans-1918
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4. 数据增强
- en: Use normal data augmentation techniques plus Generative models(Unsupervised).
  id: totrans-1919
  prefs: []
  type: TYPE_NORMAL
  zh: 使用常规数据增强技术加上生成模型（无监督）。
- en: 5\. Make sure that Validation Set and Test set come from same distribution
  id: totrans-1920
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5. 确保验证集和测试集来自相同的分布
- en: This will avoid having a test or validation set that does not tell the reality.
    Also helps to check if your training is valid.
  id: totrans-1921
  prefs: []
  type: TYPE_NORMAL
  zh: 这将避免有一个不能反映现实的测试或验证集。还有助于检查您的训练是否有效。
- en: 6\. Have Human level performance metric
  id: totrans-1922
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6\. 具有人类水平的性能指标
- en: Have a team of experts to compare with your current system performance. Also
    it drives decisions between getting more data, or making model more complex.
  id: totrans-1923
  prefs: []
  type: TYPE_NORMAL
  zh: 组建一个专家团队来比较你当前系统的性能。同时，它推动在获取更多数据与使模型更复杂之间做出决策。
- en: 7\. Data server
  id: totrans-1924
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7\. 数据服务器
- en: Have a unified data-warehouse. All team must have access to data, with SSD quality
    access speed.
  id: totrans-1925
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有统一的数据仓库。所有团队必须能够访问数据，并且具有 SSD 质量的访问速度。
- en: 8\. Using Games
  id: totrans-1926
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8\. 使用游戏
- en: Using games are cool to help augment datasets, but attention because games does
    not have the same variants of the same class as real life. For example GTA does
    not have enough car models compared to real life.
  id: totrans-1927
  prefs: []
  type: TYPE_NORMAL
  zh: 使用游戏来帮助增加数据集是很酷的，但要注意，因为游戏与现实生活中的同一类别的变种不同。例如，GTA 的汽车模型不足以与现实生活相比较。
- en: 9\. Ensembles always help
  id: totrans-1928
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9\. 集成始终是有帮助的
- en: Training separately different networks and averaging their end results always
    gives some extra 2% accuracy. (Imagenet 2016 best results were simple ensambles)
  id: totrans-1929
  prefs: []
  type: TYPE_NORMAL
  zh: 分别训练不同的网络并平均它们的最终结果总是会增加额外的 2% 的准确性。（Imagenet 2016 年的最佳结果是简单的集成模型）
- en: 10\. What to do if you have more than 1000 classes
  id: totrans-1930
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10\. 如果你有超过 1000 个类别该怎么办？
- en: Use hierarchical Softmax to increase performance.
  id: totrans-1931
  prefs: []
  type: TYPE_NORMAL
  zh: 使用分层 Softmax 来提高性能。
- en: 11\. How many samples per class do we need to have good result
  id: totrans-1932
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11\. 每个类别需要多少样本才能获得良好的结果？
- en: If training from scratch, use the same number of parameters. For example Model
    has 1000 parameters, so use 1000 samples per class.
  id: totrans-1933
  prefs: []
  type: TYPE_NORMAL
  zh: 如果从头开始训练，请使用相同数量的参数。例如，模型有 1000 个参数，因此每个类别使用 1000 个样本。
- en: If doing transfer learning is much less (Much is not defined yet, more is better).
  id: totrans-1934
  prefs: []
  type: TYPE_NORMAL
  zh: 如果进行迁移学习，则样本数量要少得多（“多”尚未定义，更多是更好的）。
