- en: MapReduce
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MapReduce
- en: '6.824 2015 Lecture 13: MapReduce'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6.824 2015年讲座13：MapReduce
- en: '**Note:** These lecture notes were slightly modified from the ones posted on
    the 6.824 [course website](http://nil.csail.mit.edu/6.824/2015/schedule.html)
    from Spring 2015.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：**这些讲义笔记是从2015年春季的6.824[课程网站](http://nil.csail.mit.edu/6.824/2015/schedule.html)上略微修改的。'
- en: Intro
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 2nd trip to this paper, talk more about fault tolerance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二次查看这篇论文，更多地讨论容错。
- en: See [first lecture](l01-intro.html)
  id: totrans-5
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参见[第一讲](l01-intro.html)
- en: a real triumph of simplicity for the programmer
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序员的真正胜利是简单性
- en: clever design tricks to get good performance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 巧妙的设计技巧以获得良好的性能。
- en: 'Example: Building an inverted index'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 例如：构建倒排索引
- en: you need an inverted index for a search index
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要一个倒排索引来进行搜索索引
- en: maps keywords to documents they are found in
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将关键字映射到它们所在的文档
- en: 'Example:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output that we want, is an index: for each word in the input, we want a
    list of every place that word occurred (document + offset):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要的输出是一个索引：对于输入中的每个单词，我们希望得到该单词出现的每个地方的列表（文档+偏移量）：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The actual map/reduce functions for building an inverted index:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 用于构建倒排索引的实际映射/减少函数：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Input files
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入文件
- en: In MapReduce, the input is stored in GFS (Google's file system)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在MapReduce中，输入存储在GFS（Google的文件系统）中
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: What happens if the column of data for a reduce worker not fitting in memory?
    Seems like it would go to disk.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个减少工作者的数据列不适合内存会发生什么？似乎会写入磁盘。
- en: Note that a single reduce call happens for every unique keyword. So, in our
    inverted index example, this would mean a single reduce call for the keyword "the"
    which would appear probably a billion times in a large collection of documents.
    Thus, this will take a while. MapReduce cannot parallelize the work in a reduce
    call (lost opportunity for certain reduce functions that are composable, like
    f(reduce(k, l1), reduce(k, l2)) = reduce(k, l1+l2) ).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，对于每个唯一的关键字，都会发生一次单独的减少调用。因此，在我们的倒排索引示例中，这意味着对于关键字“the”，可能会出现一亿次在大量文档中。因此，这会花一些时间。MapReduce无法并行处理减少调用中的工作（对于某些可组合的减少函数（比如f(reduce(k,
    l1), reduce(k, l2)) = reduce(k, l1+l2)）来说是一个失去的机会）。
- en: I think *combiner functions* mentioned in the paper, can alleviate this issue
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我认为论文中提到的*组合器函数*可以缓解这个问题。
- en: Performance
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: it's all about data movement
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一切都是关于数据移动的
- en: pushing terrabytes of data across a cluster
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在集群中推送几千兆字节的数据
- en: 1000 machines
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1000台机器
- en: can maybe push data to RAM (1GB/s) at 1000 GB/s
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能可以将数据推送到RAM（1GB/s）以达到1000GB/s
- en: can maybe push data to disk (100MB/s) at 100 GB/s
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能可以将数据推送到磁盘（100MB/s）以达到100GB/s
- en: network can run at 1Gbit/s = 100MB/s on a machine
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络在一台机器上可以以1Gbit/s = 100MB/s的速度运行。
- en: for 1000 machine, the wiring is expensive and costs you speed
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于1000台机器，布线是昂贵的，并且会降低速度
- en: network is usually a tree with servers at the leaves and bigger switches in
    the internal nodes
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络通常是一棵树，叶子节点上有服务器，内部节点上有更大的交换机。
- en: bottleneck is root switch, which runs at 18GB/s at Google
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 瓶颈是根交换机，在谷歌以18GB/s运行
- en: thus, network can only push data at 18GB/s `=>` *bottleneck*
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，网络只能以18GB/s的速度推送数据`=>` *瓶颈*
- en: Design insights
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计见解
- en: Need to cope with the network problem.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 需要应对网络问题。
- en: Distributed Shared Memory (DSM) is very flexible in that any machine can write
    memory on any location in (distributed) memory. The problem is that you end up
    w/ very bandwidth inefficient and latency sensitive systems. If you allow arbitrary
    reads/writes to data you end up with a bunch of latency-sensitive small data movements
    across the network.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式共享内存（DSM）在任何机器都可以在（分布式）内存中写入内存方面非常灵活。问题在于，你最终会得到非常低效的带宽和延迟敏感的系统。如果允许对数据进行任意读/写，则最终会出现一堆跨网络的延迟敏感的小数据移动。
- en: DSM makes fault tolerance quite difficult, when a single machine dies, because
    each machine can do whatever it wants (read or write any mem. loc.), so it's hard
    to checkpoint the system.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当单台机器死机时，DSM使容错变得非常困难，因为每台机器都可以做任何想做的事情（读取或写入任何内存位置），因此很难对系统进行检查点。
- en: '**Key ideas:**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键点：**'
- en: '`Map()` and `Reduce()` work on local data only.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Map()` 和 `Reduce()` 仅在本地数据上运行。'
- en: '`Map()` and `Reduce()` only operate on big pieces of data'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Map()` 和 `Reduce()` 只对大块数据进行操作'
- en: to amortize network cost of sending
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分摊发送网络成本
- en: very little interaction between parts of the system
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统各部分之间的交互非常少
- en: maps cannot talk to each other
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射无法相互通信。
- en: reduces cannot talk to each other
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少调用不能相互通信。
- en: maps and reduces cannot talk to each other
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射和减少调用无法相互通信
- en: other than the implicit communication of sending the mapped data to the reduce
    functions
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了将映射数据发送到减少函数的隐式通信之外，减少函数无法相互通信。
- en: give programmer abstract control over the network communication
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给程序员抽象控制网络通信
- en: some control over how keys are mapped into the reduce partitions
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些控制如何将键映射到减少分区
- en: Input is typically stored striped (64MB chunks) in GFS, over a lot of disks
    and machines.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输入通常存储为条纹（64MB块）在GFS中，分布在许多磁盘和机器上。
- en: gotta be clever, because this would imply that Map tasks are limited by network
    bandwidth
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须要聪明，因为这将意味着Map任务受限于网络带宽
- en: MapReduce takes advantage of GFS knowledge, to actually run the map tasks locally
    on the GFS machines where the file chunks are stored. `=>` increase bandwitdh
    to maps from 18GB/s to 100GB/s
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce利用GFS的知识，实际上在存储文件块的GFS机器上本地运行映射任务。`=>`将带宽从maps增加到18GB/s到100GB/s
- en: Intermediate map files generated by map are also stored locally. Downside is
    that there's a single copy of the data on that one machine and the reduce worker
    has to talk to it only `=>` limited bandwidth.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: map生成的中间映射文件也会被存储在本地。缺点是数据只有一份副本存储在那台机器上，减少工作者只能与它进行通信`=>`带宽有限。
- en: if the machine stops or crashes, the data is lost, have to restart map
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器停止或崩溃，数据将丢失，必须重新启动映射
- en: Data in GFS is actually replicated (2 or 3 copies), and this gives MapReduce
    a choice of 2-3 servers that it can run every map task on.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: GFS中的数据实际上是复制的（2或3个副本），这给MapReduce提供了一个可以在每个映射任务上运行的选择2-3台服务器。
- en: good for load/balancing (MR master can move slow map tasks to other machines)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对负载平衡有利（MR主节点可以将慢速映射任务移动到其他机器上）
- en: don't get this benefit for reduce tasks
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少任务无法获得此优势
- en: Output of reduce is stored in GFS `=>` reduce output is written across the network.
    `=>` total output of MapReduce system is 18GB/s, if that's your cross-section
    bandwidth.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 减少的输出存储在GFS中`=>`减少的输出通过网络写入。`=>`如果这是你的横截面带宽，MapReduce系统的总输出为18GB/s。
- en: QOTD
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: QOTD
- en: How soon can reduce start after map emitted some data?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 减少在映射发出一些数据后多快可以开始？
- en: 'Morris: As soon as a column is filled with data `<=>` as soon as all the maps
    are finished.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Morris：只要一列数据填满了`<=>`只要所有映射完成。
- en: Apparently, you could do it as soon as a map task emits a keyword, by feeding
    values as they are generated in the reduce task's iterator, but performance can
    be tricky to achieve in that case.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，只要一个映射任务发出关键字，就可以通过在减少任务的迭代器中生成值来进行，但在这种情况下性能可能很难实现。
- en: Does MapReduce scale well?
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MapReduce的扩展性好吗？
- en: One of the big benefit of a distributed system, is that you *might* be able
    to speed it up by just buying more machines. Cheaper to buy machines than to pay
    programmers.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统的一个重要好处是，通过购买更多的机器，你*可能*能够加速它。购买机器比支付程序员更便宜。
- en: '`nx` hardware => `nx` performance?, `n > 1`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`nx`硬件 => `nx`性能？ `n > 1`'
- en: 'As we grow # of machines (10 fold), and input size stays constant `=>` input
    size has to be decreased (10 fold). Smaller splits (10x smaller).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器数量的增长（增加10倍），输入大小保持不变`=>`输入大小必须减少（减少10倍）。更小的切分（减小10倍）。
- en: If we have millions of machines, the splits can be kilobytes in size `=>` network
    latency will kill our performance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有数百万台机器，切分的大小可能是几千字节`=>`网络延迟会影响我们的性能。
- en: You can't have more reduce workers than you have keys.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你不能比你有的键更多的减少工作者。
- en: Scalability is limited by
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性受限于
- en: map split size
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射切分大小
- en: 'number of keys `>=` # of reduce workers'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 键的数量`>=`减少工作者的数量
- en: network bandwidth (need to buy more "network" too, as we buy more machines)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络带宽（随着购买更多机器，需要购买更多的“网络”）
- en: a really important problem
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个非常重要的问题
- en: 'The answer: certainly get some scaling, but not infinite (limited by network)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：肯定会获得一些扩展，但不是无限的（受网络限制）
- en: Fault tolerance
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容错性
- en: 'Challenge: if you run big jobs on 1000s of computers, you are sure to get some
    failures. So cannot simply restart whole computation. Must just redo failed machine''s
    work.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战：如果在数千台计算机上运行大型作业，你肯定会遇到一些故障。因此不能简单地重新启动整个计算。必须只重做失败的机器的工作。
- en: Difficult to achieve for DSM, easier for MapReduce.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于DSM难以实现，对于MapReduce较容易。
- en: Assuming independent failures (also because maps/reduces are independent)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 假设独立故障（也因为映射/减少是独立的）
- en: 'If worker failed:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果工作者失败：
- en: can just restart
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以重新启动
- en: can save intermediate output and resume after failure
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以保存中间输出并在故障后恢复
- en: If maps fail, we have to rerun it, because it stores its output on the same
    machine, which is done. Master knows what the map was working on, so it can just
    restart.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果映射失败，我们必须重新运行它，因为它将其输出存储在同一台机器上，这已完成。主节点知道映射正在处理的内容，因此可以重新启动。
- en: If a reduce worker crashes, because they store their output on GFS, on replicated
    different servers. We have a good chance of not having to recompute, if the reduce
    worker finished.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 reduce worker 崩溃，因为他们的输出存储在 GFS 上，分布在不同的服务器上。我们有很大的机会不需要重新计算，如果 reduce worker
    已经完成了。
- en: Paper's performance eval
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 论文的性能评估。
- en: Figure 2 in paper. Why does the bandwidth take 60 seconds to achieve 30GB/s?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的图 2。为什么带宽需要 60 秒才能达到 30GB/s？
- en: The MR job has 1800 mappers, and some *poor* master that has to give work to
    each one. So maybe the master takes a while to contact everyone.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: MR 作业有 1800 个 mappers，还有一些*可怜的* master 需要给每个 mapper 分配工作。所以也许 master 联系每个人需要一段时间。
- en: Why only 30GB/s? These are map tasks so no network overhead. Maybe the CPU is
    the limit? Unlikely. Seems like this is a disk bandwidth issue. 30GB/s / 1800
    machines `=>` 17MB/s per disk
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么只有 30GB/s？这些是 map 任务，所以没有网络开销。也许 CPU 是瓶颈？不太可能。看起来像是磁盘带宽问题。30GB/s / 1800 台机器
    `=>` 每个磁盘 17MB/s。
- en: Figure 3 in paper. 800 secs for sorting 1TB of data `=>` 1.25GB/s sort throughput
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的图 3。对 1TB 的数据进行排序需要 800 秒 `=>` 1.25GB/s 的排序吞吐量。
- en: One thing to notice is that the terrabyte of data fits in the memory of the
    1800 machines.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一件事是 1800 台机器的内存足以容纳一 terrabyte 的数据。
- en: On a single machine with enough memory, Morris extrapolated that it would take
    around 30,000 seconds to sort 1TB of data (takes 2500secs to sort 100GB)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在一台有足够内存的单机上，Morris 推断，对 1TB 的数据进行排序需要大约 30,000 秒（对 100GB 的数据进行排序需要 2500 秒）。
- en: 'Middle graph says they are only able to move data across the network at 5GB/s.
    Simply moving 1TB of data will take 200 seconds. And MapReduces moves it more
    than once: from maps to reduce, from reduce to GFS (multiple times for replication)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 中间的图表表明他们只能以 5GB/s 的速度在网络上传输数据。简单地移动 1TB 的数据将需要 200 秒。而且 MapReduce 会多次移动它：从
    map 到 reduce，从 reduce 到 GFS（多次复制）。
- en: '*Important insight:* Computation involves moving data. Not just CPU cycles.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*重要洞察：* 计算涉及数据的移动。不仅仅是 CPU 周期。'
- en: 6.824 original notes
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6.824 原始笔记。
- en: '[PRE4]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
