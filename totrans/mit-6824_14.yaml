- en: Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark
- en: '6.824 2015 Lecture 14: Spark'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6.824 2015 年第 14 讲：Spark
- en: '**Note:** These lecture notes were slightly modified from the ones posted on
    the 6.824 [course website](http://nil.csail.mit.edu/6.824/2015/schedule.html)
    from Spring 2015.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 这些讲义是稍作修改的，源自 2015 年春季学期的 6.824 [课程网站](http://nil.csail.mit.edu/6.824/2015/schedule.html)。'
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'MapReduce benefits:'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MapReduce 的好处：
- en: Scales
  id: totrans-5
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展
- en: Fault tolerance
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容错性
- en: Strategy dealing with stragglers
  id: totrans-7
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理落后者的策略
- en: If a map task is low, MapReduce starts another task on a different machine
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个映射任务失败，MapReduce 就会在另一台不同的机器上启动另一个任务
- en: Tasks don't communicate, so easy to have them run twice in parallel
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务之间不通信，所以容易让它们并行运行两次
- en: 'MapReduce limitations:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MapReduce 的局限性：
- en: very rigid form of computation
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常严格的计算形式
- en: one map phase, one level of communication between maps and reduce, and the reduce
    phase
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个映射阶段，一个映射和减少之间的通信级别，以及减少阶段
- en: what if you wanted to build an inverted index **and** then sort it by the most
    popular keyword `=>` you would need two MapReduce jobs
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想要构建一个倒排索引 **并且** 按照最流行的关键字排序 `=>` 您需要两个 MapReduce 作业
- en: so, cannot properly deal with multi-stage, iterative nor interactive jobs
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所以，无法正确处理多阶段、迭代性或交互式作业
- en: Users needed more complicated computations `=>` Spark
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 用户需要更复杂的计算 `=>` Spark
- en: There were previous solutions that tackled different types of computations individually.
    Spark's aim was to provide one solution for a general enough model of computation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以前有解决方案专门解决不同类型的计算。Spark 的目标是为足够通用的计算模型提供一个解决方案。
- en: Spark
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark
- en: Hard to do DSM while maintaining scalability and fault tolerance properties.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在保持可伸缩性和容错性的同时很难进行 DSM。
- en: '**RDDs: Resilient Distributed Datasets**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**RDD：弹性分布式数据集**'
- en: a Scala object essentially
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本质上是一个 Scala 对象
- en: immutable
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可变的
- en: partitioned across machines
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在机器之间分区
- en: 'Example (build an RDD of all the lines in a text file that start with "ERROR"):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 示例（构建一个 RDD，其中包含文本文件中以“ERROR”开头的所有行）：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'RDDs are created by:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: RDD 是通过以下方式创建的：
- en: by referring to data in external storage
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过引用外部存储中的数据
- en: by *transforming* other RDDs
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过*转换*其他 RDD
- en: like the `Filter` call above
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像上面的 `Filter` 调用一样
- en: '**Actions** kick off a computation on the RDD, like the `count()` call in the
    example.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作** 在 RDD 上启动计算，就像上面的 `count()` 调用一样。'
- en: The `persist()` call tells Spark to hold the RDD in memory, for fast access.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`persist()` 调用告诉 Spark 将 RDD 保留在内存中，以便快速访问。'
- en: No work is done until the `count()` action is seen and executed (lazy evaluation)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 直到看到并执行`count()`操作才开始执行任何工作（惰性评估）
- en: you can save work by combining all the filters applied before the action
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过将所有应用于操作之前的过滤器组合来节省工作
- en: faster to read AND filter than to read the file entirely and then do another
    filter pass
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取并过滤比完全读取文件然后再进行另一个过滤步骤要快
- en: Fault tolerance
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容错性
- en: 'Lineage graphs: dependencies between RDDs'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 衍生图：RDD 之间的依赖关系
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Machines:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 机器：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you lose an RDD's partition like p4 (because M2 failed), you can rebuild
    it by tracing through the dependency graph and decide (based on what's already
    computed) where to start and what to recompute.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果丢失了 RDD 的分区，例如 p4（因为 M2 失败了），您可以通过跟踪依赖图并根据已经计算的内容决定从哪里开始和重新计算来重新构建它。
- en: How do you know on what machines to recompute? In this example, `b3` and `b4`
    would be replicated on other machines (maybe on `M1` and `M3`), so that's where
    you would restart the computation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如何知道要在哪些机器上重新计算？在这个例子中，`b3` 和 `b4` 可能会被复制到其他机器上（也许是 `M1` 和 `M3`），所以您可以从那里重新启动计算。
- en: Comparison
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Spark computation expressivity
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark 计算表达能力
- en: 'Spark is pretty general: a lot of existing parallel computation paradigms,
    like MapReduce, can be implemented easily on top of it'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 非常通用：许多现有的并行计算范式，如 MapReduce，可以很容易地在其之上实现
- en: The reason coarse-grained writes are good enough is because a lot of parallel
    algorithms simply apply the same op over all data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 粗粒度写入足够好的原因是因为许多并行算法简单地对所有数据应用相同的操作。
- en: Partitioning
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分区
- en: Can have a custom partitioning function that says "this RDD has 10 partitions,
    1st one is all elements starting with `a`, etc.."
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 可以有一个自定义的分区函数，说“这个 RDD 有 10 个分区，第一个分区是所有以`a`开头的元素，等等..”
- en: If you use your data set multiple times, grouping it properly so that the data
    you need sits on the same machine is important.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您多次使用数据集，则正确分组数据集以使您需要的数据位于同一台机器上很重要。
- en: PageRank example
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PageRank 示例
- en: 'Example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Algorithm:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 算法：
- en: Start every page with rank 1
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每页都从等级 1 开始
- en: Everyone splits their rank across their neighbours
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个人都将自己的等级分配给他们的邻居
- en: website 1 will give 0.5 to node 3 and node 4 and receive 0.5 from node 2
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站 1 将给节点 3 和节点 4 各 0.5，并从节点 2 收到 0.5
- en: Iterate how many times? Until it converges apparently.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代多少次？显然直到收敛。
- en: 'Data:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Example of bad allocation, because we''ll transfer a lot of data:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不良分配的示例，因为我们将传输大量数据：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Example with partitioning:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 带有分区的示例：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Does PageRank need communication at all then? Yes, the `contribs` RDD does a
    `reduceByKey`
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 PageRank 需要通信吗？是的，`contribs` RDD 执行 `reduceByKey`
- en: 'TODO: Not sure what it does'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 待办事项：不确定它的作用是什么
- en: Internal representation
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内部表示
- en: 'RDD methods:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: RDD 方法：
- en: '`partitions` -- returns a list of partitions'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`partitions` -- 返回一个分区列表'
- en: '`preferredLocations(p)` -- returns the preferred locations of a partition'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`preferredLocations(p)` -- 返回分区的首选位置'
- en: tells you about machines where computation would be faster
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 告诉您计算速度更快的机器
- en: '`dependencies`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dependencies`'
- en: how you depend on other RDDs
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您如何依赖其他 RDD
- en: '`iterator(p, parentIters)`'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterator(p, parentIters)`'
- en: ask an RDD to compute one of its partitions
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求 RDD 计算其一个分区
- en: '`partitioner`'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`partitioner`'
- en: allows you to specify a partitioning function
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许您指定一个分区函数
- en: 6.824 notes
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6.824 笔记
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
