- en: 'Chapter 10: Higher Derivatives, Taylor Series, Quadratic Approximations and
    Accuracy of Approximations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We investigate quadratic and higher polynomial approximations to a function
    culminating in the Taylor series. Application to behavior at critical points and
    to determining the accuracy of approximations are discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Topics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 10.1  [The Quadratic Approximation](section01.html)
  prefs: []
  type: TYPE_NORMAL
- en: 10.2  [Higher Approximations and Taylor Series](section02.html)
  prefs: []
  type: TYPE_NORMAL
- en: 10.3  [Uses of Higher Approximations](section03.html)
  prefs: []
  type: TYPE_NORMAL
- en: 10.4  [Quadratic Behavior at Critical Points](section04.html)
  prefs: []
  type: TYPE_NORMAL
- en: 10.5  [Accuracy of Approximations, and the Mean Value Theorem](section05.html)
  prefs: []
  type: TYPE_NORMAL
- en: 10.1 The Quadratic Approximation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The linear approximation to f is exactly true if f ' is constant for that means
    that f is linear. The inaccuracy of the linear approximation to f at x[0] at argument
    x arises from the changes to f ' between arguments x[0] and x.
  prefs: []
  type: TYPE_NORMAL
- en: If f ' is differentiable in the interval between x[0] and x we can get a better
    approximation to f at x by making a linear approximation to f ' and using it to
    estimate the change to f in the interval.
  prefs: []
  type: TYPE_NORMAL
- en: In short if f ' is differentiable in that interval we can compute its derivative,
    called **the second derivative of f with respect to x** and written as f "(x)
    or as ![](../Images/2fdc90077a943c7fe0f05bc59972cb5f.jpg) or sometimes as ![](../Images/6af7736663d2d5a179dafba3b993ab12.jpg)and
    use it to improve the estimate of f.
  prefs: []
  type: TYPE_NORMAL
- en: All of our standard functions have differentiable derivatives and even differentiable
    second derivatives, etc on forever wherever they are defined, except perhaps at
    specific singular points.
  prefs: []
  type: TYPE_NORMAL
- en: They are said to be "infinitely differentiable" because we can keep differentiating
    them as long as we like. We may therefore compute second derivatives, and also
    third and higher derivatives and generate a sequence of better and better approximations
    to any such function.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2 Higher Approximations and Taylor Series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We address the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What are these higher, non-linear approximations to f in terms of its derivatives?
  prefs: []
  type: TYPE_NORMAL
- en: Why do we do these things?
  prefs: []
  type: TYPE_NORMAL
- en: How accurate are these approximations?
  prefs: []
  type: TYPE_NORMAL
- en: What happens when f is a function of several variables?
  prefs: []
  type: TYPE_NORMAL
- en: The linear approximation to f at x[0] is the linear function with value f(x[0])
    and first derivative f '(x[0]) there.
  prefs: []
  type: TYPE_NORMAL
- en: The quadratic approximation is the quadratic function whose value and first
    two derivatives agree with those of f at argument x[0]. Being quadratic it can
    be written as f(x[0]) + a(x - x[0]) + b(x - x[0])².
  prefs: []
  type: TYPE_NORMAL
- en: We determine a and b by applying the condition that its derivatives are those
    of f at argument ![](../Images/5111793d93d84dd6a0bae79900e76721.jpg). Since its
    first derivative at ![](../Images/5111793d93d84dd6a0bae79900e76721.jpg) is a,
    and second derivative is 2b, we deduce�![](../Images/05c88f8b015aaf2aa6d78c2d5955ade5.jpg)
    so that the quadratic approximation to f at ![](../Images/5111793d93d84dd6a0bae79900e76721.jpg)
    becomes
  prefs: []
  type: TYPE_NORMAL
- en: '**![](../Images/fa8531436f69d5c398c43d030225c117.jpg)**'
  prefs: []
  type: TYPE_NORMAL
- en: We can extend this argument to create the cubic approximation, etc, when f is
    suitably differentiable by applying the same steps with still higher derivatives.
    If we do this on forever, we get the **"Taylor series expansion of f at argument
    x[0]."**
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1 Write down the Taylor series expansion about x[0] for a general infinitely
    differential function f.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.2 Write down the approximation formula of degree 5 for a general function
    that is 5 times differentiable, and apply it explicitly for the sine function
    at x[0] = 0\.** **Give the cubic approximation to the sine, formed at x[0] = 1.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.3 The exponential function, being its own derivative, can be factored
    out of its Taylor series expansion. Apply that expansion around x[0], to deduce
    the relation between exp(x)� and exp(x[0]).**'
  prefs: []
  type: TYPE_NORMAL
- en: The following applet allows you to enter a standard function and look at what
    the first three of these approximations look like, as defined over a domain of
    your choosing.
  prefs: []
  type: TYPE_NORMAL
- en: <applet code="FunctionApproximations" codebase="../applets/" archive="functionApproximations.jar,mk_lib.jar,parser_math.jar,jcbwt363.jar"
    width="760" height="450"></applet>
  prefs: []
  type: TYPE_NORMAL
- en: 10.3 Uses of Higher approximations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'These higher approximations are useful in the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. They tell us key information about f when all its lower derivatives are
    0 at x[0].
  prefs: []
  type: TYPE_NORMAL
- en: 2\. They allow us to get bounds on the accuracy of lower approximations.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. They can be used to deduce important facts (as in [exercise 10.3](section02.html#Exercise_10_3)).
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Being polynomials they are typically easier to manipulate than f itself
    is.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. The higher derivatives are sometimes of interest in themselves. Thus the
    equations of� motion of mechanics directly involve acceleration, which is the
    second derivative of position.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Finally, they extend the distance from the expansion point over which they
    are accurate, when compared to a lower approximation.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4 Quadratic Behavior at Critical Points
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An argument x[0] at which f ' is 0, so that f itself is flat, is called a **critical
    point of f.**
  prefs: []
  type: TYPE_NORMAL
- en: When f " is not zero at such a point, its quadratic approximation there is a
    quadratic centered about x[0].
  prefs: []
  type: TYPE_NORMAL
- en: Quadratic functions all essentially look alike, particularly if you are willing
    to stand on your head. Their behavior, when centered about 0, is the behavior
    of ax² + c. The constant c determines where it appears in its graph, but the look
    of the graph is determined entirely by the parameter a. If a is positive the function
    looks like a fatter or thinner x²; if a is negative it looks like a fat or skinny
    -x². This tells us that f has a local **minimum** at x[0] when its second derivative
    is **positive** just as x² does, and has a local maximum when a is negative (f
    has a local maximum at a point at which it is as big or bigger than those in some
    open interval containing it).
  prefs: []
  type: TYPE_NORMAL
- en: When a is zero, so that f and f ' both have critical points at x[0], the quadratic
    approximation is flat and you must look to the cubic or higher approximation to
    determine the behavior of f near that point.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 10.4 Under what circumstances will f have a maximum at x[0] when
    both its first and second derivatives vanish there?**'
  prefs: []
  type: TYPE_NORMAL
- en: 10.5 Accuracy of Approximations, and the Mean Value Theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now ask, how **accurate** are any of the approximations here, from the trivial
    one, the constant approximation f(x) = f(x[0]), the linear approximation, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose x > x[0], m is the minimum value of the k-th derivative of f between
    these two arguments, and M is the maximum value of that derivative there.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will invoke a principle, which in its simplest form is the statement: **the
    faster you move, the further you go, other things being equal.** Here we claim
    that if we invent a new function f[M] by replacing the actual value of the k-th
    derivative of f throughout the interval (x[0], z) by its maximum value over that
    interval, then ![](../Images/2180793d65fcd1bae663b0969a31aa98.jpg) and all its
    first k = 1 derivatives will obey ![](../Images/d4c85508299d5da4a7194cbc48c56b4d.jpg)
    for all x '' in that interval.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of it this way: if you increase your speed f '' to the value M you increase
    the distance traveled. If alternately you increase acceleration f " to M, by the
    same argument, that will increase speed, and hence will increase distance traveled.
    And so on. If you increase a higher derivative, that increase will trickle down
    to increase all the lower derivatives, and ultimately f itself.'
  prefs: []
  type: TYPE_NORMAL
- en: The nice thing about doing this is that the degree k approximation to ![](../Images/77bf3dc827defe2a51568f68b0b13938.jpg)
    at ![](../Images/5111793d93d84dd6a0bae79900e76721.jpg) is **exact** at argument
    x, because ![](../Images/77bf3dc827defe2a51568f68b0b13938.jpg)'s k-th derivative
    is constant in the interval between ![](../Images/5111793d93d84dd6a0bae79900e76721.jpg)
    and x. Now the degree k approximation to ![](../Images/77bf3dc827defe2a51568f68b0b13938.jpg)
    is the degree k-1 approximation to f� plus ![](../Images/2e6de797bac5b674f487af78a72af953.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: Our inequality above applied with j = 0 therefore tells us that the (k - 1)-th
    approximation to f,� plus ![](../Images/2e6de797bac5b674f487af78a72af953.jpg)
    is **at least** f(x), while by the same argument applied in the opposite order
    with M replaced by m, we can deduce that the same approximation plus ![](../Images/81d54586df518517f0a804b14e794cd3.jpg)
    is **at most** f(x).
  prefs: []
  type: TYPE_NORMAL
- en: 'The upshot of all this is have bounds on how far off the degree� k - 1 approximation
    to f at ![](../Images/5111793d93d84dd6a0bae79900e76721.jpg) is from f at argument
    x: their difference lies between ![](../Images/81d54586df518517f0a804b14e794cd3.jpg)
    and ![](../Images/2e6de797bac5b674f487af78a72af953.jpg).'
  prefs: []
  type: TYPE_NORMAL
- en: We can go one step further and notice that this tells us that the error in the
    degree k - 1 approximation can be written as ![](../Images/e81a83de21728f72213d26a115546e52.jpg)
    where q lies between m and M.
  prefs: []
  type: TYPE_NORMAL
- en: Since m and M are the minimum and maximum values of f ^((k)) between x[0] and
    x, if f ^((k)) takes on all values in between its maximum and minimum (which it
    must if it is differentiable in that interval), it will take on the value q. We
    can therefore write ![](../Images/20f56c61a4ad9ffa2fec0eef99961351.jpg) for some
    x ' in that interval.
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to translate our conclusion here into the following statement.
  prefs: []
  type: TYPE_NORMAL
- en: '**Theorem:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**The error in the degree k - 1 approximation to f at x[0] evaluated at argument
    x is**'
  prefs: []
  type: TYPE_NORMAL
- en: '**![](../Images/8015175530fe4645282ca6aea488e2a5.jpg)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**for some x '' in the interval (x[0], x), if f ^((k)) is continuous in that
    interval.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.5 State this theorem for k = 1\. This result is called "the mean value
    theorem".**'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6 Repeat the argument above for the situation that occurs when x < x[0].
    How does the conclusion change? What is different in the argument?**'
  prefs: []
  type: TYPE_NORMAL
