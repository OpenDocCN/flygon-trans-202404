["```\nobject SparkModelServer {\n...\n def main(args: Array[String]): Unit = {\n...\n   // Initial state RDD for current models\n   val modelsRDD = ssc.sparkContext.emptyRDD[(String, Model)]\n\n   // Create models kafka stream\n   val kafkaParams = KafkaSupport.getKafkaConsumerConfig(\n     ModelServingConfiguration.LOCAL_KAFKA_BROKER)\n   val modelsStream = KafkaUtils.createDirectStream[Array[Byte],\n      Array[Byte]](ssc,PreferConsistent,Subscribe[Array[Byte],\n         Array[Byte]]\n   (Set(ModelServingConfiguration.MODELS_TOPIC),kafkaParams))\n\n   // Create data kafka stream\n   val dataStream = KafkaUtils.createDirectStream[Array[Byte],\n      Array[Byte]](ssc, PreferConsistent,Subscribe[Array[Byte],\n        Array[Byte]]\n   (Set(ModelServingConfiguration.DATA_TOPIC),kafkaParams))\n\n   // Convert streams\n   val data = dataStream.map(r =>\n   DataRecord.fromByteArray(r.value())).filter(_.isSuccess)\n    .map(d => DataWithModel(None, Some(d.get)))\n\n   val models = modelsStream.map(r =>\n   ModelToServe.fromByteArray(r.value())).filter(_.isSuccess)\n      .map(m => DataWithModel(Some(m.get), None))\n\n   // Combine streams\n   val unionStream = ssc.union(Seq(data, models)).\n     map(r => (r.getDataType, r))\n   // Score model using mapWithState\n   val mappingFunc = (dataType: String, dataWithModel:\n       Option[DataWithModel], state: State[Model]) => {\n\n     val currentModel = state.getOption().getOrElse(null\n       .asInstanceOf[Model])\n     dataWithModel match {\n       case Some(value) =>\n         if (value.isModel) {\n           // Process model\n           if (currentModel != null) currentModel.cleanup()\n           val model = factories.get(value.getModel.modelType.value)\n           match {\n             case Some(factory) => factory.create(value.getModel)\n             case _ => None\n           }\n           model match {\n             case Some(m) => state.update(m)\n             case _ =>\n           }\n           None\n         }\n         else {\n           // Process data\n           if (currentModel != null)\n             Some(currentModel.\n             score(value.getData.\n               asInstanceOf[AnyVal]).asInstanceOf[Double])\n           else\n             None\n         }\n       case _ => None\n     }\n   }\n   val resultDstream = unionStream.mapWithState(StateSpec.\n     function(mappingFunc).initialState(modelsRDD))\n   resultDstream.print()\n   // Execute\n   ssc.start()\n   ssc.awaitTermination()\n }\n}\n```", "```\nclass ModelSerializerKryo extends Serializer[Model]{\n...\n override def read(kryo: Kryo, input: Input, `type`: Class[Model]):\n   Model = {\n   import ModelSerializerKryo._\n\n   val mType = input.readLong().asInstanceOf[Int]\n   val bytes = Stream.continually(input.readByte()).\n     takeWhile(_ != -1).toArray\n   factories.get(mType) match {\n     case Some(factory) => factory.restore(bytes)\n     case _ => throw new Exception(s\"Unknown model type $mType\")\n   }\n }\n\n override def write(kryo: Kryo, output: Output, value: Model):\n   Unit = {\n   println(\"KRYO serialization\")\n   output.writeLong(value.getType)\n   output.write(value.toBytes)\n }\n}\n...\n\nclass ModelRegistrator extends KryoRegistrator {\n override def registerClasses(kryo: Kryo) {\n   kryo.register(classOf[Model], new ModelSerializerKryo())\n }\n}\n```"]