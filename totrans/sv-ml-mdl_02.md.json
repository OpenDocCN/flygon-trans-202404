["```\n...\n# Create TF session and set it in Keras\nsess = tf.Session()\nK.set_session(sess)\n...\n# Saver op to save and restore all the variables\nsaver = tf.train.Saver()\n# Save produced model\nmodel_path = \"path\"\nmodel_name = \"WineQuality\"\nsave_path = saver.save(sess, model_path+model_name+\".ckpt\")\nprint \"Saved model at \", save_path\n# Now freeze the graph (put variables into graph)\ninput_saver_def_path = \"\"\ninput_binary = False\noutput_node_names = \"dense_3/Sigmoid\"\nrestore_op_name = \"save/restore_all\"\nfilename_tensor_name = \"save/Const:0\"\noutput_frozen_graph_name = model_path + 'frozen_' + model_name\n  + '.pb'\nclear_devices = True\nfreeze_graph.freeze_graph(graph_path, input_saver_def_path,\ninput_binary, save_path,Output_node_names,\nrestore_op_name, filename_tensor_name,\noutput_frozen_graph_name, clear_devices, \"\")\n# Optimizing graph\ninput_graph_def = tf.GraphDef()\nwith tf.gfile.Open(output_frozen_graph_name, \"r\") as f:\n   data = f.read()\n   input_graph_def.ParseFromString(data)\noutput_graph_def =\n  optimize_for_inference_lib.optimize_for_inference(\n   input_graph_def,\n   [\"dense_1_input\"],\n   [\"dense_3/Sigmoid\"],\n   tf.float32.as_datatype_enum)\n# Save the optimized graph\ntf.train.write_graph(output_graph_def, model_path,\n  \"optimized_\" + model_name + \".pb\", as_text=False)\n```", "```\nclass WineModelServing(path : String) {\n import WineModelServing._\n // Constructor\n val lg = readGraph(Paths.get (path))\n val ls = new Session (lg)\n\n def score(record : Array[Float]) : Double = {\n   val input = Tensor.create(Array(record))\n   val result = ls.runner.feed(\"dense_1_input\",input).\n     fetch(\"dense_3/Sigmoid\").run().get(0)\n   // Extract result value\n   val rshape = result.shape\n   var rMatrix =\n     Array.ofDim[Float](rshape(0).asInstanceOf[Int],rshape(1).\n       asInstanceOf[Int])result.copyTo(rMatrix)\n   var value = (0, rMatrix(0)(0))\n   1 to (rshape(1).asInstanceOf[Int] -1) foreach{i => {\n      if(rMatrix(0)(i) > value._2)\n        value = (i, rMatrix(0)(i))\n    }}\n    value._1.toDouble\n }\n def cleanup() : Unit = {\n   ls.close\n }\n}\nobject WineModelServing{\n def main(args: Array[String]): Unit = {\n   val model_path = \"/optimized_WineQuality.pb\"   // model\n   val data_path = \"/winequality_red.csv\" // data\n   val lmodel = new WineModelServing(model_path)\n   val inputs = getListOfRecords(data_path)\n   inputs.foreach(record =>\n     println(s\"result ${lmodel.score(record._1)}\"))\n   lmodel.cleanup()\n }\n private def readGraph(path: Path) : Graph = {\n   try {\n     val graphData = Files.readAllBytes(path)\n     val g = new Graph\n     g.importGraphDef(graphData)\n     g\n   } ...\n }\n...\n}\n```", "```\nassets/\nassets.extra/\nvariables/\n    variables.data-?????-of-?????\n    variables.index\nSaved_model.pb\n```", "```\n#export_version =...  # version number (integer)\nexport_dir = \"savedmodels/WineQuality/\"\nbuilder = saved_model_builder.SavedModelBuilder(export_dir)\nsignature = predict_signature_def(inputs={'winedata': model.input},\n  outputs={'quality': model.output})\nbuilder.add_meta_graph_and_variables(sess=sess,\n  tags=[tag_constants.SERVING],\n  signature_def_map={'predict': signature})\nbuilder.save()\n```", "```\nobject WineModelServingBundle {\n def apply(path: String, label: String): WineModelServingBundle =\nnew WineModelServingBundle(path, label)\n def main(args: Array[String]): Unit = {\n   val data_path = \"/winequality_red.csv\"\n   val saved_model_path = \"/savedmodels/WineQuality\"\n   val label = \"serve\"\n   val model = WineModelServingBundle(saved_model_path, label)\n   val inputs = getListOfRecords(data_path)\n   inputs.foreach(record =>\n     println(s\"result ${model.score(record._1)}\n       expected ${record._2}\"))\n   model.cleanup()\n }\n...\nclass WineModelServingBundle(path : String, label : String){\n val bundle = SavedModelBundle.load(path, label)\n val ls: Session = bundle.session\n val metaGraphDef = MetaGraphDef.parseFrom(bundle.metaGraphDef())\n val signatures = parseSignature(\n   metaGraphDef.getSignatureDefMap.asScala)\n def score(record : Array[Float]) : Double = {\n   val input = Tensor.create(Array(record))\n   val result = ls.runner.feed(signatures(0).inputs(0).name, input)\n .fetch(signatures(0).outputs(0).name).run().get(0)\n   ...\n }\n...\n def convertParameters(tensorInfo: Map[String,TensorInfo]) :\n   Seq[Parameter] = {\n   var parameters = Seq.empty[Parameter]\n   tensorInfo.foreach(input => {\n     ...\n     fields.foreach(descriptor => {\n       descriptor._2.asInstanceOf[TensorShapeProto].getDimList\n      .toArray.map(d => d.asInstanceOf[\n        TensorShapeProto.Dim].getSize)\n      .toSeq.foreach(v => shape = shape :+ v.toInt)\n      .foreach(v => shape = shape :+ v.toInt)\n       }\n       if(descriptor._1.getName.contains(\"name\") ) {\n         name = descriptor._2.toString.split(\":\")(0)\n       }\n       if(descriptor._1.getName.contains(\"dtype\") ) {\n         dtype = descriptor._2.toString\n       }\n     })\n     parameters = Parameter(name, dtype, shape) +: parameters\n   })\n   parameters\n }\n def parseSignature(signatureMap : Map[String, SignatureDef])\n   : Seq[Signature] = {\n\n   var signatures = Seq.empty[Signature]\n   signatureMap.foreach(definition => {\n     val inputDefs = definition._2.getInputsMap.asScala\n     val outputDefs = definition._2.getOutputsMap.asScala\n     val inputs = convertParameters(inputDefs)\n     val outputs = convertParameters(outputDefs)\n     signatures = Signature(definition._1, inputs, outputs)\n       +: signatures\n   })\n   signatures\n }\n}\n...\n```", "```\nobject WineQualityRandomForestClassifierPMML {\n def main(args: Array[String]): Unit = {\n   ...\n   // Load and parse the data file\n   ...\n   // Decision Tree operates on feature vectors\n   val assembler = new VectorAssembler().\n     setInputCols(inputFields.toArray).setOutputCol(\"features\")\n   // Fit on whole dataset to include all labels in index.\n   val labelIndexer = new StringIndexer()\n     .setInputCol(\"quality\").setOutputCol(\"indexedLabel\").fit(dff)\n   // Create classifier\n   val dt = new RandomForestClassifier().setLabelCol(\"indexedLabel\")\n      .setFeaturesCol(\"features\").setNumTrees(10)\n   // Convert indexed labels back to original labels.\n   val labelConverter= new IndexToString().setInputCol(\"prediction\")\n    .setOutputCol(\"predictedLabel\").setLabels(labelIndexer.labels)\n   // Create pileline\n   val pipeline = new Pipeline()\n     .setStages(Array(assembler, labelIndexer, dt, labelConverter))\n   // Train model\n   val model = pipeline.fit(dff)\n   // PMML\n   val schema = dff.schema\n   val pmml = ConverterUtil.toPMML(schema, model)\n   MetroJAXBUtil.marshalPMML(pmml, System.out)\n   spark.stop()\n }\n}\n```", "```\nclass WineQualityRandomForestClassifier(path : String) {\n import WineQualityRandomForestClassifier._\n var arguments = mutable.Map[FieldName, FieldValue]()\n // constructor\n val pmml: PMML = readPMML(path)\n optimize(pmml)\n // Create and verify evaluator\n val evaluator = ModelEvaluatorFactory.newInstance()\n   .newModelEvaluator(pmml)\n evaluator.verify()\n // Get input/target fields\n val inputFields = evaluator.getInputFields\n val target: TargetField = evaluator.getTargetFields.get(0)\n val tname = target.getName\n\n def score(record : Array[Float]) : Double = {\n   arguments.clear()\n   inputFields.foreach(field => {\n     arguments.put(field.getName, field\n       .prepare(getValueByName(record, field.getName.getValue)))\n   })\n   // Calculate output\n   val result = evaluator.evaluate(arguments)\n   // Convert output\n   result.get(tname) match {\n      case c : Computable => c.getResult.toString.toDouble\n      case v : Any => v.asInstanceOf[Double]\n   }\n }\n...\nobject WineQualityRandomForestClassifier {\n def main(args: Array[String]): Unit = {\n   val model_path = \"data/\n     winequalityRandonForrestClassification.pmml\"\n   val data_path = \"data/winequality_red.csv\"\n   val lmodel = new WineQualityRandomForestClassifier(model_path)\n   val inputs = getListOfRecords(data_path)\n   inputs.foreach(record =>\n     println(s\"result ${lmodel.score(record._1)}\"))\n }\n def readPMML(file: String): PMML = {\n   var is = null.asInstanceOf[InputStream]\n   try {\n     is = new FileInputStream(file)\n     PMMLUtil.unmarshal(is)\n   }\n   finally if (is != null) is.close()\n }\n private val optimizers = ...\n def optimize(pmml : PMML) = this.synchronized {\n   ...\n }\n...\n}\n```"]