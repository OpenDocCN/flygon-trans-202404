- en: 'Chapter 26: Numerical Solution of Differential Equations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can employ techniques like Simpson's Rule to solve numerical solutions to
    more general first order differential equations. We explore how.
  prefs: []
  type: TYPE_NORMAL
- en: Topics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 26.1  [Introduction to Differential Equations](section01.html)
  prefs: []
  type: TYPE_NORMAL
- en: 26.2  [The Left Hand Rule with Extrapolation](section02.html)
  prefs: []
  type: TYPE_NORMAL
- en: 26.3  [Generalization of the Trapezoid Rule](section03.html)
  prefs: []
  type: TYPE_NORMAL
- en: 26.4  [Generalization of Simpson's Rule; the Runge-Kutta 2^(th) Order Rule](section04.html)
  prefs: []
  type: TYPE_NORMAL
- en: 26.5  [Comments](section05.html)
  prefs: []
  type: TYPE_NORMAL
- en: 26.1 Introduction to Differential Equations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **differential equation** is an equation involving derivatives. **The order**
    of the equation is the highest derivative occurring in the equation.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some examples
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c8a242ce86c8c3d7110af030df531869.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The first four of these are **first order** differential equations, the last
    is a **second order** equation.
  prefs: []
  type: TYPE_NORMAL
- en: The first two are called linear differential equations because they are **linear**
    in the variable y, the first has an **"inhomogeneous term"** that is independent
    of y on the right, the second is a **homogeneous linear equation** since all terms
    are linear in y.
  prefs: []
  type: TYPE_NORMAL
- en: The first three of these are **"separable"** differential equations, since they
    can be rewritten as dx f(x) = dy g(y) for appropriate f and g.
  prefs: []
  type: TYPE_NORMAL
- en: If you know only the derivative of a function, you do not have enough information
    to determine it completely. You can therefore seek either **a solution** to a
    differential equation, or **a general solution** (which usually has a constant
    for each order of the equation in it) or **a solution subject to some additional
    condition or conditions.**
  prefs: []
  type: TYPE_NORMAL
- en: You can find the general solution to any **separable first order** differential
    equation by integration, (or as it is sometimes referred to, by **"quadrature"**).
    All you need do is to integrate both sides of the equation dx f(x) = dy g(y).
    Thus you can apply the numerical techniques of the previous chapter to each of
    these directly and solve them numerically, if you cannot integrate them exactly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The question we address here is:'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have a **first order differential equation that is not separable,**
    so we cannot reduce its solution to quadratures directly. Can we apply the numerical
    techniques previously for doing integrals to the task of solving these equations?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is yes and we show how below. There is indeed a complication which
    we discuss next, but it can be overcome.
  prefs: []
  type: TYPE_NORMAL
- en: The implication of this fact is, that any system whose behavior can be modeled
    by a first order differential equation, or even by a set of linked first order
    equations, can be solved numerically to any desired accuracy by a modern computer
    very quickly. This makes possible real time control of such systems and is of
    great value in engineering.
  prefs: []
  type: TYPE_NORMAL
- en: 26.2 The Left Hand Rule with Extrapolation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We seek the solution of a **first order differential equation** of the form
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a989a64a2064b24aab0c57323a49309.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and we will assume that **we know y(a)** and wish to find y(x) for arguments
    between a and b, and in particular **want to find y(b).**
  prefs: []
  type: TYPE_NORMAL
- en: We consider the example
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/317df2ee6c8de480f49017e7d957339f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: below with a = 0, b = 1 or 2 and y(0) = 1, to illustrate the methods discussed.
  prefs: []
  type: TYPE_NORMAL
- en: '**We want to break up the interval [a, b] into small subintervals, each of
    length d and for each subinterval approximate the change in y by an estimate of
    ![](../Images/60535789e5b27c8127497ae6f289ce70.jpg) in it, multiplied by d.**'
  prefs: []
  type: TYPE_NORMAL
- en: With ordinary integration we had many different ways of estimating f, **a left
    rule, right rule, trapezoid rule, or Simpson rule, and others as well,** based
    upon using the values of f at various arguments within the subinterval.
  prefs: []
  type: TYPE_NORMAL
- en: The complication here is that we do not know the value of y anywhere but at
    the point a, or more generally, we can only expect to have an approximate value
    for y at the left hand side of our subinterval based upon our computations on
    previous subintervals. In fact the purpose of our treatment of that subinterval
    is to extend our estimate of y on its left end to an estimate of y on its right
    end.
  prefs: []
  type: TYPE_NORMAL
- en: In consequence of this fact, we have to use some procedure for estimating y
    in the subinterval in order to apply any of the previous techniques other than
    the left hand rule.
  prefs: []
  type: TYPE_NORMAL
- en: 'This complication does not affect **the left hand rule;** so we first ask,
    **how can we apply that rule?** And then: **is it possible to get an accurate
    numerical solution by use of the left hand rule?** The left hand rule discovered
    by Euler and others, consists of making the estimate for the change in y over
    the interval x to x + d'
  prefs: []
  type: TYPE_NORMAL
- en: '**y(x + d) - y(x) = f(x, y(x))*d**'
  prefs: []
  type: TYPE_NORMAL
- en: and successively applying it to each subinterval between a and b to compute
    y(a + j*d) successively for each j and compute ultimately y(b). It involves computing
    the change in y over each interval by using the value of x and y obtained previously
    at the left end of the interval in f(x, y).
  prefs: []
  type: TYPE_NORMAL
- en: This method has the virtue that it is extremely easy to implement on a spreadsheet.
    It has the defect that it is not very accurate. It is asymmetric between the endpoints
    of each subinterval, and as a result, **if you decrease d by a factor of two,
    the leading error term goes down by a factor of two.** As a consequence, to improve
    accuracy by a factor of 1000 you have to reduce d by a factor of 1000, and that
    is not an efficient way to solve such differential equations.
  prefs: []
  type: TYPE_NORMAL
- en: The following instructions implement this rule for f(x, y) when the last row
    here is copied or filled down N - 1 rows. These are columns A, B, C and D and
    rows 1-9.
  prefs: []
  type: TYPE_NORMAL
- en: To switch to a different differential equation you need only change the D9 entry
    appropriately and copy the results down.
  prefs: []
  type: TYPE_NORMAL
- en: '| A | B | C | D | 1=row number |'
  prefs: []
  type: TYPE_TB
- en: '| Left Hand Rule |   |   | f(x,y)=x+y | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| enter a | 0 |   |   | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| enter b | 1 |   |   | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| enter N | 64 |   |   | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| enter y(a) | 1 |   |   | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| d | =(B4-B3)/B5 | � |   | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| interval index | X | Y | f(x,y) | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | =B3 | =B6 | =B9+C9 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| =A9+1 | =B9+$B$7 | =C9+(B10-B9)*D9 | =B10+C10 | 10 |'
  prefs: []
  type: TYPE_TB
- en: The interval index plays no role here and is included only to allow convenient
    checking that you have enough rows for your computation. (You could omit it.)
  prefs: []
  type: TYPE_NORMAL
- en: '**We can use extrapolation to improve performance here,** just as we used it
    for numerical differentiation in [Chapter 7](../chapter07/contents.html) and for
    numerical integration in the last previous chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we characterize our subdivision of the interval [a, b] by the number
    of subintervals N. Let us refer to the result of applying the left hand rule here
    as just described as L(N). To compute L(N/2) given your computation of L(N) you
    need only copy the whole thing over elsewhere, switch the entry in B10 by multiplying
    the second term by 2, and copy that entry down. The answer will appear after half
    as many steps.
  prefs: []
  type: TYPE_NORMAL
- en: We can then define an extrapolated left hand rule, L[2](N) whose accuracy should
    improve by a factor of 4 when N is replaced by 2N, by
  prefs: []
  type: TYPE_NORMAL
- en: L[2](2N) = 2L(2N) - L(N)
  prefs: []
  type: TYPE_NORMAL
- en: 'This rule should then have behavior not far from that of the trapezoid rule.
    And we can do better by extrapolating this rule, to form L[3]:'
  prefs: []
  type: TYPE_NORMAL
- en: L[3](2N) = (4*L[2](2N) - L[2](N))/3
  prefs: []
  type: TYPE_NORMAL
- en: This should cause errors to decrease by a factor of 8 on doubling the number
    of intervals, and we can extrapolate again, to form L[4], and so on, according
    to the rule
  prefs: []
  type: TYPE_NORMAL
- en: '**L[j](2N) = ((2^(j-1))* L[j-1](2N) - L[j-1](N))/(2^(j - 1)-1)**'
  prefs: []
  type: TYPE_NORMAL
- en: Surprisingly enough, you can achieve considerable accuracy this way. L(32) is
    not very accurate, and L(1), L(2), L(4), ..., L(16) are worse, but they permit
    computation of L[6](32) which is much better.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 26.1 Set up a spreadsheet to compute these for f(x, y) = x + y,
    a = 0, b = 1 with y(a) = 1 and compute L[6](64) for the value of y at x = 1.**'
  prefs: []
  type: TYPE_NORMAL
- en: The results obtained for y(2) for this problem are as follows. The proportional
    error is described in the second table
  prefs: []
  type: TYPE_NORMAL
- en: '| N | L | L[2] | L[3] | L[4] | L[5] | L[6] | L[7] | L[8] |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 3 |   |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5 | 7 |   | exact answer | = | 11.7781122 |   |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 7.125 | 9.25 | 10 |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 8.921 | 10.71686 | 11.20581 | 11.37807 |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 10.17 | 11.41207 | 11.64381 | 11.70638 | 11.728268 |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 10.92 | 11.66817 | 11.75353 | 11.76921 | 11.773395 | 11.77485027 |  
    |   |'
  prefs: []
  type: TYPE_TB
- en: '| 64 | 11.33 | 11.74777 | 11.77431 | 11.77727 | 11.777811 | 11.77795396 | 11.77800322
    |   |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 11.55 | 11.77013 | 11.77758 | 11.77805 | 11.778098 | 11.7781071 | 11.77810953
    | 11.77811037 |'
  prefs: []
  type: TYPE_TB
- en: It is quite remarkable, but even going back to the one interval approximation
    improves the final answer, by allowing one more extrapolation
  prefs: []
  type: TYPE_NORMAL
- en: '| N\L index | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | -0.7453 |   |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | -0.5755 | -0.405677 | -1 | � | � | � | � |   |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | -0.3951 | -0.214645 | -0.15097 | � | � | � | � |   |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | -0.2426 | -0.090104 | -0.04859 | -0.03396 | � | � | � |   |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | -0.1368 | -0.031078 | -0.0114 | -0.00609 | -0.00423 | � | � |   |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | -0.0731 | -0.009335 | -0.00209 | -0.00076 | -0.0004 | -0.000277 | �
    |   |'
  prefs: []
  type: TYPE_TB
- en: '| 64 | -0.0378 | -0.002576 | -0.00032 | -7.1E-05 | -2.6E-05 | -1.34E-05 | -9.25E-06
    |   |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | -0.0193 | -0.000678 | -4.5E-05 | -5.6E-06 | -1.2E-06 | -4.33E-07 |
    -2.27E-07 | -1.56E-07 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Proportional Error for Left Hand Rule y'' = y + z, y(0) = 1, finding
    y(2) |   |   |'
  prefs: []
  type: TYPE_TB
- en: '**It can be seen by these results that using the simplest possible numerical
    method and extrapolating the hell out of it, can actually give accurate results.**'
  prefs: []
  type: TYPE_NORMAL
- en: Note here that all extrapolation was done with the **final answers** at x =
    2 obtained using the left hand rule. You could obtain slightly better results
    by applying the extrapolations at intermediate x values, as soon as they become
    available to improve all the computations.
  prefs: []
  type: TYPE_NORMAL
- en: Thus the first extrapolation could be applied to update y after two intervals,
    the second after each set of four intervals, etc. This reduces the effect of errors
    in y compounding, which is only slightly helpful here.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously you do better the smaller you make d, that is, the large you make
    N.
  prefs: []
  type: TYPE_NORMAL
- en: But here extrapolating using smaller values of N is much more effective than
    doubling N in improving the answer.
  prefs: []
  type: TYPE_NORMAL
- en: <applet code="FirstOrderODE" codebase="../applets/" archive="firstOrderODE.jar,mk_lib.jar,parser_math.jar,jcbwt363.jar"
    width="760" height="450"></applet>
  prefs: []
  type: TYPE_NORMAL
- en: 26.3 Generalization of the Trapezoid Rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use of the trapezoid rule, which is substantially better than use of the left
    hand rule for approximating integrals numerically, can be applied here if you
    can find a way to calculate f(x, y) at the right ends of the intervals when you
    only have an estimate for y at the left end.
  prefs: []
  type: TYPE_NORMAL
- en: An obvious first approximation to doing this is to approximate y at the right
    end of the interval using the linear approximation to y defined at the left end.
    The resulting rule is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a78def72cc980b189f7715987cf1400e.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This rule consists of approximating the difference between the values of y at
    the ends of the interval by **half of d multiplied the sum of the derivative f
    at the left end and the linear approximation to the derivative at the right end
    defined at the left end.** When f does not depend on y we get the usual trapezoid
    rule.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to look at this for subinterval from x to x + d is by defining "iterations"
    of the left hand rule, as follows
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/32908ee170e7b366e4077e38f235d237.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In these terms the computation rule here is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/53f36528c2aa15ffb89467168ec830d2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The left hand rule is off because y changes over the interval. The linear approximation
    to y applied here is off only because **y's derivative changes,** and this is
    a second derivative effect.
  prefs: []
  type: TYPE_NORMAL
- en: Thus the error it causes is quadratic in the interval size, and is on a par
    with the error intrinsic to the trapezoid rule. We therefore expect this rule
    to give results that improve in accuracy by a factor of four when N is doubled.
  prefs: []
  type: TYPE_NORMAL
- en: Again, there is no great complication in setting up a spreadsheet to compute
    the predictions of this rule for any N and you can extrapolate as before with
    it.
  prefs: []
  type: TYPE_NORMAL
- en: It has the advantage that you can start with the factor 4 extrapolation because
    accuracy improvement by a factor of 4 on doubling the number of points is built
    into its structure.
  prefs: []
  type: TYPE_NORMAL
- en: The rule no longer has the same weight structure as the trapezoid rule because
    when you compute f(x, y) at a given intermediate point from the left you are using
    the linear approximation at the previous point, while when you compute it in the
    interval to its right you use the value of y computed from the rule itself in
    the previous interval. Such is life.
  prefs: []
  type: TYPE_NORMAL
- en: Here are the entries in rows 9 and 10 that can be used in place of those above
    to produce this computation, when those in red are copied down. The red entries
    in columns D and E are given for the differential equation y' = x + y. They have
    to be changed and the results copied down, in order to switch to a different differential
    equation.
  prefs: []
  type: TYPE_NORMAL
- en: '| B | C | D | E |   |'
  prefs: []
  type: TYPE_TB
- en: '| X | y=y(x-d)+(f[0](x-d)+f[1](x))*d/2 | f[0](x)=x+y(x) | f[1](x+d)=x+d+y(x)+d*f[0](x)
    | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| =B3 | =B6 | =B9+C9 | =B10+C9+(B10-B9)*D9 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| =B9+$B$7 | =C9+(D9+E9)*(B10-B9)/2 | =B10+C10 | =B12+C10+(B12-B10)*D10 | 10
    |'
  prefs: []
  type: TYPE_TB
- en: '**Exercise 26.2 Compare the results obtained using the rule above, with those
    obtained using the left hand rule, upon the same problem.**'
  prefs: []
  type: TYPE_NORMAL
- en: Here are results obtained using this trapezoid like method with various levels
    of extrapolation
  prefs: []
  type: TYPE_NORMAL
- en: '| N\L# | L[1] | L[2] | L[3] | L[4] | L[5] | L[6] | L[7] | L[8] |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 5 |   |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 9.5 | 11 |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 10.9458 | 11.42773 | 11.48883929 |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 11.52449 | 11.71739 | 11.75877194 | 11.77676745 |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 11.70817 | 11.76939 | 11.77681781 | 11.77802087 | 11.7780613 |   |  
    |   |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 11.75976 | 11.77696 | 11.77804039 | 11.77812189 | 11.77812515 | 11.77812617
    |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 64 | 11.77341 | 11.77796 | 11.77810835 | 11.77811289 | 11.77811259 | 11.7781124
    | 11.77811229 |   |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 11.77692 | 11.77809 | 11.77811199 | 11.77811223 | 11.77811221 | 11.7781122
    | 11.7781122 | 11.7781122 |'
  prefs: []
  type: TYPE_TB
- en: The accuracy of these calculations for this problem are shown in the following
    table
  prefs: []
  type: TYPE_NORMAL
- en: '| N\L# | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | -0.57548 | � |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | -0.19342 | -0.06606 |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | -0.07067 | -0.02975 | -0.02456 | � | � |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | -0.02153 | -0.00516 | -0.00164 | -0.00011 | � |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | -0.00594 | -0.00074 | -0.00011 | -7.8E-06 | -4E-06 |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | -0.00156 | -9.8E-05 | -6.1E-06 | 8.23E-07 | 1.1E-06 | 1.19E-06 | � |
    � |'
  prefs: []
  type: TYPE_TB
- en: '| 64 | -0.0004 | -1.3E-05 | -3.3E-07 | 5.84E-08 | 3.4E-08 | 1.68E-08 | 7.6E-09
    | � |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | -0.0001 | -1.6E-06 | -1.8E-08 | 2.51E-09 | 7.1E-10 | 1.84E-10 | 5.3E-11
    | 2.4E-11 |'
  prefs: []
  type: TYPE_TB
- en: '| ����������� Proportional Error for (f[0](x) + f[1](x+d))/2 Rule y'' = y +
    z, y(0) = 1,finding y(2) |   |   |'
  prefs: []
  type: TYPE_TB
- en: You will note that the estimates here without extrapolation are a little better
    than those for the first iteration of the previous method, by a factor of 6 for
    N = 128\. However, after extrapolation the results are more accurate by a factor
    of thousands than in the previous table. [See First Order ODE Applet](section02.html#FirstOrderODE)
  prefs: []
  type: TYPE_NORMAL
- en: 26.4 Generalization of Simpson's Rule; the Runge-Kutta 2^(th) Order Rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can do even better by providing a rule for estimating the change in y over
    an interval with the accuracy of Simpson's rule.
  prefs: []
  type: TYPE_NORMAL
- en: To do so we estimate f at the beginning, middle and end of the interval, and
    give relative weights to these of 1 4 1 as in Simpson's rule. It is only necessary
    to apply estimates of f at the middle and right endpoints that are accurate "to
    second order", so that their error is cubic or smaller.
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to do this. The left hand value for f presents no problems
    at all and is f(x, y(x)). The Runge-Kutta second order rule involves using
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3ae4d4d1b9084952184ad02c89a9d382.jpg)'
  prefs: []
  type: TYPE_IMG
- en: to approximate the integrand in the middle of the interval, and
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/181ca403e44250f50da13eb0c02a7957.jpg)'
  prefs: []
  type: TYPE_IMG
- en: to approximate it at the right end, with
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08a2dcd55b7196ac31e8eff1dbfeb95f.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, with the notations given this method provides the following rule
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e985a585295c36097fdda1317afbcd3e.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Again, this rule can be implemented without much difficulty on a spreadsheet.
    You now need a column for each of x, y and the four f terms that occur in this
    rule, which requires one or two entries and copying for each column. It can be
    extrapolated as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 26.3 Compute solution to the same equation, y'' = y + x using this
    method with the old initial conditions, y(0) = 1 at x = 1\. How much better is
    it than the previous one for N = 32?**'
  prefs: []
  type: TYPE_NORMAL
- en: The remarkable thing about this rule is that the error is of fourth order, as
    it is for Simpson's rule. Thus, if we double the number of intervals the error
    falls by 16 for large N values. Simpson's rule has the symmetry that makes this
    so. It is a bit surprising that the estimates here do not have a cubic error term,
    but they do not have one.
  prefs: []
  type: TYPE_NORMAL
- en: With x in B11 and y in C11 here are the relevant entries for the f 's in D,
    E, F and G for this equation, to be copied down for the equation y' = y + x
  prefs: []
  type: TYPE_NORMAL
- en: '| f = x + y(x) | f[1] = f + (1 + f)d / 2 | f + (1 + f[1])d / 2 | f + (1 + f[2])d
    |'
  prefs: []
  type: TYPE_TB
- en: '| =B11+C11 | =D11+(1+D11)*(B12-B11)/2 | =D11+(1+E11)*(B12-B11)/2 | =D11+(1+F11)*(B12-B11)
    |'
  prefs: []
  type: TYPE_TB
- en: Here are results for this method at x = 2\. The extrapolations start with the
    assumption that the leading term in the error decreases by a factor of 16 on halving
    the intervals
  prefs: []
  type: TYPE_NORMAL
- en: '| N\L# | 1 | 2 | 3 | 4 | 5 | 6 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 11 | � |   |   | exact answer | = | 11.7781122 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 11.670139 | 11.71481481 | � |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 11.767941 | 11.77446077 | 11.77638483 |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 11.777331 | 11.77795654 | 11.77806931 | 11.77809605 |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 11.778058 | 11.7781065 | 11.77811134 | 11.77811201 | 11.77811213 |  
    |   |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 11.778109 | 11.77811201 | 11.77811218 | 11.7781122 | 11.7781122 | 11.7781122
    |   |'
  prefs: []
  type: TYPE_TB
- en: '| 64 | 11.778112 | 11.77811219 | 11.7781122 | 11.7781122 | 11.7781122 | 11.7781122
    | 11.7781122 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Runge-Kutta rule y'' = y + x, y(0) = 1, value for y(2) with extrapolations
    |   |   |'
  prefs: []
  type: TYPE_TB
- en: The proportional errors are indicated here
  prefs: []
  type: TYPE_NORMAL
- en: '| N\L# | 1 | 2 | 3 | 4 | 5 | 6 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | -0.06606425 |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | -0.00916728 | -0.00537 |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | -0.0008636 | -0.00031 | -0.00015 |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | -6.6365E-05 | -1.3E-05 | -3.6E-06 | -1.4E-06 |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | -4.6011E-06 | -4.8E-07 | -7.3E-08 | -1.6E-08 | -5.5E-09 |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | -3.0291E-07 | -1.6E-08 | -1.3E-09 | -1.6E-10 | -3.2E-11 | -1.1E-11 |
      |'
  prefs: []
  type: TYPE_TB
- en: '| 64 | -1.9431E-08 | -5.3E-10 | -2.2E-11 | -1.4E-12 | -1.4E-13 | -1.3E-14 |
    8.3E-15 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Runge-Kutta rule y'' = y + x, y(0) = 1, proportional error for y(2) with
    extrapolations |'
  prefs: []
  type: TYPE_TB
- en: It can be seen that the same number of evaluation points (N for Runge Kutta
    is comparable to 2N for the trapezoid like rule) yields perhaps a thousand times
    the accuracy for this evaluation rule in this example, though the best extrapolation
    for the trapezoid is better than the best unextrapolated Runge-Kutta formula here
    by a factor of a thousand. [See First Order ODE Applet](section02.html#FirstOrderODE)
  prefs: []
  type: TYPE_NORMAL
- en: 26.5 Comments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'These methods suggest the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**When will they fail?'
  prefs: []
  type: TYPE_NORMAL
- en: Can they be improved?
  prefs: []
  type: TYPE_NORMAL
- en: Are there better techniques available?**
  prefs: []
  type: TYPE_NORMAL
- en: These methods obviously cannot be applied directly on **an infinite interval,**
    so if confronted by one you must do something to it, like changing the independent
    variable to make it into a finite interval problem before even thinking of using
    one.
  prefs: []
  type: TYPE_NORMAL
- en: They can and will fail as well for finite problems, in two general cases; **if
    f is such that its higher derivatives become large,** you may have trouble attempting
    to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of such are **sin(100000x)** and ![](../Images/5fbfab4140fbb96f1dfe7972d0016eab.jpg)
    for x near 0\. These are definite trouble for techniques like this.
  prefs: []
  type: TYPE_NORMAL
- en: In the former case, though f is bounded, using small N values will not give
    a reasonable picture of f, and in the latter case, no N value will do so sufficiently
    near 0.
  prefs: []
  type: TYPE_NORMAL
- en: There is another way you can run into a problem and that is when, though f is
    well behaved, the **solution you seek becomes infinite at some point in the interval
    you are concerned with.**
  prefs: []
  type: TYPE_NORMAL
- en: That is not really as bad or strange a problem as you might expect. It does
    mess up these methods if you try to apply them naively though.
  prefs: []
  type: TYPE_NORMAL
- en: First it only really means that the reciprocal of y, the function ![](../Images/bbc3ca3074a5791ebd97075f55e9869f.jpg),
    goes through zero at the point at which y becomes infinite. It is really no more
    surprising for ![](../Images/bbc3ca3074a5791ebd97075f55e9869f.jpg) to be zero
    than it is for it to be anything else, **so this can easily happen with a non-linear
    differential equation.**
  prefs: []
  type: TYPE_NORMAL
- en: 'Second and most important, **if you know y'' you also know ![](../Images/978cc56f9c322071add477ed5303754e.jpg)**
    and can apply these methods to ![](../Images/bbc3ca3074a5791ebd97075f55e9869f.jpg)
    just as easily as you can to y. If we make the definition: ![](../Images/e6079840c174e0eed830084f97176d04.jpg)
    we find, for y'' = f(x, y)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7cbe19d2fc985bcbf3d8d2e3f01f4f0b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and we can apply the rules discussed to solve for z(b) instead of y(b) given
    z(a).
  prefs: []
  type: TYPE_NORMAL
- en: In fact when y is greater than 1, the derivative of z will be smaller than that
    of y and so you can expect to find it easier to approximate the changes in z than
    in y. When y explodes and goes to infinity, z wanders quietly near 0, and its
    behavior can easily be tracked by our methods.
  prefs: []
  type: TYPE_NORMAL
- en: Thus a cautious approach to solving equations where this can happen is to set
    up your favorite method for y and for z ![](../Images/6e5ef7bf6dd62f0e3986ab11a568cfb6.jpg)
    **simultaneously,** and **use the y approach when the magnitude of y is less than
    1 and the z one when the magnitude of z is at most 1.**
  prefs: []
  type: TYPE_NORMAL
- en: In our example, in which we have y' = x + y, the equation for z becomes z' =
    -z²x - z, which is quite as easy to handle as the original equation.
  prefs: []
  type: TYPE_NORMAL
- en: In our computation we worked with the y' equation, though y was greater than
    1 throughout the interval. We could probably have done even better by working
    with the z equation.
  prefs: []
  type: TYPE_NORMAL
- en: Of course in our example, the original equation is linear in y and the inhomogeneous
    term is linear in x, so this problem will not arise.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 26.4 Try your favorite method on the differential equation ![](../Images/6755d5cf5fb0e2241cba07cd8c9fd9aa.jpg),
    with z(0) = 1, and compare the reciprocal of the values you obtain for z(1), that
    is, ![](../Images/32c55f6a518737e0fd53c4387ed8ae78.jpg) with those you obtained
    earlier for y.**'
  prefs: []
  type: TYPE_NORMAL
- en: There is much lore about numerical methods, and the subject is called numerical
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: It used to be a very dry field, because it is tedious and dull to learn a method
    that you can't possibly use, something like trying to read a cookbook when you
    have no kitchen to cook in.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays you can easily play with these methods, and they have dramatic application
    to real time control so that the field is now actually fun.
  prefs: []
  type: TYPE_NORMAL
- en: You will note that in every case, extrapolation using larger intervals only
    was able to improve the accuracy of estimates here, by factors on the order of
    a hundred thousand to a million, for each method.
  prefs: []
  type: TYPE_NORMAL
- en: Is extrapolation of the kind we have used the best we can do here to improve
    solutions?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is no.
  prefs: []
  type: TYPE_NORMAL
- en: These extrapolations have the great advantage that they are easy to perform,
    but they gain one added power of accuracy at the cost of doubling N.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, if you play your cards right, you can gain one added power of accuracy
    by increasing N by 2, by choosing the best possible weights, for the points and
    using the correspondingly accurate rule for approximating f in each interval.
  prefs: []
  type: TYPE_NORMAL
- en: If you imagine y written as a power series in x, theoretically each new point
    could be used to eliminate the contribution from one higher power, so that with
    N points it could be possible to produce a rule whose error would occur only from
    the N-th and higher derivatives of y.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, much greater accuracy is possible than what we have attained here. But
    then again, what we have done here requires relatively little effort.
  prefs: []
  type: TYPE_NORMAL
