- en: Review of Asymptotic Complexity
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 渐近复杂性的回顾
- en: '* * *'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: <menu>*   [Asymptotic Analysis](#1)*   [Worst-Case and Average-Case Analysis](#2)*   [Order
    of Growth and Big-O Notation](#3)*   [Comparing Orders of Growth](#4)*   [Binary
    Search Trees](#6)*   [Exercises](#Exercises)</menu>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <menu>*   [渐近分析](#1)*   [最坏情况和平均情况分析](#2)*   [增长顺序和大O符号](#3)*   [比较增长顺序](#4)*   [二叉搜索树](#6)*   [练习](#练习)</menu>
- en: '* * *'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Asymptotic Analysis
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 渐近分析
- en: When analyzing the running time or space usage of programs, we usually try to
    estimate the time or space as function of the input size. For example, when analyzing
    the worst case running time of a function that sorts a list of numbers, we will
    be concerned with how long it takes as a function of the length of the input list. 
    For example, we say the standard insertion sort takes time *T*(*n*) where *T*(*n*)*=
    c*n*²*+k* for some constants *c and k*.  In contrast, merge sort takes time *T* ′*(*n*)
    *= c*′***n*log*[2](*n*) + *k*′*.***
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析程序的运行时间或空间使用率时，我们通常尝试估计时间或空间作为输入大小的函数。例如，当分析对数字列表进行排序的函数的最坏情况运行时间时，我们将关注它随着输入列表长度的增长而需要多长时间。例如，我们说标准插入排序的时间是*T(n)*，其中*T(n)=c*n*²+k*，对于某些常数*c*和*k*。相比之下，归并排序的时间是*T'(*n*)*=c'***n*log*[2](*n*)+k'*。
- en: '**The **asymptotic** behavior of a function *f(n)* (such as *f(n)=c*n* or *f(n)=c*n²*,
    etc.)refers to the growth of *f(n)* as *n* gets large. We typically ignore small
    values of *n*, since we are usually interested in estimating how slow the program
    will be on large inputs. A good rule of thumb is: the slower the asymptotic growth
    rate, the better the algorithm (although this is often not the whole story).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 函数*f(n)*（例如*f(n)=c*n*或*f(n)=c*n²*等）的**渐近行为**指的是*n*增大时*f(n)*的增长。我们通常忽略*n*的小值，因为我们通常只关心对大输入估计程序的速度有多慢。一个好的经验法则是：渐近增长率越慢，算法越好（尽管这通常不是全部）。
- en: By this measure, a linear algorithm (*i.e., f(n)=d*n+k*) is always asymptotically
    better than a quadratic one (*e.g., f(n)=c*n²+q*). That is because for any given
    (positive) *c,k,d*, and *q* there is always some *n* at which the magnitude of
    *c*n²+q* overtakes *d*n+k*. For moderate values of *n*, the quadratic algorithm
    could very well take less time than the linear one, for example if *c* is significantly
    smaller than *d* and/or *k* is significantly smaller than *q*. However, the linear
    algorithm will always be better for sufficiently large inputs. Remember to **THINK
    BIG** when working with asymptotic rates of growth.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这个标准，一个线性算法（*即，f(n)=d*n+k*）在渐近上总是比二次的好（*例如，f(n)=c*n²+q*）。这是因为对于任何给定的（正）*c，k，d*和*q*，总会有一些*n*，在这个*n*处，*c*n²+q*的量级会超过*d*n+k*。对于适度的*n*值，二次算法很可能比线性算法需要更少的时间，例如如果*c*显著小于*d*和/或*k*显著小于*q*。然而，对于足够大的输入，线性算法总是更好的。在处理渐近增长率时，请记得**展望未来**。
- en: Worst-Case and Average-Case Analysis
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最坏情况与平均情况分析
- en: When we say that an algorithm runs in time *T(n)*, we mean that *T(n)* is an
    upper bound on the running time that holds for all inputs of size *n*. This is
    called *worst-case analysis*. The algorithm may very well take less time on some
    inputs of size *n*, but it doesn't matter. If an algorithm takes *T(n)=c*n²+k*
    steps on only a single input of each size *n* and only *n* steps on the rest,
    we still say that it is a quadratic algorithm.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说一个算法的运行时间是*T(n)*时，我们的意思是*T(n)*是对运行时间的一个上界，对于所有大小为*n*的输入都成立。这称为**最坏情况分析**。该算法在某些大小为*n*的输入上可能需要更少的时间，但这无关紧要。如果一个算法对每个大小为*n*的输入只需步骤*T(n)=c*n²+k*，并且对其余输入只需*n*步，我们仍然说它是一个二次算法。
- en: A popular alternative to worst-case analysis is *average-case analysis*. Here
    we do not bound the worst case running time, but try to calculate the expected
    time spent on a randomly chosen input. This kind of analysis is generally harder,
    since it involves probabilistic arguments and often requires assumptions about
    the distribution of inputs that may be difficult to justify. On the other hand,
    it can be more useful because sometimes the worst-case behavior of an algorithm
    is misleadingly bad. A good example of this is the popular quicksort algorithm,
    whose worst-case running time on an input sequence of length *n* is proportional
    to *n*² but whose expected running time is proportional to *n* log *n.*
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 替代最坏情况分析的一种流行方法是*平均情况分析*。在这里，我们不限制最坏情况的运行时间，而是尝试计算在随机选择的输入上花费的期望时间。这种分析通常更难，因为它涉及概率论论证，并且通常需要对输入分布进行难以证明的假设。另一方面，它可能更有用，因为有时算法的最坏情况行为会误导性地很差。一个很好的例子是流行的快速排序算法，其在长度为*n*的输入序列上的最坏情况运行时间与*n*²成正比，但其期望运行时间与*n*
    log *n*成正比。
- en: Order of Growth and Big-O Notation
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增长顺序和大O表示法
- en: In estimating the running time of `insert_sort` (or any other program) we don't
    know what the constants *c* or *k* are. We know that it is a constant of moderate
    size, but other than that it is not important; we have enough evidence from the
    asymptotic analysis to know that a `merge_sort` (see below) is faster than the
    quadratic `insert_sort`, even though the constants may differ somewhat. (This
    does not always hold; the constants can sometimes make a difference, but in general
    it is a very good rule of thumb.)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在估计`insert_sort`（或任何其他程序）的运行时间时，我们不知道常数*c*或*k*是多少。我们知道它是一个中等大小的常数，但除此之外并不重要；我们有足够的证据来知道`merge_sort`（见下文）比二次的`insert_sort`更快，即使常数可能有所不同。（这并不总是成立；常数有时会产生影响，但一般来说这是一个非常好的经验法则。）
- en: We may not even be able to measure the constant *c* directly. For example, we
    may know that a given expression of the language, such as `if`, takes a constant
    number of machine instructions, but we may not know exactly how many. Moreover,
    the same sequence of instructions executed on a Pentium IV will take less time
    than on a Pentium II (although the difference will be roughly a constant factor).
    So these estimates are usually only accurate up to a constant factor anyway. For
    these reasons, we usually ignore constant factors in comparing asymptotic running
    times.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可能无法直接测量常数*c*。例如，我们可能知道语言中的给定表达式，比如`if`，需要常数个机器指令，但我们可能不知道究竟有多少。此外，相同的指令序列在Pentium
    IV上执行的时间将比在Pentium II上少（尽管差异大致是一个常数因子）。因此，这些估计通常只准确到一个常数因子。出于这些原因，我们通常忽略比较渐近运行时间中的常数因子。
- en: 'Computer scientists have developed a convenient notation for hiding the constant
    factor. We write *O(n)* (read: ''''order *n*'''') instead of ''''*cn* for some
    constant *c*.'''' Thus an algorithm is said to be *O(n)* or *linear time* if there
    is a fixed constant *c* such that for all sufficiently large *n*, the algorithm
    takes time at most *cn* on inputs of size *n*. An algorithm is said to be *O(n²)*
    or *quadratic time* if there is a fixed constant *c* such that for all sufficiently
    large *n*, the algorithm takes time at most *cn²* on inputs of size *n*. *O(1)*
    means *constant time*.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学家已经开发了一个方便的符号来隐藏常数因子。我们写成*O(n)*（读作：“阶 *n*”）而不是“*cn*是某个常数 *c*”。因此，如果存在一个固定的常数*c*，对于所有足够大的*n*，算法在大小为*n*的输入上最多花费*cn*的时间，则称算法为*O(n)*或*线性时间*。如果存在一个固定的常数*c*，对于所有足够大的*n*，算法在大小为*n*的输入上最多花费*cn²*的时间，则称算法为*O(n²)*或*二次时间*。*O(1)*意味着*常数时间*。
- en: '*Polynomial time* means *n^(O(1))*, or *n^c* for some constant *c*. Thus any
    constant, linear, quadratic, or cubic (*O(n³)*) time algorithm is a polynomial-time
    algorithm.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*多项式时间*意味着*n^(O(1))*，或者*n^c*，其中*c*是某个常数。因此，任何常数、线性、二次或三次（*O(n³)*）时间算法都是多项式时间算法。'
- en: This is called *big-O notation*. It concisely captures the important differences
    in the asymptotic growth rates of functions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为*大O表示法*。它简洁地捕捉了函数渐近增长率之间的重要差异。
- en: One important advantage of big-O notation is that it makes algorithms much easier
    to analyze, since we can conveniently ignore low-order terms. For example, an
    algorithm that runs in time
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大O表示法的一个重要优点是它使得算法分析变得更加容易，因为我们可以方便地忽略低阶项。例如，一个运行时间为
- en: '*10n³ + 24n² + 3n log n + 144*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*10n³ + 24n² + 3n log n + 144*'
- en: is still a cubic algorithm, since
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然是一个三次算法，因为
- en: '*10n³ + 24n² + 3n log n + 144'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*10n³ + 24n² + 3n log n + 144*'
- en: <= 10n³ + 24n³ + 3n³ + 144n³
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: <= 10n³ + 24n³ + 3n³ + 144n³
- en: <= (10 + 24 + 3 + 144)n³
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: <= (10 + 24 + 3 + 144)n³
- en: = O(n³)*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: = O(n³)*。
- en: Of course, since we are ignoring constant factors, any two linear algorithms
    will be considered equally good by this measure. There may even be some situations
    in which the constant is so huge in a linear algorithm that even an exponential
    algorithm with a small constant may be preferable in practice. This is a valid
    criticism of asymptotic analysis and big-O notation. However, as a rule of thumb
    it has served us well. Just be aware that it is *only* a rule of thumb--the asymptotically
    optimal algorithm is not necessarily the best one.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，由于我们忽略了常数因子，任何两个线性算法在这个度量标准下都会被认为是同样好的。甚至可能存在一些情况，线性算法中的常数太大，以至于在实践中，即使是具有较小常数的指数算法也可能更可取。这是对渐近分析和大O符号的一个有效批评。然而，作为一个经验法则，它已经为我们服务得很好。只需注意它*仅仅*是一个经验法则--渐近最优算法不一定是最好的。
- en: Some common orders of growth seen often in complexity analysis are
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在复杂度分析中经常见到的一些常见增长阶数是
- en: '| *O(1)* | constant |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| *O(1)* | 常数阶 |'
- en: '| *O(log n)* | logarithmic |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| *O(log n)* | 对数阶 |'
- en: '| *O(n)* | linear |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| *O(n)* | 线性阶 |'
- en: '| *O(n log n)* | "n log n" |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| *O(n log n)* | "n log n" |'
- en: '| *O(n²)* | quadratic |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| *O(n²)* | 二次阶 |'
- en: '| *O(n³)* | cubic |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| *O(n³)* | 立方阶 |'
- en: Here *log* means *log[2]* or the logarithm base 2, although the logarithm base
    doesn't really matter since logarithms with different bases differ by a constant
    factor. Note also that *2^(O(n))* and *O(2^n)* are not the same!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的*log*表示*log[2]*或以2为底的对数，尽管对数的底实际上并不重要，因为不同底的对数之间只相差一个常数因子。还要注意*2^(O(n))*和*O(2^n)*并不相同！
- en: Comparing Orders of Growth
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较增长阶数
- en: '**O**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**O**'
- en: 'Let *f* and *g* be functions from positive integers to positive integers. We
    say *f* is *O(g(n))* (read: ''''*f* is order *g*'''') if *g* is an upper bound
    on *f*:  there exist a positive constant *c* and a positive constant *n*[0], such
    that for all *n≥n*[0],'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 设*f*和*g*是从正整数到正整数的函数。如果*g*是*f*的上界：存在一个正常数*c*和一个正整数*n*[0]，使得对所有*n≥n*[0]，
- en: '*f(n) ≤ cg(n)*.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(n) ≤ cg(n)*。'
- en: Equivalently, *f* is *O(g(n))* if the function *f(n)/g(n)* is bounded above
    by some constant.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果函数*f(n)/g(n)*被某个常数上界限制，则*f*是*O(g(n))*。
- en: '**o**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**o**'
- en: 'We say *f* is *o(g(n))* (read: "*f* is little-o of *g*'''') if for all positive
    constants *c*, there exists a positive constant *n*[0], such that for all *n≥n*[0],'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说*f*是*o(g(n))*（读作：“f是g的小o”），如果对于所有正常数*c*，存在一个正整数*n*[0]，使得对所有*n≥n*[0]，
- en: '*f(n) ≤ cg(n)*.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(n) ≤ cg(n)*。'
- en: Equivalently, *f* is *o(g)* if the function *f(n)/g(n)* tends to 0 as *n* tends
    to infinity. That is, f is small compared to g. If *f* is *o(g)* then *f* is also
    *O(g)*
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果函数*f(n)/g(n)*随着*n*趋向无穷而趋向于0，则*f*是*o(g)*。也就是说，f相对于g来说很小。如果*f*是*o(g)*，那么*f*也是*O(g)*。
- en: The main difference between the definitions of O and o is that the bound in
    O holds for *some* constant *c*, but the bound in o holds for *all* constants
    *c*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: O和o的定义之间的主要区别在于，O中的上界对于*某个*常数*c*成立，而o中的上界对于*所有*常数*c*成立。
- en: '**Ω**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ω**'
- en: 'We say that *f* is Ω(*g*(*n*)) (read: "f is omega of g") if *g* is a *lower*
    bound on *f* for large *n.* Formally, f is Ω(g) if there is a fixed constant *c*
    and a fixed *n*[0] such that for all *n*>*n*[0],'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说*f*是Ω(*g*(*n*))（读作：“f是g的omega”），如果*g*对于大的*n*是*f*的下界。形式上，如果存在一个固定常数*c*和一个固定的*n*[0]，使得对所有*n*>*n*[0]，
- en: '*c**g*(*n*) *≤* *f*(*n*)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*c**g*(*n*) *≤* *f*(*n*)'
- en: For example, any polynomial whose highest exponent is *n^k* is Ω(*n^k*). If
    *f*(*n*) is Ω(*g*(*n*)) then *g(n)* is O(*f*(*n*)). If *f*(*n*) is *o*(*g*(*n*))
    then *f(n)* is *not* Ω(*g*(*n*)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，任何最高指数为*n^k*的多项式都是Ω(*n^k*)。如果*f*(*n*)是Ω(*g*(*n*))，那么*g(n)*是O(*f*(*n*))。如果*f*(*n*)是*o*(*g*(*n*))，那么*f(n)*不是Ω(*g*(*n*))。
- en: '**Θ**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**Θ**'
- en: 'We say that *f* is Θ(*g(n)*) (read: "f is theta of g") if *g* is an accurate
    characterization of *f* for large *n:* it can be scaled so it is both an upper
    and a lower bound of *f*. That is, *f* is both O(*g*(*n*)) and Ω(*g*(*n*)). Expanding
    out the definitions of  Ω and *O*, *f* is Θ(*g*(*n*)) if there are fixed constants
    *c*[1] and *c*[2] and a fixed *n*[0] such that for all *n*>*n*[0],'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说*f*是Θ(*g(n)*)（读作：“f是g的theta”），如果*g*对于大的*n*是*f*的准确描述：它可以被缩放，使其既是*f*的上界又是下界。也就是说，*f*既是O(*g*(*n*))又是Ω(*g*(*n*))。展开Ω和*O*的定义，如果存在固定常数*c*[1]和*c*[2]以及固定的*n*[0]，使得对所有*n*>*n*[0]，
- en: '*c*[1]*g*(*n*) *≤* *f*(*n*) *≤* *c*[2] *g*(*n*)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*c*[1]*g*(*n*) *≤* *f*(*n*) *≤* *c*[2] *g*(*n*)'
- en: For example, any polynomial whose highest exponent is *n^k* is  Θ(*n^k*). If
    *f* is Θ(g), then it is *O*(*g*) but not *o*(*g*). Sometimes people use *O*(*g*(*n*))
    a bit informally to mean the stronger property Θ(*g*(*n*)); however, the two are
    different.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，任何最高指数为 *n^k* 的多项式都是 Θ(*n^k*)。如果 *f* 是 Θ(g)，那么它是 *O*(*g*) 但不是 *o*(*g*)。有时人们有点非正式地使用
    *O*(*g*(*n*)) 来表示更强的性质 Θ(*g*(*n*))；然而，这两者是不同的。
- en: 'Here are some examples:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些例子：
- en: '*n + log n* is *O(n)* andQ(*n*), because for all *n > 1*, *n* < *n + log n
    < 2n*.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n + log n* 是 *O(n)* 和Q(*n*)，因为对于所有 *n > 1*，*n* < *n + log n < 2n*。'
- en: '*n^(1000)* is *o(2^n)*, because *n^(1000)/2^n* tends to 0 as *n* tends to infinity.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n^(1000)* 是 *o(2^n)*，因为 *n^(1000)/2^n* 随着 *n* 趋向无穷大而趋向于 0。'
- en: For any fixed but arbitrarily small real number *c*, *n log n* is *o(n^(1+c))*,
    since *n log n / n^(1+c)* tends to 0\. To see this, take the logarithm
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于任意固定但任意小的实数 *c*，*n log n* 是 *o(n^(1+c))*，因为 *n log n / n^(1+c)* 趋向于 0。为了看到这一点，取对数
- en: '*log(n log n / n^(1+c))'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*log(n log n / n^(1+c))'
- en: = log(n log n) - log(n^(1+c))
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: = log(n log n) - log(n^(1+c))
- en: = log n + log log n - (1+c)log n
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: = log n + log log n - (1+c)log n
- en: = log log n - c log n*
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: = log log n - c log n*
- en: and observe that it tends to negative infinity.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 并观察它趋向于负无穷大。
- en: 'The meaning of an expression like *O*(*n*²) is really a set of functions: all
    the functions that are *O*(*n*²). When we say that *f(n)* is *O(n*²*)*, we mean
    that *f(n)* is a member of this set. It is also common to write this as *f*(*n*)
    = *O*(*g*(*n*)) although it is not really an equality.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 像 *O*(*n*²) 这样的表达式的含义实际上是一组函数：所有 *O*(*n*²) 的函数。当我们说 *f(n)* 是 *O(n*²*)* 时，我们的意思是
    *f(n)* 是这个集合的一个成员。通常也写成 *f*(*n*) = *O*(*g*(*n*))，虽然它不是真正的等式。
- en: 'We now introduce some convenient rules for manipulating expressions involving
    order notation. These rules, which we state without proof, are useful for working
    with orders of growth. They are really statements about sets of functions. For
    example, we can read #2 as saying that the product of any two functions in *O*(*f*(*n*))
    and *O*(*g*(*n*)) is in *O*(*f*(*n*)*g*(*n*)).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，我们介绍一些方便的规则来操作涉及顺序符号的表达式。这些规则，我们不加证明地陈述，对于处理增长顺序非常有用。它们实际上是关于函数集合的陈述。例如，我们可以把
    #2 看作是说，在 *O*(*f*(*n*)) 和 *O*(*g*(*n*)) 中任意两个函数的乘积也在 *O*(*f*(*n*)*g*(*n*)) 中。'
- en: '*cn^m = O(n^k)* for any constant *c* and any *m ≤ k*.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*cn^m = O(n^k)* 对于任何常数 *c* 和任何 *m ≤ k*。'
- en: '*O(f(n)) + O(g(n)) = O(f(n) + g(n))*.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*O(f(n)) + O(g(n)) = O(f(n) + g(n))*。'
- en: '*O(f(n))O(g(n)) = O(f(n)g(n))*.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*O(f(n))O(g(n)) = O(f(n)g(n))*。'
- en: '*O(cf(n)) = O(f(n))* for any constant *c*.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*O(cf(n)) = O(f(n))* 对于任何常数 *c*。'
- en: '*c* is *O(1)* for any constant *c*.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于任何常数 *c*，*c* 是 *O(1)*。
- en: '*log[b]n = O(log n)* for any base *b*.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*log[b]n = O(log n)* 对于任何基数 *b*。'
- en: 'All of these rules (except #1) also hold for Θ as well.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些规则（除了#1）也适用于 Θ。
- en: '* * *'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Exercises
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: '1\. Write an implementation of stacks using lists.  What is the big-O running
    time of each operation?  The signature for stacks is:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 使用列表编写堆栈的实现。每个操作的大O运行时间是多少？堆栈的签名是：
- en: '[PRE0]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '2\. Write an implementation of queues using lists.  What is the big-O running
    time of each operation?  The signature for queues is:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 使用列表编写队列的实现。每个操作的大O运行时间是多少？队列的签名是：
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 3.  Write some of the functions that occur in the List structure by hand (e.g.,
    rev, @, map, foldl, etc.) and analyze them to determine their big-O running time.**
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 3.  手写 List 结构中出现的一些函数（例如，rev、@、map、foldl 等），并分析它们以确定它们的大O运行时间。**
