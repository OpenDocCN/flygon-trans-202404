["```\n# Lab 4 Multi-variable linear regression\nimport tensorflow as tf\ntf.set_random_seed(777)  # for reproducibility\n\nx1_data = [73., 93., 89., 96., 73.]\nx2_data = [80., 88., 91., 98., 66.]\nx3_data = [75., 93., 90., 100., 70.]\n\ny_data = [152., 185., 180., 196., 142.]\n\n# placeholders for a tensor that will be always fed.\nx1 = tf.placeholder(tf.float32)\nx2 = tf.placeholder(tf.float32)\nx3 = tf.placeholder(tf.float32)\n\nY = tf.placeholder(tf.float32)\n\nw1 = tf.Variable(tf.random_normal([1]), name='weight1')\nw2 = tf.Variable(tf.random_normal([1]), name='weight2')\nw3 = tf.Variable(tf.random_normal([1]), name='weight3')\nb = tf.Variable(tf.random_normal([1]), name='bias')\n\nhypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n\n# cost/loss function\ncost = tf.reduce_mean(tf.square(hypothesis - Y))\n\n# Minimize. Need a very small learning rate for this data set\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\ntrain = optimizer.minimize(cost)\n\n# Launch the graph in a session.\nsess = tf.Session()\n# Initializes global variables in the graph.\nsess.run(tf.global_variables_initializer())\n\nfor step in range(2001):\n    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n    if step % 10 == 0:\n        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n\n'''\n0 Cost:  19614.8\nPrediction:\n [ 21.69748688  39.10213089  31.82624626  35.14236832  32.55316544]\n10 Cost:  14.0682\nPrediction:\n [ 145.56100464  187.94958496  178.50236511  194.86721802  146.08096313]\n\n ...\n\n1990 Cost:  4.9197\nPrediction:\n [ 148.15084839  186.88632202  179.6293335   195.81796265  144.46044922]\n2000 Cost:  4.89449\nPrediction:\n [ 148.15931702  186.8805542   179.63194275  195.81971741  144.45298767]\n''' \n```"]