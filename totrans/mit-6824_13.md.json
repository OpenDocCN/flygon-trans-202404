["```\ndoc 31: I am Alex\ndoc 32: Alex at 8 am \n```", "```\nalex: 31/2, 32/0 ...\nam:   31/1, 32/3 ... \n```", "```\nmap(doc file)\n    split doc into words\n    for each word\n        emit(word, {doc #, offset})\n\nreduce(word string, occurrences list<doc #, offset>)\n    emit(word, sorted list of ocurrences by doc # and then by offset) \n```", "```\nInput, M splits, one    R reduce tasks\nmap function for each \nsplit\n\n---------               ---------------------------------\n|       |               |   |   | * |           |   |   |\n---------               ----------|----------------------\n|       |               |   |   | * |           |   |   |\n---------               ----------|----------------------\n|       |               |   |   | * |           |   |   |\n---------               ----------|----------------------\n|       |               .   .   . |  \n---------               .   .   .  \\\n|       |               .   .   .   \\-----> data for a single reduce task\n---------               .   .   .           is all the data in the column\n|       |               .   .   .\n---------               .   .   .\n|       |               .   .   .\n---------               .   .   . \n```", "```\n Why MapReduce?\n      Second look for fault tolerance and performance\n      Starting point in current enthusiasm for big cluster computing\n      A triumph of simplicity for programmer\n      Bulk orientation well matched to cluster with slow network\n      Very influential, inspired many successors (Hadoop, Spark, &c)\n\n    Cluster computing for Big Data\n      1000 computers + disks\n      a LAN\n      split up data+computation among machines\n      communicate as needed\n      similar to DSM vision but much bigger, no desire for compatibilty\n\n    Example: inverted index\n      e.g. index terabytes of web pages for a search engine\n      Input:\n        A collection of documents, e.g. crawled copy of entire web\n        doc 31: i am alex\n        doc 32: alex at 8 am\n      Output:\n        alex: 31/3 32/1 ...\n        am: 31/2 32/4 ...\n      Map(document file i):\n        split into words\n        for each offset j\n          emit key=word[j] value=i/j\n      Reduce(word, list of d/o)\n        emit word, sorted list of d/o\n\n    Diagram:\n      * input partitioned into M splits on GFS: A, B, C, ...\n      * Maps read local split, produce R local intermediate files (A0, A1 .. AR)\n      * Reduce # = hash(key) % R\n      * Reduce task i fetches Ai, Bi, Ci -- from every Map worker\n      * Sort the fetched files to bring same key together\n      * Call Reduce function on each key's values\n      * Write output to GFS\n      * Master controls all:\n        Map task list\n        Reduce task list\n        Location of intermediate data (which Map worker ran which Map task)\n\n    Notice:\n      Input is huge -- terabytes\n      Info from all parts of input contributes to each output index entry\n        So terabytes must be communicated between machines\n      Output is huge -- terabytes\n\n    The main challenge: communication bottleneck\n      Three kinds of data movement needed:\n        Read huge input\n        Move huge intermediate data\n        Store huge output\n      How fast can one move data?\n        RAM: 1000*1 GB/sec =    1000 GB/sec\n        disk: 1000*0.1 GB/sec =  100 GB/sec\n        net cross-section:        10 GB/sec\n      Explain host link b/w vs net cross-section b/w\n\n    How to cope with communication bottleneck\n      Locality: split storage and computation the same way, onto same machines\n        Because disk and RAM are faster than the network\n      Batching: move megabytes at a time, not e.g. little key/value puts/gets\n        Because network latency is a worse problem than network throughput\n      Programming: let the developer indicate how data should move between machines\n        Because the most powerful solutions lie with application structure\n\n    The big programming idea in MapReduce is the key-driven shuffle\n      Map function implicitly specifies what and where data is moved -- with keys\n      Programmer can control movement, but isn't burdened with details\n      Programs are pretty constrained to help with communication:\n        Map can only read the local split of input data, for locality and simplicity\n        Just one batch shuffle per computation\n        Reduce can only look at one key, for locality and simplicity\n\n    Where does MapReduce input come from?\n      Input is striped+replicated over GFS in 64 MB chunks\n      But in fact Map always reads from a local disk\n        They run the Maps on the GFS server that holds the data\n      Tradeoff:\n        Good: Map can read at disk speed, much faster than reading over net from GFS server\n        Bad: only two or three choices of where a given Map can run\n             potential problem for load balance, stragglers\n\n    Where does MapReduce store intermediate data?\n      On the local disk of the Map server (not in GFS)\n      Tradeoff:\n        Good: local disk write is faster than writing over network to GFS server\n        Bad: only one copy, potential problem for fault-tolerance and load-balance\n\n    Where does MapReduce store output?\n      In GFS, replicated, separate file per Reduce task\n      So output requires network communication -- slow\n      The reason: output can then be used as input for subsequent MapReduce\n\n    The Question: How soon after it receives the first file of\n      intermediate data can a reduce worker start calling the application's\n      Reduce function?\n\n    Why does MapReduce postpone choice of which worker runs a Reduce?\n      After all, might run faster if Map output directly streamed to reduce worker\n      Dynamic load balance!\n      If fixed in advance, one machine 2x slower -> 2x delay for whole computation\n        and maybe the rest of the cluster idle/wasted half the time\n\n    Will MR scale?\n      Will buying 2x machines yield 1/2 the run-time, indefinitely?\n      Map calls probably scale\n        2x machines -> each Map's input 1/2 as big -> done in 1/2 the time\n        but: input may not be infinitely partitionable\n        but: tiny input and intermediate files have high overhead\n      Reduce calls probably scale\n        2x machines -> each handles 1/2 as many keys -> done in 1/2 the time\n        but: can't have more workers than keys\n        but: limited if some keys have more values than others\n          e.g. \"the\" has vast number of values for inverted index\n          so 2x machines -> no faster, since limited by key w/ most values\n      Network may limit scaling, if large intermediate data\n        Must spend money on faster core switches as well as more machines\n        Not easy -- a hot R+D area now\n      Stragglers are a problem, if one machine is slow, or load imbalance\n        Can't solve imbalance w/ more machines\n      Start-up time is about a minute!!!\n        Can't reduce that no matter how many machines you buy (probably makes it worse)\n      More machines -> more failures\n\n    Now let's talk about fault tolerance\n      The challenge: paper says one server failure per job!\n      Too frequent for whole-job restart to be attractive\n\n    The main idea: Map and Reduce are deterministic and functional,\n        so MapReduce can deal with failures by re-executing\n      Often a choice:\n        Re-execute big tasks, or\n        Save output, replicate, use small tasks\n      Best tradeoff depends on frequency of failures and expense of communication\n\n    What if a worker fails while running Map?\n      Can we restart just that Map on another machine?\n        Yes: GFS keeps copy of each input split on 3 machines\n      Master knows, tells Reduce workers where to find intermediate files\n\n    If a Map finishes, then that worker fails, do we need to re-run that Map?\n      Intermediate output now inaccessible on worker's local disk.\n      Thus need to re-run Map elsewhere *unless* all Reduce workers have\n        already fetched that Map's output.\n\n    What if Map had started to produce output, then crashed:\n      Will some Reduces see Map's output twice?\n      And thus produce e.g. word counts that are too high?\n\n    What if a worker fails while running Reduce?\n      Where can a replacement worker find Reduce input?\n      If a Reduce finishes, then worker fails, do we need to re-run?\n        No: Reduce output is stored+replicated in GFS.\n\n    Load balance\n      What if some Map machines are faster than others?\n        Or some input splits take longer to process?\n      Don't want lots of idle machines and lots of work left to do!\n      Solution: many more input splits than machines\n      Master hands out more Map tasks as machines finish\n      Thus faster machines do bigger share of work\n      But there's a constraint:\n        Want to run Map task on machine that stores input data\n        GFS keeps 3 replicas of each input data split\n        So only three efficient choices of where to run each Map task\n\n    Stragglers\n      Often one machine is slow at finishing very last task\n        h/w or s/w wedged, overloaded with some other work\n      Load balance only balances newly assigned tasks\n      Solution: always schedule multiple copies of very last tasks!\n\n    How many Map/Reduce tasks vs workers should we have?\n      They use M = 10x number of workers, R = 2x.\n      More => finer grained load balance.\n      More => less redundant work for straggler reduction.\n      More => spread tasks of failed worker over more machines, re-execute faster.\n      More => overlap Map and shuffle, shuffle and Reduce.\n      Less => big intermediate files w/ less overhead.\n      M and R also maybe constrained by how data is striped in GFS.\n        e.g. 64 MByte GFS chunks means M needs to total data size / 64 MBytes\n\n    Let's look at paper's performance evaluation\n\n    Figure 2 / Section 5.2\n      Text search for rare 3-char pattern, just Map, no shuffle or reduce\n      One terabyte of input\n      1800 machines\n      Figure 2 x-axis is time, y-axis is input read rate\n      60 seconds of start-up time are *omitted*! (copying program, opening input files)\n      Why does it take so long (60 seconds) to reach the peak rate?\n      Why does it go up to 30,000 MB/s? Why not 3,000 or 300,000?\n        That's 17 MB/sec per server.\n        What limits the peak rate?\n\n    Figure 3(a) / Section 5.3\n      sorting a terabyte\n      Should we be impressed by 800 seconds?\n      Top graph -- Input rate\n        Why peak of 10,000 MB/s?\n        Why less than Figure 2's 30,000 MB/s? (writes disk)\n        Why does read phase last abt 100 seconds?\n      Middle graph -- Shuffle rate\n        How is shuffle able to start before Map phase finishes? (more map tasks than workers)\n        Why does it peak at 5,000 MB/s? (??? net cross-sec b/w abt 18 GB/s)\n        Why a gap, then starts again? (runs some Reduce tasks, then fetches more)\n        Why is the 2nd bump lower than first? (maybe competing w/ overlapped output writes)\n      Lower graph -- Reduce output rate\n        How can reduces start before shuffle has finished? (again, shuffle gets all files for some tasks)\n        Why is output rate so much lower than input rate? (net rather than disk; writes twice to GFS)\n        Why the gap between apparent end of output and vertical \"Done\" line? (stragglers?)\n\n    What should we buy if we wanted sort to run faster?\n      Let's guess how much each resource limits performance.\n      Reading input from disk: 30 GB/sec = 33 seconds (Figure 2)\n      Map computation: between zero and 150 seconds (Figure 3(a) top)\n      Writing intermediate to disk: ? (maybe 30 Gb/sec = 33 seconds)\n      Map->Reduce across net: 5 GB/sec = 200 seconds\n      Local sort: 2*100 seconds (gap in Figure 3(a) middle)\n      Writing output to GFS twice: 2.5 GB/sec = 400 seconds\n      Stragglers: 150 seconds? (Figure 3(a) bottom tail)\n      The answer: the network accounts for 600 of 850 seconds\n\n    Is it disappointing that sort harnesses only a small fraction of cluster CPU power?\n      After all, only 200 of 800 seconds were spent sorting.\n      If all they did was sort, they should sell CPUs/disks and buy a faster network.\n\n    Modern data centers have relatively faster networks\n      e.g. FDS's 5.5 terabits/sec cross-section b/w vs MR paper's 150 gigabits/sec\n      while CPUs are only modestly faster than in MR paper\n      so today bottleneck might have shifted away from net, towards CPU\n\n    For what applications *doesn't* MapReduce work well?\n      Small updates (re-run whole computation?)\n      Small unpredictable reads (neither Map nor Reduce can choose input)\n      Multiple shuffles (can use multiple MR but not very efficient)\n        In general, data-flow graphs with more than two stages\n      Iteration (e.g. page-rank)\n\n    MapReduce retrospective\n      Single-handedly made big cluster computation popular\n        (though coincident with big datacenters, cheap machines, data-oriented companies)\n      Hadoop is still very popular\n      Inspired better successors (Spark, DryadLINQ, &c) \n```"]