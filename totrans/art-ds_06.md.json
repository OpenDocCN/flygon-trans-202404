["```\n`25` `20` `15` `5` `30` `7` `5` `10` `12` `40` `30` `30` `10` `25` `10` `20` `10` `10` `25` `5` \n```", "```\npnorm`(``30``,` mean `=` `mean``(`x`),` sd `=` sd`(`x`),` lower.tail `=` `FALSE``)` \n```", "````\n`[``1``]` `0.1089893` \n```\n\n `So about 11% of the population would be willing to pay more than $30 for the product. Again, whether this is useful to you depends on your specific goals.\n\nNote that in the picture above there is one crucial thing that is missing\u2014the data! That\u2019s not exactly true, because we used the data to draw the picture (to calculate the mean and standard deviation of the Normal distribution), but ultimately the data do not appear directly in the plot. In this case **we are using the Normal distribution to tell us what the population looks like**, not what the data look like.\n\nThe key point here is that we used the Normal distribution to setup the shape of the distribution that we *expect* the data to follow. The Normal distribution is our expectation for what the data should look like.\n\n### 5.2 Comparing Model Expectations to Reality\n\nWe may be very proud of developing our statistical model, but ultimately its usefulness will depend on how closely it mirrors the data we collect in the real world. How do we know if our expectations match with reality?\n\n#### Drawing a fake picture\n\nTo begin with we can make some pictures, like a histogram of the data. But before we get to the data, let\u2019s figure out what we *expect* to see from the data. If the population followed roughly a Normal distribution, and the data were a random sample from that population, then the distribution estimated by the histogram should look like the theoretical model provided by the Normal distribution.\n\nIn the picture below, I\u2019ve simulated 20 data points from a Normal distribution and overlaid the theoretical Normal curve on top of the histogram.\n\n![Histogram of Simulated Normal Data](images/model-unnamed-chunk-5-1.png)\n\nHistogram of Simulated Normal Data\n\nNotice how closely the histogram bars and the blue curve match. This is what we want to see with the data. If we see this, then we might conclude that the Normal distribution is a **good statistical model for the data**.\n\nSimulating data from a hypothesized model, if possible, is a good way to setup expectations *before* you look at the data. Drawing a fake picture (even by hand, if you have to) can be a very useful tool for initiating discussions about the model and what we expect from reality.\n\nFor example, before we even look at the data, we might suspect the Normal model may not provide a perfect representation of the population. In particular, the Normal distribution allows for *negative* values, but we don\u2019t really expect that people will say that they\u2019d be willing to pay negative dollars for a book.\n\nSo we have some evidence already that the Normal model may not be a *perfect* model, but no model is perfect. The question is does the statistical model provide a reasonable approximation that can be useful in some way?\n\n#### The real picture\n\nHere is a histogram of the data from the sample of 20 respondents. On top of the histogram, I\u2019ve overlaid the Normal curve on top of the histogram of the 20 data points of the amount people say they are willing to pay for the book.\n\n![Histogram of Price Survey Data](images/model-unnamed-chunk-6-1.png)\n\nHistogram of Price Survey Data\n\nWhat we would *expect* is that the histogram and the blue line should roughly follow each other. How do the model and reality compare?\n\nAt first glance, it looks like the histogram and the Normal distribution don\u2019t match very well. The histogram has a large spike around $10, a feature that is not present with the blue curve. Also, the Normal distribution allows for negative values on the left-hand side of the plot, but there are no data points in that region of the plot.\n\nSo far the data suggest that the Normal model isn\u2019t really a very good representation of the population, given the data that we sampled from the population. It seems that the 20 people surveyed have strong preference for paying a price in the neighborhood of $10, while there are a few people willing to pay more than that. These features of the data are not well characterized by a Normal distribution.\n\n### 5.3 Reacting to Data: Refining Our Expectations\n\nOkay, so the model and the data don\u2019t match very well, as was indicated by the histogram above. So what to do? Well, we can either\n\n1.  Get a different model; or\n2.  Get different data\n\nOr we could do both. What we do in response depends a little on our beliefs about the model and our understanding of the data collection process. If we felt strongly that the population of prices people would be willing to pay should follow a Normal distribution, then we might be less likely to make major modifications to the model. We might examine the data collection process to see if it perhaps led to some bias in the data. However, if the data collection process is sound, then we might be forced to re-examine our model for the population and see what could be changed. In this case, it\u2019s likely that our model is inappropriate, especially given that it\u2019s difficult to imagine a valid data collection process that might lead to negative values in the data (as the Normal distribution allows).\n\nTo close the loop here, we will choose a different statistical model to represent the population, the *Gamma distribution*. This distribution has the feature that it only allows positive values, so it eliminates the problem we had with negative values with the Normal distribution.\n\nNow, we should go back to the top of our iteration and do the following:\n\n1.  Develop expectations: Draw a fake picture\u2014what do we expect to see before looking at the data?\n2.  Compare our expectations to the data\n3.  Refine our expectations, given what the data show\n\nFor your reference, here is a histogram of the same data with the Gamma distribution (estimated using the data) overlaid.\n\n![Price Survey Data with Gamma Distribution](images/model-unnamed-chunk-7-1.png)\n\nPrice Survey Data with Gamma Distribution\n\nHow do the data match your expectations now?\n\nYou might ask what difference does it make which model I use to represent the population from which the data were generated? Well, for starters it might affect the kinds of predictions that you might make using the model. For example, recall before that were interested in what proportion of the population might be willing to pay at least $30 dollars for the book. Our new model says that only about 7% of the population would be willing to pay at least this amount (the Normal model claimed 11% would pay $30 or more). So different models can yield different predictions based on the same data, which may impact decisions made down the road.\n\n### 5.4 Examining Linear Relationships\n\nIt\u2019s common to look at data and try to understand linear relationships between variables of interest. The most common statistical technique to help with this task is *linear regression*. We can apply the principles discussed above\u2014developing expectations, comparing our expectations to data, refining our expectations\u2014to the application of linear regression as well.\n\nFor this example we\u2019ll look at a simple air quality dataset containing information about tropospheric ozone levels in New York City in the year 1999 for months of May through 1999\\. Here are the first few rows of the dataset.\n\n```\n ozone     temp month\n`1` `25.37262` `55.33333`     `5`\n`2` `32.83333` `57.66667`     `5`\n`3` `28.88667` `56.66667`     `5`\n`4` `12.06854` `56.66667`     `5`\n`5` `11.21920` `63.66667`     `5`\n`6` `13.19110` `60.00000`     `5` \n```\n\n `The data contain daily average levels of ozone (in parts per billion [pbb]) and temperature (in degrees Fahrenheit). One question of interest that might motivate the collection of this dataset is \u201cHow is ambient temperature related to ambient ozone levels in New York?\u201d\n\n#### Expectations\n\nAfter reading a little about [ozone formation in the atmosphere](https://en.wikipedia.org/wiki/Tropospheric_ozone), we know that the formation of ozone depends critically on the presence of sunlight. Sunlight is also related to temperature in the sense that on days where there is a lot of sunlight, we would expect the average temperature for that day to be higher. Cloudy days have both lower temperatures on average and less ozone. So there\u2019s reason to believe that on days with higher temperatures we would expect there to be higher ozone levels. This is an indirect relationship\u2014we are using temperature here as essentially a proxy for the amount of sunlight.\n\nThe simplest model that we might formulate for characterizing the relationship between temperature and ozone is a *linear model*. This model says that as temperature increases, the amount of ozone in the atmosphere increases linearly with it. What do we expect this to look like?\n\nWe can simulate some data to make a *fake picture* of what the relationship between ozone and temperature should look like under a linear model. Here\u2019s a simple linear relationship along with the simulated data in a scatterplot.\n\n![Simulated Data with a Linear Model](images/model-unnamed-chunk-10-1.png)\n\nSimulated Data with a Linear Model\n\nNote that if you choose any point on the blue line, there is roughly the same number of points above the line as there are below the line (this is also referred to as unbiased errors). Also, the points on the scatterplot appear to increase linearly as you move towards the right on the x-axis, even if there is a quite a bit of noise/scatter along the line.\n\nIf we are right about our linear model, and that is the model that characterizes the data and the relationship between ozone and temperature, then roughly speaking, this is the picture we should see when we plot the data.\n\n#### Comparing expectations to data\n\nHere is the picture of the actual ozone and temperature data in New York City for the year 1999\\. On top of the scatterplot of the data, we\u2019ve plotted the fitted linear regression line estimated using the data.\n\n![Linear Model for Ozone and Temperature](images/model-unnamed-chunk-11-1.png)\n\nLinear Model for Ozone and Temperature\n\nHow does this picture compare to the picture that you were expecting to see?\n\nOne thing is clear: There does appear to be an increasing trend in ozone as temperature increases, as we hypothesized. However, there are a few deviations from the nice fake picture that we made above. The points don\u2019t appear to be evenly balanced around the blue regression line.\n\nIf you draw a vertical line around a temperature of 85 degrees, you notice that most of the points are above the line. Drawing a vertical line around 70 degrees shows that most of the points are below the line. This implies that at higher temperatures, our model is biased downward (it underestimates ozone) and at moderate temperatures our model is biased upwards. This isn\u2019t a great feature\u2013in this situation we might prefer that our model is not biased anywhere.\n\nOur simple linear regression model appears to capture the general increasing relationship between temperature and ozone, but it appears to be biased in certain ranges of temperature. It seems that there is room for improvement with this model if we want to better characterize the relationship between temperature and ozone in this dataset.\n\n#### Refining expectations\n\nFrom the picture above, it appears that the relationship between temperature and ozone may not be linear. Indeed, the data points suggest that maybe the relationship is flat up until about 70 degrees and then ozone levels increase rapidly with temperature after that. This suggest a *nonlinear* relationship between temperature and ozone.\n\nThe easiest way we can capture this revised expectation is with a smoother, in this case, a loess smoother.\n\n![Loess Smoother for Ozone and Temperature](images/model-unnamed-chunk-12-1.png)\n\nLoess Smoother for Ozone and Temperature\n\nThis plot shows a different picture\u2013the relationship is slowly increasing up until about 75 degrees, and then sharply increases afterwards. Around 90 degrees, there\u2019s a suggestion that the relationship levels off again.\n\nSmoothers (like loess) are useful tools because they quickly capture trends in a dataset without making any structural assumptions about the data. Essentially, they are an automated or computerized way to sketch a curve on to some data. However, smoothers rarely tell you anything about the mechanism of the relationship and so may be limited in that sense. In order to learn more about the relationship between temperature and ozone, we may need to resort to a more detailed model than the simple linear model we had before.\n\n### 5.5 When Do We Stop?\n\nIn the examples above, we completed one iteration of the data analysis process. In some cases, a single iteration may be sufficient, but in most real-life cases, you\u2019ll need to iterate at least a few times. From the examples above, there are still some things left to do:\n\n*   **Price Survey Data**: We ended the example by fitting a Gamma distribution model. But how does that fit the data? What would we expect from the data if they truly followed a Gamma distribution (we never made that plot)? Is there a better way to capture that spike in the distribution right around $10?\n*   **Ozone and Temperature**: The smoother suggested a nonlinear relationship between temperature and ozone, but what is the reason for this? Is the nonlinearity real or just a chance occurrence in the data? Is there a known physical process that explains the dramatic increase in ozone levels beyond a certain temperature and can we model that process?\n\nUltimately, you might be able to iterate over and over again. Every answer will usually raise more questions and require further digging into the data. When exactly do you stop the process then? Statistical theory suggests a number of different approaches to determining when a statistical model is \u201cgood enough\u201d and fits the data well. This is not what we will discuss here, but rather we will discuss a few high-level criteria to determine when you might consider stopping the data analysis iteration.\n\n#### Are you out of data?\n\nIterative data analysis will eventually begin to raise questions that simply cannot be answered with the data at hand. For example, in the ozone/temperature analysis, the modeling suggested that there isn\u2019t just a simple relationship between the two variables, that it may be nonlinear. But the data can\u2019t explain precisely why such a nonlinear relationship might exist (although they can suggest certain hypotheses). Also, you may need to collect additional data to determine whether what you observe is real or simply a fluke or statistical accident. Either way, you need to go back out into the world and collect new data. More data analysis is unlikely to bring these answers.\n\nAnother situation in which you may find yourself seeking out more data is when you\u2019ve actually completed the data analysis and come to satisfactory results, usually some interesting finding. Then, it can be very important to try to *replicate* whatever you\u2019ve found using a different, possibly independent, dataset. In the ozone/temperature example, if we concluded that there were a nonlinear relationship between temperature and ozone, our conclusion might be made more powerful if we could show that this relationship were present in other cities besides New York. Such independent confirmation can increase the strength of evidence and can play a powerful role in decision-making.\n\n#### Do you have enough evidence to make a decision?\n\nData analysis is often conducted in support of decision-making, whether in business, academia, government, or elsewhere, we often collect an analyze data to inform some sort of decision. It\u2019s important to realize that the analysis that you perform to get yourself to the point where you can make a decision about something may be very different from the analysis you perform to achieve other goals, such as writing a report, publishing a paper, or putting out a finished product.\n\nThat\u2019s why it\u2019s important to always keep in mind the *purpose* of the data analysis as you go along because you may over- or under-invest resources in the analysis if the analysis is not attuned to the ultimate goal. The purpose of a data analysis may change over time and there may in fact be multiple parallel purposes. The question of whether you have enough evidence depends on factors specific to the application at hand and your personal situation with respect to costs and benefits. If you feel you do not have enough evidence to make a decision, it may be because you are out of data, or because you need to conduct more analysis.\n\n#### Can you place your results in any larger context?\n\nAnother way to ask this question is \u201cDo the results make some sort of sense?\u201d Often, you can answer this question by searching available literature in your area or see if other people inside or outside your organization have come to a similar conclusion. If your analysis findings hew closely to what others have found, that may be a good thing, but it\u2019s not the only desirable outcome. Findings that are at odds with past results may lead down a path of new discovery. In either case, it\u2019s often difficult to come to the right answer without further investigation.\n\nYou have to be a bit careful with how you answer this question. Often, especially with very large and complex datasets, it\u2019s easy to come to a result that \u201cmakes sense\u201d and conforms to our understanding of how a given process *should* work. In this situation, it\u2019s important to be hypercritical of our findings and to challenge them as much as possible. In our experience, when the data very closely match our expectation, it can be a result of either mistakes or misunderstandings in the analysis or in the data collection process. It is critical to question every aspect of the analysis process to make sure everything was done appropriately.\n\nIf your results do *not* make sense, or the data do not match your expectation, then this is where things get interesting. You may simply have done something incorrectly in the analysis or the data collection. Chances are, that\u2019s exactly what happened. For every diamond in the rough, there are 99 pieces of coal. However, on the off-chance that you\u2019ve discovered something unusual that others have not yet seen, you\u2019ll need to (a) make sure that the analysis was done properly and (b) replicate your findings in another dataset. Surprising results are usually met with much scrutiny and you\u2019ll need to be prepared to rigorously defend your work.\n\nUltimately, if your analysis leads you to a place where you can definitively answer the question \u201cDo the results make sense?\u201d then regardless of how you answer that question, you likely need to **stop your analysis and carefully check every part of it**.\n\n#### Are you out of time?\n\nThis criterion seems arbitrary but nevertheless plays a big role in determining when to stop an analysis in practice. A related question might be \u201cAre you out of money?\u201d Ultimately, there will be both a time budget and a monetary budget that determines how many resources can be committed to a given analysis. Being aware of what these budgets are, even if you are not necessarily in control of them, can be important to managing a data analysis. In particular, you may need to argue for more resources and to persuade others to given them to you. In such a situation, it\u2019s useful to know when to stop the data analysis iteration and prepare whatever results you may have obtained to date in order to present a coherent argument for continuation of the analysis.\n\n### 5.6 Summary\n\nModel building, like the entire process of data analysis itself, is an iterative process. Models are used to provide data reduction and to give you some insight into the population about which you are trying to make inference. It\u2019s important to first set your expectations for a how a model should characterize a dataset before you actually apply a model to data. Then you can check to see how your model conforms to your expectation. Often, there will be features of the dataset that do not conform to your model and you will have to either refine your model or examine the data collection process.````"]