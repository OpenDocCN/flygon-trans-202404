- en: 'Chapter 32: Some Linear Algebra'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 32 章：一些线性代数
- en: Introduction
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: 'This chapter contains a review of the basics of linear algebra: the solution
    of linear equations, matrix inversion, determinants, transformations, invariants,
    eigenvalues, and diagonalizability.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含线性代数基础知识的复习：线性方程的解、矩阵求逆、行列式、变换、不变量、特征值和对角化。
- en: Topics
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主题
- en: 32.1   [Linear Equations](section01.html)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 32.1   [线性方程](section01.html)
- en: 32.2   [Matrices](section02.html)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 32.2   [矩阵](section02.html)
- en: 32.3   [The Inverse of a Matrix](section03.html)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 32.3   [矩阵的逆](section03.html)
- en: 32.4   [More on Determinants](section04.html)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 32.4   [更多关于行列式的内容](section04.html)
- en: 32.5   [Matrices and Transformations](section05.html)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 32.5   [矩阵和变换](section05.html)
- en: 32.6   [Invariants of Transformations](section06.html)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 32.6   [变换的不变量](section06.html)
- en: 32.7   [Other Notions of Diagonalizability](section07.html)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 32.7   [对角化的其他概念](section07.html)
- en: 32.8   [Computing Eigenvalues and Eigenvectors](section08.html)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 32.8   [计算特征值和特征向量](section08.html)
- en: 32.9   [Application to Quadratic Forms and Spring Systems](section09.html)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 32.9   [应用于二次形式和弹簧系统](section09.html)
- en: 32.10  [Computing Eigenvalues and Eigenvectors on a Spreadsheet](section10.html)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 32.10  [在电子表格上计算特征值和特征向量](section10.html)
- en: 32.11  [Guessing Eigenvectors](section11.html)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 32.11  [猜测特征向量](section11.html)
- en: 32.1 Linear Equations
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.1 线性方程
- en: Suppose we have a set of linear equations, **for example**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组线性方程，**例如**
- en: '![](../Images/154e9b105ff24f2f645d842e2d91ff0b.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/154e9b105ff24f2f645d842e2d91ff0b.jpg)'
- en: and we wish to **find a solution,** by which we mean to find the **explicit
    values of x, y and z which make these equations all true.**
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望 **找到一个解决方案**，这意味着找到 **使这些方程全部成立的显式值的 x、y 和 z。**
- en: 'The fundamental facts that allows us to find solutions are these:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 允许我们找到解决方案的基本事实是这些：
- en: '**1\. Given any equation, you can multiply it (that is, multiply every term
    in it, both on the right and on the left) by any non-zero number without changing
    its implications.**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 给定任何方程，你都可以将其乘以任意非零数（即，在其左右两边的每个项都乘以）而不改变其含义。**'
- en: '**2\. Given any two equations we define their sum to be the equation whose
    left hand side is the sum of the two left hand sides, and whose right hand side
    is the sum of the two right hand sides.**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 给定任意两个方程，我们定义它们的和为其左手边的和为两个左手边的和，其右手边的和为两个右手边的和的方程。**'
- en: '**Then you can replace either of the two equations by its sum with any multiple
    of the other without changing their implications.**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**然后你可以用其中一个方程的和替换另一个方程，而加上另一个方程的任意倍数，而不改变它们的含义。**'
- en: 'Example: you can replace the top equation above by 3x + 4y = 6 by subtracting
    the third equation from it; (subtracting the equation is the same as adding -1
    multiplied by it)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：你可以通过从中减去第三个方程来将上面的顶部方程替换为 3x + 4y = 6；（减去方程等同于加上它的 -1 倍）
- en: '**Exercise 32.1 Prove claim 2 here.** [Solution](exercise01.html)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 32.1 证明这里的断言 2。** [解答](exercise01.html)'
- en: You can solve the equations by using a sequence of manipulations of the kind
    just mentioned that put the equations into the form x = a, y = b, z = c, which
    is the solution to them.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用刚才提到的这种类型的操作的一系列操作来解方程，将方程转化为 x = a，y = b，z = c 的形式，这是它们的解。
- en: '**What sequence of manipulations should you use to solve equations?**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**你应该使用什么样的操作顺序来解方程？**'
- en: Notice that the subtraction made in the example above was chosen so that z does
    not appear in the subtracted equation, which was 3x + 4y = 6.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在上面的示例中选择的减法是为了使 z 不出现在被减的方程中，即 3x + 4y = 6。
- en: If we make an addition of an appropriate multiple of the third equation to the
    second one, again the z term in the resulting sum equation can be eliminated similarly;
    with result x - 3y = 6.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对第二个方程做适当倍数的第三个方程的加法，那么结果的和方程中的 z 项也可以类似地被消除；结果是 x - 3y = 6。
- en: We started with three equations in three variables.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从三个变量的三个方程开始。
- en: After these operations we have eliminated z from two of them and have two equations
    in two variables.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 经过这些操作，我们已经从两个方程中消除了 z，并且得到了两个变量的两个方程。
- en: By a similar manipulation we can eliminate x, for example, by subtracting three
    times the second one from the first. The resulting equation is then 13y = -12.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过类似的操作，我们可以消除 x，例如，通过从第一个方程中减去第二个方程的三倍。然后得到的方程是 13y = -12。
- en: Dividing this equation by 13 then gives us an expression for y.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 将此方程除以 13，然后我们得到了关于 y 的表达式。
- en: We can substitute it for y into either of the previous two equations and solve
    the resulting equation for x.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其替换为y，然后代入前两个方程中的任一个，并解出所得方程的x。
- en: We get ![](../Images/62f374eaec1326302efb8b511a20e170.jpg) Substituting both
    for x and y in any of the original equations then gives ![](../Images/363c1bfab175102aef42b86dc5d900af.jpg)
    and we have a complete solution to our equations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到 ![](../Images/62f374eaec1326302efb8b511a20e170.jpg) 将x和y替换为任何原始方程中的值，然后给出
    ![](../Images/363c1bfab175102aef42b86dc5d900af.jpg) 我们有了方程的完整解。
- en: '**In general you can systematically eliminate one variable at a time from all
    equations, reducing n equations in n unknowns to (n - 1) equations in (n-1) unknowns,
    and repeat the process until you can solve one equation for one unknown, and then
    substitute back to find the others, one at a time.**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**通常你可以逐个变量地系统地消去所有方程，将n个未知数的方程减少为(n-1)个未知数的方程，并重复该过程，直到你可以解出一个未知数的一个方程，然后替换回去以找到其他未知数，一个接一个。**'
- en: This procedure is called **"Gaussian elimination".**
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程称为**“高斯消元法”。**
- en: '**Exercise 32.2 Perform Gaussian elimination on the following set of equations
    to find a solution**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 32.2 对以下方程组执行高斯消元以找到解**'
- en: '![](../Images/8d2893842deb50cbaeaaddcde36ce38b.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d2893842deb50cbaeaaddcde36ce38b.jpg)'
- en: '[Solution](exercise02.html)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[解答](exercise02.html)'
- en: Please notice that in doing these operations it is very easy to make a mistake,
    and it is wise to check your answer, once you have it, in **all** the original
    equations to see if they are satisfied.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在进行这些操作时很容易出错，明智的做法是一旦得到答案，就在**所有**原始方程中检查你的答案，看它们是否满足。
- en: '**Can this procedure fail?**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**这个过程可能失败吗？**'
- en: If the equations that you start with are consistent, they will produce a unique
    solution **unless** when you try to eliminate one variable by subtracting a multiple
    of an equation from another, you eliminate the entire equation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你开始的方程一致，它们将产生唯一的解 **除非** 当你试图通过从另一个方程减去一个方程的倍数来消去一个变量时，你消去了整个方程。
- en: That is, at some stage one of your equations is a multiple of another and subtracting
    that multiple from it eliminates the entire equation.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，在某个阶段，你的一个方程是另一个方程的倍数，减去这个倍数就消去了整个方程。
- en: This will happen if in the beginning one of your equations can be expressed
    as a sum of multiples of one or more of the others. (The simplest way this happens
    is when two of the equations are identical)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在开始时你的一个方程可以表示为一个或多个其他方程的倍数之和，则会发生这种情况。（最简单的发生方式是当两个方程相同时）
- en: In this case the left hand sides of your equations are said to be **linearly
    dependent.**
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你的方程的左侧被称为**线性相关**。
- en: Otherwise, when the equations have a unique solution, the left hand sides are
    said to be **linearly independent.**
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，当方程有唯一解时，左侧被称为**线性独立**。
- en: When your equations are linearly dependent, (and you started with the same number
    of equations as you had unknowns,) you will find that you do not have enough equations
    to determine a unique solution.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的方程线性相关时（并且你开始的方程数与你的未知数数相同），你会发现你没有足够的方程来确定唯一的解。
- en: '**This is not a disaster,** but it means that there are lots of solutions,
    at least a whole line of them.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**这并不是一场灾难**，但这意味着有很多解，至少有一整条线。'
- en: You can continue the Gaussian elimination process until you are down to one
    non-vanishing equation in now two or more variables. Then **any** solution to
    that equation is a solution to the original set of equations, which is said to
    be **an underdetermined set of equations.**
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 继续高斯消元过程，直到你只剩下一个非零方程，其中有两个或更多个变量。那么，**任何**解这个方程的解都是原方程组的解，这被称为**欠定方程组**。
- en: Suppose for example, your last equation with all other unknowns eliminated is
    x = 2y + 3.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你的最后一个方程是x = 2y + 3。
- en: Then you can choose any value you please for y, compute x and then go on to
    use your other equations to compute your other unknowns, and that will be a solution,
    though of course not the only possible one. **Solutions to an equation like this
    one form a line in the xy plane.**
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以选择任意值给y，计算x，然后继续使用你的其他方程来计算你的其他未知数，这将是一个解，尽管当然不是唯一可能的解。**像这样的方程的解形成了xy平面上的一条线。**
- en: 32.2 Matrices
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.2 矩阵
- en: Matrices provide a convenient way to describe linear equations. Thus if you
    take the coefficients of your unknowns, in some standard order, as the row elements
    of your matrix, you define **a matrix of coefficients for any set of equations.**
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵提供了描述线性方程的便捷方式。因此，如果你将未知数的系数按某种标准顺序排列为矩阵的行元素，你就为任何一组方程定义了**系数矩阵。**
- en: For the example equations above, the coefficient matrix, call it M, is, with
    the standard ordering of x, y and z
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上面的示例方程，系数矩阵，称为M，是按照x、y和z的标准顺序排列的
- en: '![](../Images/7149e6da35a1ff32dea21d39e453e226.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7149e6da35a1ff32dea21d39e453e226.jpg)'
- en: We can then write the original equations as the single matrix equation
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将原方程写成单一矩阵方程
- en: '![](../Images/569ce160ba5a560d93f59db9050e035e.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/569ce160ba5a560d93f59db9050e035e.jpg)'
- en: 'Using the definition of matrix multiplication, which is: **taking the dot products
    of the rows of the first matrix with the columns (here single column) of the second
    to produce the corresponding elements of the product,** you should verify that
    this matrix equation is exactly the same as our original three equations.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用矩阵乘法的定义，即：**将第一个矩阵的行与第二个矩阵的列（这里是单列）进行点积，以产生乘积的相应元素**，你应该验证这个矩阵方程与我们最初的三个方程完全相同。
- en: 'The process of **Gaussian elimination** can be applied in this matrix form
    here. The rules are:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯消元法**可以应用于这种矩阵形式。规则是：'
- en: '**1\. You can multiply an entire row (on both sides of the equation) by any
    non-zero number without changing the content of the equations.**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 你可以将整行（方程两侧）乘以任意非零数，而不改变方程的内容。**'
- en: '**2\. You can add a multiple of any row to another without changing the content
    of the equations. You must add entirely across the row, including the other side
    of the matrix, however.**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 你可以将任意行的倍数加到另一行上，而不改变方程的内容。但是，你必须完全跨越整行，包括矩阵的另一侧。**'
- en: In this form such operations are called **"elementary row operations"** and
    Gaussian elimination is called **row reduction.**
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种形式下，这些操作被称为**"初等行操作"**，高斯消元被称为**行简化。**
- en: What you do here is perform enough of operation 2 to **form 0's in the matrix
    on one side of the main diagonal.** When this is done you can determine one unknown
    and then substitute successively to find the others.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里你要做的是执行足够多的第2种操作，**在主对角线的一侧形成矩阵中的0。**当这样做时，你可以确定一个未知数，然后逐步代入找到其他未知数。
- en: You can also attempt to perform these operations **until all elements of your
    matrix off the main diagonal are 0's,** and the diagonal elements are 1\. In that
    case the right hand side vectors are the solutions for the corresponding variables
    and you need not substitute back to find all the unknowns.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以尝试执行这些操作**直到矩阵主对角线之外的所有元素都是0**，对角线元素为1。在这种情况下，右侧向量是相应变量的解，你无需回代找到所有未知数。
- en: '**The n dimensional matrix whose diagonal elements are 1 and off diagonal elements
    are 0** is called the **n dimensional identity matrix,** and is written as **I**
    usually without any indication of what its size is, unless that can cause confusion,
    in which case it is written as **I[n].**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**对角元素为1，非对角元素为0的n维矩阵**称为**n维单位矩阵**，通常写为**I**，除非可能引起混淆，此时会写为**I[n]。**'
- en: It has the property that its matrix product with any matrix M of the same dimension
    is M itself, and its operation on any n dimensional vector **v** is **v** itself.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有这样的性质，即其与相同维度的任何矩阵M的矩阵乘积是M本身，并且其对任何n维向量**v**的操作是**v**本身。
- en: Thus if you start with the matrix equation **Mv = r,** and row reduce to find
    another representation of the same set of equations for which M has been reduced
    to the identity matrix I, you have **Iv = r'** where **r' is the result of the
    same row operations on the right side of the equation as those that reduced M
    to I.**
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你从矩阵方程**Mv = r**开始，并通过行简化找到另一组相同方程的表示，其中M已被简化为单位矩阵I，你会得到**Iv = r'**，其中**r'是右侧方程上的相同行操作的结果，这些操作将M简化为I。**
- en: You thereby obtain **the solution, v = r'.**
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你因此得到**解，v = r'。**
- en: 32.3 The Inverse of a Matrix
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.3 矩阵的逆
- en: If two square matrices M and A have the property that **MA = I,** (in infinite
    dimensions you also need the condition that AM = I) then **A and M are said to
    be inverses of one another and we write A = M^(-1) and M= A^(-1).**
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个方阵M和A满足**MA = I**（在无限维度中，你还需要条件AM = I），那么**A和M被称为彼此的逆，我们写为A = M^(-1)和M=
    A^(-1)。**
- en: A wonderful feature of row reduction as we have described it is that when you
    have a matrix equation AB = C, **you can apply your reduction operations for the
    matrix A to the rows of A and C simultaneously and ignore B, and what you get
    will be as true as what** you started with.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所描述的，行简化的一个很棒的特性是，当你有一个矩阵方程AB = C时，**你可以将A的简化操作同时应用于A和C的行，而忽略B，你得到的结果与**你开始的一样正确。
- en: This is exactly what we did when B was the column vector with components equal
    to our unknowns, x, y and z, but it is equally true for any matrix B.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是当B是列向量，其分量等于我们的未知数x，y和z时所做的事情，但对于任何矩阵B来说同样成立。
- en: Thus, suppose you start with the matrix equation **AA^(-1) = I.**
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，假设你从矩阵方程**AA^(-1) = I**开始。
- en: If we row reduce A so it becomes the identity matrix I, then the left hand side
    here becomes IA^(-1) which is A^(-1), the matrix inverse to A. The right hand
    side however is **what you obtain if you apply the row operations necessary to
    reduce A to the identity, starting with the identity matrix I.**
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对A进行行简化，使其成为单位矩阵I，那么这里的左侧变为IA^(-1)，即A^(-1)，A的逆矩阵。然而右侧是**如果你应用必要的行操作将A简化为单位矩阵，从单位矩阵I开始，你会得到的结果。**
- en: We can conclude that the inverse matrix, **A^(-1) can be obtained by applying
    the row reduction operations that make A into I starting with I.**
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出结论，逆矩阵**A^(-1)可以通过将使A成为I的行简化操作应用于I开始的矩阵A来获得。**
- en: '**Example:** we give a two dimensional example, but the method and idea hold
    in any dimension, and computers are capable of doing this for n by n matrices
    when n is in the hundreds even thousands.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**例子：** 我们给出一个二维的例子，但这种方法和思想在任何维度都适用，当n为数百甚至数千时，计算机可以对n乘n矩阵进行这样的操作。'
- en: Suppose we want the inverse of the following matrix
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要以下矩阵的逆矩阵。
- en: '![](../Images/8faa047e5297fdab11c561949736712d.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8faa047e5297fdab11c561949736712d.jpg)'
- en: We can place an identity matrix next to it, and perform row operations simultaneously
    on both. Here we will first subtract 5 times the first row from the second row,
    then divide the second row by -9 then subtract three times the second from the
    first
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在其旁边放置一个单位矩阵，并同时对两者进行行操作。这里我们首先从第二行减去第一行的5倍，然后将第二行除以-9，然后从第一行减去第二行的三倍。
- en: '![](../Images/bdef25fe56047e22f4bf1f4d71213e45.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bdef25fe56047e22f4bf1f4d71213e45.jpg)'
- en: '![](../Images/458e404765f996bbacb1fa9a265145e1.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/458e404765f996bbacb1fa9a265145e1.jpg)'
- en: and the last matrix here is the inverse, A^(-1) of our original matrix A.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个矩阵是我们原始矩阵A的逆矩阵。
- en: Notice that the **rows of A and the columns of A^(-1) have dot products either
    1 or 0 with one another, and the same statement holds with rows of A^(-1) and
    columns of A.** This is of course the defining property of being inverses.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意**A的行和A^(-1)的列彼此之间的点积要么为1，要么为0，A^(-1)的行和A的列也是如此。** 这当然是逆矩阵的定义特性。
- en: '**Exercise 32.3 Find the inverse to the matrix B whose rows are first (2 4);
    second (1 3).** [Solution](exercise03.html)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 32.3 找到矩阵B的逆矩阵，其行为(2 4)；第二行为(1 3)。** [解答](exercise03.html)'
- en: The inverse of a matrix can be useful for solving equations, when you need to
    solve the same equations with different right hand sides. It is overkill if you
    only want to solve the equations once.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵的逆矩阵在解方程时非常有用，当你需要用不同的右侧解相同的方程时。如果你只想解方程一次，那么这就有点大材小用了。
- en: If your original equations had the form M**v** = **r**, by multiplying both
    sides by M^(-1) you obtain **v** = I**v** = M^(-1)M**v** = M^(-1)**r**, so you
    need only multiply the inverse, M^(-1) of M by your right hand side, **r**, to
    obtain a solution of your equations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的原始方程形式为M**v** = **r**，通过将两边乘以M^(-1)，你会得到**v** = I**v** = M^(-1)M**v** =
    M^(-1)**r**，因此你只需将逆矩阵M^(-1)乘以右侧的**r**，就可以得到方程的解。
- en: If you think of what you do here to compute the inverse matrix, and realize
    that in the process the different columns of M^(-1) do not interact with one another
    at all, you are **essentially solving the inhomogeneous equation Mv = r for r
    given by each of the three columns of the identity matrix,** and **arranging the
    results next to each other.**
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑在这里计算逆矩阵时所做的事情，并意识到在这个过程中M^(-1)的不同列根本不相互作用，你**本质上是在解非齐次方程Mv = r，其中r由单位矩阵的三列给出**，**并将结果排列在一起。**
- en: What we are saying here then is that to solve the equations for general **r**
    it is sufficient to **solve it for each of the columns of I, and then the solution
    for a general linear combination r of these columns is the same linear combination
    of the corresponding solutions.**
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们在这里说的是，为了解一般的方程**r**，只需**对I的每一列求解，然后一般线性组合r的解是相同的线性组合的相应解。**
- en: '**What matrices have inverses?**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么矩阵有逆？**'
- en: Not every matrix has an inverse.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个矩阵都有逆。
- en: As we have seen, when the rows of M are **linearly dependent,** the equations
    that M defines do not have unique solutions, which means that for some right hand
    sides there are lots of solutions and for some there are none. If so the **matrix
    M does not have an inverse.**
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，当M的行**线性相关**时，M定义的方程组没有唯一解，这意味着对于某些右手边，有很多解，而对于某些右手边则没有解。如果是这样，**矩阵M没有逆。**
- en: One way to characterize the **linear dependence** of the rows (or columns, if
    the rows are linearly dependent and the matrix is square, then the columns are
    linearly dependent as well) in three dimensions is that the volume of the parallelepiped
    formed by the rows (or columns) of M is zero.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在三维中刻画行（如果行是线性相关的，则列，如果矩阵是方的，那么列也是线性相关的）的**线性相关性**的一种方法是，由M的行（或列）形成的平行六面体的体积为零。
- en: The volume of the parallelepiped formed by the rows of M is not changed under
    the second kind of row operation, adding a multiple of a row to another, though
    it is changes by a factor |c| if you multiply each element of a row by c.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: M的行形成的平行六面体的体积在第二种行操作下不会改变，即向另一行添加倍数的行，尽管如果你将一行的每个元素乘以c，则会变化为|c|的因子。
- en: 'The fact that **volume is always positive** so that the absolute value |c|
    appears here is a bit awkward, and so it is customary to define a quantity that
    **when positive is this volume but has the property of linearity: if you multiply
    a column by c it changes by a factor of c rather than by |c|.** This quantity
    (and an analogue holds in any dimension) is called **the determinant of M.**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 体积始终是正数的事实，所以绝对值|c|出现在这里有些尴尬，因此惯例上定义了一个量，**当它为正时是这个体积，但具有线性性质：如果你将一列乘以c，它的变化因子为c而不是|c|。**这个量（在任何维度上都有类似的量）被称为**矩阵M的行列式。**
- en: 'Thus the absolute value of the determinant of M is:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，M的行列式的绝对值是：
- en: In **one dimension the absolute value of the single matrix element of M.**
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在**一维中M的单个矩阵元素的绝对值。**
- en: In **two dimensions the area of the parallelogram with sides given by the rows
    (or if you prefer, columns) of M.**
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在**二维中，由M的行（或者如果您愿意，列）给出的平行四边形的面积。**
- en: In **three dimensions the volume of the parallelepiped with sides given by the
    rows (or alternately the columns) of M.**
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在**三维中，以M的行（或者列的交替排列）作为边的平行六面体的体积。**
- en: In **higher dimensions the "hypervolume" or higher dimensional analogue of volume
    of the region with sides given by the rows (or columns) of M.**
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在**更高的维度中，以M的行（或列）作为边界的区域的“超体积”或高维模拟体积。**
- en: In **0 dimensions we give whatever it is the value 1.**
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在**0维中我们给出它的值为1。**
- en: And the determinant of M in any dimension is **linear in each of its rows or
    columns and is unchanged upon replacing one row , say q, by the sum of q and any
    multiple of any other row.**
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式M的行或列中的任何一个都是**线性的，并且在用任何其他行的任意倍数的和替换其中一行，比如q时保持不变。**
- en: These statements specify the determinant up to a sign. **The sign is determined
    by convention to be positive for the identity matrix I whose determinant is always
    1.**
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这些陈述规定了行列式的符号。**根据约定，行列式对于恒等矩阵I的符号被确定为正，其行列式总是1。**
- en: 'The condition that M has an inverse is: **the determinant of M is not zero.**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: M具有逆的条件是：**M的行列式不为零。**
- en: We will soon see how to calculate determinants, and how to express the inverse
    of a matrix in terms of its determinant.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快将看到如何计算行列式，以及如何用行列式来表示矩阵的逆。
- en: 32.4 More on Determinants
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.4 关于行列式的更多信息
- en: We have defined **the determinant of a matrix to be a linear function of its
    rows or columns whose magnitude is the hypervolume of the region with edges given
    by its columns, or by its rows.**
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了**矩阵的行或列的行列式为线性函数，其大小是由其列或行给出的边界的区域的超体积。**
- en: 'The determinant has a number of important properties as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式有一些重要的性质如下：
- en: We will list them then offer proofs of them.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将列出它们然后提供它们的证明。
- en: 1\. **Linearity in columns:** if we have column n-vectors c(k) and d(k), for
    k = 1 to n, and pick any j in this range then the n dimensional determinant obeys
    the condition
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. **列的线性性：** 如果我们有列向量c(k)和d(k)，对于k = 1到n，并选择这个范围内的任意j，则n维行列式满足条件
- en: det (c(1), …c(j - 1), **a*c(j) + b*d(j)**, c(j + 1),…,c(n)) = **a***det (c(1),
    …c(j - 1), **c(j)**, c(j + 1),...,c(n)) + **b***det (c(1), …c(j-1), **d(j)**,
    c(j + 1),...,c(n)).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: det (c(1), …c(j - 1), **a*c(j) + b*d(j)**, c(j + 1),…,c(n)) = **a***det (c(1),
    …c(j - 1), **c(j)**, c(j + 1),...,c(n)) + **b***det (c(1), …c(j-1), **d(j)**,
    c(j + 1),...,c(n)).
- en: 2\. **Linearity in rows:** write this one out yourself.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **行的线性性：** 请自己写出这个。
- en: 3\. **The determinant is 0 if two columns are the same.** (Likewise for rows.)
    Equivalently, it changes sign if you interchange two rows (or columns).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **如果两列相同，则行列式为0。**（行也是如此。）换句话说，如果交换两行（或列），行列式会改变符号。
- en: '**4.** The determinant can be evaluated by a process **like row reduction.**
    You can add multiples of rows to one another until all elements on one side of
    the main diagonal are 0.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**4.** 行列式可以通过类似行变换的过程来计算。可以将一行的倍数加到另一行，直到主对角线一侧的所有元素都为0。'
- en: '**Then the product of the diagonal elements is the determinant.**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**然后对角线元素的乘积就是行列式。**'
- en: 5\. **The determinant of the matrix product of two matrices is the product of
    their determinants.**
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. **两个矩阵的乘积的行列式等于它们的行列式的乘积。**
- en: 6\. In terms of the elements of a matrix M in any one column say M[1j], M[2j],
    ...
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 对于矩阵M中的任意一列元素，比如M[1j]，M[2j]，...
- en: The determinant can be expressed as
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式可以表示为
- en: '**det M = M[1j]*C(1, j) + M[2j]*C(2, j) + ...**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**det M = M[1j]*C(1, j) + M[2j]*C(2, j) + ...**'
- en: The quantities **C(i, j)** that occur here are called **co-factors** of the
    **matrix M.**
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里出现的量**C(i, j)**被称为**矩阵M的余子式**。
- en: '**C(i, j)** must be **linear in all the rows of M except the i-th and in all
    the columns of M except the j-th, and it must be 0 if two of those rows or columns
    are the same;** so it is **proportional to the determinant of the matrix obtained
    by removing the i-th row and j-th column from M. The proportionality constant
    turns out to be (-1)^(i+j).**'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**C(i, j)**必须**对M的除第i行和第j列外的所有行和所有列都是线性的，并且如果这两行或列相同，则必须为0；**因此它**与从M中删除第i行和第j列得到的矩阵的行列式成比例。比例常数结果为(-1)^(i+j)。**'
- en: '**7\. The inverse of the matrix M is the matrix whose (i, j)-th element is
    ![](../Images/d3936880283c27a9cd884203d9ca53fe.jpg).**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**7\. 矩阵M的逆矩阵是其（i, j）-th元素为![](../Images/d3936880283c27a9cd884203d9ca53fe.jpg)的矩阵。**'
- en: 8\. If you have a set of equations of the form M**v** = **c**, then the i-th
    component of **v** is given by **the ratio of the determinant of the matrix obtained
    by taking M and substituting c for the i-th column of M, divided by the determinant
    of M itself.** (This statement is called Cramer's Rule.)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. 如果有一组形如M**v** = **c**的方程组，则**v**的第i个分量由**取M并用c替换M的第i列得到的矩阵的行列式除以M的行列式**给出。（这个陈述被称为克莱姆法则。）
- en: 9\. The condition that the determinant of a matrix is 0 means that the **hyper-volume
    of the region determined by the columns is 0** which means that **they are linearly
    dependent,** and it means that **there is a non-zero linear combination of the
    columns that is the zero vector.** Which means that for this vector **v**, we
    have M**v** = **0**.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 9\. 矩阵的行列式为0的条件意味着由列确定的区域的**超体积为0**，这意味着**它们线性相关**，并且意味着**存在一个非零线性组合的列是零向量**。这意味着对于这个向量**v**，我们有M**v**
    = **0**。
- en: 10\. The determinant is unchanged by rotations of coordinates.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 10\. 行列式不受坐标旋转的影响。
- en: 11\. The polynomial of degree n in x defined by **det(M - xI)** is called **the
    characteristic polynomial of M.** Its roots (solutions to it = 0) are called **the
    eigenvalues** of M.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 11\. 在x中的n次多项式由**det(M - xI)**定义，称为**矩阵M的特征多项式**。其根（满足it = 0的解）称为M的**特征值**。
- en: We now comment on these claims.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对这些说法进行评论。
- en: The first three follow immediately from the definition of the determinant as
    a linear version of hyper-volume.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 前三个立即由行列式的定义作为超体积的线性版本得出。
- en: 'It follows from these that you can add a multiple of one row to another without
    changing the determinant: because by linearity the change would have to be a multiple
    of the determinant of a matrix with two identical rows.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 由此可知，可以在不改变行列式的情况下，将一行的倍数加到另一行上：因为根据线性性，变化必须是具有两个相同行的矩阵的行列式的倍数。
- en: But then you can do this until the matrix is diagonal, at which point the determinant,
    again by linearity, is the product of the diagonal elements times the determinant
    of the identity matrix (which is 1).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 但是你可以一直这样做，直到矩阵是对角线矩阵，此时行列式，再次通过线性性，是对角线元素的乘积乘以单位矩阵的行列式（为1）。
- en: 'The statement **that the determinant of a product of two matrices is the product
    of the determinants** is important and useful. It follows by these two observations:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 两个矩阵乘积的行列式是行列式乘积的陈述**是重要且有用的。这可以通过以下两点观察得出：
- en: 1\. If the **matrix A is diagonal,** then det A is the product of the diagonal
    elements of A.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 如果**矩阵 A 是对角线矩阵**，那么 det A 是 A 的对角线元素的乘积。
- en: On the other hand, the rows **of AB are just the rows of B each multiplied by
    the corresponding diagonal element of A.**
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，AB 的行**只是 B 的行，每个都乘以 A 的对角线元素。**
- en: By linearity then, the **determinant of AB is the product of the diagonal elements
    of A times the determinant of B,** that is, it is **the product of the determinant
    of A and that of B,** as we have claimed.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过线性性，**AB 的行列式是 A 的对角线元素的乘积乘以 B 的行列式，也就是 A 的行列式和 B 的行列式的乘积，**正如我们所声称的。
- en: 2\. If we **apply a row operation (no multiplying rows by constants allowed)
    as discussed in property 4 above, on A to obtain a new matrix A' and apply the
    same row operation to (AB) to obtain (AB)' we will have**
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 如果我们**对 A 应用一个行操作（不允许将行乘以常数）如上述属性 4 中讨论的，得到一个新矩阵 A'，并对 (AB) 应用相同的行操作得到 (AB)'，我们将有**
- en: (A'B) = (AB)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: (A'B) = (AB)'
- en: and we will have det A = det A' , and det AB = det A'B.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将有 det A = det A'，以及 det AB = det A'B。
- en: 'We can do this until A is diagonal, at which point we can use the first statement
    here to tell us: (det A'') * (det B) = det A''B, from which our conclusion follows.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以一直这样做，直到 A 是对角线矩阵，此时我们可以使用这里的第一个陈述告诉我们：(det A') * (det B) = det A'B，从而得出我们的结论。
- en: The statements about cofactors merely make explicit what it means to be linear
    in each row and column.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 关于余子式的陈述只是明确了在每行和每列中线性的含义。
- en: The sign factor can be deduced from the fact that it is 1 if you consider the
    first row and column, (think of the identity matrix) and you can switch rows and
    columns with their neighbors i - 1 and j - 1 times to rearrange things so that
    the i-th row and j-th column become the first and everything else is in their
    original orders.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 符号因子可以从这样一个事实中推导出来，即如果你考虑第一行和第一列，（想想单位矩阵）你可以交换行和列与它们的邻居 i - 1 和 j - 1 次，重新排列事物，使得第
    i 行和第 j 列成为第一行，其他所有行列保持原始顺序。
- en: This will cause i + j - 2 sign changes, which gives the sign factor noted.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致 i + j - 2 个符号变化，这给出了所述的符号因子。
- en: As already noted somewhere the **cofactor formula for the inverse** is a statement
    about the dot products of the rows of the inverse with the columns of the original
    matrix. The diagonal products must be 1 which follows for **![](../Images/d3936880283c27a9cd884203d9ca53fe.jpg)**
    from the cofactor formula for the determinant, and the off diagonal ones must
    be zero because by that same formula they represent the determinants of matrices
    with two identical columns or rows.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，**逆的余子式公式**是关于逆的行与原始矩阵的列的点积的陈述。对角线乘积必须为 1，这可以从行列式的余子式公式中得出，而非对角线乘积必须为零，因为根据相同的公式，它们代表具有两个相同列或行的矩阵的行列式。
- en: '**Cramer''s rule** is the observation that by the **definition of the inverse,**
    the desired coefficient is **the dot product of the i-th row of the inverse of
    M with the vector c.** But by the cofactor formula this is **the dot product of
    the i-th column of the cofactor matrix with the vector c, divided by the determinant
    of M,** and that is the ratio of the two determinants of Cramer''s rule.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**克莱姆法则**是观察到，根据**逆的定义，**所需系数是**矩阵 M 的逆的第 i 行与向量 c 的点积。**但根据余子式公式，这是**余子式矩阵的第
    i 列与向量 c 的点积，除以 M 的行列式，**这就是克莱姆法则的两个行列式的比率。'
- en: 32.5 Matrices and Transformations
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.5 矩阵和变换
- en: '**The most important use of matrices lies in representing linear transformations
    on a vector space.**'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵最重要的用途在于表示向量空间上的线性变换。**'
- en: '**How?**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何？**'
- en: A matrix represents the tranformation which takes **the first basis vector into
    first column of the matrix, second basis vector into the second column of the
    matrix, j-th basis vector into j-th column.**
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 一个矩阵表示了将**第一个基向量转换为矩阵的第一列，第二个基向量转换为矩阵的第二列，第 j 个基向量转换为矩阵的第 j 列。**
- en: '**What does it do to other vectors?**'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**它对其他向量做了什么？**'
- en: 'Remember that any other vector, say **v** can be expressed as **a linear combination
    of the basis vectors: v** gets transformed by the transformation to **that same
    linear combination of the column vectors of the matrix.**'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，任何其他向量，比如**v**，都可以表示为**基向量的线性组合：v**通过变换转换为**矩阵的列向量的同一线性组合**。
- en: For example, the sum of the first two basis vectors gets mapped into the sum
    of the first two columns of the matrix; the average of the two basis vectors into
    the average of the columns, and so on.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，前两个基向量的和被映射为矩阵的前两列的和；两个基向量的平均值被映射为列的平均值，依此类推。
- en: '**Notice that the same transformation acting on vectors will usually be described
    by a different matrix if you use a different basis.**'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**请注意，如果使用不同的基，作用于向量的相同变换通常会由不同的矩阵描述。**'
- en: '[Example](example01.html)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例](example01.html)'
- en: 32.6 Invariants of Transformations
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.6 变换的不变量
- en: 'Since the same transformation can often be represented by many different matrices,
    depending upon the basis chosen to describe them, the following questions can
    be raised:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 由于相同的变换通常可以用许多不同的矩阵来表示，取决于所选择的基，因此可以提出以下问题：
- en: '**What properties of a matrix are the same independent of the basis, being
    intrinsic properties of the transformation the matrices represent?**'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵的哪些属性是独立于基的相同，是矩阵所代表的变换的固有属性？**'
- en: '**When do two matrices represent the same transformation with different bases?**'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么时候两个矩阵代表相同的变换但使用不同的基？**'
- en: There are actually several questions that can be raised for each of these, because
    we can be describing matrices whose elements are **all real, or we can permit
    complex elements,** and we can insist that we stick to **bases that are orthonormal
    (the dot product of any basis vector with itself is 1 and its dot product with
    any other basis vector is 0) or allow more general bases including those with
    complex components.**
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，对于每个问题，都可以提出几个问题，因为我们可以描述元素全部为**实数的矩阵，或者允许复数元素**，并且我们可以坚持使用**正交规范基（任何基向量与自身的点积为1，与任何其他基向量的点积为0）或允许更一般的基，包括具有复数分量的基。**
- en: The answers are a bit different depending on which context we consider, but
    they are fundamentally similar.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 答案在考虑的上下文不同时略有不同，但基本上是相似的。
- en: We will here consider **real matrices and real orthonormal bases** only.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这里只考虑**实矩阵和实正交规范基**。
- en: A matrix which takes our original basis vectors into another orthonormal set
    of basis vectors is called an **orthogonal matrix;** its columns must be **mutually
    orthogonal and have dot products 1 with themselves, since these columns must form
    an orthonormal basis.**
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们的原始基向量转换为另一组正交规范基向量的矩阵称为**正交矩阵；**其列必须**相互正交并且与自身的点积为1，因为这些列必须形成正交规范基。**
- en: These conditions mean that an orthogonal matrix has its [transpose](#Transpose)
    as its inverse! **(The condition for two matrices to be inverses of one another
    is that the rows of one are orthogonal to the columns of the other, except that
    rows and columns with the same index have dot product one with one another.)**
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这些条件意味着正交矩阵的[转置](#Transpose)就是它的逆！**(两个矩阵互为逆矩阵的条件是一个矩阵的行与另一个矩阵的列正交，除了具有相同索引的行和列之外，它们的点积为1)**
- en: 'The next question we address is: **what happens to a matrix M when an orthogonal
    transformation A is applied to the original basis vectors?**'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要讨论的问题是：**当正交变换A应用于原始基向量时，矩阵M会发生什么变化？**
- en: A transforms the initial basis to A's columns. We want to know what the matrix
    M does to these column vectors. That is **exactly what the matrix MA** does to
    the original column basis vectors. **A takes them into the new basis vectors and
    M then transforms these into whatever it does to them.**
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: A将初始基转换为A的列。我们想知道矩阵M对这些列向量做了什么。那就是**矩阵MA**对原始列基向量所做的事情。**A将它们带入新的基向量，然后M将这些向量转换为它们所做的任何事情。**
- en: However the product MA expresses what M does to the new basis vectors **in terms
    of the old ones; its columns give the effect of M on the new basis vectors as
    linear combinations of the old basis vectors.**
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，乘积MA表达了M对新基向量的作用**以旧基向量为基础的线性组合；其列给出了M对新基向量的作用，作为旧基向量的线性组合。**
- en: We want to re-express these columns as linear combinations of the new basis
    vectors.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望将这些列重新表达为新基向量的线性组合。
- en: '**How do we do this?**'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们该如何做到这一点？**'
- en: The easiest way to see is to **look at what happens when M is the identity matrix,
    I. This is the matrix which takes any vector into itself. After the change of
    basis, it must still take any vector into itself, so it must still be the identity
    matrix.**
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 最容易看到的方法是**观察当 M 是单位矩阵 I 时会发生什么。这是一个将任何向量映射为自身的矩阵。在基变换后，它仍然必须将任何向量映射为自身，因此它仍然是单位矩阵。**
- en: But if M = I then MA is just IA or A itself and that is what I becomes in terms
    of the old basis That is columns of A tell what the new basis vectors look like
    in terms of the old ones.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果 M = I，那么 MA 就是 IA 或 A 本身，这就是 I 在旧基中的表达方式。这就是说 A 的列告诉了新基向量在旧基中的样子。
- en: To re-express I in terms of the new basis you must do something which takes
    AI back into I. **The way to do this is to multiply on the left by A^(-1) which
    is A^T.**
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要用新基来重新表示 I，您必须做一些将 AI 返回到 I 的事情。 **这样做的方法是左乘 A^(-1)，即 A^T。**
- en: We deduce that multiplying on the left by A^(-1) performs the desired re-expression
    **for I and therefore for any matrix M.** We conclude that in the new basis the
    matrix M becomes **A^TMA.**
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们推断左乘 A^(-1) 执行了所需的重新表达**对于 I 和因此对于任何矩阵 M。** 我们得出结论，在新基中，矩阵 M 变为**A^TMA。**
- en: '**The transpose of a matrix is the matrix obtained by interchanging its rows
    and columns.**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵的转置是通过交换其行和列而获得的矩阵。**'
- en: '**A matrix is symmetric if it the same after such a transformation.**'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵在这样的变换之后仍然相同，它就是对称的。**'
- en: We have just seen that **an orthogonal transformation** changes a matrix M to
    one of the form A^TMA, where A^TA = I, and the **matrix A has columns given by
    the new orthonormal basis expressed in terms of the old basis.**
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到**正交变换**将矩阵 M 变为形式 A^TMA，其中 A^TA = I，并且**矩阵 A 的列由新基在旧基中表示而成的正交归一化基给出。**
- en: A nice feature of such a transformation is that **if M is symmetric, it stays
    symmetric after any such transformation.**
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这种变换的一个好处是**如果 M 是对称的，那么在任何这样的变换后它仍然保持对称。**
- en: '**Exercise 32.4 Prove this claim: that M is symmetric if and only if A^TMA
    is symmetric.**'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 32.4 证明这个声明：如果 A^TMA 是对称的，则 M 是对称的。**'
- en: This tells us that the only matrices that can possibly be made diagonal by such
    transformations are **symmetric;** since **when they are diagonal they are trivially
    symmetric.**
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们可能可以通过这种变换使对角化的唯一矩阵是**对称的；** 因为**当它们是对角的时，它们显然是对称的。**
- en: '**If a matrix is diagonal, its eigenvectors are the basis vectors. So we have
    shown that only symmetric matrices have real orthonormal bases.**'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果一个矩阵是对角的，它的特征向量就是基向量。因此，我们已经证明只有对称矩阵具有实正交基。**'
- en: On the other hand, **any matrix that is symmetric can be made diagonal by an
    orthogonal transformation.** Another way to say this is there is an orthonormal
    basis of real eigenvectors for every symmetric matrix. [Proof of this claim](proof01.html)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**任何对称矩阵都可以通过正交变换对角化。** 另一种说法是每个对称矩阵都有一个实特征向量的正交归一化基。 [此声明的证明](proof01.html)
- en: 'We have answered our first question: **which matrices can be put in diagonal
    form by choosing a new orthonormal basis? The answer being any symmetric matrix.**
    And the way to put a matrix in such form is to find its eigenvectors and choose
    an orthonormal set of these.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经回答了我们的第一个问题：**哪些矩阵可以通过选择一个新的正交归一化基来对角化？答案是任何对称矩阵。** 将矩阵放入这种形式的方法是找到其特征向量并选择其中的正交集。
- en: 'Our second question was: **when will two such matrices be representations of
    the same transformation in a different basis**. And the answer is, when their
    characteristic equations are the same, so that their eigenvalues are the same
    and have the same multiplicities.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个问题是：**两个这样的矩阵何时会成为不同基中相同变换的表示**。答案是，当它们的特征方程相同时，它们的特征值相同且具有相同的重数时。
- en: 32.7 Other Notions of Diagonalizability
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.7 对角化的其他概念
- en: We have noted that our first question has a number of variants, and we will
    note the changes in the answers when the variants are used.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经注意到，我们的第一个问题有许多变体，当使用这些变体时，我们将注意到答案的变化。
- en: When we allow complex matrix elements, and complex vectors, we can diagonalize
    a wider class of matrices.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们允许复数矩阵元素和复向量时，我们可以对更广泛的矩阵进行对角化。
- en: When a vector has complex valued entries, we still want to interpret its length
    as the square root of its dot product with itself. **We want this to be positive.**
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个向量具有复值元素时，我们仍然希望将其长度解释为其与自身的点积的平方根。**我们希望这个值是正的。**
- en: '**Therefore we redefine the dot product to make this so: the dot product of
    a complex vector with itself is the sum of the absolute value squared of its entries.**'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**因此，我们重新定义点积：复向量与自身的点积是其条目的绝对值的平方之和。**'
- en: We generalize this to the dot product of a row vector and a column vector by
    making it **the sum of the products of the complex conjugate of the component
    of the row vector with the corresponding component of the column vector.**
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个推广到一行向量和一列向量的点积，通过将它定义为**行向量的复共轭与列向量的相应分量的乘积之和**。
- en: Thus the dot product of the column vector with entries (a + ib, c + id) with
    the same row vector is
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，具有条目（a + ib, c + id）的列向量与相同行向量的点积是
- en: (a - ib) * (a + ib) + (c - id) * (c + id)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: （a - ib）*（a + ib）+（c - id）*（c + id）
- en: or
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 或
- en: a² + b² + c² + d²
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: a² + b² + c² + d²
- en: The dot product of the same column vector with (e + if, g + ih) is instead
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 与（e + if, g + ih）相同的列向量的点积反而是
- en: (e - if) * (a + ib) + (g - ih) * (c + id)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: （e - if）*（a + ib）+（g - ih）*（c + id）
- en: Notice that with this definition the dot product is no longer symmetric. However
    it does not change if you interchange row and column and also take the complex
    conjugate, since the asymmetry lies in taking the complex conjugate of the row
    and not the column.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，按照这个定义，点积不再对称。但是如果你交换行和列并且取复共轭，它不会改变，因为不对称性在于取行的复共轭而不是列。
- en: With complex vectors we define an **orthonormal basis** to be one for which
    **the dot product of each column with the complex conjugate of the entries in
    the other columns are zero.**
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 用复向量，我们定义一个**正交归一基**，使得**每列与其他列中的条目的复共轭的点积都为零**。
- en: This means that with this definition, a matrix that takes a given basis into
    another **orthonormal basis in this context has the property that its complex
    conjugate transpose is its inverse.**
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着按照这个定义，一个矩阵，将给定的基转换为另一个**正交归一基在这个背景下具有其复共轭转置为其逆的属性。**
- en: Such a matrix is called a **unitary matrix,** and **the linear transformation
    which takes one orthonormal complex basis to another is called a unitary transformation.**
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的矩阵称为**酉矩阵**，而**将一个正交归一复基转换到另一个的线性变换称为酉变换。**
- en: The effect of a unitary transformation described by the unitary matrix U on
    a matrix M is now U^t * MU as can be shown by the same argument as before. (Of
    course real unitary matrices are orthogonal.)
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 由于与之前相同的论证，酉矩阵U描述的酉变换对矩阵M的影响现在是U^t * MU，（当然，实数酉矩阵是正交的）。
- en: '**Again we can ask, what matrices can be diagonalized by a unitary transformation?**
    A preliminary question is: **which matrices can be diagonalized so that its eigenvalues,
    which are what appear on the diagonal when it is diagonalized, are all real?**'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**再次我们可以问，哪些矩阵可以被一个酉变换对角化？** 一个初步的问题是：**哪些矩阵可以被对角化，以便它的特征值，也就是在对角化时出现在对角线上的值，都是实数？**'
- en: 'The answer now is that any matrix that **is its own transpose complex conjugate**
    will have this property: which implies if M is n by n, **M has n real eigenvalues
    and an orthonormal basis of eigenvectors.**'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的答案是，任何矩阵**它自己的转置的复共轭**将具有此属性：这意味着如果M是n乘以n，**M具有n个实特征值和一组特征向量的正交基。**
- en: Such matrices are called Hermitian matrices.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的矩阵称为厄米矩阵。
- en: Again the necessity of this condition follows from the fact that **"Hermitivity"
    is preserved by unitary transformations and real diagonal matrices are Hermitian.**
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，这个条件的必要性来自于**“厄米性”被酉变换保留，而实对角矩阵是厄米的。**
- en: '**Hermitian matrices are of particular importance** because they have the possibility
    of representing measurable real observables in physical systems. They do so in
    quantum mechanics.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**厄米矩阵具有特殊重要性**，因为它们有可能在物理系统中表示可测的实观测量。在量子力学中确实如此。'
- en: Answer to the general question, **without reference to real eigenvalues is that
    the matrix must commute with its complex conjugate transpose.**
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一般问题的回答，**不涉及实特征值是该矩阵必须与其复共轭转置交换。**
- en: This condition is again preserved under unitary transformations, and it is a
    property of diagonal matrices, since all diagonal matrices commute with one another,
    so it is definitely necessary.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个条件再次在酉变换下保持不变，并且它是对角线矩阵的一个属性，因为所有对角线矩阵彼此交换，所以它绝对是必要的。
- en: Still another question is, **when can a matrix be diagonalized by any change
    of basis, without any requirement about orthonormality; that is when does there
    exist any kind of a basis of eigenvectors for the matrix M?**
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，**何时可以通过任何基础变换使矩阵对角化，而不需要关于正交性的任何要求；也就是说，何时存在矩阵 M 的任何类型的特征向量的基？**
- en: There is an easy answer which again can easily be seen to be necessary. Suppose
    a[1], a[2], ..., a[k] are the **distinct eigenvalues of M.**
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个简单的答案，而且可以很容易地看到是必要的。假设 a[1]、a[2]、...、a[k] 是 M 的 **不同特征值**。
- en: Any vector can be written as a sum of basis vectors.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 任何向量都可以写成基向量的和。
- en: If each basis vector is an eigenvector of M, say corresponding to eigenvalue
    a[j], then M - a[j]I acting on it will be the zero vector.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果每个基向量都是 M 的特征向量，对应于特征值 a[j]，那么 M - a[j]I 作用于它将得到零向量。
- en: On the other hand M - a[h]I for a[h] different from a[j], acting on it merely
    multiplies it by a[j] - a[h].
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，对于 a[h] 不同于 a[j] 的情况，M - a[h]I 对其的作用仅仅是将其乘以 a[j] - a[h]。
- en: Thus, if there is a basis consisting of eigenvectors of M then the **product
    over all j from 1 to k of (M - a[j]I)** must be the zero matrix, **since it must
    give 0 in acting on every basis vector.**
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果存在由 M 的特征向量组成的基，则 **从 1 到 k 的所有 j 的乘积 (M - a[j]I)** 必须是零矩阵，**因为它在作用于每个基向量时必须得到
    0。**
- en: This product is called the **minimal polynomial of M** and the equation that
    it is the zero matrix is called the minimal equation for M. Thus **if M obeys
    its own minimal equation then it has a basis of eigenvectors.**
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这个乘积称为 **M 的最小多项式**，它为零矩阵的方程称为 M 的最小方程。因此，**如果 M 遵循其自己的最小方程，则它具有特征向量的基。**
- en: By the way an interesting and curious fact is that **every matrix obeys its
    own characteristic equation** (that is if you substitute M for the variable x
    in it, you get the 0 matrix).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，一个有趣而奇特的事实是 **每个矩阵都遵循其自己的特征方程**（也就是说，如果您用 M 替换变量 x，您将得到 0 矩阵）。
- en: 32.8 Computing Eigenvalues and Eigenvectors
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.8 计算特征值和特征向量
- en: 'We here address the following questions:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里解决以下问题：
- en: 1\. How can we actually compute eigenvalues and eigenvectors of a given matrix?
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 我们如何实际计算给定矩阵的特征值和特征向量？
- en: 2\. How can we apply what we know about matrices to quadratic functions (also
    called quadratic forms)? And to critical points and saddle points.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 我们如何将我们对矩阵的了解应用到二次函数（也称为二次形式）？以及临界点和鞍点。
- en: '3\. We describe an eigenvector game: learn how to just look at a matrix and
    guess an eigenvector!'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 我们描述了一种特征向量游戏：学会如何只看一个矩阵就猜出一个特征向量！
- en: How to compute eigenvalues and eigenvectors for large matrices is an important
    question in numerical analysis. We will merely scratch the surface for small matrices.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如何计算大型矩阵的特征值和特征向量是数值分析中的一个重要问题。我们将仅仅浅尝辄止小矩阵。
- en: 'There is an obvious way to look for real eigenvalues of a real matrix: you
    need only write out its characteristic polynomial, plot it and find its solutions.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 查找实矩阵的实特征值有一个明显的方法：您只需写出其特征多项式，绘制它并找到其解。
- en: This is quite easy to do in two dimensions, not difficult in three or four dimensions,
    and not really difficult for a computer in many more dimensions.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这在两个维度上很容易做到，在三维或四维上不难，在更多维度上对计算机来说也不是很困难。
- en: This is very straightforward and dull.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这很简单，也很枯燥。
- en: In two dimensions the characteristic equation is
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个维度中，特征方程为
- en: x² - tr(M)x + det(M) = 0
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: x² - tr(M)x + det(M) = 0
- en: This equation can be solved using the quadratic formula and the eigenvalues
    can be obtained by explicit formulae.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程可以使用二次方程式求解，特征值可以通过显式公式获得。
- en: In three dimensions the characteristic equation is
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在三维中，特征方程为
- en: x³ - tr(M)x² + Ax - det(M) = 0
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: x³ - tr(M)x² + Ax - det(M) = 0
- en: where A is the sum of pairs of diagonal elements minus the products of each
    opposite pair of off diagonal elements
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 A 是对角元素对的和减去每个对角线元素对的相反对角线元素的乘积
- en: A = M[11] * M[22] + M[11] * M[33] + M[22] * M[33] - M[12] * M[21] - M[13] *
    M[31] - M[23] * M[32]
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: A = M[11] * M[22] + M[11] * M[33] + M[22] * M[33] - M[12] * M[21] - M[13] *
    M[31] - M[23] * M[32]
- en: There is a cubic formula for solving this equation but it is probably easier
    to find one solution, say z, numerically, whereupon the other two obey the quadratic
    equation
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个用于解这个方程的立方体公式，但可能更容易找到一个解，比如 z，数值上找到另外两个遵循二次方程
- en: '![](../Images/fcdf31ff51d8ba43fca4aae2411d804a.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcdf31ff51d8ba43fca4aae2411d804a.jpg)'
- en: Since the characteristic polynomial is cubic, it goes in opposite directions
    for large arguments positive versus negative, and so by starting at same and homing
    in (by the divide and conquer approach) you can find a solution to any desired
    accuracy with relative ease.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '由于特征多项式是三次的，它在大的正和负参数方向上是相反的，所以通过从相同的地方开始并通过分而治之的方法逼近，你可以相对容易地找到任意精度的解决方案。 '
- en: So how do we find an eigenvector given an eigenvalue z? There is a very simple
    answer that usually works. A column eigenvector can be obtained by taking the
    cofactors of any row of M - zI and arranging them as a column vector.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何在给定特征值 z 的情况下找到一个特征向量呢？通常有一个非常简单的答案。通过取 M - zI 的任何一行的余子式，并将它们排列成一列向量，可以获得一个列特征向量。
- en: '**Exercises:**'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习：**'
- en: '**32.5 When will this approach fail?**'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**32.5 这种方法何时会失败？**'
- en: '**32.6 Prove that if the cofactors don''t all vanish they provide a column
    eigenvector.**'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**32.6 证明如果余子式不全为零，它们会提供一个列特征向量。**'
- en: '**32.7 Choose a random 3 by 3 matrix and find an eigenvalue and corresponding
    eigenvector.**'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**32.7 随机选择一个 3×3 矩阵并找到一个特征值及其相应的特征向量。**'
- en: There are other ways to find eigenvectors and eigenvalues that often work.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他方法可以找到通常有效的特征向量和特征值。
- en: One approach is to raise the matrix to a high power. This is easier to do than
    it sounds.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是将矩阵提升到一个高次幂。这比听起来要容易些。
- en: You can then notice that the high power of the matrix will tend to have rank
    1, usually, and you can read off a row and a column eigenvector from it.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你随后会注意到矩阵的高次幂通常会趋向于具有秩为 1，并且你可以从中读取一行和一列的特征向量。
- en: You can easily deduce the corresponding eigenvalue by having the matrix act
    on the eigenvector you find.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 通过让矩阵作用于你找到的特征向量，你可以很容易地推导出相应的特征值。
- en: If there is an eigenvalue that has greater magnitude than any other and it has
    only one eigenvector, (it is not a multiple root of the characteristic equation
    for M) then this method will usually find it.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在一个特征值的数量级大于其他任何特征值，并且它只有一个特征向量（它不是 M 的特征方程的多重根），那么这种方法通常能够找到它。
- en: You can apply the same approach to the inverse matrix to M to find an eigenvalue
    smallest in magnitude and its eigenvector.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以应用相同的方法到 M 的逆矩阵，以找到数量级最小的特征值及其特征向量。
- en: These actions are relatively easy on Excel spreadsheets, because these have
    functions that take the product of two matrices (called mmult), which finds the
    inverse of a matrix (minverse) and takes the determinant of a matrix (mdeterm).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Excel 电子表格上执行这些操作相对容易，因为它们具有可取两个矩阵的乘积（称为 mmult）、找到矩阵的逆（minverse）和求解矩阵的行列式（mdeterm）的函数。
- en: Using mmult it is quite easy to square a matrix, copying the procedure to raise
    it to the fourth power, copy both procedures to raise it to the eighth and then
    sixteenth power; copy the whole mess to raise to the 256^(th) power etc.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 mmult 很容易将矩阵平方，复制该过程以将其提升到四次方，并复制两个过程将其提升到八次方，然后十六次方；将整个过程复制以提升到 256 次方等等。
- en: For a four by four matrix once you have two eigenvalues, then you can get the
    rest by solving quadratics and you can usually get the largest and smallest in
    magnitude by raising A and A^(-1) to high powers.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个四乘四的矩阵，一旦你有了两个特征值，那么你可以通过求解二次方程得到其余的，并且通常可以通过将 A 和 A^(-1) 提升到高次幂来得到数量级最大和最小的。
- en: Of course once you have the eigenvalue that is largest in magnitude, you could
    look for the second largest. This can be accomplished by projecting the columns
    of M to vectors normal to the first row eigenvector, and working with the resulting
    matrix.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一旦你有了数量级最大的特征值，你可以寻找第二大的特征值。这可以通过将 M 的列投影到垂直于第一行特征向量的向量上，并处理得到的矩阵来完成。
- en: Of course you run into trouble with this approach if there are two eigenvectors
    with the same largest magnitude of eigenvalue or nearly the same one.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 当存在两个特征向量具有相同数量级的特征值或几乎相同的特征值时，当然你会遇到问题。
- en: How do we find the matrix A which we can use to diagonalize M?
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何找到矩阵 A，以便用于对角化 M？
- en: A's columns are normalized eigenvectors of M.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: A 的列是 M 的归一化特征向量。
- en: <applet code="LinearTransformations3D" codebase="../applets/" archive="linearTransformations3D.jar,go.jar,goText.jar,mk_lib.jar,parser_math.jar,jcbwt363.jar,jama.jar"
    width="760" height="450"></applet>
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: <applet code="LinearTransformations3D" codebase="../applets/" archive="linearTransformations3D.jar,go.jar,goText.jar,mk_lib.jar,parser_math.jar,jcbwt363.jar,jama.jar"
    width="760" height="450"></applet>
- en: 32.9 Application to Quadratic Forms and Spring Systems
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.9 应用于二次型和弹簧系统
- en: Another place in which matrices have appeared in previous chapters was in the
    discussion of the behavior of functions of several variables at a critical point
    (at which the gradient of the function is the **0** vector).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵在前面章节中出现的另一个地方是在讨论多个变量的函数在临界点（函数的梯度为**0**向量的点）的行为时。
- en: We then noticed that the behavior of the function could be described by the
    matrix of second derivatives of the function at that point. This is the matrix
    whose ij-th element is the second partial derivative of the function with respect
    to the i-th and j-th variable.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后注意到函数的行为可以由该点的函数的二阶导数矩阵描述。 这是指函数相对于第 i 和 j 个变量的二阶偏导数。
- en: Symmetric matrices each have a an orthonormal basis of real eigenvectors as
    we proved above, obtainable by an orthogonal transformation.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 对称矩阵每个都有一个由上面证明的实特征向量组成的标准正交基，可通过正交变换获得。
- en: 'If we examine the structure of the matrix for the form using this basis, we
    find that it is diagonal, and so the conditions for an extremum become simple:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查使用这个基础的形式的矩阵的结构，我们会发现它是对角线的，因此极值的条件变得简单：
- en: '**If all the eigenvalues of the second derivative matrix have the same sign
    the function has a local maximum or minimum, with a minimum when they are all
    positive.**'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果二阶导数矩阵的所有特征值都具有相同的符号，则函数具有局部极大值或极小值，当它们全部为正时，为极小值。**'
- en: There is a saddle if the signs are mixed, and you must sometimes look at higher
    derivatives when some of the eigenvalues are 0's.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果符号混合，则存在一个鞍点，并且当一些特征值为 0 时，有时必须查看更高阶导数。
- en: When talking about the matrix of second derivatives we are really talking about
    the quadratic form which describes the quadratic terms in the Taylor series expansion
    of our function about the critical point.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈论二阶导数矩阵时，我们实际上是在谈论描述我们函数关于临界点的 Taylor 级数展开式中的二次项的二次型。
- en: If we focus on quadratic forms we realize that we can use a wider class of transformations
    in order to change their appearance than we can when dealing with transformations.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们专注于二次型，我们会意识到我们可以使用更广泛的变换类来改变它们的外观，而在处理变换时我们所能使用的变换类则较少。
- en: Thus we can make changes of scale of the individual variables to make any positive
    diagonal quadratic into one that has all (non-zero) eigenvalues the same. (Thus
    we can change ![](../Images/4638051d3cef96abffe3c6cb680c6c6a.jpg) by setting ![](../Images/060ade7be3680b8729c5429cb2474691.jpg))
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以改变各个变量的尺度来使任何正对角二次型变成具有所有（非零）特征值相同的二次型。 (因此，我们可以通过设定 ![](../Images/4638051d3cef96abffe3c6cb680c6c6a.jpg)
    来改变 ![](../Images/060ade7be3680b8729c5429cb2474691.jpg))
- en: This allows us to diagonalize two distinct quadratic forms simultaneously. You
    can make the matrix of one into an identity matrix, and then diagonalize the other.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够同时对两个不同的二次型进行对角化。您可以将其中一个矩阵变成单位矩阵，然后对另一个进行对角化。
- en: This is in contrast to what happens with transformations. Two transformations
    must commute to be simultaneously diagonal with the same basis (obviously necessary
    since all diagonal matrices commute with one another).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这与变换发生的情况相反。 两个变换必须可交换以同时与相同的基础对角化（显然是必要的，因为所有对角矩阵都可以彼此交换）。
- en: '(This statement is proven as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: （此声明的证明如下：
- en: Diagonalize the matrix M. You can then observe that the condition that M and
    N commute is the condition that all the off diagonal elements of N say the ij-th
    link indices whose diagonal elements of M are the same.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 对矩阵 M 进行对角化。 您然后可以观察到，M 和 N 可交换的条件是所有 N 的非对角线元素都是相同的，即对角线元素为 M 的 ij-th 链接索引。
- en: Thus if the ij-th entry of N is non-zero then the i-th and j-th eigenvalues
    of M must be the same if N and M are to commute.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果矩阵 N 的 ij-th 元素非零，则矩阵 M 的第 i 和 j 个特征值必须相同，如果要使 N 和 M 可交换。
- en: If they are the same then as far as diagonalizing N is concerned, the problem
    breaks up into parts for each eigenvalue of M; and for each part M is a multiple
    of the identity matrix and will stay diagonal when the corresponding block of
    N is diagonalized.)
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它们相同，那么就在对角化 N 方面，问题分解成了 M 的每个特征值的部分；对于每个部分，M 是单位矩阵的倍数，并且在 N 的相应块被对角化时保持对角化状态。）
- en: Given a system of springs and masses, there will be one quadratic form that
    represents the kinetic energy of the system in terms of momentum variables, and
    another which represents the potential energy of the system in position variables.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组弹簧和质量，将有一个二次形式代表系统的动量变量的动能，另一个代表系统的位置变量的势能。
- en: The remarks above tell us that it is always possible to choose a normalization
    and basis of coordinates so that both of these forms are diagonal. This means
    that the entire system can be analyzed as a bunch of independent simple one dimensional
    springs (each of which can represent a complex combination of original coordinates).
    The corresponding eigenvalues determine the "normal modes" of the system.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 上述说明告诉我们，总是可以选择一种规范化和坐标基，使得这两种形式都是对角的。这意味着整个系统可以被分析为一堆独立的简单一维弹簧（每个弹簧可以表示原始坐标的复杂组合）。相应的特征值确定了系统的“正常模式”。
- en: 32.10 Computing Eigenvalues and Eigenvectors on a Spreadsheet
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.10 在电子表格上计算特征值和特征向量
- en: You can build a spreadsheet that will find same for any 3 by 3 matrix that has
    three real eigenvalues, as follows. It is very worthwhile for you to attempt to
    do this.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以建立一个电子表格，用于找到任何具有三个实特征值的 3x3 矩阵的特征向量，方法如下。你尝试做这个是非常值得的。
- en: First find the trace determinant and second invariant (A) of the given matrix.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 首先找到给定矩阵的迹、行列式和第二不变量（A）。
- en: How?
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 如何做呢？
- en: The trace is easy, the determinant is a single command in excel.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 迹很容易，行列式是 Excel 中的一个单一命令。
- en: 'To get the second invariant in excel is also easy: extend the matrix by making
    a fourth row and column which are the same as the first ones, and make the 44
    entry the same as the 11 entry.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Excel 中获得第二个不变量也很容易：通过增加一个第四行和列，使其与第一行和列相同，并将第 44 个元素设为与第 11 个元素相同。
- en: Then find the two by two diagonal matrices in columns and rows 1, 2 in columns
    and rows 2, 3 and in columns and rows 3, 4\. The sum of these three will be A.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在第一、二列和行以及第二、三列和行，以及第三、四列和行中找到二乘二对角矩阵。这三者之和就是 A。
- en: Then solve the characteristic equation. This can be done by starting with very
    large values say +1000 and -1000 and homing in on a solution using the divide
    and conquer approach.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 然后解特征方程。这可以通过从非常大的值开始，比如 +1000 和 -1000，并使用分而治之的方法逼近解来完成。
- en: Then find the other two eigenvalues by solving the quadratic equation previously
    described.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过求解前述的二次方程找到另外两个特征值。
- en: They will not always exist, since the roots of the quadratic could be complex;
    if so change your matrix to make them real.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 它们不会总是存在，因为二次方程的根可能是复数；如果是这样，就把你的矩阵改变为使它们变为实数。
- en: It is barely possible that your matrix is not diagonalizable, in which case
    it does not have three eigenvectors, but this can only happen if two of the eigenvalues
    are the same.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎不可能你的矩阵不可对角化，除非两个特征值相同。否则它不会有三个特征向量。
- en: Now find eigenvectors.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在找到特征向量。
- en: How?
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如何做呢？
- en: 'Here is a good try: write down the matrix M - zI where z is one of your eigenvalues.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个不错的尝试：写下矩阵 M - zI，其中 z 是你的特征值之一。
- en: Extend the matrix to a fourth and fifth column by copying the first column to
    the fourth and second to fifth.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将第一列复制到第四列，将第二列复制到第五列来扩展矩阵。
- en: Then take the two by two determinants given by the first two rows and columns
    23, 34 and 45\. Arrange these as a column. This should be your eigenvector.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过由前两行和列 23、34 和 45 给出的二乘二行列式来找到它们。将这些排列成一列，这应该是你的特征向量。
- en: It could be that these two by two determinants are all 0\. If so you can try
    again with the second and third rows and you could even copy the first row to
    a fourth row and do the same for the third and fourth rows.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 可能这些二乘二行列式都是 0。如果是这样，你可以尝试用第二和第三行再次尝试，甚至可以将第一行复制到第四行，对第三和第四行做同样的事情。
- en: If you always fail that means that you had a double eigenvalue (at least two
    of your three eigenvalues are the same). Eigenvectors are actually easier to find
    in this case, when they exist.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你总是失败，那意味着你有一个双重特征值（至少你的三个特征值中有两个相同）。在这种情况下，特征向量实际上更容易找到。
- en: If all the eigenvalues are the same then M was a multiple of the identity, and
    every vector is an eigenvector.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有的特征值都相同，那么 M 是单位矩阵的倍数，每个向量都是特征向量。
- en: Otherwise you can find a column eigenvector for that eigenvalue as described,
    and find a row eigenvector by doing the same thing interchanging rows and columns.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，你可以按照描述找到该特征值的列特征向量，并通过交换行和列做同样的事情来找到一个行特征向量。
- en: Then the column eigenvectors for your double eigenvalue will be any vectors
    normal to your row eigenvector for the other eigenvalue.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你双重特征值的列特征向量将是与另一个特征值的行特征向量正交的任意向量。
- en: Once you have three column eigenvectors, you can form them into a matrix, A
    and examine A^(-1) and A^(-1)MA, which should come out to be diagonal. (These
    are very easy to find in excel using the mmult and minverse functions.)
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了三列特征向量，你可以把它们组成一个矩阵 A，并检查 A^(-1) 和 A^(-1)MA，应该是对角的。（这些在 Excel 中使用 mmult
    和 minverse 函数非常容易找到。）
- en: 32.11 Guessing Eigenvectors
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 32.11 猜测特征向量
- en: Here is a game you can set up on a spreadsheet. Enter an arbitrary matrix M
    somewhere.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个你可以在电子表格上设置的游戏。在任意地方输入一个任意的矩阵 M。
- en: Three by three is a good way to start.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 从 3x3 开始是一个很好的开始。
- en: Enter a 3 component column vector **v** and use the mmult command (or do it
    out yourself) to compute M**v** and for each component of **v** compute the ratio
    of ![](../Images/22cc4f958539c007ba1cb9778692ae92.jpg)
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 输入一个 3 分量列向量 **v**，并使用 mmult 命令（或自己计算）来计算 M**v**，对于 **v** 的每个分量，计算![](../Images/22cc4f958539c007ba1cb9778692ae92.jpg)的比率。
- en: Calculate the variance of these ratios (that is, the sum of their squares minus
    the square of their sum).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 计算这些比率的方差（即它们的平方和减去它们的平方和的平方）。
- en: The players can take turns generating the original M and **v**; then they take
    turns modifying **v** by changing **one** of its components.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家可以轮流生成原始矩阵 M 和 **v**；然后他们轮流通过改变 **v** 的**一个**分量来修改 **v**。
- en: If the variance of the ratios decreases the player scores a point, otherwise
    loses one. The game ends when the variance becomes negligible, say less than 10^(-10).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 如果比率的方差减小，玩家得分一点，否则失去一点。当方差变得可以忽略不计时，游戏结束，比如小于 10^(-10)。
- en: The ratios then will be more or less the same and hence the eigenvalue associated
    with the eigenvector produced.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这些比率将会或多或少相同，因此与特征向量相关联的特征值产生。
- en: If you get too good at this, you can try with a 5 by 5 matrix, though it is
    boring to enter one at the start.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在这方面太在行，你可以尝试用一个 5x5 的矩阵，尽管一开始输入一个矩阵会很无聊。
