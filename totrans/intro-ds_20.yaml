- en: '[Map](data_mining_map.htm) > [Data Science](data_mining.htm) > [Predicting
    the Future](predicting_the_future.htm) > [Modeling](modeling.htm) > [Classification](classification.htm)
    > Logistic Regression'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logistic regression predicts the probability of an outcome that can only have
    two values (i.e. a dichotomy). The prediction is based on the use of one or several
    predictors (numerical and categorical). A linear regression is not appropriate
    for predicting the value of a binary variable for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: A linear regression will predict values outside the acceptable range (e.g. predicting
    probabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: outside the range 0 to 1)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Since the dichotomous experiments can only have one of two possible values for
    each experiment, the residuals will not be normally distributed about the predicted
    line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, a logistic regression produces a logistic curve, which is
    limited to values between 0 and 1\. Logistic regression is similar to a linear
    regression, but the curve is constructed using the natural logarithm of the �odds�
    of the target variable, rather than the probability. Moreover, the predictors
    do not have to be normally distributed or have equal variance in each group.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b9e381daf20982692eeccdc666bcf022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the logistic regression the constant (*b[0]*) moves the curve left and right
    and the slope (*b[1]*) defines the steepness of the curve. By simple transformation,
    the logistic regression equation can be written in terms of an odds ratio.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e3401486902983be5086bf25ad3476b1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Finally, taking the natural log of both sides, we can write the equation in
    terms of log-odds (logit) which is a linear function of the predictors. The coefficient
    (*b[1]*) is the amount the logit (log-odds) changes with a one unit change in
    *x*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a01f83911f42fd5a3a02382d694d7a79.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As mentioned before, logistic regression can handle any number of numerical
    and/or categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4bb8d0e702a4115b4514eb6dd6b2867c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There are several analogies between linear regression and logistic regression.
    Just as ordinary least square regression is the method used to estimate coefficients
    for the best fit line in linear regression, logistic regression uses **[maximum
    likelihood estimation](further_readings.htm)** (MLE) to obtain the model coefficients
    that relate predictors to the target. After this initial function is estimated,
    the process is repeated until LL (Log Likelihood) does not change significantly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e451cdda30e152c7ddfc0c4ecab8d5a6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A **pseudo R²** value is also available to indicate the adequacy of the regression
    model. **Likelihood ratio test** is a test of the significance of the difference
    between the likelihood ratio for the baseline model minus the likelihood ratio
    for a reduced model. This difference is called "model chi-square�. **Wald test**
    is used to test the statistical significance of each coefficient (*b*) in the
    model (i.e., predictors contribution).  **Pseudo R²** There are several measures
    intended to mimic the R² analysis to evaluate the goodness-of-fit of logistic
    models, but they cannot be interpreted as one would interpret an R² and different
    pseudo R² can arrive at very different values. Here we discuss three pseudo R²measures.
  prefs: []
  type: TYPE_NORMAL
- en: '| Pseudo R² | Equation |  Description |'
  prefs: []
  type: TYPE_TB
- en: '| Efron''s |  ![](../Images/e90afa24f1531ddbe1feff3fd7c71a3d.jpg) | *''p''*
    is the logistic model predicted probability. The model residuals are squared,
    summed, and divided by the total variability in the dependent variable. |'
  prefs: []
  type: TYPE_TB
- en: '| McFadden''s |   ![](../Images/9280318f31b4486b33d6fe68716d3b92.jpg) | The
    ratio of the log-likelihoods suggests the level of improvement over the intercept
    model offered by the full model.  |'
  prefs: []
  type: TYPE_TB
- en: '| Count |   ![](../Images/17657667dd6b0a3a4be28fea3f7832c6.jpg) | The number
    of records correctly predicted, given a cutoff point of .5 divided by the total
    count of cases. This is equal to the [accuracy](model_evaluation.htm) of a classification
    model. |'
  prefs: []
  type: TYPE_TB
- en: '**Likelihood Ratio Test**The likelihood ratio test provides the means for comparing
    the likelihood of the data under one model (e.g., full model) against the likelihood
    of the data under another, more restricted model (e.g., intercept model). ![](../Images/709374935c784337d77cf3683e7a3028.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: where '*p'* is the logistic model predicted probability. The next step is to
    calculate the difference between these two log-likelihoods.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/882389f7f070fcfe4b4c6a9ef2e1cf05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The difference between two likelihoods is multiplied by a factor of 2 in order
    to be assessed for statistical significance using standard significance levels
    (Chi² test). The degrees of freedom for the test will equal the difference in
    the number of parameters being estimated under the models (e.g., full and intercept).   **Wald
    test**A Wald test is used to evaluate the statistical significance of each coefficient
    (*b*) in the model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be985dc422f24f54e98b4fbd498fec5e.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *W* is the Wald's statistic with a normal distribution (like Z-test),
    *b* is the coefficient and *SE* is its standard error. The *W* value is then squared,
    yielding a Wald statistic with a chi-square distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/25696dddd90a144c44196478c9a0fe4c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Predictors Contributions** The Wald test is usually used to assess the significance
    of prediction of each predictor. Another indicator of contribution of a predictor
    is *exp*(*b*) or **odds-ratio** of coefficient which is the amount the logit (log-odds)
    changes, with a one unit change in the predictor (*x*).'
  prefs: []
  type: TYPE_NORMAL
- en: '| [Exercise](logistic_regression_exercise.htm) | [![](../Images/a890baab528b0ca069f7f2599c0c5e39.jpg)](datasets/Logistic.txt)
    |  |'
  prefs: []
  type: TYPE_TB
- en: '![](../Images/dc9f5f2d562c6ce8cb7def0d0596abff.jpg) [Logistic Regression Interactive](flash/LogReg.html)'
  prefs: []
  type: TYPE_IMG
