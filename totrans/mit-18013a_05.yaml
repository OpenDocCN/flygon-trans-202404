- en: 'Chapter 4: Area of a Parallelogram, Determinants, Volume and Hypervolume, the
    Vector Product'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We consider area of a parallelogram and volume of a parallelepiped and the notion
    of determinant in two and three dimensions, whose magnitudes are these for figures
    with their column vectors as edges. We then consider the application of matrices
    to describing linear transformations on vectors, and methods for evaluating determinants.
  prefs: []
  type: TYPE_NORMAL
- en: We further discuss the notion of the inverse of a matrix and how it can be computed,
    and introduce the notions of eigenvalue and charactreristic equation, and the
    vector or cross product.
  prefs: []
  type: TYPE_NORMAL
- en: Topics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1  [Area, Volume and the Determinant in Two and Three Dimensions](section01.html)
  prefs: []
  type: TYPE_NORMAL
- en: 4.2  [Matrices and Transformations on Vectors; the Meaning of 0 Determinant](section02.html)
  prefs: []
  type: TYPE_NORMAL
- en: 4.3  [Evaluating the Determinant by Gaussian Elimination and by Row or Column
    Expansion](section03.html)
  prefs: []
  type: TYPE_NORMAL
- en: 4.4  [The Determinant and the Inverse of a Matrix](section04.html)
  prefs: []
  type: TYPE_NORMAL
- en: 4.5  [The Vector Product](section05.html)
  prefs: []
  type: TYPE_NORMAL
- en: 4.6  [Eigenvalues and the Characteristic Equation of a Matrix](section06.html)
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Area, Volume and the Determinant in Two and Three Dimensions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In two dimensional space there is a simple formula for the area of a parallelogram
    bounded by vectors **v** and **w** with **v** = (a, b) and **w** = (c, d): namely
    ![](../Images/cf06276d21fe810233f470d26f6741f6.jpg)ad - bc![](../Images/cf06276d21fe810233f470d26f6741f6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is this so?**'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. The statement that the area of a parallelogram with sides given by the vectors
    (a, b) and (c, d) is |ad - bc| is obviously true if b and c are 0, since the parallelogram
    is then a rectangle with sides |a| and |d|, whose area is |ad|.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. **Neither the area nor ![](../Images/cf06276d21fe810233f470d26f6741f6.jpg)ad
    - bc![](../Images/cf06276d21fe810233f470d26f6741f6.jpg) changes if we add a multiple
    of (a, b) to (c, d) or vice versa.** The parallelogram merely tilts, and its base
    and altitude remain the same. If we for example, add a to c, we get a change of
    ad - bc to ad - b(c + a) so of -ba; but adding b to d produces a compensating
    change of ab to it; a(b + d) - b(c + a) = ad - bc and the net change is 0.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Starting with any a, b, c and d, **by repeatedly adding multiples of one
    row to another we can force b and c to be 0,** after which we are in the case
    considered in the first paragraph and we know that the area is |ad - bc|.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Since these addings didn't change the area and didn't change |ad - bc|,
    these must have been the same from the start.
  prefs: []
  type: TYPE_NORMAL
- en: The combination **ad - bc** is called the **determinant** of the **matrix whose
    rows are (a,b) and (c,d).** It is often written as
  prefs: []
  type: TYPE_NORMAL
- en: '**![](../Images/cef3f39017b5e329971b19be3897ac7b.jpg)**'
  prefs: []
  type: TYPE_NORMAL
- en: Given **three** vectors in three dimensions we can form a 3 by 3 matrix of their
    components, and we will see that **the absolute value of the determinant of that
    matrix is the volume of the parallelepiped whose edges are determined by the three
    vectors.**
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact an analogous results holds for k k-vectors: **the absolute value of
    the determinant of the matrix of their components is the k-volume of the figure
    they bound.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**What then is the determinant of a matrix?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**In any dimension, it is defined as follows:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. A determinant is linear in the elements of any row (or column) so that
    multiplying everything in that row by z multiplies the determinant by z, and the
    determinant with row v + w is the sum of the determinants otherwise identical
    with that row being v and that row being w.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. It changes sign if two of its rows are interchanged (**an equivalent
    condition is that **it is 0 if two rows are identical).**'
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. The matrix with 1''s on the diagonal and 0''s elsewhere has determinant
    1.**'
  prefs: []
  type: TYPE_NORMAL
- en: An alternate definition of the determinant of a k by k matrix is that it is
    the "signed" and therefore linear version of volume in k dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: The determinant is generally written as det M or as | M | or sometimes || M
    ||.
  prefs: []
  type: TYPE_NORMAL
- en: If **v** and **w** are two rows of the matrix M we can deduce from the first
    two conditions that adding a multiple of **v** to **w** does not change the determinant
    of M.
  prefs: []
  type: TYPE_NORMAL
- en: The **volume of a parallelepiped** bounded by edges whose directions and lengths
    are that of **u, v** and **w** is almost linear in **u, v** and **w;** it differs
    from linearity only in that it is always positive, like length in one dimension
    is.
  prefs: []
  type: TYPE_NORMAL
- en: This volume is 1 if the vectors have unit length and are mutually perpendicular,
    and does not change if one side is added to another; (that just tilts the parallelepiped
    without changing its volume.) The absolute value of the determinant of the matrix
    formed by the components of the three vectors obeys exactly the same conditions
    and is therefore the same thing.
  prefs: []
  type: TYPE_NORMAL
- en: '**In higher dimensions the analog of volume is called hyper-volume and the
    same conclusion can be drawn by the same argument: the hyper-volume of the parallel
    sided region determined by k vectors in k dimensions is the absolute value of
    the determinant whose entries are their components in the directions of the (orthonormal)
    basis vectors.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**In fact, the determinant can be considered a linear and signed version of
    hyper-volume.**'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the hyper-volume of a parallel-sided region with sides xA, B, C, ...,
    as a function of the variable x. It is linear in x for positive or negative x,
    but it is always positive, and its graph looks like a V, taking the value 0 for
    x = 0.
  prefs: []
  type: TYPE_NORMAL
- en: The determinant is the same as the hyper-volume for positive or negative x and
    minus the hyper-volume for the other, and is linear as a function of x. Its **sign**
    is determined by the convention that it is positive for the **"identity matrix"**
    which has **1's on the main diagonal and 0's elsewhere. This identity matrix is
    usually written as I.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.0 Prove the statement above: the condition on the determinant that it change
    sign if two rows are interchanged is equivalent to the alternative condition that
    the determinant is 0 if two rows are identical (given its linearity in rows).**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.1 Suppose A, B and C are three vectors in the plane. Consider three triangles
    with sides A and B, A and C, and A and B + C, respectively. What relation holds
    between their areas? (If you don''t see it, try some simple examples and generalize.
    The relation sought here is an either or statement.) What is the analogous statement
    about the determinants whose rows are the components of the given vectors (A and
    B), (A and C) and (A and B + C)?**'
  prefs: []
  type: TYPE_NORMAL
- en: In the following applet you can enter three 3-vectors, see them and the parallelepiped
    they define, and the value of the determinant whose absolute value is its volume.
    We will soon see how to compute the determinant. Also shown are the vector (or
    cross) products of pairs of these vectors which will be defined in [**section
    4.5**](section05.html).
  prefs: []
  type: TYPE_NORMAL
- en: <applet code="DeterminantVectorProducts" codebase="../applets/" archive="determinantVectorProducts.jar,go.jar,goText.jar,mk_lib.jar,parser_math.jar,jcbwt363.jar"
    width="760" height="450"></applet>
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Matrices and Transformations on Vectors; the Meaning of 0 Determinant
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Matrices and determinants appear in two other important contexts; one is in
    solving simultaneous linear equations in several variables. The other is in representing
    linear transformations of vectors. The first of these is discussed in detail in
    [Chapter 32](../chapter32/contents.html).
  prefs: []
  type: TYPE_NORMAL
- en: In the latter context **a matrix represents the transformation that takes the
    column basis vectors into the vectors that are the corresponding columns of the
    matrix.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Sums of original basis vectors are transformed into the same sums of the
    corresponding columns.** This fact defines the transformation on all vectors.'
  prefs: []
  type: TYPE_NORMAL
- en: '**When the determinant of a matrix is zero, the volume of the region with sides
    given by its columns or rows is zero,** which means the matrix considered as a
    transformation takes the basis vectors into vectors that are linearly dependent
    and define 0 volume.'
  prefs: []
  type: TYPE_NORMAL
- en: This happens, **the determinant is zero, when the columns (and rows) of the
    matrix are linearly dependent.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.2 What is the matrix of the transformation which takes a unit vector in
    the direction of the x axis into one in the direction of the y axis, and similarly
    one along the y axis into one along the z axis, and one along the z axis into
    one along the x axis?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.3 What matrix describes the transformation which doubles the component
    of vectors in the x direction, halves components in the y direction, and leaves
    components in the z direction alone.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.4 What matrix describes the transformation in three dimensions which projects
    vectors into the (x, y) plane? onto the x axis? onto the diagonal in the (x, y)
    plane?**'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Evaluating the Determinant by Gaussian Elimination and by Row or Column
    Expansion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section is extremely sketchy. For further discussion see [Chapter 32](../chapter32/contents.html).
  prefs: []
  type: TYPE_NORMAL
- en: '**Evaluating a Determinant by Gaussian elimination:** to do this you add multiples
    of one row to another until all entries below the main diagonal are 0\. The determinant
    (which is unchanged by these actions) is then the product of the diagonal entries.
    Machines can do such things for n by n matrices with n in the hundreds or thousands,
    but people find the exercise a bit dull.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Expansion of a determinant �in a row or column:** let the matrix M have elements
    m[ij]. The first index describes the row number, the second the column number.'
  prefs: []
  type: TYPE_NORMAL
- en: M's determinant is a sum of the elements of any single row each multiplied by
    a factor. What factor?
  prefs: []
  type: TYPE_NORMAL
- en: For the j-th element of the i-th row it is the determinant of the matrix obtained
    by removing that row and column, multiplied by a sign factor of -1 to the sum
    of the indices of the element, i + j
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be3089eddd9c5ea6ae884f5f056e6676.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where **M[ij] is the determinant of the matrix obtained from M by eliminating
    its i-th row and j-th column and closing the rest up into a square array.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is this so?**'
  prefs: []
  type: TYPE_NORMAL
- en: The factor multiplying m[ij] must be linear in the other rows and be 0 if two
    of them are identical, so it must be proportional to their determinant, M[ij].
    (Also since the determinant is linear in the j-th column this term can have no
    factor other than m[ij] from that column.)
  prefs: []
  type: TYPE_NORMAL
- en: '**The only question left, then, is: why the sign factor?**'
  prefs: []
  type: TYPE_NORMAL
- en: You can interchange two rows or columns of a matrix which have the same parity
    (which means that both have even indices or both odd indices) with an even number
    of single row or column interchanges, while you need an odd number of interchanges
    when they have opposite parity, Each interchange requires a sign change, so there
    must be a sign change if the parity of the row and column indices are different,
    to make the computation for different indices consistent.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we also have
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c811716e17b4d6f033dcaf54c387998b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: since by equation (A) this is the determinant of a matrix with two of its rows,
    the i-th and the k-th, equal to the k-th row of M, and a matrix with two identical
    rows has 0 determinant.
  prefs: []
  type: TYPE_NORMAL
- en: The formula (A) is called the expansion of det M in the i-th row. The same thing
    can be done for a column, and even for several rows or columns together.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expression (-1)^(i + j)M[ij] is called the ij-th **cofactor** of the matrix
    M. The statement (A) can then be phrased as: **the dot product of any row of M
    with the vector of cofactors of the entries in that row is the determinant of
    M.** The same statement holds with the word "row" replaced by "column".'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.5\. Evaluate the determinant of the matrix whose rows are, in order, (1,
    2, 5), (3, 1, -2) and (4, -2, 7) be each of the methods described above. Which
    do you find faster?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.6\. Do the same for a random but non-trivial 4 by 4 matrix. Which is faster?**'
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 The Determinant and the Inverse of a Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The inverse of a square matrix M is a matrix, denoted as M^(-1), with the property
    that M^(-1) M = M M^(-1) = I. Here I is the identity matrix of the same size as
    M, having 1's on the diagonal and 0's elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of transformations, M^(-1) undoes the transformation produced by M
    and so the combination M^(-1)M represents the transformation that changes nothing.
  prefs: []
  type: TYPE_NORMAL
- en: The condition MM^(-1) = I can be written as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cb03041f06ea0e80e78211e11037c6b7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/261875dfed402c9a8ad04c3f486e5a9b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: when k and i are different, and these conditions completely determine the matrix
    M^(-1) given M, when M has an inverse.
  prefs: []
  type: TYPE_NORMAL
- en: These equations have the same form as the two conditions [(A)](section03.html)
    and [(B)](section03.html) of section 4.3 except that det M is on the left-hand
    side in (A) instead of 1, and (-1)^(i + j)M[ij] appears in (A) and (B) instead
    of M^(-1)[ji] here.
  prefs: []
  type: TYPE_NORMAL
- en: We can therefore divide both sides of (A) and (B) by det M, and deduce
  prefs: []
  type: TYPE_NORMAL
- en: '**![](../Images/a81604aae92b22fb4cac4004489bc59a.jpg)**'
  prefs: []
  type: TYPE_NORMAL
- en: Remember that here M[ij] is the determinant of the matrix obtained by omitting
    the i-th row and j-th column of M; the elements of M are the m[ij], while M^(-1)[ji]
    here represents the element of the inverse matrix to M in j-th row and i-th column.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can phrase this in words as: **the inverse of a matrix M is the matrix of
    its cofactors, with rows and columns interchanged, divided by its determinant.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.7 Compute the inverse of the matrix in** [Exercise 4.4](section02.html#Exercise_4_4)
    **using this formula. Check the product M^(-1)M to be sure your result is correct.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.8 Set up a spreadsheet that computes the inverse of any three by three
    matrix with non-zero determinant, using this formula.'
  prefs: []
  type: TYPE_NORMAL
- en: '(Hint: by copying the first two rows into a fourth and fifth row and the first
    two columns into a fourth and fifth column, you can make one entry and copy to
    get all of the (-1)^(i + j)M[ij] at once. Then all that is left is rearranging
    to swap indices and dividing by the determinant (which is the dot product of any
    row of M with the corresponding cofactors).)**'
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 The Vector Product
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **vector product** of two 3-vectors, **v** and **w**, written as **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w**
    is the determinant of the 3 by 3 matrix whose first� two columns are the components
    of **v** and **w** and whose third column consists of the basis vectors **i, j**
    and **k**.
  prefs: []
  type: TYPE_NORMAL
- en: This definition appears somewhat mysterious. But all that it means is that **its
    components** in the direction of the various axes are **the cofactors** of **i,
    j,** and **k** here. These are determinants of ordinary two by two matrices.
  prefs: []
  type: TYPE_NORMAL
- en: '**v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w** is a vector NOT a
    number, and is sometimes called the **"cross product"** of **v** and **w**.'
  prefs: []
  type: TYPE_NORMAL
- en: From this definition we can see that the dot product of **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w**
    with another vector, **u**, is the determinant of the matrix whose columns (or
    rows) are the components of these three vectors, in the order **v, w, u,** which
    makes its magnitude the volume of the parallelepiped determined by these vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Explicitly, the x component of the cross product ![](../Images/2060b7325b050b7b3582bb08b8499f48.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: Its other components can be obtained by cyclically shifting among the variables
    x, y and z changing x to y, y to z and z to x.
  prefs: []
  type: TYPE_NORMAL
- en: The **vector product** is, from the properties of determinants, **linear in
    both its vector factors.** Thus if you multiply **v** by 10, **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w**
    gets multiplied by 10, and you also have
  prefs: []
  type: TYPE_NORMAL
- en: '**(v + z)![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w = v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w
    + z![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w**'
  prefs: []
  type: TYPE_NORMAL
- en: Also, **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w changes sign if
    the order of its factors is reversed:** **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w**
    = - **w![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)v**. These statements
    follow from similar properties of determinants.
  prefs: []
  type: TYPE_NORMAL
- en: '**The magnitude of v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w is
    the area of the parallelogram defined by its factors, that is**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c06505fdc42b3e863f1cfd8edc0d9ab.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w** is perpendicular
    to both its arguments: **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w![](../Images/071f52d9568eed49a669a89edb7a4579.jpg)v**
    = **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w![](../Images/071f52d9568eed49a669a89edb7a4579.jpg)w**
    = 0\. This follows from the statement that the determinant of a matrix with two
    identical columns, which is what either of these expressions is, is 0.'
  prefs: []
  type: TYPE_NORMAL
- en: We can deduce **(v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w)![](../Images/071f52d9568eed49a669a89edb7a4579.jpg)
    (v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w) = (v![](../Images/071f52d9568eed49a669a89edb7a4579.jpg)v)(w![](../Images/071f52d9568eed49a669a89edb7a4579.jpg)w)
    - (v![](../Images/071f52d9568eed49a669a89edb7a4579.jpg)w)(w![](../Images/071f52d9568eed49a669a89edb7a4579.jpg)v),**
    since both sides here represent the **square** of the area of the parallelogram
    with sides **v** and **w** (see [Exercise 3.2](../chapter03/section03.html#Exercise_3_2)).
  prefs: []
  type: TYPE_NORMAL
- en: Human beings make numerical errors in evaluating 3 by 3 determinants or vector
    products roughly one out of every four times they do them, even more so when the
    vectors components or matrix entries have lots of negative values. It is wise
    to build a determinant and vector product tool on a spreadsheet and use it to
    check **not replace** your own computations. You will then get the right answer
    every time.
  prefs: []
  type: TYPE_NORMAL
- en: It is actually easier to build such a tool than to do even one cross product
    by hand. It's just about as easy as doing a dot product. To do it, enter **v**
    and **w** as two parallel rows, say with v[x] in A2, v[y] in B2, v[z] in C2 and
    the components of **w** similarly in A3-C3\. In D2 put =A2 and copy that into
    D3, E2 and E3\. (You are now half done.) Next, in A4 put =B2*C3-C2*B3, and copy
    that into B4 and C4\. That's it! Row 4 contains the cross product, **v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w**
    of **v** with **w.** You can check by verifying that its dot product with either
    of the first two rows is 0.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that you can now change **v** and **w** and (with luck) row four will
    then contain the cross product of the new rows 2 and 3.
  prefs: []
  type: TYPE_NORMAL
- en: You can see what vector products look like from the [applet in section 4.1](section01.html#DeterminantVectorProducts).
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.9 Write out the vector product v![](../Images/f2074d3db9f79425fe458e2cc3cd8563.jpg)w
    explicitly in terms of the components of its factors.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.10 Compute the vector product of the two vectors (1, 2, 3) and (4, 5, 6).**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.11 Build a vector product tool as indicated above.**'
  prefs: []
  type: TYPE_NORMAL
- en: 4.6 Eigenvalues and the Characteristic Equation of a Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**A vector which satisfies Mv = xv for some number x is called an eigenvector
    of the matrix M and x is called the eigenvalue of M corresponding to v. (v is
    called an eigenvector corresponding to x.)**'
  prefs: []
  type: TYPE_NORMAL
- en: The condition M**v** = x**v** can be rewritten as (M - xI)**v** = **0**. This
    equation says that the matrix (M - xI) takes **v** into the **0** vector, which
    implies that (M - xI) cannot have an inverse so that its determinant must be 0.
  prefs: []
  type: TYPE_NORMAL
- en: The equation **det (M - xI) = 0** is a polynomial equation in the variable x
    for given M. It is called **the characteristic equation** of the matrix M. You
    can solve it to find the eigenvalues x, of M.
  prefs: []
  type: TYPE_NORMAL
- en: The **trace** of a square matrix M, **written as Tr(M),** is **the sum of its
    diagonal elements.**
  prefs: []
  type: TYPE_NORMAL
- en: The characteristic equation of a 2 by 2 matrix M takes the form
  prefs: []
  type: TYPE_NORMAL
- en: x² - xTr(M) + det M = 0
  prefs: []
  type: TYPE_NORMAL
- en: Once you know an eigenvalue x of M, there is an easy way to find a column eigenvector
    corresponding to x (which works when x is not a multiple root of the characteristic
    equation). We will describe it for 3 by 3 matrices, but it can be generalized
    to apply to any size square matrices. To do so, **take the cross product of any
    two distinct rows of (M - xI).**
  prefs: []
  type: TYPE_NORMAL
- en: If it is not the **0** vector, it is a column eigenvector!
  prefs: []
  type: TYPE_NORMAL
- en: '**Why does this work?**'
  prefs: []
  type: TYPE_NORMAL
- en: The condition that **v** is a column eigenvector of M is the condition that
    (M - xI)**v** = **0**.
  prefs: []
  type: TYPE_NORMAL
- en: The components of (M - xI)**v** are the dot products of the rows of (M - xI)
    with **v**.
  prefs: []
  type: TYPE_NORMAL
- en: If **v** is the vector product of two rows of (M - xI) it certainly has dot
    product 0 with those two rows.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, its dot product with the other row of (M - xI) is the determinant
    of (M - xI), which is also 0.
  prefs: []
  type: TYPE_NORMAL
- en: We can deduce then that the vector product of any two rows of (M - xI) has 0
    dot product with every row of (M - xI), which is the condition that **v** is an
    eigenvector of M corresponding to eigenvalue x.
  prefs: []
  type: TYPE_NORMAL
- en: What can go wrong? Well, the vector product could be **0**. This will happen
    if one of the rows is a multiple of the other. If it happens for two different
    row pairs, this means all the rows are multiples of each other, which means every
    vector perpendicular to any row that is not all zeroes, is an eigenvector.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.12 Write the characteristic equation for the matrix with rows (1, 2) and
    (3, 4).**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.13 Do the same for the matrix with rows (1, 2, 5), (3, 1, -3) and (4, -2,
    -8).**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.14 Find an eigenvalue of this matrix. (Hint: there is one that is a pretty
    simple number.)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**4.15 Find a column eigenvector corresponding to it.**'
  prefs: []
  type: TYPE_NORMAL
