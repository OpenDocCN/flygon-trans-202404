- en: Primary/Backup Replication
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主/备份复制
- en: '6.824 2015 Lecture 3: Primary/Backup Replication'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6.824 2015年第3讲：主/备份复制
- en: '**Note:** These lecture notes were slightly modified from the ones posted on
    the 6.824 [course website](http://nil.csail.mit.edu/6.824/2015/schedule.html)
    from Spring 2015.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：**这些讲座笔记略有修改自2015年春季6.824 [课程网站](http://nil.csail.mit.edu/6.824/2015/schedule.html)上发布的内容。'
- en: Today
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 今天
- en: Replication
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制
- en: '[Remus](papers/remus.pdf) case study'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Remus](papers/remus.pdf)案例研究'
- en: Lab 2 introduction
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验2介绍
- en: Fault tolerance
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容错
- en: We'd like a service that continues despite failures!
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望一个服务能够在发生故障时继续运行！
- en: '**Definitions:**'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义：**'
- en: '*Available* -- still usable despite [some class of] failures'
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可用* -- 尽管[某些类别的]故障仍可使用'
- en: '*Correct* -- act just like a single server to clients'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*正确* -- 对客户端的行为就像单个服务器'
- en: A lot of issues that come up have to do with *correctness*
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出现的许多问题与*正确性*有关
- en: Very hard!
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常困难！
- en: Very useful!
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常有用！
- en: 'Need a failure model: what will we try to cope with?'
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 需要一个故障模型：我们将尝试应对什么？
- en: '*Most common:* Independent fail-stop computer failures'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最常见：*独立的故障停止计算机故障'
- en: '*fail-stop failures:* computed correctly for a while and then stopped'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*故障停止故障：*一段时间内计算正确，然后停止'
- en: as opposed to computing incorrectly (different situation)
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与计算不正确（不同情况）相反
- en: have to assume independence of failures
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须假设故障独立
- en: (o.w. we could have primary fail `=>` backup fail `=>` fffffuu....)
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: （否则我们可能会有主节点故障`=>`备份故障`=>` fffffuu....）
- en: Remus further assumes only one failure at a time
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Remus进一步假设一次只有一个故障
- en: '*Another model:* Site-wide power failure (and eventual reboot)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*另一个模型：*站点范围内的停电（以及最终重启）'
- en: (Network partition)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （网络分区）
- en: No bugs, no malice
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有错误，没有恶意
- en: 'Core idea: replication'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核心思想：复制
- en: '*Two* servers (or more)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*两个*服务器（或更多）'
- en: Each replica keeps state needed for the service
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个副本保留所需的服务状态
- en: If one replica fails, others can continue
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个副本失败，其他副本可以继续
- en: 'Example: fault-tolerant MapReduce master'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 例如：容错MapReduce主节点
- en: Lab 1 workers are already fault-tolerant, but not master
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验室1的工作节点已经具有容错能力，但主节点没有
- en: '`[Diagram: M1, M2, workers]`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[图表：M1，M2，工作节点]`'
- en: 'State:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 状态：
- en: worker list
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作节点列表
- en: which jobs done
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些工作已完成
- en: which workers idle
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些工作节点空闲
- en: TCP connection state
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP连接状态
- en: program counter
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序计数器
- en: Big questions
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重要问题
- en: What *state* to replicate?
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要复制什么*状态*？
- en: '*Example:* Remus replicates all of RAM and the CPU state'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*例子：*Remus复制所有RAM和CPU状态'
- en: How does replica get state?
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 副本如何获取状态？
- en: When to *cut over* to backup?
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时切换到备份？
- en: Is primary really down or is just the network down?
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主节点真的宕机了还是只是网络宕机了？
- en: Are anomalies visible at cut-over?
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 切换时是否可见异常？
- en: What will clients see?
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端会看到什么？
- en: How to repair / re-integrate?
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何修复/重新集成？
- en: How to get a new backup?
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何获得新的备份？
- en: 'Two main approaches:'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 两种主要方法：
- en: '**State transfer**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**状态转移**'
- en: '"Primary" replica executes the service'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: “主”副本执行服务
- en: Primary sends [new] state to backups
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主节点向备份发送[新]状态
- en: '*Example:* Remus'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*例子：*Remus'
- en: '**Replicated state machine**'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**复制状态机**'
- en: All replicas (primary and backup) execute all operations
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有副本（主节点和备份）执行所有操作
- en: If same start state & same operations & same order & deterministic & *then*
    `=>` same end state
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果相同的起始状态和相同的操作和相同的顺序和确定性和*然后* `=>` 相同的结束状态
- en: '*Ops* are transferred and not the state'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*操作*被转移而不是状态'
- en: '*State transfer* is simpler'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*状态转移*更简单'
- en: But state may be large, slow to transfer
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但状态可能很大，传输速度慢
- en: '*Remus* uses state transfer'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Remus*使用状态转移'
- en: '*Replicated state machine* can be more efficient'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*复���状态机*可能更有效'
- en: If operations are small compared to data
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果操作相对于数据很小
- en: But complex, e.g. order on multi-core, determinism
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但复杂，例如多核上的顺序，确定性
- en: Hard to make sure everyone got to the same state
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很难确保每个人都达到相同的状态
- en: Determinism can be problematic (time, threads, etc.)
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定性可能会有问题（时间，线程等）
- en: Labs use replicated state machines
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验使用复制状态机
- en: 'Remus: High Availability via Asynchronous Virtual Machine Replication, NSDI
    2008'
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Remus：通过异步虚拟机复制实现高可用性，NSDI 2008
- en: Very ambitious system
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非常雄心勃勃的系统
- en: Whole-system replication
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整个系统复制
- en: Completely *transparent* to applications and clients
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对应用程序和客户端完全*透明*
- en: High availability for any existing software
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何现有软件的高可用性
- en: Would be magic if it worked well!
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果运行良好将是奇迹！
- en: '*Failure model:*'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*故障模型：*'
- en: Independent hardware faults
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 独立的硬件故障
- en: Site-wide power failure
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 站点范围内的停电
- en: 'Plan 1 (slow, broken):'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计划1（缓慢，破碎）：
- en: '`[Diagram: app, O/S, Remus underneath]`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[图表：应用程序，操作系统，Remus底层]`'
- en: two machines, *primary* and *backup*; plus net and other machines
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两台机器，*主节点*和*备份*；加上网络和其他机器
- en: primary runs o/s and application s/w, talks to clients, etc.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: backup does *not* initially execute o/s, applications, etc.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: it only executes some Remus code
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a few times per second:'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pause primary
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: copy **entire RAM**, registers, disk to backup
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 10Gbps = 1GB/s network bandwidth
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 100MB/s disk bandwidth
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: network bandwidth limits RAM transfer rate
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: disk bandwidth limits disk transfer rate
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: resume primary
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'if primary fails:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: start backup executing!
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Q:** Is Plan 1 correct (as described above)?'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: i.e. does it look just like a single reliable server?
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'No:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: client sends write req. to primary, primary replies before backup had a chance
    to copy the new state
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: primary fails, backup takes over, but it does not reflect the last write req.
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: client will be screwed because his write was lost
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Q:** What will outside world see if primary fails and replica takes over?'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Will backup have same state as last visible on primary?
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Might a client request be lost? Executed twice?
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yes: see above question'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Q:** How to decide if primary has failed?'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '**Q:** How will clients know to talk to backup rather than primary?'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '**Q:** What if site-wide power failure?'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Primary is running some o/s, has a plan for reboot from disk "crash-consistent"
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Q:** What if primary fails while sending state to backup?'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: i.e. backup is mid-way through absorbing new state?
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Q:** What if primary gets request, sends checkpoint to backup, and just before
    replying primary fails?'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: TCP layer will take care of this? If client retransmits request, that could
    be problematic (side effects). So hopefully TCP kicks in and notices that no reply
    came back. How? Primary was just about to reply, but Remus held the reply in the
    buffer. Backup will have same state so it'll think it has replied and wait for
    an ACK from the client, which will never come because the client got nothing.
    Thus, backup will retransmit the packets that the primary never had a chance to
    and finally get the ACK from the client.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Q:** Is Plan 1 efficient?'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Can we eliminate the fact that backup *state* trails the primary?
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seems very hard!
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Primary would have to tell backup (and wait) on every instruction.
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we *conceal* the fact that backup's state lags primary?
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prevent outside world from *seeing* that backup is behind last primary state
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: e.g. prevent primary sent RPC reply but backup state doesn't reflect that RPC
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: e.g. MapReduce `Register()` RPC, which it would be bad for backup to forget
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Idea:* primary "holds" output until backup state catches up to output point'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: e.g. primary receives RPC request, processes it, creates reply packet, but Remus
    holds reply packet until backup has received corresponding state update
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Remus epochs, checkpoints
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Primary runs for a while in Epoch 1 (E1), holding E1's output
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Primary pauses
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Primary copies RAM+disk changes from E1 to local buffer
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Primary resumes execution in E2, holding E2's output
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Primary sends checkpoint of RAM+disk to backup
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Backup copies all to separate RAM, then applies, then ACKs
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Primary releases E1's output
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Backup applies E1's changes to RAM and disk
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 备份服务器将 E1 的更改应用于 RAM 和磁盘
- en: If primary fails, backup finishes applying last epoch's disk+RAM, then starts
    executing
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主服务器失败，备份服务器完成应用上一个时期的磁盘+内存，然后开始执行
- en: '**Q:** Any externally visible anomalies?'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 有任何外部可见的异常吗？'
- en: '**Q:** What if primary receives + executes a request, crashes before checkpoint?
    backup won''t have seen request!'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 如果主服务器接收并执行一个请求，然后在检查点之前崩溃了？备份服务器将不会看到请求！'
- en: 'That''s fine as long as primary did not reply to that request: client will
    just send request again'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要主服务器没有回复该请求，这没问题：客户端将重新发送请求
- en: '**Q:** If primary sends a packet, then crashes, is backup guaranteed to have
    state changes implied by that packet?'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 如果主服务器发送了一个数据包，然后崩溃了，备份服务器是否保证具有该数据包暗示的状态更改？'
- en: Yes. That's the whole point of keeping the sent network packets buffered until
    the backup is up to date.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是的。这就是将发送的网络数据包缓冲直到备份服务器更新的全部意义。
- en: '**Q:** What if primary crashes partway through release of output? must backup
    re-send? How does it know what to re-send?'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 如果主服务器在释放输出的过程中部分崩溃了？备份服务器必须重新发送吗？它如何知道重新发送什么？'
- en: '**Q:** How does Remus decide it should switch to backup?'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** Remus 如何决定应切换到备份？'
- en: 'Naive mechanism: If the primary stops talking to the backup, then something
    went wrong.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天真的机制：如果主服务器停止与备份服务器通信，则出现了问题。
- en: '**Q:** Are there situations in which Remus will incorrectly activate the backup?
    i.e. primary is actually alive'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 是否存在 Remus 会错误激活备份的情况？即主服务器实际上是活着的'
- en: Network partition...
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络分区...
- en: '**Q:** When primary recovers, how does Remus restore replication? Needed, since
    eventually active ex-backup will itself fail'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 主服务器恢复后，Remus 如何恢复复制？这是必要的，因为最终活动的前备份服务器本身也将失败'
- en: '**Q:** What if *both* fail, e.g. site-wide power failure?'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 如果 *两个* 都失败了，例如整个站点的停电？'
- en: RAM content will be lost, but disks will probably survive
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAM 内容将丢失，但磁盘可能会幸存
- en: After power is restored, reboot guest from one of the disks
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复电源后，从其中一个磁盘重新启动客户机
- en: O/S and application recovery code will execute
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统和应用程序恢复代码将执行
- en: disk must be "crash-consistent"
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 磁盘必须是“崩溃一致”的
- en: So probably not the backup disk if was in middle of installing checkpoint
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果正在安装检查点，则可能不是备份服务器的磁盘
- en: disk shouldn't reflect any held outputs (... why not?)
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 磁盘不应反映任何保持的输出（...为什么不呢？）
- en: So probably not the primary's disk if was executing
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果正在执行，则可能不是主服务器的磁盘
- en: I do not understand this part of the paper (Section 2.5)
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我不理解论文的这部分（第 2.5 节）
- en: Seems to be a window during which neither disk could be used if power failed
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 似乎有一个窗口，在此期间如果断电，则两个磁盘都不能使用
- en: primary writes its disk during epoch
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主服务器在时期期间写入其磁盘
- en: meanwhile backup applies last epoch's writes to its disk
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与此同时，备份服务器将上一个时期的写入应用到其磁盘上
- en: '**Q:** In what situations will Remus likely have good performance?'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 在哪些情况下 Remus 可能会有良好的性能？'
- en: '**Q:** In what situations will Remus likely have low performance?'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 在哪些情况下 Remus 可能会有低性能？'
- en: '**Q:** Should epochs be short or long?'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 时期应该是短的还是长的？'
- en: Remus evaluation
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Remus 评估
- en: '*Summary:* 1/2 to 1/4 native speed'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*摘要：* 原生速度的 1/2 到 1/4'
- en: Checkpoints are big and take time to send
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查点很大且需要时间发送
- en: Output hold limits speed at which clients can interact
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出保持限制了客户端交互的速度
- en: Why so slow?
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么这么慢？
- en: Checkpoints are big and take time to generate and send
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查点很大且需要时间生成和发送
- en: 100ms for SPECweb2005 -- because many pages written
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 100ms 用于 SPECweb2005 -- 因为有很多页面需要编写
- en: So inter-checkpoint intervals must be long
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，检查点间隔必须很长
- en: So output must be held for quite a while
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，输出必须保持相当长的时间
- en: So client interactions are slow
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此客户端交互速度慢
- en: Only 10 RPCs per second per client
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个客户端每秒只有 10 个远程过程调用
- en: How could one get better performance for replication?
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何提高复制性能？
- en: 'Big savings possible with application-specific schemes:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用特定于应用程序的方案可能会节省大量资源：
- en: just send state really needed by application, not all state
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只发送应用程序实际需要的状态，而不是全部状态
- en: send state in optimized format, not whole pages
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以优化的格式发送状态，而不是整个页面
- en: send operations if they are smaller than state
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果操作比状态小，则发送操作
- en: likely *not* transparent to applications
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能 *不* 对应用程序透明
- en: and probably not to clients either
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 也可能不是对客户端的
- en: Primary-backup replication in Lab 2
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验室 2 中的主-备份复制
- en: Outline
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概述
- en: simple key/value database
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的键/值数据库
- en: primary and backup
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主服务器和备份服务器
- en: '*replicated state machine:* replicate by primary sending each operation to
    backups'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*复制状态机：* 主服务器将每个操作发送到备份服务器进行复制'
- en: tolerate network problems, including partition
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容忍网络问题，包括分区
- en: either keep going, correctly
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要么继续运行，正确执行
- en: or suspend operations until network is repaired
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者暂停操作直到网络修复
- en: allow replacement of failed servers
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许替换失败的服务器
- en: you implement essentially all of this (unlike lab 1)
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你实际上要实现所有这些（不像实验1）
- en: '*"View server"* decides who primary `p` and backup `b` are'
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*"视图服务器"* 决定谁是主服务器 `p` 和备份 `b`'
- en: '*Main goal:* avoid "split brain" -- disagreement about who primary is'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主要目标：* 避免"分裂大脑"——关于谁是主服务器的分歧'
- en: Clients and servers ask view server
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端和服务器询问视图服务器
- en: They don't make independent decisions
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们不会做出独立的决定
- en: Repair
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修复
- en: view server can co-opt "idle" server as `b` after old `b` becomes `p`
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视图服务器可以在旧的备份成为主服务器后将"空闲"服务器作为 `b`
- en: primary initializes new backup's state
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主服务器初始化新备份的状态
- en: 'Key points:'
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键点：
- en: Only one primary at a time!
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一次只能有一个主服务器！
- en: The primary must have the latest state!
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主服务器必须拥有最新的状态！
- en: We will work out some rules to ensure these
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将制定一些规则来确保这些
- en: View server
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 视图服务器
- en: Maintains a sequence of "views"
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护一系列"视图"
- en: 'Example:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 例子：
- en: '[PRE0]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Monitors server liveness
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控服务器的存活状态
- en: each server periodically sends a ping RPC (more like a heartbeat)
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个服务器定期发送ping RPC（更像是心跳）
- en: '*"dead"* if missed `N` pings in a row'
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*"死亡"* 如果连续错过 `N` 次ping'
- en: '*"live"* after single ping'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*"活着"* 经过单次ping后'
- en: Can be more than two servers pinging view server
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以有两个以上的服务器对视图服务器进行ping
- en: if more than two, *"idle"* servers
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有两个以上的*"空闲"*服务器
- en: 'If primary is dead:'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果主服务器死了：
- en: new view with previous backup as primary
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新视图中之前的备份作为主服务器
- en: If backup is dead, or no backup
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果备份死了，或者没有备份
- en: new view with previously idle server as backup
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新视图中之前的空闲服务器作为备份
- en: OK to have a view with just a primary, and no backup
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有一个主服务器，没有备份也可以
- en: But -- if an idle server is available, make it the backup
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但是——如果有空闲服务器可用，让其成为备份
- en: How to ensure new primary has up-to-date replica of state?
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何确保新主服务器拥有最新的状态副本？
- en: Only promote previous backup
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只提升之前的备份
- en: i.e. don't make an idle server the primary
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即不要让空闲服务器成为主服务器
- en: Backup must remember if it has been initialized by primary
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份必须记住是否已被主服务器初始化
- en: If not, don't function as primary even if promoted!
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有，即使被提升也不要作为主服务器运行！
- en: '**Q:** Can more than one server think it is primary?'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 是否可能有多个服务器认为自己是主服务器？'
- en: '[PRE1]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How to ensure only one server acts as primary?
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何确保只有一个服务器充当主服务器？
- en: '...even though more than one may *think* it is primary.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '...即使有多个可能*认为*自己是主服务器。'
- en: '*"Acts as"* `==` executes and responds to client requests'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '*"Acts as"* `==` 执行并响应客户端请求'
- en: '*The basic idea:*'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*基本思想：*'
- en: '[PRE2]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The rules:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 规则：
- en: Primary in view `i` must have been primary or backup in view `i-1`
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视图 `i` 中的主服务器必须在视图 `i-1` 中是主服务器或备份
- en: Primary must wait for backup to accept each request
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主服务器必须等待备份接受每个请求
- en: '**Q:** What if there''s no backup or the backup doesn''t know it''s a backup?'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Q:** 如果没有备份或备份不知道自己是备份怎么办？'
- en: '**A:** Primary can''t make progress without a backup if it''s part of the view,
    so it just waits'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A:** 如果主服务器是视图的一部分但没有备份，那么主服务器无法取得进展，因此只能等待'
- en: '**A:** If the view is updated and the backup is taken out of the view then
    primary can operate in "dangerous mode" without a backup'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A:** 如果视图已更新并且备份被移出视图，则主服务器可以在没有备份的情况下以"危险模式"运行'
- en: Non-backup must reject forwarded requests
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非备份必须拒绝转发的请求
- en: Non-primary must reject direct client requests
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非主服务器必须拒绝直接的客户端请求
- en: Every operation must be before or after state transfer
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个操作必须在状态转移之前或之后
- en: 'Example:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 例子：
- en: '[PRE3]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How can new backup get state?
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新备份如何获取状态？
- en: e.g. all the keys and values
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如所有的键和值
- en: if S2 is backup in view `i`, but was not in view `i-1`,
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 S2 是视图 `i` 中的备份，但不在视图 `i-1` 中，
- en: S2 should ask primary to transfer the complete state
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: S2 应该要求主服务器传输完整的状态
- en: 'Rule for state transfer:'
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 状态转移规则：
- en: every operation (`Put/Get/Append`) must be either before or after state xfer
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个操作（`Put/Get/Append`）必须在状态转移之前或之后
- en: '`==` state xfer must be atomic w.r.t. operations'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`==` 状态转移必须对操作是原子的'
- en: either
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者
- en: op is before, and xferred state reflects op
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作在之前，状态转移后反映操作
- en: op is after, xferred state doesn't reflect op, primary forwards op after state
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作在之后，状态转移不反映操作，主服务器在状��后转发操作
- en: '**Q:** Does primary need to forward `Get()`''s to backup?'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 主服务器需要将 `Get()` 转发给备份吗？'
- en: After all, `Get()` doesn't change anything, so why does backup need to know?
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 毕竟，`Get()` 不会改变任何东西，那为什么备份需要知道呢？
- en: and the extra RPC costs time
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 而额外的RPC会耗费时间
- en: 'has to do with ensuring there''s just one primary:'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与确保只有一个主服务器有关：
- en: suppose there's two primaries by accident (P and P' both think they are primaries)
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设出现两个主服务器（P 和 P' 都认为自己是主服务器）
- en: how can this occur? network partition?
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这可能发生吗？网络分区？
- en: suppose client sends a Get request to the wrong primary P'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设客户端向错误的主节点 P' 发送 Get 请求
- en: then P' will try to fwd the request to P (which P' thinks it's the backup)
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后 P' 将尝试将请求转发到 P（P'认为它是备份）
- en: 'then P will tell P'': *"Hey, bug off, I''m the primary"*'
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后 P 将告诉 P'：*“嘿，滚开，我是主要的”*
- en: '**Q:** How could we make primary-only `Get()`''s work?'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 我们如何使仅主要的 `Get()` 起作用？'
- en: '**Q:** Are there cases when the Lab 2 protocol cannot make forward progress?'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**问：** 在实验 2 协议中是否存在无法取得前进的情况？'
- en: View service fails
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视图服务失败
- en: Primary fails before backup gets state
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在备份获取状态之前，主要失败
- en: We will start fixing those in Lab 3
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将在实验 3 中开始修复这些问题
