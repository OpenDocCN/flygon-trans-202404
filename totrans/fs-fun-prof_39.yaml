- en: Swapping type-safety for high performance using compiler directives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Swapping type-safety for high performance using compiler directives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*TL;DR; An experiment: you can use lots of domain modelling types at development
    time and swap them out for a more performant implementation later using compiler
    directives.*'
  prefs: []
  type: TYPE_NORMAL
- en: Domain Modelling vs. Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I am a big fan of using [types for domain modelling](http://fsharpforfunandprofit.com/ddd/)
    -- lots and lots and *lots* of types!
  prefs: []
  type: TYPE_NORMAL
- en: These types act both as documentation and as a compile time constraint to ensure
    that only valid data is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if I have two types `CustomerId` and `OrderId`, I can represent
    them as separate types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: and by doing this, I guarantee that I can't use an `OrderId` where I need an
    `CustomerId`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is that adding a layer of indirection like this can affect performance:'
  prefs: []
  type: TYPE_NORMAL
- en: the extra indirection can cause data access to be much slower.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the wrapper class needs extra memory, creating memory pressure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: this in turn triggers the garbage collector more often, which can often be the
    cause of performance problems in managed code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, I don't generally worry about micro-performance like this at design-time.
    Many many things will have a *much* bigger impact on performance, including any
    kind of I/O, and the algorithms you choose.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, I am very much *against* doing micro-benchmarks out of context.
    You should always profile a real app in a real context, rather than worrying too
    much over things that might not be important.
  prefs: []
  type: TYPE_NORMAL
- en: Having said that, I am now going to do some micro-benchmarks!
  prefs: []
  type: TYPE_NORMAL
- en: Micro-benchmarking a wrapper type
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s see how a wrapper type fares when used in large numbers. Let''s say
    we want to:'
  prefs: []
  type: TYPE_NORMAL
- en: create ten million customer ids
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: then, map over them twice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: then, filter them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admittedly, it's a bit silly adding 1 to a customer id -- we'll look at a better
    example later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, here''s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*The code sample above is [available on GitHub](https://gist.github.com/swlaschin/348b6b9e64d4b150cf86#file-typesafe-performance-with-compiler-directives-1-fsx)*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*(Again, let me stress that this is a terrible way to profile code!)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical timed result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: That is, it takes about 0.3 seconds to do those steps, and it creates quite
    a bit of garbage, triggering four gen1 collections. If you are not sure what "gen0",
    "gen1", and "gen2" mean, then [this is a good place to start](https://msdn.microsoft.com/en-us/library/ms973837.aspx).
  prefs: []
  type: TYPE_NORMAL
- en: '*DISCLAIMER: I''m going to be doing all my benchmarking in F# interactive.
    Compiled code with optimizations might have a completely different performance
    profile. Past performance is no guarantee of future results. Draw conclusions
    at your own risk. Etc., etc.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we increase the array size to 10 million, we get a more than 10x slower
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: That is, it takes about 3.5 seconds to do those steps, and it creates *a lot*
    of garbage, including a few gen2 GC's, which are really bad. In fact, you might
    even get an "out of memory" exception, in which case, you'll have to restart F#
    Interactive!
  prefs: []
  type: TYPE_NORMAL
- en: 'So what are the alternatives to using a wrapper? There are two common approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Using type aliases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using units of measure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start with type aliases.
  prefs: []
  type: TYPE_NORMAL
- en: Using type aliases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the type alias approach, I would simply dispense with the wrapper, but keep
    the type around as documentation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If I want to use the type as documentation, I must then annotate the functions
    appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the `add1ToCustomerId` below both the parameter and the return
    value have been annotated so that it has the type `CustomerId -> CustomerId` rather
    than `int -> int`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Micro-benchmarking a type alias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s create another micro-benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*The code sample above is [available on GitHub](https://gist.github.com/swlaschin/348b6b9e64d4b150cf86#file-typesafe-performance-with-compiler-directives-2-fsx)*.'
  prefs: []
  type: TYPE_NORMAL
- en: The results are spectacularly better!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It takes about 17 milliseconds to do those steps, and more importantly, very
    little garbage was generated.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we increase the array size to 10 million, we get a 10x slower result, but
    still no garbage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Compared with the earlier version at over three seconds, that's excellent.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with type aliases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Alas, the problem with type aliases is that we have completely lost type safety
    now!
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate, here''s some code that creates a `CustomerId` and an `OrderId`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: And sadly, the two ids compare equal, and we can pass an `OrderId` to function
    expecting a `CustomerId` without any complaint from the compiler.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Ok, so that doesn't look promising! What next?
  prefs: []
  type: TYPE_NORMAL
- en: Using units of measure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The other common option is to use units of measure to distinguish the two types,
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '`CustomerId` and `OrderId` are still two different types, but the unit of measure
    is erased, so by the time the JIT sees it the type looks like an primitive int.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that this is true when we time the same steps as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*The code sample above is [available on GitHub](https://gist.github.com/swlaschin/348b6b9e64d4b150cf86#file-typesafe-performance-with-compiler-directives-3-fsx)*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical timed result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Again, the code is very fast (22 milliseconds), and just as importantly, very
    little garbage was generated again.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we increase the array size to 10 million, we maintain the high performance
    (just as with the type alias approach) and still no garbage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Problems with units of measure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The advantage of units of measure is that the `CustomerId` and `OrderId` types
    are incompatible, so we get the type safety that we want.
  prefs: []
  type: TYPE_NORMAL
- en: But I find them unsatisfactory from an esthetic point of view. I like my wrapper
    types!
  prefs: []
  type: TYPE_NORMAL
- en: 'And also, units of measure are really meant to be used with numeric values.
    For example, I can create a customer id and order id:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: and then I can divide CustomerId(12) by OrderId(4) to get three...
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Three what though? Three customer ids per order id? What does that even mean?
  prefs: []
  type: TYPE_NORMAL
- en: Yes, surely this will never happen in practice, but still it bothers me!
  prefs: []
  type: TYPE_NORMAL
- en: Using compiler directives to get the best of both worlds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Did I mention that I really like wrapper types? I really like them up until
    I get a call saying that production systems are having performance hiccups because
    of too many big GCs.
  prefs: []
  type: TYPE_NORMAL
- en: So, can we get the best of both worlds? Type-safe wrapper types AND fast performance?
  prefs: []
  type: TYPE_NORMAL
- en: I think so, if you are willing to put up with some extra work during development
    and build.
  prefs: []
  type: TYPE_NORMAL
- en: The trick is to have *both* the "wrapper type" implemention and the "type alias"
    implementation available to you, and then switch between them based on a compiler
    directive.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this to work:'
  prefs: []
  type: TYPE_NORMAL
- en: you will need to tweak your code to not access the type directly, but only via
    functions and pattern matching.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: you will need to create a "type alias" implementation that implements a "constructor",
    various "getters" and for pattern matching, active patterns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here's an example, using the `COMPILED` and `INTERACTIVE` directives so that
    you can play with it interactively. Obviously, in real code, you would use your
    own directive such as `FASTTYPES` or similar.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: You can see that for both versions I've created a constructor `createCustomerId`
    and a getter `customerIdValue` and, for the type alias version, an active pattern
    that looks just like `CustomerId`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this code in place, we can use `CustomerId` without caring about the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'And now we can run the *same* micro-benchmark with both implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*The code sample above is [available on GitHub](https://gist.github.com/swlaschin/348b6b9e64d4b150cf86#file-typesafe-performance-with-compiler-directives-4-fsx)*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are similar to the previous examples. The aliased version is much
    faster and does not create GC pressure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'and for the 10 million element version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: A more complex example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, we might want something more complex than a simple wrapper.
  prefs: []
  type: TYPE_NORMAL
- en: For example, here is an `EmailAddress` (a simple wrapper type, but constrained
    to be non-empty and containing a "@") and some sort of `Activity` record that
    stores an email and the number of visits, say.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: As before, for each type there is a constructor and a getter for each field.
  prefs: []
  type: TYPE_NORMAL
- en: '*NOTE: Normally I would define a type outside a module, but because the real
    constructor needs to be private, I''ve put the type inside the module and given
    the module and the type the same name. If this is too awkward, you can rename
    the module to be different from the type, or use the OCaml convention of calling
    the main type in a module just "T", so you get `EmailAddress.T` as the type name.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To make a more performant version, we replace `EmailAddress` with a type alias,
    and `Activity` with a struct, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This version reimplements the constructor and a getter for each field. I could
    have made the field names for `ActivityHistory` be the same in both cases too,
    but. in the struct case, type inference would not work. By making them different,
    the user is forced to use the getter functions rather than dotting in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both implementations have the same "API", so we can create code that works
    with both:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Pros and cons of this approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One nice thing about this approach is that it is self-correcting -- it forces
    you to use the "API" properly.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if I started accessing fields directly by dotting into the `ActivityHistory`
    record, then that code would break when the compiler directive was turned on and
    the struct implementation was used.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you could also create a signature file to enforce the API.
  prefs: []
  type: TYPE_NORMAL
- en: On the negative side, we do lose some of the nice syntax such as `{rec with
    ...}`. But you should really only be using this technique with small records (2-3
    fields), so not having `with` is not a big burden.
  prefs: []
  type: TYPE_NORMAL
- en: Timing the two implementations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Rather than using `#time`, this time I wrote a custom timer that runs a function
    10 times and prints out the GC and memory used on each run.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '*The code sample above is [available on GitHub](https://gist.github.com/swlaschin/348b6b9e64d4b150cf86#file-typesafe-performance-with-compiler-directives-5-fsx)*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now run `mapAndFilter` with a million records in the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now this code no longer consists of only value types, so the profiling is getting
    muddier now! The `mapAndFilter` function uses `createCustomerWithRandomActivity`
    which in turn uses `Option`, a reference type, so there will be a large number
    of reference types being allocated. Just as in real life, it's hard to keep things
    pure!
  prefs: []
  type: TYPE_NORMAL
- en: Even so, you can see that the wrapped version is slower than the aliased version
    (approx 800ms vs. 150ms) and creates more garbage on each iteration (approx 72Mb
    vs 24Mb) and most importantly has two big GC pauses (in the 5th and 9th iterations),
    while the aliased version never even does a gen1 GC, let alone a gen2.
  prefs: []
  type: TYPE_NORMAL
- en: '*NOTE: The fact that aliased version is using up memory and yet there are no
    gen1s makes me a bit suspicious of these figures. I think they might be different
    if run outside of F# interactive.*'
  prefs: []
  type: TYPE_NORMAL
- en: What about non-record types?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What if the type we want to optimise is a discriminated union rather than a
    record?
  prefs: []
  type: TYPE_NORMAL
- en: My suggestion is to turn the DU into a struct with a tag for each case, and
    fields for all possible data.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s say that we have DU that classifies an `Activity` into
    `Active` and `Inactive`, and for the `Active` case we store the email and visits
    and for the inactive case we only store the email:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'To turn this into a struct, I would do something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Note that `Visits` is not used in the `Inactive` case, so is set to a default
    value.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's create a function that classifies the activity history, creates a
    `Classification` and then filters and extracts the email only for active customers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '*The code sample above is [available on GitHub](https://gist.github.com/swlaschin/348b6b9e64d4b150cf86#file-typesafe-performance-with-compiler-directives-5-fsx)*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The results of profiling this function with the two different implementations
    are shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: As before, the aliased/struct version is more performant, being faster and generating
    less garbage (although there was a GC pause at the end, oh dear).
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Isn't this a lot of work, creating two implementations?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Yes! *I don't think you should do this in general.* This is just an experiment
    on my part.
  prefs: []
  type: TYPE_NORMAL
- en: I suggest that turning records and DUs into structs is a last resort, only done
    after you have eliminated all other bottlenecks first.
  prefs: []
  type: TYPE_NORMAL
- en: However, there may be a few special cases where speed and memory are critical,
    and then, perhaps, it might be worth doing something like this.
  prefs: []
  type: TYPE_NORMAL
- en: What are the downsides?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to all the extra work and maintenance, you mean?
  prefs: []
  type: TYPE_NORMAL
- en: Well, because the types are essentially private, we do lose some of the nice
    syntax available when you have access to the internals of the type, such as `{rec
    with ...}`, but as I said, you should really only be using this technique with
    small records anyway.
  prefs: []
  type: TYPE_NORMAL
- en: More importantly, value types like structs are not a silver bullet. They have
    their own problems.
  prefs: []
  type: TYPE_NORMAL
- en: For example, they can be slower when passed as arguments (because of copy-by-value)
    and you must be careful not to [box them implicitly](http://theburningmonk.com/2015/07/beware-of-implicit-boxing-of-value-types/),
    otherwise you end up doing allocations and creating garbage. Microsoft has [guidelines
    on using classes vs structs](https://msdn.microsoft.com/en-us/library/ms229017.aspx),
    but see also [this commentary on breaking these guidelines](http://stackoverflow.com/a/6973171/1136133)
    and [these rules](http://stackoverflow.com/a/598268/1136133).
  prefs: []
  type: TYPE_NORMAL
- en: What about using shadowing?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Shadowing is used when the client wants to use a different implementation. For
    example, you can switch from unchecked to checked arithmetic by opening the [Checked
    module](https://msdn.microsoft.com/en-us/library/ee340296.aspx). [More details
    here](http://theburningmonk.com/2012/01/checked-context-in-c-and-f/).
  prefs: []
  type: TYPE_NORMAL
- en: But that would not work here -- I don't want each client to decide which version
    of the type they will use. That would lead to all sorts of incompatibility problems.
    Also, it's not a per-module decision, it's a decision based on deployment context.
  prefs: []
  type: TYPE_NORMAL
- en: What about more performant collection types?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I am using `array` everywhere as the collection type. If you want other high
    performing collections, check out [FSharpx.Collections](https://fsprojects.github.io/FSharpx.Collections/)
    or [Funq collections](https://github.com/GregRos/Funq).
  prefs: []
  type: TYPE_NORMAL
- en: You've mixed up allocations, mapping, filtering. What about a more fine-grained
    analysis?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I'm trying to keep some semblage of dignity after I said that micro-benchmarking
    was bad!
  prefs: []
  type: TYPE_NORMAL
- en: So, yes, I deliberately created a case with mixed usage and measured it as a
    whole rather than benchmarking each part separately. Your usage scenarios will
    obviously be different, so I don't think there's any need to go deeper.
  prefs: []
  type: TYPE_NORMAL
- en: Also, I'm doing all my benchmarking in F# interactive. Compiled code with optimizations
    might have a completely different performance profile.
  prefs: []
  type: TYPE_NORMAL
- en: What other ways are there to increase performance?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since F# is a .NET language, the performance tips for C# work for F# as well,
    standard stuff like:'
  prefs: []
  type: TYPE_NORMAL
- en: Make all I/O async. Use streaming IO over random access IO if possible. Batch
    up your requests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check your algorithms. Anything worse than O(n log(n)) should be looked at.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't do things twice. Cache as needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep things in the CPU cache by keeping objects in contiguous memory and avoiding
    too many deep reference (pointer) chains. Things that help with this are using
    arrays instead of lists, value types instead of reference types, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid pressure on the garbage collector by minimizing allocations. Avoid creating
    long-lived objects that survive gen0 collections.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To be clear, I don't claim to be an expert on .NET performance and garbage collection.
    In fact, if you see something wrong with this analysis, please let me know!
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some sources that helped me:'
  prefs: []
  type: TYPE_NORMAL
- en: The book [Writing High-Performance .NET Code](http://www.writinghighperf.net/)
    by Ben Watson.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Martin Thompson has a great [blog](http://mechanical-sympathy.blogspot.jp/2012/08/memory-access-patterns-are-important.html)
    on performance and some excellent videos, such as [Top 10 Performance Folklore](http://www.infoq.com/presentations/top-10-performance-myths).
    ([Good summary here](http://weronikalabaj.com/performance-myths-and-facts/).)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Latency](https://www.youtube.com/watch?v=9MKY4KypBzg), a video
    by Gil Tene.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Truths Everyone Should Know about Performance in a Large Managed
    Codebase](https://channel9.msdn.com/Events/TechEd/NorthAmerica/2013/DEV-B333),
    a video by Dustin Cambell at Microsoft.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For F# in particular:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yan Cui has some blog posts on [records vs structs](http://theburningmonk.com/2011/10/fsharp-performance-test-structs-vs-records/)
    and [memory layout](http://theburningmonk.com/2015/07/smallest-net-ref-type-is-12-bytes-or-why-you-should-consider-using-value-types).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Jon Harrop has a number of good articles such as [this one](http://flyingfrogblog.blogspot.co.uk/2012/06/are-functional-languages-inherently.html)
    but some of it is behind a paywall.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Video: [High Performance F# in .NET and on the GPU](https://vimeo.com/33699102)
    with Jack Pappas. The sound is bad, but the slides and discussion are good!'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Resources for Math and Statistics](http://fsharp.org/guides/math-and-statistics/)
    on fsharp.org'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '"Keep it clean; keep it simple; aim to be elegant." -- *Martin Thompson*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This was a little experiment to see if I could have my cake and eat it too.
    Domain modelling using lots of types, but with the ability to get performance
    when needed in an elegant way.
  prefs: []
  type: TYPE_NORMAL
- en: I think that this is quite a nice solution, but as I said earlier, this optimization
    (and uglification) should only ever be needed for a small number of heavily used
    core types that are allocated many millions of times.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, I have not used this approach myself in a large production system (I've
    never needed to), so I would be interested in getting feedback from people in
    the trenches on what they do.
  prefs: []
  type: TYPE_NORMAL
- en: '*The code samples used in this post are [available on GitHub](https://gist.github.com/swlaschin/348b6b9e64d4b150cf86)*.'
  prefs: []
  type: TYPE_NORMAL
