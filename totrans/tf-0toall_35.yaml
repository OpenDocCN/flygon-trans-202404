- en: lab 10.6 mnist nn batchnorm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: lab 10.6 mnist nn batchnorm
- en: lab 10.6 Batchnormalization Layer
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: lab 10.6 批归一化层
- en: What is a batchnormalization layer?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是批归一化层？
- en: It is a layer that normalize the output before the activation layer. [The original
    paper](https://arxiv.org/abs/1502.03167) was proposed by Sergey Ioffe in 2015.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在激活层之前对输出进行归一化的层。[原始论文](https://arxiv.org/abs/1502.03167)是由Sergey Ioffe在2015年提出的。
- en: 'Batch Normalization Layer looks like this: ![](b0e213f4.PNG)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 批归一化层看起来像这样：![](b0e213f4.PNG)
- en: Why batchnormalization?
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要使用批归一化？
- en: The distribution of each layer's input changes because the weights of the previous
    layer change as we update weights by the gradient descent. This is called a covariance
    shift, which makes the network training difficult.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层的输入分布会发生变化，因为前一层的权重会随着梯度下降的权重更新而改变。这被称为协变量转移，这使得网络训练变得困难。
- en: For example, if the activation layer is a relu layer and the input of the activation
    layer is shifted to less than zeros, no weights will be activated!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果激活层是一个relu层，而激活层的输入被移动到小于零，那么没有权重会被激活！
- en: One thing also worth mentioning is that $\gamma$ and $\beta$ parameters in $$
    y = \gamma \hat{x} + \beta $$ are also trainable.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得一提的是，$$ y = \gamma \hat{x} + \beta $$ 中的$\gamma$和$\beta$参数也是可训练的。
- en: '**What it means is that if we don''t need the batchnormalization, its parameters
    will be updated such that it offsets the normalization step.**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**这意味着如果我们不需要批归一化，它的参数将被更新，以抵消归一化步骤。**'
- en: For example, assume that
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设
- en: \begin{align} \gamma &= \sqrt{\sigma^2_B + \epsilon}\ \beta &= \mu_B \end{align}
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \begin{align} \gamma &= \sqrt{\sigma^2_B + \epsilon}\ \beta &= \mu_B \end{align}
- en: then
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然后
- en: $$ y_i = \gamma \hat{x_i} + \beta = x_i $$
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: $$ y_i = \gamma \hat{x_i} + \beta = x_i $$
- en: Also note that $\mu$ and $\sigma$ are computed using moving averages during
    the training step. However, during the test time, the computed $\mu$ and $\sigma$
    will be used as fixed
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，在训练步骤中，$\mu$和$\sigma$是使用移动平均值计算的。然而，在测试时，计算得到的$\mu$和$\sigma$将被固定使用
- en: Conclusion
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Always use the batch normalization!
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是使用批归一化！
- en: 'Enough Talk: how to implement in Tensorflow'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 足够的讨论：如何在Tensorflow中实现
- en: 1\. Load Library
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 加载库
- en: We use the famous MNIST data
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用著名的MNIST数据
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 2\. Define Model & Solver Class
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 定义模型和解算器类
- en: Object-Oriented-Programming allows to define multiple model easily
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面向对象编程允许轻松定义多个模型
- en: Why do we separate model and solver classes?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么我们要将模型和解算器类分开？
- en: We can just swap out the model class in the Solver class when we need a different
    network architecture
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们需要不同的网络架构时，我们可以在解算器类中轻松更换模型类
- en: Usually we need one solver class
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常我们只需要一个解算器类
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 3\. Instantiate Model/Solver classes
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 实例化模型/解算器类
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 4\. Run the train step
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 运行训练步骤
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 5\. Performance Comparison
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. 性能比较
- en: With the batchnormalization, the loss is lower and it's more accurate too!
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用批归一化后，损失更低，而且更准确！
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![png](lab-10-6-mnist_nn_batchnorm_17_0.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![png](lab-10-6-mnist_nn_batchnorm_17_0.png)'
- en: '[PRE16]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![png](lab-10-6-mnist_nn_batchnorm_18_0.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![png](lab-10-6-mnist_nn_batchnorm_18_0.png)'
- en: '[PRE17]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![png](lab-10-6-mnist_nn_batchnorm_19_0.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![png](lab-10-6-mnist_nn_batchnorm_19_0.png)'
- en: '[PRE18]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![png](lab-10-6-mnist_nn_batchnorm_20_0.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![png](lab-10-6-mnist_nn_batchnorm_20_0.png)'
