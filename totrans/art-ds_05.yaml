- en: 4\. Exploratory Data Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Exploratory data analysis is the process of exploring your data, and it typically
    includes examining the structure and components of your dataset, the distributions
    of individual variables, and the relationships between two or more variables.
    The most heavily relied upon tool for exploratory data analysis is visualizing
    data using a graphical representation of the data. Data visualization is arguably
    the most important tool for exploratory data analysis because the information
    conveyed by graphical display can be very quickly absorbed and because it is generally
    easy to recognize patterns in a graphical display.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several goals of exploratory data analysis, which are:'
  prefs: []
  type: TYPE_NORMAL
- en: To determine if there are any problems with your dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To determine whether the question you are asking can be answered by the data
    that you have.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To develop a sketch of the answer to your question.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your application of exploratory data analysis will be guided by your question.
    The example question used in this chapter is: “Do counties in the eastern United
    States have higher ozone levels than counties in the western United States?” In
    this instance, you will explore the data to determine if there are problems with
    the dataset, and to determine if you can answer your question with this dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: To answer the question of course, you need ozone, county, and US region data.
    The next step is to use exploratory data analysis to begin to answer your question,
    which could include displaying boxplots of ozone by region of the US. At the end
    of exploratory data analysis, you should have a good sense of what the answer
    to your question is and be armed with sufficient information to move onto the
    next steps of data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that here, again, the concept of the epicycle of analysis
    applies. You should have an expectation of what your dataset will look like and
    whether your question can be answered by the data you have. If the content and
    structure of the dataset doesn’t match your expectation, then you will need to
    go back and figure out if your expectation was correct (but there was a problem
    with the data) or alternatively, your expectation was incorrect, so you cannot
    use the dataset to answer the question and will need to find another dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You should also have some expectation of what the ozone levels will be as well
    as whether one region’s ozone should be higher (or lower) than another’s. As you
    move to step 3 of beginning to answer your question, you will again apply the
    epicycle of analysis so that if, for example, the ozone levels in the dataset
    are lower than what you expected from looking at previously published data, you
    will need to pause and figure out if there is an issue with your data or if your
    expectation was incorrect. Your expectation could be incorrect, for example, if
    your source of information for setting your expectation about ozone levels was
    data collected from 20 years ago (when levels were likely higher) or from only
    a single city in the U.S. We will go into more detail with the case study below,
    but this should give you an overview about the approach and goals of exploratory
    data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '4.1 Exploratory Data Analysis Checklist: A Case Study'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section we will run through an informal “checklist” of things to do
    when embarking on an exploratory data analysis. As a running example I will use
    a dataset on hourly ozone levels in the United States for the year 2014\. The
    elements of the checklist are
  prefs: []
  type: TYPE_NORMAL
- en: Formulate your question
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read in your data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the packaging
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Look at the top and the bottom of your data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check your “n”s
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Validate with at least one external data source
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make a plot
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try the easy solution first
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Follow up
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Throughout this example we will depict an ongoing analysis with R code and real
    data. Some of the examples and recommendations here will be specific to the R
    statistical analysis environment, but most should be applicable to any software
    system. Being fluent in R is not necessary for understanding the main ideas of
    the example. Feel free to skip over the code sections.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Formulate your question
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Previously in this book](chap02.xhtml#chapter-question), we have discussed
    the importance of properly formulating a question. Formulating a question can
    be a useful way to guide the exploratory data analysis process and to limit the
    exponential number of paths that can be taken with any sizeable dataset. In particular,
    a *sharp* question or hypothesis can serve as a dimension reduction tool that
    can eliminate variables that are not immediately relevant to the question.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, in this chapter we will be looking at an air pollution dataset
    from the U.S. Environmental Protection Agency (EPA). A general question one could
    as is
  prefs: []
  type: TYPE_NORMAL
- en: Are air pollution levels higher on the east coast than on the west coast?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: But a more specific question might be
  prefs: []
  type: TYPE_NORMAL
- en: Are hourly ozone levels on average higher in New York City than they are in
    Los Angeles?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note that both questions may be of interest, and neither is right or wrong.
    But the first question requires looking at all pollutants across the entire east
    and west coasts, while the second question only requires looking at single pollutant
    in two cities.
  prefs: []
  type: TYPE_NORMAL
- en: It’s usually a good idea to spend a few minutes to figure out what is the question
    you’re *really* interested in, and narrow it down to be as specific as possible
    (without becoming uninteresting).
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, we will consider the following question:'
  prefs: []
  type: TYPE_NORMAL
- en: Do counties in the eastern United States have higher ozone levels than counties
    in the western United States?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As a side note, one of the most important questions you can answer with an exploratory
    data analysis is “Do I have the right data to answer this question?” Often this
    question is difficult to answer at first, but can become more clear as we sort
    through and look at the data.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Read in your data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next task in any exploratory data analysis is to read in some data. Sometimes
    the data will come in a very messy format and you’ll need to do some cleaning.
    Other times, someone else will have cleaned up that data for you so you’ll be
    spared the pain of having to do the cleaning.
  prefs: []
  type: TYPE_NORMAL
- en: We won’t go through the pain of cleaning up a dataset here, not because it’s
    not important, but rather because there’s often not much generalizable knowledge
    to obtain from going through it. Every dataset has its unique quirks and so for
    now it’s probably best to not get bogged down in the details.
  prefs: []
  type: TYPE_NORMAL
- en: Here we have a relatively clean dataset from the U.S. EPA on hourly ozone measurements
    in the entire U.S. for the year 2014\. The data are available from the EPA’s [Air
    Quality System web page](http://aqsdr1.epa.gov/aqsweb/aqstmp/airdata/download_files.html).
    I’ve simply downloaded the zip file from the web site, unzipped the archive, and
    put the resulting file in a directory called “data”. If you want to run this code
    you’ll have to use the same directory structure.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is a comma-separated value (CSV) file, where each row of the file
    contains one hourly measurement of ozone at some location in the country.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: Running the code below may take a few minutes. There are 7,147,884
    rows in the CSV file. If it takes too long, you can read in a subset by specifying
    a value for the `n_max` argument to `read_csv()` that is greater than 0.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`The `readr` package by Hadley Wickham is a nice package for reading in flat
    files (like CSV files) *very* fast, or at least much faster than R’s built-in
    functions. It makes some tradeoffs to obtain that speed, so these functions are
    not always appropriate, but they serve our purposes here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The character string provided to the `col_types` argument specifies the class
    of each column in the dataset. Each letter represents the class of a column: “c”
    for character, “n” for numeric”, and “i” for integer. No, I didn’t magically know
    the classes of each column—I just looked quickly at the file to see what the column
    classes were. If there are too many columns, you can not specify `col_types` and
    `read_csv()` will try to figure it out for you.'
  prefs: []
  type: TYPE_NORMAL
- en: Just as a convenience for later, we can rewrite the names of the columns to
    remove any spaces.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`### 4.4 Check the Packaging'
  prefs: []
  type: TYPE_NORMAL
- en: Have you ever gotten a present *before* the time when you were allowed to open
    it? Sure, we all have. The problem is that the present is wrapped, but you desperately
    want to know what’s inside. What’s a person to do in those circumstances? Well,
    you can shake the box a bit, maybe knock it with your knuckle to see if it makes
    a hollow sound, or even weigh it to see how heavy it is. This is how you should
    think about your dataset before you start analyzing it for real.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming you don’t get any warnings or errors when reading in the dataset, you
    should now have an object in your workspace named `ozone`. It’s usually a good
    idea to poke at that object a little bit before we break open the wrapping paper.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you should check the number of rows
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`and columns.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`Remember when we said there were 7,147,884 rows in the file? How does that
    match up with what we’ve read in? This dataset also has relatively few columns,
    so you might be able to check the original text file to see if the number of columns
    printed out (23) here matches the number of columns you see in the original file.'
  prefs: []
  type: TYPE_NORMAL
- en: Another thing you can do in R is run `str()` on the dataset. This is usually
    a safe operation in the sense that even with a very large dataset, running `str()`
    shouldn’t take too long.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]The output for `str()` duplicates some information that we already have,
    like the number of rows and columns. More importantly, you can examine the *classes*
    of each of the columns to make sure they are correctly specified (i.e. numbers
    are `numeric` and strings are `character`, etc.). Because we pre-specified all
    of the column classes in `read_csv()`, they all should match up with what we specified.'
  prefs: []
  type: TYPE_NORMAL
- en: Often, with just these simple maneuvers, you can identify potential problems
    with the data before plunging in head first into a complicated data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 Look at the Top and the Bottom of your Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s often useful to look at the “beginning” and “end” of a dataset right after
    you check the packaging. This lets you know if the data were read in properly,
    things are properly formatted, and that everything is there. If your data are
    time series data, then make sure the dates at the beginning and end of the dataset
    match what you expect the beginning and ending time period to be.
  prefs: []
  type: TYPE_NORMAL
- en: In R, you can peek at the top and bottom of the data with the `head()` and `tail()`
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the top.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`For brevity I’ve only taken a few columns. And here’s the bottom.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`The `tail()` function can be particularly useful because often there will
    be some problem reading the end of a dataset and if you don’t check that specifically
    you’d never know. Sometimes there’s weird formatting at the end or some extra
    comment lines that someone decided to stick at the end. This is particularly common
    with data that are exported from Microsoft Excel spreadsheets.'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to check all the columns and verify that all of the data in each column
    looks the way it’s supposed to look. This isn’t a foolproof approach, because
    we’re only looking at a few rows, but it’s a decent start.
  prefs: []
  type: TYPE_NORMAL
- en: '4.6 ABC: Always be Checking Your “n”s'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In general, counting things is usually a good way to figure out if anything
    is wrong or not. In the simplest case, if you’re expecting there to be 1,000 observations
    and it turns out there’s only 20, you know something must have gone wrong somewhere.
    But there are other areas that you can check depending on your application. To
    do this properly, you need to identify some *landmarks* that can be used to check
    against your data. For example, if you are collecting data on people, such as
    in a survey or clinical trial, then you should know how many people there are
    in your study. That’s something you should check in your dataset, to make sure
    that you have data on all the people you thought you would have data on.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will use the fact that the dataset purportedly contains
    *hourly* data for the *entire country*. These will be our two landmarks for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have hourly ozone data that comes from monitors across the country.
    The monitors should be monitoring continuously during the day, so all hours should
    be represented. We can take a look at the `Time.Local` variable to see what time
    measurements are recorded as being taken.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`One thing we notice here is that while almost all measurements in the dataset
    are recorded as being taken on the hour, some are taken at slightly different
    times. Such a small number of readings are taken at these off times that we might
    not want to care. But it does seem a bit odd, so it might be worth a quick check.'
  prefs: []
  type: TYPE_NORMAL
- en: We can take a look at which observations were measured at time “00:01”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`We can see that it’s a monitor in Franklin County, New York and that the measurements
    were taken on September 30, 2014\. What if we just pulled all of the measurements
    taken at this monitor on this date?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`Now we can see that this monitor just records its values at odd times, rather
    than on the hour. It seems, from looking at the previous output, that this is
    the only monitor in the country that does this, so it’s probably not something
    we should worry about.'
  prefs: []
  type: TYPE_NORMAL
- en: Because the EPA monitors pollution across the country, there should be a good
    representation of states. Perhaps we should see exactly how many states are represented
    in this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '`So it seems the representation is a bit too good—there are 52 states in the
    dataset, but only 50 states in the U.S.!'
  prefs: []
  type: TYPE_NORMAL
- en: We can take a look at the unique elements of the `State.Name` variable to see
    what’s going on.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`Now we can see that Washington, D.C. (District of Columbia) and Puerto Rico
    are the “extra” states included in the dataset. Since they are clearly part of
    the U.S. (but not official states of the union) that all seems okay.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This last bit of analysis made use of something we will discuss in the next
    section: external data. We knew that there are only 50 states in the U.S., so
    seeing 52 state names was an immediate trigger that something might be off. In
    this case, all was well, but validating your data with an external data source
    can be very useful. Which brings us to….'
  prefs: []
  type: TYPE_NORMAL
- en: 4.7 Validate With at Least One External Data Source
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Making sure your data matches something outside of the dataset is very important.
    It allows you to ensure that the measurements are roughly in line with what they
    should be and it serves as a check on what *other* things might be wrong in your
    dataset. External validation can often be as simple as checking your data against
    a single number, as we will do here.
  prefs: []
  type: TYPE_NORMAL
- en: In the U.S. we have national ambient air quality standards, and for ozone, the
    [current standard](http://www.epa.gov/ttn/naaqs/standards/ozone/s_o3_history.html)
    set in 2008 is that the “annual fourth-highest daily maximum 8-hr concentration,
    averaged over 3 years” should not exceed 0.075 parts per million (ppm). The exact
    details of how to calculate this are not important for this analysis, but roughly
    speaking, the 8-hour average concentration should not be too much higher than
    0.075 ppm (it can be higher because of the way the standard is worded).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at the hourly measurements of ozone.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`From the summary we can see that the maximum hourly concentration is quite
    high (0.349 ppm) but that in general, the bulk of the distribution is far below
    0.075\.'
  prefs: []
  type: TYPE_NORMAL
- en: We can get a bit more detail on the distribution by looking at deciles of the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`Knowing that the national standard for ozone is something like 0.075, we can
    see from the data that'
  prefs: []
  type: TYPE_NORMAL
- en: The data are at least of the right order of magnitude (i.e. the units are correct)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The range of the distribution is roughly what we’d expect, given the regulation
    around ambient pollution levels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some hourly levels (less than 10%) are above 0.075 but this may be reasonable
    given the wording of the standard and the averaging involved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.8 Make a Plot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Making a plot to visualize your data is a good way to further your understanding
    of your question and your data. Plotting can occur at different stages of a data
    analysis. For example, plotting may occur at the exploratory phase or later on
    in the presentation/communication phase.
  prefs: []
  type: TYPE_NORMAL
- en: There are two key reasons for making a plot of your data. They are *creating
    expectations* and *checking deviations from expectations*.
  prefs: []
  type: TYPE_NORMAL
- en: At the early stages of analysis, you may be equipped with a question/hypothesis,
    but you may have little sense of what is going on in the data. You may have peeked
    at some of it for sake of doing some sanity checks, but if your dataset is big
    enough, it will be difficult to simply look at all the data. So making some sort
    of plot, which serves as a summary, will be a useful tool for *setting expectations
    for what the data should look like*.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have a good understanding of the data, a good question/hypothesis,
    and a set of expectations for what the data should say vis a vis your question,
    making a plot can be a useful tool to see how well the data match your expectations.
    Plots are particularly good at letting you see *deviations* from what you might
    expect. Tables typically are good at *summarizing* data by presenting things like
    means, medians, or other statistics. Plots, however, can show you those things,
    as well as show you things that are far from the mean or median, so you can check
    to see if something is *supposed* to be that far away. Often, what is obvious
    in a plot can be hidden away in a table.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a simple [boxplot](https://en.wikipedia.org/wiki/Box_plot) of the ozone
    data, with one boxplot for each state.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`![Boxplot of ozone values by state](images/EDA-unnamed-chunk-16-1.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Boxplot of ozone values by state
  prefs: []
  type: TYPE_NORMAL
- en: From the plot, we can see that for most states the data are within a pretty
    narrow range below 0.05 ppm. However, for Puerto Rico, we see that the typical
    values are very low, except for some extremely high values. Similarly, Georgia
    and Hawaii appear to experience an occasional very high value. These might be
    worth exploring further, depending on your question.
  prefs: []
  type: TYPE_NORMAL
- en: 4.9 Try the Easy Solution First
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recall that our original question was
  prefs: []
  type: TYPE_NORMAL
- en: Do counties in the eastern United States have higher ozone levels than counties
    in the western United States?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What’s the simplest answer we could provide to this question? For the moment,
    don’t worry about whether the answer is correct, but the point is how could you
    provide *prima facie* evidence for your hypothesis or question. You may refute
    that evidence later with deeper analysis, but this is the first pass. Importantly,
    if you do not find evidence of a signal in the data using just a simple plot or
    analysis, then often it is unlikely that you will find something using a more
    sophisticated analysis.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to define what we mean by “eastern” and “western”. The simplest
    thing to do here is to simply divide the country into east and west using a specific
    longitude value. For now, we will use -100 as our cutoff. Any monitor with longitude
    less than -100 will be “west” and any monitor with longitude greater than or equal
    to -100 will be “east”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`![Map of East and West Regions](images/EDA-unnamed-chunk-17-1.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Map of East and West Regions
  prefs: []
  type: TYPE_NORMAL
- en: Here we create a new variable called `region` that we use to indicate whether
    a given measurement in the dataset was recorded in the “east” or the “west”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '``Now, we can make a simple summary of ozone levels in the east and west of
    the U.S. to see where levels tend to be higher.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '`Both the mean and the median ozone level are higher in the western U.S. than
    in the eastern U.S., by about 0.004 ppm.'
  prefs: []
  type: TYPE_NORMAL
- en: We can also make a boxplot of the ozone in the two regions to see how they compare.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '`![Boxplot of Ozone for East and West Regions](images/EDA-unnamed-chunk-20-1.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Boxplot of Ozone for East and West Regions
  prefs: []
  type: TYPE_NORMAL
- en: We can see from the boxplots that the variability of ozone in the east tends
    to be a lot higher than the variability in the west.
  prefs: []
  type: TYPE_NORMAL
- en: Challenge Your Solution
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The easy solution is nice because it is, well, easy, but you should never allow
    those results to hold the day. You should always be thinking of ways to challenge
    the results, especially if those results comport with your prior expectation.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that previously we noticed that three states had some unusually high
    values of ozone. We don’t know if these values are real or not (for now, let’s
    assume they are real), but it might be interesting to see if the same pattern
    of east/west holds up if we remove these states that have unusual activity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '`Indeed, it seems the pattern is the same even with those 3 states removed.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.10 Follow-up Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter we’ve presented some simple steps to take when starting off
    on an exploratory analysis. The example analysis conducted in this chapter was
    far from perfect, but it got us thinking about the data and the question of interest.
    It also gave us a number of things to follow up on in case we continue to be interested
    in this question.
  prefs: []
  type: TYPE_NORMAL
- en: At this point it’s useful to consider a few follow-up questions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Do you have the right data?** Sometimes at the conclusion of an exploratory
    data analysis, the conclusion is that the dataset is not really appropriate for
    this question. In this case, the dataset seemed perfectly fine for answering the
    question of whether counties in the eastern U.S. have higher levels in the western
    U.S.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Do you need other data?** While the data seemed adequate for answering the
    question posed, it’s worth noting that the dataset only covered one year (2014).
    It may be worth examining whether the east/west pattern holds for other years,
    in which case we’d have to go out and obtain other data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Do you have the right question?** In this case, it’s not clear that the question
    we tried to answer has immediate relevance, and the data didn’t really indicate
    anything to increase the question’s relevance. For example, it might have been
    more interesting to assess which counties were in violation of the national ambient
    air quality standard, because determining this could have regulatory implications.
    However, this is a much more complicated calculation to do, requiring data from
    at least 3 previous years.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The goal of exploratory data analysis is to get you thinking about your data
    and reasoning about your question. At this point, we can refine our question or
    collect new data, all in an iterative process to get at the truth.[PRE21]
  prefs: []
  type: TYPE_NORMAL
