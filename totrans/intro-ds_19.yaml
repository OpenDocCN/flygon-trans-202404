- en: '[Map](data_mining_map.htm) > [Data Science](data_mining.htm) > [Predicting
    the Future](predicting_the_future.htm) > [Modeling](modeling.htm) > [Classification](classification.htm)
    > Linear Discriminant Analysis'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '[地图](data_mining_map.htm) > [数据科学](data_mining.htm) > [预测未来](predicting_the_future.htm)
    > [建模](modeling.htm) > [分类](classification.htm) > 线性判别分析'
- en: Linear Discriminant Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性判别分析
- en: Linear Discriminant Analysis (LDA) is a classification method originally developed
    in 1936 by R. A. Fisher. It is simple, mathematically robust and often produces
    models whose accuracy is as good as more complex methods. **Algorithm**LDA is
    based upon the concept of searching for a linear combination of variables (predictors)
    that best separates two classes (targets). To capture the notion of separability,
    Fisher defined the following score function.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 线性判别分析（LDA）是一种最初由R·A·费舍尔于1936年开发的分类方法。它简单、数学上健壮，并且通常能产生准确率与更复杂方法一样好的模型。**算法**LDA基于寻找一组最佳分离两个类别（目标）的变量（预测器）的线性组合的概念。为了捕捉可分离性的概念，费舍尔定义了以下评分函数。
- en: '![](../Images/37aecbc9efcf8175e0bf51fe29adbeb7.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37aecbc9efcf8175e0bf51fe29adbeb7.jpg)'
- en: Given the score function, the problem is to estimate the linear coefficients
    that maximize the score which can be solved by the following equations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 给定评分函数，问题是估计最大化评分的线性系数，这可以通过以下方程解决。
- en: '![](../Images/3630d0950655fdb2e98a9b2c8ec219a7.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3630d0950655fdb2e98a9b2c8ec219a7.jpg)'
- en: One way of assessing the effectiveness of the discrimination is to calculate
    the **Mahalanobis distance** between two groups. A distance greater than 3 means
    that in two averages differ by more than 3 standard deviations. It means that
    the overlap (probability of misclassification) is quite small.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 评估判别效果的一种方法是计算两组之间的**马氏距离**。距离大于3意味着两个平均值相差超过3个标准差。这意味着重叠（误分类的概率）非常小。
- en: '![](../Images/8b46439cc878333f1cf28e0775cd8af4.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b46439cc878333f1cf28e0775cd8af4.jpg)'
- en: 'Finally, a new point is classified by projecting it onto the maximally separating
    direction and classifying it as *C1* if:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过将新点投影到最大分离方向上对其进行分类，并在以下条件下将其分类为*C1*：
- en: '![](../Images/3046b9e244e18c82995c96c08b42d8e0.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3046b9e244e18c82995c96c08b42d8e0.jpg)'
- en: '*Example*:Suppose we received a [dataset](datasets/credit_scoring_lda.xlsx)
    from a bank regarding its small business clients who defaulted (red square) and
    those that did not (blue circle) separated by delinquent days (DAYSDELQ) and number
    of months in business (BUSAGE). We use LDA to find an optimal linear model that
    best separates two classes (default and non-default).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*例子*：假设我们收到一家银行关于其小型企业客户的[数据集](datasets/credit_scoring_lda.xlsx)，其中包括违约（红色方块）和未违约（蓝色圆圈）的客户，以逾期天数（DAYSDELQ）和业务月数（BUSAGE）分隔。我们使用LDA来找到最佳线性模型，最佳地分离两个类别（违约和非违约）。'
- en: '![](../Images/859d400cc05286876b7e01fdad43ddbd.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/859d400cc05286876b7e01fdad43ddbd.jpg)'
- en: The first step is to calculate the mean (average) vectors, covariance matrices
    and class probabilities.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是计算均值（平均）、协方差矩阵和类别概率。
- en: '![](../Images/6a1d31c9f72a6675699438e79c5a1aa2.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a1d31c9f72a6675699438e79c5a1aa2.jpg)'
- en: Then, we calculate pooled covariance matrix and finally the coefficients of
    the linear model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算混合协方差矩阵，最后计算线性模型的系数。
- en: '![](../Images/39e2c5567f811540813d5bcbb65183ec.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39e2c5567f811540813d5bcbb65183ec.jpg)'
- en: A *Mahalanobis distance* of 2.32 shows a small overlap between two groups which
    means a good separation between classes by the linear model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**马氏距离**为2.32表明两组之间存在很小的重叠，这意味着线性模型对类别的良好分离。'
- en: '![](../Images/914da9b30755cff1e7b2bb5fa253da4b.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/914da9b30755cff1e7b2bb5fa253da4b.jpg)'
- en: In the following table, we calculate Z score using the above Z equation. However,
    a score by itself cannot be used for predicting an outcome. We also need the equation
    in column 5 to choose Class N or Y. We predict Class N if the calculated value
    is bigger than -1.1 otherwise Class Y. As it is shown below, the LDA model made
    two errors.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，我们使用上述Z方程计算Z得分。然而，仅凭得分本身不能用于预测结果。我们还需要第5列中的方程式来选择N类或Y类。如果计算值大于-1.1，则预测为N类，否则为Y类。正如下文所示，LDA模型犯了两个错误。
- en: '![](../Images/1f872e4aa0953f8125a766ee2960c226.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f872e4aa0953f8125a766ee2960c226.jpg)'
- en: '**Predictors Contribution**A simple linear correlation between the model scores
    and predictors can be used to test which predictors contribute significantly to
    the discriminant function. Correlation varies from -1 to 1, with -1 and 1 meaning
    the highest contribution but in different directions and 0 means no contribution
    at all.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测因子贡献**可以使用模型分数与预测因子之间的简单线性相关性来测试哪些预测因子对判别函数有显著贡献。相关性的变化范围为-1到1，-1和1表示最高贡献但方向不同，而0表示根本没有贡献。'
- en: Quadratic Discriminant Analysis (QDA)
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二次判别分析（QDA）
- en: QDA is a general discriminant function with a quadratic decision boundaries
    which can be used to classify datasets with two or more classes. QDA has more
    predictability power than LDA but it needs to estimate the covariance matrix for
    each classes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: QDA是具有二次决策边界的通用判别函数，可用于对具有两个或更多类的数据集进行分类。QDA具有比LDA更强的预测能力，但需要估计每个类别的协方差矩阵。
- en: '![](../Images/c8e761fbe717f8ae0dd82f8080aa2651.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8e761fbe717f8ae0dd82f8080aa2651.jpg)'
- en: where **C***[k]* is the covariance matrix for the class *k* (-1 means inverse
    matrix), |**C***[k]*| is the determinant of the covariance matrix **C***[k]*,
    and *P*(*c[k]*) is the prior probability of the class *k*. The classification
    rule is simply to find the class with highest *Z* value.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其中**C***[k]*是类*k*的协方差矩阵（-1表示逆矩阵），|**C***[k]*|是协方差矩阵**C***[k]*的行列式，*P*(*c[k]*)是类*k*的先验概率。分类规则是简单地找到具有最高*Z*值的类。
- en: '| [![](../Images/a890baab528b0ca069f7f2599c0c5e39.jpg)](datasets/Lda.txt) |
    ![](../Images/dc9f5f2d562c6ce8cb7def0d0596abff.jpg)[LDA Interactive](flash/LDA_flash.html)
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| [![](../Images/a890baab528b0ca069f7f2599c0c5e39.jpg)](datasets/Lda.txt) |
    ![](../Images/dc9f5f2d562c6ce8cb7def0d0596abff.jpg)[LDA互动](flash/LDA_flash.html)
    |'
- en: '![](../Images/04c11d11a10b9a2348a1ab8beb8ecdd8.jpg) Try to invent a real time
    LDA classifier. You should be able to add or remove data and variables (predictors
    and classes) on the fly.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/04c11d11a10b9a2348a1ab8beb8ecdd8.jpg) 尝试发明一个实时LDA分类器。您应该能够随时添加或删除数据和变量（预测因子和类）。'
