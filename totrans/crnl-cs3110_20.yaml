- en: 'Lecture 13: Hash tables'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 13 讲：哈希表
- en: Hash tables
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希表
- en: Suppose we want a data structure to implement either a mutable set of elements
    (with operations like contains, add, and remove that take an element as an argument)
    or a mutable map from keys to values (with operations like get, put, and remove
    that take a key for an arguments). A mutable map is also known as an **associative
    array**. We've now seen a few data structures that could be used for both of these
    implementation tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要一个数据结构来实现一个可变元素的集合（包括包含、添加和移除等操作，该操作以一个元素作为参数），或者实现一个从键到值的可变映射（包括获取、放置和移除等操作，该操作以一个键作为参数）。可变映射也被称为**关联数组**。我们现在已经看到了一些数据结构，可以用于这两个实现任务。
- en: We consider the problem of implementing sets and maps together because most
    data structures that can implement a set can also implement a map. A set of key–value
    pairs can act as a map, as long as the way we compare key–value pairs is to compare
    the keys. Alternatively, we can view the transformation from a set to a map as
    starting with a data structure that implements set of keys and then adding an
    associated value to each data structure node that stores a key.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑实现集合和映射的问题，因为大多数可以实现集合的数据结构也可以实现映射。一组键-值对可以充当映射，只要我们比较键-值对的方式是比较键。或者，我们可以将从集合到映射的转换视为从一个实现键集合的数据结构开始，然后为每个存储键的数据结构节点添加一个关联值。
- en: 'Here are the data structures we''ve seen so far, with the asymptotic complexities
    for each of their key operations:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到的数据结构以及它们各自关键操作的渐近复杂度如下：
- en: '| Data structure | lookup (contains/get) | add/put | remove |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| 数据结构 | 查找（包含/获取） | 添加/放置 | 移除 |'
- en: '| Array | O(n) | O(1) | O(n) |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| 数组 | O(n) | O(1) | O(n) |'
- en: '| Function | O(1) | O(n) | N/A |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 函数 | O(1) | O(n) | N/A |'
- en: '| Linked list | O(n) | O(1) | O(n) |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 链表 | O(n) | O(1) | O(n) |'
- en: '| Search tree | O(lg n) | O(lg n) | O(lg n) |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 搜索树 | O(lg n) | O(lg n) | O(lg n) |'
- en: 'Naturally, we might wonder if there is a data structure that can do better.
    And it turns out that there is: the **hash table**, one of the best and most useful
    data structures there is—when used correctly.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，我们可能会想知道是否有一种数据结构可以做得更好。事实证明确实有：**哈希表**，它是最好的、最有用的数据结构之一——当正确使用时。
- en: Many variations on hash tables have been developed. We'll explore the most common
    ones, building up in steps.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 已经开发了许多哈希表的变体。我们将逐步探索最常见的那些。
- en: 'Step 1: Direct address tables'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：直接寻址表
- en: While arrays make a slow data structure when you don't know what index to look
    at, all of their operations are very fast when you do. This is the insight behind
    the **direct address table**. Suppose that for each element that we want to store
    in the data structure, we can determine a unique integer index in the range 0..m–1\.
    That is, we need an **injective** function that maps elements (or keys) to integers
    in the range. Then we can use the indices produced by the function to decide at
    which index to store the elements in an array of size m.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们不知道要查找的索引时，数组作为数据结构会很慢，但当你知道索引时，所有操作都非常快。这就是**直接寻址表**背后的见解。假设对于我们想要存储在数据结构中的每个元素，我们都可以确定一个在范围
    0..m–1 内的唯一整数索引。也就是说，我们需要一个将元素（或键）映射到范围内整数的**单射**函数。然后我们可以使用函数产生的索引来决定在大小为 m 的数组中存储元素的位置。
- en: For example, suppose we are maintaining a collection of objects representing
    houses on the same street. We can use the street address as the index into a direct
    address table. Not every possible street address will be used, so some array entries
    will be empty. This is not a problem as long as there are not too many empty entries.
    However, it is often hard to come up with an injective function that does not
    require many empty entries. For example, suppose that instead we are maintaining
    a collection of employees whom we want to look up by social security number. Using
    the social security number as the index into a direct address table means we need
    an array of 10 billion elements, almost all of which are likely to be unused.
    Even assuming our computer has enough memory to store such a **sparse** array,
    it will be a waste of memory. Furthermore, on most computer hardware, the use
    of caches means that accesses to large arrays are actually significantly slower
    than accesses to small arrays—sometimes, two orders of magnitude slower!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们正在维护一个表示同一条街上房屋的对象集合。我们可以使用街道地址作为直接地址表的索引。并不是每个可能的街道地址都会被使用，因此一些数组条目将为空。只要空条目不太多，这并不是一个问题。然而，通常很难想出一个不需要太多空条目的单射函数。例如，假设我们要维护一组按社会安全号码查找的员工。使用社会安全号码作为直接地址表的索引意味着我们需要一个包含
    100 亿元素的数组，几乎所有元素都可能未被使用。即使假设我们的计算机有足够的内存来存储这样一个**稀疏**数组，它也将是一种浪费内存的方式。此外，在大多数计算机硬件上，使用缓存意味着对大数组的访问实际上明显比对小数组的访问慢得多——有时慢两个数量级！
- en: 'Step 2: Hashing'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2：哈希
- en: Instead of requiring that the key be mapped to an index without any collisions,
    we allow collisions in which two keys maps to the same array index. To avoid having
    many collisions, this mapping is performed by a **hash function** that maps the
    key in a reproducible but “random” way to a **hash** that is a legal array index.
    If the hash function is good, collisions occur as if completely at random. Suppose
    that we are using an array with 13 entries and our keys are social security numbers,
    expressed as `long` values. Then we might use **modular hashing**, in which the
    array index is computed as `key % 13`. This is not a very random hash function,
    but is likely to be good enough unless there is an adversary purposely trying
    to produce collisions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不要求键被映射到一个没有任何冲突的索引，而是允许发生冲突，即两个键映射到同一个数组索引的情况。为了避免发生许多冲突，这种映射是由一个**哈希函数**执行的，它以可复现但“随机”的方式将键映射到一个合法的数组索引**哈希**。如果哈希函数很好，冲突的发生就像完全随机一样。假设我们使用一个具有
    13 个条目的数组，我们的键是表示为 `long` 值的社会安全号码。那么我们可能使用**模数哈希**，其中数组索引计算为 `key % 13`。这不是一个非常随机的哈希函数，但除非有人故意制造冲突，否则可能足够好。
- en: 'Step 3: Collision resolution'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3：解决冲突
- en: Open hashing (chaining)
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开放哈希（链式哈希）
- en: 'There are two main ideas for how to deal with collisions. The best way is usually
    **chaining**: each array entry corresponds to a **bucket** containing a mutable
    set of elements. (Confusingly, this approach is also known as **closed addressing**
    or **open hashing**.) Typically, the bucket is implemented as a linked list, so
    each array entry (if nonempty) contains a pointer to the head of the linked list.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 处理冲突的两个主要思路。最好的方法通常是**链式**：每个数组条目对应一个包含可变元素集的**桶**。（令人困惑的是，这种方法也被称为**闭合寻址**或**开放哈希**。）通常，桶被实现为一个链表，因此每个数组条目（如果非空）都包含指向链表头部的指针。
- en: To check whether an element is in the hash table, the key is first hashed to
    find the correct bucket to look in. Then, the linked list is scanned to see if
    the desired element is present. If the linked list is short, this scan is very
    quick.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查一个元素是否在哈希表中，首先将键进行哈希以找到要查找的正确桶。然后，扫描链表以查看所需元素是否存在。如果链表很短，则此扫描非常快。
- en: An element is added or removed by hashing it to find the correct bucket. Then,
    the bucket is checked to see if the element is there, and finally the element
    is added or removed appropriately from the bucket in the usual way for linked
    lists.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 添加或删除元素是通过将其哈希来找到正确的桶来完成的。然后，检查桶以查看元素是否在其中，最后按照通常的方式从桶中适当地添加或删除元素。
- en: Closed hashing (probing)
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 封闭哈希（探查法）
- en: Another approach to collision resolution that is worth knowing about is **probing**.
    (Confusingly, this technique is also known as **open addressing** or **closed
    hashing**.) Rather than put colliding elements in a linked list, all elements
    are stored in the array itself. When adding a new element to the hash table creates
    a collision, the hash table finds somewhere else in the array to put it. The simple
    way to find an empty index is to search ahead through the array indices with a
    fixed stride (often 1), looking for an unused entry; this **linear probing** strategy
    tends to produce a lot of clustering of elements in the table, leading to bad
    performance. A better strategy is to use a second hash function to compute the
    probing interval; this strategy is called **double hashing**. Regardless of how
    probing is implemented, however, the time required to search for or add an element
    grows rapidly as the hash table fills up. By contrast, the performance of chaining
    degrades more gracefully, and chaining is usually faster than probing even when
    the hash table is not nearly full. Therefore chaining is usually preferred over
    probing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 值得了解的冲突解决方法之一是**探测**。（令人困惑的是，这种技术也被称为**开放寻址**或**闭散列**。）与其将碰撞的元素放在链表中，不如将所有元素存储在数组中。当向哈希表中添加新元素创建冲突时，哈希表会在数组中找到其他位置来放置它。找到空索引的简单方法是通过数组索引以固定步长（通常为1）向前搜索，寻找未使用的条目；这种**线性探测**策略往往会在表中产生大量元素聚集，导致性能不佳。更好的策略是使用第二个哈希函数来计算探测间隔；这种策略称为**双重哈希**。然而，无论如何实现探测，搜索或添加元素所需的时间都会随着哈希表填满而迅速增加。相比之下，链接的性能下降更为温和，即使哈希表并未填满，链接通常也比探测快。因此，通常更喜欢使用链接而不是探测。
- en: A recently popular variant of closed hashing is Cuckoo hashing, in which two
    hash functions are used. Each element is stored at one of the two locations computed
    by these hash functions, so at most two table locations must be consulted in order
    to determine whether the element is present. If both possible locations are occupied,
    the newly added element *displaces* the element that was there, and this element
    is then re-added to the table. In general, a chain of displacements occurs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最近流行的闭散列变体是Cuckoo散列，其中使用了两个哈希函数。每个元素存储在这些哈希函数计算的两个位置之一，因此最多只需查看两个表位置以确定元素是否存在。如果两个可能的位置都被占用，新添加的元素将*替换*那里的元素，然后将此元素重新添加到表中。一般来说，会发生一系列的替换。
- en: Performance of hash tables
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希表的性能
- en: Suppose we are using a chained hash table with m buckets, and the number of
    elements in the hash table is n. Then the average number of elements per bucket
    is n/m, which is called the **load factor** of the hash table, denoted α. When
    an element that is not in the hash table is searched for, the expected length
    of the linked list traversed is α. Since there is always the initial (constant)
    cost of hashing, the cost of hash table operations with a good hash function is,
    on average, O(1 + α). If we can ensure that the load factor α never exceeds some
    fixed value α[max], then all operations will be O(1 + α[max]) = O(1).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在使用具有m个桶的链接哈希表，哈希表中的元素数量为n。那么每个桶中的平均元素数量为n/m，称为哈希表的**负载因子**，表示为α。当搜索不在哈希表中的元素时，预期遍历的链表长度为α。由于哈希的初始（常数）成本始终存在，具有良好哈希函数的哈希表操作的成本平均为O(1
    + α)。如果我们能确保负载因子α永远不会超过某个固定值α[max]，那么所有操作都将是O(1 + α[max]) = O(1)。
- en: In practice, we will get the best performance out of hash tables when α is within
    a narrow range, from approximately 1/2 to 2\. If α is less than 1/2, the bucket
    array is becoming sparse and a smaller array is likely to give better performance.
    If α is greater than 2, the cost of traversing the linked lists limits performance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，当α在约为1/2到2之间的窄范围内时，哈希表的性能最佳。如果α小于1/2，则桶数组变得稀疏，较小的数组可能会提供更好的性能。如果α大于2，则遍历链表的成本限制了性能。
- en: One way to hit the desired range for α is to allocate the bucket array is just
    the right size for the number of elements that are being added to it. In general,
    however, it's hard to know ahead of time what this size will be, and in any case,
    the number of elements in the hash table may need to change over time.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 达到所需α范围的一种方法是为添加到其中的元素数量分配正确大小的桶数组。然而，一般来说，很难提前知道这个大小会是多少，而且无论如何，哈希表中的元素数量可能会随着时间的推移而改变。
- en: 'Step 4: Resizable arrays'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '步骤 4: 可调整大小的数组'
- en: Since we can't predict how big to make the bucket array ahead of time, why not
    dynamically adjust its size? We can use a **resizable array** data structure to
    achieve this. Instead of representing the hash table as a bucket array, we introduce
    a header object that contains a pointer to the current bucket array, and also
    keeps track of the number of elements in the hash table.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们无法预测何时才能使桶数组的大小达到所需大小，为什么不动态调整其大小呢？我们可以使用一个**可调整大小的数组**数据结构来实现这一点。我们不再将哈希表表示为桶数组，而是引入一个包含指向当前桶数组的指针的头对象，并且还跟踪哈希表中元素的数量。
- en: Whenever adding an element would cause α to exceed α[max], the hash table generates
    a new bucket array whose size is a multiple of the original size. Typically, the
    new bucket array is twice the size of the current one. Then, *all* of the elements
    must be rehashed into the new bucket array. This means a change of hash function;
    typically, hash functions are designed so they take the array size m as a parameter,
    so this parameter just needs to be changed.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每当添加一个元素会导致α超过α[max]时，哈希表就会生成一个新的桶数组，其大小是原始大小的倍数。通常，新的桶数组是当前桶数组大小的两倍。然后，*所有*元素都必须被重新哈希到新的桶数组中。这意味着哈希函数的变化；通常，哈希函数被设计为以数组大小m作为参数，因此只需要更改此参数。
- en: Amortized complexity
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摊销复杂度
- en: Since some add() operations cause all the elements to be rehashed, the cost
    of each such operation is O(n) in the number of elements. For a large hash table,
    this may take enough time that it causes problems for the program. Perhaps surprisingly,
    however, the cost per operation is still always O(1). In particular, any sequence
    of n operations on the hash table always takes O(n) time, or O(1) per operation.
    Therefore we say that the **amortized** asymptotic complexity of hash table operations
    is O(1).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于一些add()操作会导致所有元素被重新哈希，每个这样的操作的成本是元素数量的O(n)。对于大型哈希表，这可能需要足够的时间，导致程序出现问题。然而，令人惊讶的是，每个操作的成本仍然始终为O(1)。特别地，哈希表上的任何n个操作序列总是需要O(n)时间，或者每个操作为O(1)。因此，我们说哈希表操作的摊销渐近复杂度为O(1)。
- en: To see why this is true, consider a hash table with α[max] = 1\. The most expensive
    sequence of n operations we can do is a series of n add() calls where n = 2^j,
    meaning that the hash table resizes on the very last call to add(). The cost of
    the operations can be measured in the number of uses of the hash functions. There
    are n initial hashes when elements are added. The hash table is resized whenever
    it hits a power of two is size, so the extra hashes caused by resizing are 1 +
    2 + 4 + 8 + ... + 2^j. This sum is bounded by 2*2^j = 2n, so the total number
    of hashes is less than 3n, which is O(n).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要看到为什么这是正确的，考虑一个哈希表，其中α[max] = 1。我们可以做的最昂贵的n个操作序列是一系列n个add()调用，其中n = 2^j，这意味着哈希表在最后一次add()调用时调整大小。操作的成本可以通过哈希函数的使用次数来衡量。添加元素时会有n个初始哈希。当哈希表达到大小的2的幂时会调整大小，因此由调整大小引起的额外哈希是1
    + 2 + 4 + 8 + ... + 2^j。这个和被2*2^j = 2n所限制，所以总哈希数小于3n，即O(n)。
- en: Notice that it is crucial that the array size grows geometrically (doubling).
    It may be tempting to grow the array by a fixed increment (e.g., 100 elements
    at time), but this causes n elements to be rehashed O(n) times on average, resulting
    in O(n²) total insertion time, or amortized complexity of O(n).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，数组大小呈几何增长（翻倍）是至关重要的。固定增量（例如，每次增加100个元素）可能会很诱人，但这会导致平均情况下有n个元素被重新哈希O(n)次，导致O(n²)的总插入时间，或者摊销复杂度为O(n)。
- en: Hash functions
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希函数
- en: 'Hash tables are one of the most useful data structures ever invented. Unfortunately,
    they are also one of the most misused. Code built using hash tables often falls
    far short of achievable performance. There are two reasons for this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表是有史以来最有用的数据结构之一。不幸的是，它们也是最被滥用的之一。使用哈希表构建的代码通常远远达不到可实现的性能水平。造成这种情况的原因有两个：
- en: Clients choose poor hash functions that do not act like random number generators,
    invalidating the simple uniform hashing assumption.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端选择了不像随机数生成器一样工作的差劲哈希函数，使得简单均匀哈希假设无效。
- en: Hash table abstractions do not adequately specify what is required of the hash
    function, or make it difficult to provide a good hash function.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哈希表抽象并未充分指定哈希函数的要求，或者使得提供一个良好的哈希函数变得困难。
- en: Clearly, a bad hash function can destroy our attempts at a constant running
    time. A lot of obvious hash function choices are bad. For example, if we're mapping
    names to phone numbers, then hashing each name to its length would be a very poor
    function, as would a hash function that used only the first name, or only the
    last name. We want our hash function to use all of the information in the key.
    This is a bit of an art. While hash tables are extremely effective when used well,
    all too often poor hash functions are used that sabotage performance.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，糟糕的哈希函数会破坏我们对恒定运行时间的努力。很多明显的哈希函数选择都是糟糕的。例如，如果我们要将姓名映射到电话号码，那么将每个姓名哈希为其长度将是一个非常糟糕的函数，同样的，只使用名字或只使用姓氏的哈希函数也是如此。我们希望我们的哈希函数能够利用键中的所有信息。这有点像一门艺术。虽然哈希表在使用得当时非常有效，但常常使用糟糕的哈希函数来破坏性能。
- en: Recall that hash tables work well when the hash function satisfies the simple
    uniform hashing assumption -- that the hash function should look random. If it
    is to look random, this means that any change to a key, even a small one, should
    change the bucket index in an apparently random way. If we imagine writing the
    bucket index as a binary number, a small change to the key should randomly flip
    the bits in the bucket index. This is called **information diffusion**. For example,
    a one-bit change to the key should cause every bit in the index to flip with 1/2
    probability.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，哈希表在哈希函数满足简单均匀哈希假设时表现良好——即哈希函数应该看起来是随机的。如果要看起来是随机的，这意味着对键的任何更改，即使是很小的更改，也应该以明显随机的方式更改桶索引。如果我们想象将桶索引写成二进制数，那么对键进行一点小的更改应该以1/2的概率随机翻转桶索引中的位。这称为**信息扩散**。例如，对键进行一位的更改应该导致索引中的每一位以1/2的概率翻转。
- en: Client vs. implementer
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户端与实现者
- en: As we've described it, the hash function is a single function that maps from
    the key type to a bucket index. In practice, the hash function is the composition
    of *two* functions, one provided by the client and one by the implementer. This
    is because the implementer doesn't understand the element type, the client doesn't
    know how many buckets there are, and the implementer probably doesn't trust the
    client to achieve diffusion.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所描述的，哈希函数是将键类型映射到桶索引的单个函数。实际上，哈希函数是*两个*函数的组合，一个由客户端提供，一个由实现者提供。这是因为实现者不了解元素类型，客户端不知道有多少个桶，而且实现者可能不信任客户端能实现扩散。
- en: 'The client function h[client] first converts the key into an integer hash code,
    and the implementation function h[impl] converts the hash code into a bucket index.
    The actual hash function is the composition of these two functions, h[client]∘h[impl]:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端函数 h[client] 首先将键转换为整数哈希码，而实现函数 h[impl] 将哈希码转换为桶索引。实际的哈希函数是这两个函数的组合，即 h[client]∘h[impl]：
- en: '![](../Images/0dcf11e4ffae441924436699da8709c1.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![测量聚集](../Images/0dcf11e4ffae441924436699da8709c1.jpg)'
- en: To see what goes wrong, suppose our hash code function on objects is the memory
    address of the objects, as in Java. This is the usual choice. And suppose that
    our implementation hash function is like the one in SML/NJ; it takes the hash
    code modulo the number of buckets, where the number of buckets is always a power
    of two. This is also the usual implementation-side choice. But memory addresses
    are typically equal to zero modulo 16, so at most 1/16 of the buckets will be
    used, and the performance of the hash table will be 16 times slower than one might
    expect.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要看到问题出在哪里，假设我们对象的哈希码函数是对象的内存地址，就像在Java中一样。这是通常的选择。并且假设我们的实现哈希函数类似于SML/NJ中的函数；它将哈希码取模为桶的数量，其中桶的数量始终是2的幂。这也是通常的实现选择。但是内存地址通常对16取模等于零，所以最多只有1/16的桶会被使用，并且哈希表的性能将比预期慢16倍。
- en: Measuring clustering
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量聚集
- en: When the distribution of keys into buckets is not random, we say that the hash
    table exhibits **clustering**. It's a good idea to test your function to make
    sure it does not exhibit clustering with the data. With any hash function, it
    is possible to generate data that cause it to behave poorly, but a good hash function
    will make this unlikely.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当键被分配到桶中的分布不是随机时，我们称哈希表表现出**聚集**。测试函数以确保它在数据中不表现出聚集是一个好主意。使用任何哈希函数，都有可能生成导致其表现不佳的数据，但好的哈希函数会使这种情况不太可能发生。
- en: 'A good way to determine whether your hash function is working well is to measure
    clustering. If bucket *i* contains *x*[*i*] elements, then a good measure of clustering
    is the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 确定哈希函数是否工作良好的一种好方法是测量聚集度。 如果桶 *i* 包含 *x*[*i*] 个元素，则聚集度的一个很好的度量是以下内容：
- en: '*C* = (*m*/*n*−1)(∑[*i*](*x*[*i*]²)/*n*) - 1).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*C* = (*m*/*n*−1)(∑[*i*](*x*[*i*]²)/*n*) - 1)'
- en: A uniform hash function produces clustering *C* near 1.0 with high probability.
    A clustering measure of *C* > 1 greater than one means that the performance of
    the hash table is slowed down by clustering by approximately a factor of *C*.
    For example, if *m*=*n* and all elements are hashed into one bucket, the clustering
    measure evaluates to *n*. If the hash function is perfect and every element lands
    in its own bucket, the clustering measure will be 0\. If the clustering measure
    is less than 1.0, the hash function is spreading elements out more evenly than
    a random hash function would; not something to count on!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 均匀散列函数会产生接近 1.0 的聚集 *C*，其概率很高。 *C* 大于一的聚集度意味着散列表的性能受到了聚集的影响，大约减慢了 *C* 倍。例如，如果
    *m*=*n* 并且所有元素都散列到一个桶中，那么聚集度评估为 *n*。如果散列函数完美且每个元素都落入其自己的桶中，则聚集度将为 0。如果聚集度小于 1.0，则散列函数将元素更均匀地分布在桶中，而不是依靠随机散列函数！
- en: Unfortunately most hash table implementations do not give the client a way to
    measure clustering. This means the client can't directly tell whether the hash
    function is performing well or not. Hash table designers should provide some clustering
    estimation as part of the interface. Note that it's not necessary to compute the
    sum of squares of *all* bucket lengths; picking a few at random is cheaper and
    usually good enough.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数哈希表实现都不提供客户端测量聚集度的方法。 这意味着客户端无法直接判断哈希函数的性能如何。 哈希表设计者应该在接口的一部分中提供一些聚集度估计。
    请注意，不需要计算 *所有* 桶长度的平方和； 随机选择几个更便宜且通常足够了。
- en: The reason the clustering measure works is because it is based on an estimate
    of the **variance** of the distribution of bucket sizes. If clustering is occurring,
    some buckets will have more elements than they should, and some will have fewer.
    So there will be a wider range of bucket sizes than one would expect from a random
    hash function.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 聚集度工作的原因是因为它基于对桶大小分布的 **方差** 的估计。 如果发生聚集，一些桶将具有比预期更多的元素，而一些将具有更少的元素。 因此，桶的大小范围将比从随机散列函数中预期的要宽。
- en: '**For those who have taken some probability theory:** Consider bucket *i* containing
    *x*[*i*] elements. For each of the *n* elements, we can imagine a random variable
    *e*[*j*], whose value is 1 if the element lands in bucket *i* (with probability
    1/*m*), and 0 otherwise. The bucket size *x*[*i*] is a random variable that is
    the sum of all these random variables:'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**对于那些已经学过一些概率论的人：**考虑包含 *x*[*i*] 个元素的桶 *i*。 对于每个 *n* 个元素，我们可以想象一个随机变量 *e*[*j*]，如果元素落入桶
    *i*（概率为 1/*m*），则其值为 1，否则为 0。 桶大小 *x*[*i*] 是所有这些随机变量的总和：'
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*x*[*i*] = ∑[*j*∈1..*n*]*e*[*j*]'
  id: totrans-56
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*x*[*i*] = ∑[*j*∈1..*n*]*e*[*j*]'
- en: ''
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let''s write ⟨*x*⟩ for the **expected value** of variable *x*, and Var(*x*)
    for the **variance** of *x*, which is equal to ⟨(*x* - ⟨*x*⟩)²⟩ = ⟨*x*²⟩ - ⟨*x*⟩².
    Then we have:'
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 让我们用 ⟨*x*⟩ 表示变量 *x* 的 **期望值**，用 Var(*x*) 表示 *x* 的 **方差**，它等于 ⟨(*x* - ⟨*x*⟩)²⟩
    = ⟨*x*²⟩ - ⟨*x*⟩²。 那么我们有：
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ⟨*e[j]*⟩ = 1/*m*
  id: totrans-60
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⟨*e[j]*⟩ = 1/*m*
- en: ⟨*e[j]*²⟩ = 1/*m*
  id: totrans-61
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⟨*e[j]*²⟩ = 1/*m*
- en: Var(*e[j]*) = 1/*m* - 1/*m²*
  id: totrans-62
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Var(*e[j]*) = 1/*m* - 1/*m²*
- en: ⟨*x[i]*⟩ = *n*⟨*e[j]*⟩ = α
  id: totrans-63
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⟨*x[i]*⟩ = *n*⟨*e[j]*⟩ = α
- en: ''
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The variance of the sum of independent random variables is the sum of their
    variances. If we assume that the *e[j]* are independent random variables, then:'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 独立随机变量的总和的方差等于它们的方差之和。 如果我们假设 *e[j]* 是独立的随机变量，则：
- en: ''
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Var(*x*[*i*]) = *n* Var(*e*[*j*]) = α - α/*m* = ⟨*x*[*i*]²⟩ - ⟨*x*[*i*]⟩²
  id: totrans-67
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Var(*x*[*i*]) = *n* Var(*e*[*j*]) = α - α/*m* = ⟨*x*[*i*]²⟩ - ⟨*x*[*i*]⟩²
- en: ⟨*x*[*i*]²⟩ = Var(*x*[*i*]) + ⟨*x*[*i*]⟩²
  id: totrans-68
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⟨*x*[*i*]²⟩ = Var(*x*[*i*]) + ⟨*x*[*i*]⟩²
- en: = α(1 - 1/*m*) + α²
  id: totrans-69
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = α(1 - 1/*m*) + α²
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now, if we sum up all *m* of the variables *x[i]*, and divide by *n*, as in
    the formula, we should effectively divide this by α:'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在，如果我们将所有 *m* 个变量 *x[i]* 加起来，并按照公式除以 *n*，我们应该有效地将其除以 α：
- en: ''
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: (1/*n*) ⟨∑ *x*[*i*]²⟩ = (1/α)⟨*x*[*i*]²⟩ = 1 - 1/*m* + α
  id: totrans-73
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: (1/*n*) ⟨∑ *x*[*i*]²⟩ = (1/α)⟨*x*[*i*]²⟩ = 1 - 1/*m* + α
- en: ''
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Subtracting 1, we get (*n*−1)/*m*. The clustering measure multiplies this by
    its reciprocal to get 1.
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 减去 1，我们得到 (*n*−1)/*m*。 聚集度将其乘以其倒数以获得 1。
- en: ''
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Suppose instead we had a hash function that hit only one of every *c* buckets,
    but was random among those buckets. In this case, for the non-empty buckets, we'd
    have
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 假设我们有一个哈希函数，它只命中每个*c*个桶中的一个，但在这些桶中是随机的。在这种情况下，对于非空桶，我们将有
- en: ''
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ⟨*e[j]*⟩ = ⟨*e[j]²*⟩ = *c*/*m*
  id: totrans-79
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⟨*e[j]*⟩ = ⟨*e[j]²*⟩ = *c*/*m*
- en: ⟨*x[i]*⟩ = α*c*
  id: totrans-80
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⟨*x[i]*⟩ = α*c*
- en: (1/*n*) ⟨∑ *x*[*i*]²⟩ - 1 = α*c* − *c*/*m*
  id: totrans-81
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: (1/*n*) ⟨∑ *x*[*i*]²⟩ - 1 = α*c* − *c*/*m*
- en: = *c*(*n*-1)/*m*
  id: totrans-82
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: = *c*(*n*-1)/*m*
- en: ''
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Therefore, the clustering measure evaluates in this case to *c*. In other words,
    if the clustering measure gives a value significantly greater than one, it is
    like having a hash function that doesn't hit a substantial fraction of buckets.
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 因此，此时的聚类度量评估为*c*。换句话说，如果聚类度量给出的值显著大于1，则像具有未命中大部分桶的哈希函数。
- en: Designing a hash function
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计哈希函数
- en: 'For a hash table to work well, we want the hash function to have two properties:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使哈希表正常工作，我们希望哈希函数具有两个特性：
- en: '**Injection**: for two keys k[1] ≠ k[2], the hash function should give different
    results h(k[1]) ≠ h(k[2]), with probability m-1/m.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注入**：对于两个不同的密钥*k*[1] ≠ *k*[2]，哈希函数应该以概率*m*-1/*m*给出不同的结果*h*(*k*[1]) ≠ *h*(*k*[2])。'
- en: '**Diffusion** (stronger than injection): if k[1] ≠ k[2], knowing h(k[1]) gives
    *no information* about h(k[2]). For example, if k[2] is exactly the same as k[1],
    except for one bit, then every bit in h(k[2]) should change with 1/2 probability
    compared to h(k[1]). Knowing the bits of h(k[1]) does not give any information
    about the bits of h(k[2]).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩散**（比注入更强）：如果*k*[1] ≠ *k*[2]，则知道*h*(*k*[1])对*h*(*k*[2])不提供任何信息。例如，如果*k*[2]与*k*[1]完全相同，除了一个位，则*h*(*k*[2])中的每个位应该与*h*(*k*[1])相比以1/2的概率更改。知道*h*(*k*[1])的位不提供有关*h*(*k*[2])的位的任何信息。'
- en: As a hash table designer, you need to figure out which of the client hash function
    and the implementation hash function is going to provide diffusion. For example,
    Java hash tables provide (somewhat weak) information diffusion, allowing the client
    hashcode computation to just aim for the injection property. In SML/NJ hash tables,
    the implementation provide only the injection property. Regardless, the hash table
    specification should say whether the client is expected to provide a hash code
    with good diffusion (unfortunately, few do).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 作为哈希表设计者，您需要弄清楚客户端哈希函数和实现哈希函数哪个将提供扩散。例如，Java哈希表提供（稍弱的）信息扩散，允许客户端哈希码计算仅针对注入属性。在SML/NJ哈希表中，实现仅提供注入属性。无论如何，哈希表规范都应说明是否期望客户端提供具有良好扩散的哈希码（不幸的是，很少有这样的）。
- en: If clients are sufficiently savvy, it makes sense to push the diffusion onto
    them, leaving the hash table implementation as simple and fast as possible. The
    easy way to accomplish this is to break the computation of the bucket index into
    three steps.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果客户足够精明，将扩散推到他们身上是有意义的，这样可以使哈希表实现尽可能简单和快速。实现这一点的简单方法是将桶索引的计算分为三个步骤。
- en: 'Serialization: Transform the key into a stream of bytes that contains all of
    the information in the original key. Two equal keys must result in the same byte
    stream. Two byte streams should be equal only if the keys are actually equal.
    How to do this depends on the form of the key. If the key is a string, then the
    stream of bytes would simply be the characters of the string.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 序列化：将密钥转换为包含原始密钥中所有信息的字节流。两个相等的密钥必须产生相同的字节流。只有当密钥实际上相等时，两个字节流才应该相等。如何做到这一点取决于密钥的形式。如果密钥是一个字符串，那么字节流将简单地是字符串的字符。
- en: 'Diffusion: Map the stream of bytes into a large integer *x* in a way that causes
    every change in the stream to affect the bits of *x* apparently randomly. There
    are a number of good off-the-shelf ways to accomplish this, with a tradeoff in
    performance versus randomness (and security).'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩散：以一种使流中的每个变化似乎随机影响*x*的位的方式将字节流映射到一个大整数*x*中。有许多很好的现成方法可以做到这一点，性能与随机性（和安全性）之间存在权衡。
- en: Compute the hash bucket index as *x* mod *m*. This is particularly cheap if
    *m* is a power of two, but see the caveats below.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算哈希桶索引为*x* mod *m*。如果*m*是2的幂，则这尤其便宜，但请参见下面的注意事项。
- en: Therefore the client-side hash function *h[client]*(*k*) is defined as (*h[diff]*
    ∘ *h[serial]*)(*k*) mod *m*, where *h[diff]* implements diffusion.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，客户端哈希函数*h*[client](*k*)定义为(*h*[diff] ∘ *h*[serial])(*k*) mod *m*，其中*h*[diff]*实现扩散。
- en: 'There are several different good ways to implement diffusion (step 2): multiplicative
    hashing, modular hashing, cyclic redundancy checks, and secure hash functions
    such as MD5 and SHA-1\. They offer a tradeoff between collision resistance and
    performance.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种不同的好方法可以实现扩散（步骤 2）：乘法哈希、模块化哈希、循环冗余检查和安全哈希函数，如 MD5 和 SHA-1。它们在冲突抵抗力和性能之间提供了一种权衡。
- en: Usually, hash tables are designed in a way that doesn't let the client fully
    control the hash function. Instead, the client is expected to implement steps
    1 and 2 to produce an integer **hash code**, as in Java. The implementation side
    then uses the hash code and the value of *m* (usually not exposed to the client,
    unfortunately) to compute the bucket index.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，哈希表的设计不允许客户完全控制哈希函数。相反，客户端应该实现步骤 1 和 2 以生成整数**哈希码**，就像 Java 中那样。然后，实现方面使用哈希码和
    *m* 的值（通常不向客户端公开，遗憾的是）来计算桶索引。
- en: Some hash table implementations expect the hash code to look completely random,
    because they directly use the low-order bits of the hash code as a bucket index,
    throwing away the information in the high-order bits. Other hash table implementations
    take a hash code and put it through an additional step of applying an **integer
    hash function** that provides additional diffusion. With these implementations,
    the client doesn't have to be as careful to produce a good hash code,
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一些哈希表实现期望哈希码看起来完全随机，因为它们直接使用哈希码的低阶位作为桶索引，丢弃了高阶位的信息。其他哈希表实现采用哈希码并经过额外的步骤，应用一个提供额外扩散的**整数哈希函数**。对于这些实现，客户端不必太小心地生成好的哈希码，
- en: Any hash table interface should specify whether the hash function is expected
    to look random. If the client can't tell from the interface whether this is the
    case, the safest thing is to compute a high-quality hash code by hashing into
    the space of all integers. This may duplicate work done on the implementation
    side, but it's better than having a lot of collisions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 任何哈希表接口都应该指定哈希函数是否被期望看起来是随机的。如果客户端无法从接口中判断是否是这种情况，最安全的做法是通过哈希到所有整数空间来计算高质量的哈希码。这可能会重复实现方面的工作，但比有很多冲突要好。
- en: Modular hashing
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模块化哈希
- en: With **modular hashing**, the hash function is simply *h*(*k*) = *k* mod *m*
    for some *m* (usually, the number of buckets). The value *k* is an integer hash
    code generated from the key. If *m* is a power of two (i.e., *m*=2^(*p*)), then
    *h*(*k*) is just the *p* lowest-order bits of *k*. The SML/NJ implementation of
    hash tables does modular hashing with *m* equal to a power of two. This is very
    fast but the the client needs to design the hash function carefully.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**模块化哈希**，哈希函数简单地是 *h*(*k*) = *k* mod *m*，其中 *m* 为某个数（通常是桶的数量）。值 *k* 是从键生成的整数哈希码。如果
    *m* 是二的幂（即，*m*=2^(*p*)），那么 *h*(*k*) 就是 *k* 的 *p* 个最低位。SML/NJ 的哈希表实现使用 *m* 等于二的幂的模块化哈希。这非常快，但客户端需要仔细设计哈希函数。
- en: 'The Java `Hashmap` class is a little friendlier but also slower: it uses modular
    hashing with *m* equal to a prime number. Modulo operations can be accelerated
    by precomputing *1/m* as a fixed-point number, e.g. (2^(31)/*m*). A precomputed
    table of various primes and their fixed-point reciprocals is therefore useful
    with this approach, because the implementation can then use multiplication instead
    of division to implement the mod operation.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Java `Hashmap` 类稍微友好一些，但速度较慢：它使用 *m* 等于素数的模块化哈希。模运算可以通过预先计算 *1/m* 作为定点数来加速，例如（2^(31)/*m*）。因此，有一个预先计算的各种素数及其定点倒数的表对这种方法非常有用，因为实现可以使用乘法而不是除法来实现模运算。
- en: Multiplicative hashing
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 乘法哈希
- en: A faster but often misused alternative is **multiplicative hashing**, in which
    the hash index is computed as ⌊*m ** frac(*ka*)⌋. Here *k* is again an integer
    hash code, *a* is a real number and frac is the function that returns the fractional
    part of a real number. Multiplicative hashing sets the hash index from the fractional
    part of multiplying *k* by a large real number. It's faster if this computation
    is done using fixed point rather than floating point, which is accomplished by
    computing (*ka*/2*^q*) mod *m*for appropriately chosen integer values of *a, m,*
    and *q*. So *q* determines the number of bits of precision in the fractional part
    of *a*.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 更快但经常被误用的替代方法是**乘法哈希**，其中哈希索引计算为⌊*m ** frac(*ka*)⌋。这里*k*再次是一个整数哈希码，*a*是一个实数，frac是返回实数的小数部分的函数。乘法哈希通过将*k*乘以一个大实数的小数部分来设置哈希索引。如果使用固定点而不是浮点进行此计算，则速度更快，这可以通过计算(*ka*/2*^q*) mod *m*来实现，其中*a,
    m,*和*q*是适当选择的整数值。因此*q*确定了*a*小数部分的精度位数。
- en: 'Here is an example of multiplicative hashing code, written assuming a word
    size of 32 bits:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个乘法哈希代码的示例，假设字长为32位：
- en: '[PRE0]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Multiplicative hashing works well for the same reason that linear congruential
    multipliers generate apparently random numbers—it's like generating a pseudo-random
    number with the hashcode as the seed. The multiplier *a* should be large and its
    binary representation should be a "random" mix of 1's and 0's. Multiplicative
    hashing is cheaper than modular hashing because multiplication is usually considerably
    faster than division (or mod). It also works well with a bucket array of size
    *m*=2*^p*, which is convenient.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 乘法哈希之所以有效，原因与线性同余乘数生成表面上随机数的原因相同——就像使用哈希码作为种子生成伪随机数一样。乘数*a*应该很大，其二进制表示应该是1和0的“随机”混合。乘法哈希比模哈希更便宜，因为乘法通常比除法（或模）快得多。它还可以很好地与大小为*m*=2*^p*的桶数组配合使用，这很方便。
- en: In the fixed-point version, The division by 2^(*q*) is crucial. The common mistake
    when doing multiplicative hashing is to forget to do it, and in fact you can find
    web pages highly ranked by Google that explain multiplicative hashing without
    this step. Without this division, there is little point to multiplying by a, because
    *ka* mod *m* = (*k* mod *m*) * (*a* mod *m*) mod *m* . This is no better than
    modular hashing with a modulus of *m*, and quite possibly worse.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在固定点版本中，除以2^(*q*)是至关重要的。在进行乘法哈希时的常见错误是忘记执行此操作，实际上您可以找到谷歌高排名的网页，解释乘法哈希而没有这一步。如果没有这个除法，乘以*a*就没有意义，因为*ka* mod *m*
    = (*k* mod *m*) * (*a* mod *m*) mod *m*。这不比具有模*m*的模哈希更好，而且很可能更糟。
- en: Cyclic redundancy checks (CRCs)
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 循环冗余校验（CRC）
- en: For a longer stream of serialized key data, a cyclic redundancy check (CRC)
    makes a good, reasonably fast hash function. A CRC of a data stream is the remainder
    after performing a long division of the data (treated as a large binary number),
    but using exclusive or instead of subtraction at each long division step. This
    corresponds to computing a remainder in the field of polynomials with binary coefficients.
    CRCs can be computed very quickly in specialized hardware. Fast software CRC algorithms
    rely on precomputed tables of data. As a rule of thumb, CRCs are about 3-4 times
    slower than multiplicative hashing.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较长的序列化关键数据流，循环冗余校验（CRC）是一个不错的、相当快速的哈希函数。数据流的CRC是在执行数据的长除法后的余数（将其视为一个大二进制数），但在每个长除法步骤中使用异或而不是减法。这相当于在具有二进制系数的多项式域中计算余数。CRC可以在专用硬件上非常快速地计算。快速软件CRC算法依赖于预先计算的数据表。一般来说，CRC比乘法哈希慢大约3-4倍。
- en: Cryptographic hash functions
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 密码哈希函数
- en: 'Sometimes software systems are used by adversaries who might try to pick keys
    that collide in the hash function, thereby making the system have poor performance.
    **Cryptographic hash functions** are hash functions that try to make it computationally
    infeasible to invert them: if you know *h*(*x*), there is no way to compute *x*
    that is asymptotically faster than just trying all possible values and see which
    one hashes to the right result. Usually these functions also try to make it hard
    to find different values of *x* that cause collisions; they are **collision-resistant**.
    Examples of cryptographic hash functions are MD5 and SHA-1\. MD5 is not as strong
    as once thought, but it is roughly four times faster than SHA-1 and usually still
    fine for generating hash table indices. As a rule of thumb, MD5 is about twice
    as slow as using a CRC.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有时软件系统会被对手使用，他们可能会尝试选择在哈希函数中发生碰撞的密钥，从而使系统性能不佳。**密码哈希函数**是一种尝试使其计算上不可逆的哈希函数：如果你知道*h*(*x*)，那么没有比尝试所有可能的值并查看哪个值哈希到正确结果更快的方法来计算*x*。通常，这些函数还试图使找到导致碰撞的不同值*x*变得困难；它们是**抗碰撞**的。密码哈希函数的示例包括MD5和SHA-1。MD5并不像曾经想象的那样强大，但它大约比SHA-1快四倍，通常仍然适用于生成哈希表索引。粗略地说，MD5的速度大约是使用CRC的两倍。
- en: Precomputing hash codes
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预先计算哈希码
- en: High-quality hash functions can be expensive. If the same values are being hashed
    repeatedly, one trick is to precompute their hash codes and store them with the
    value. Hash tables can also store the full hash codes of values, which makes scanning
    down one bucket fast. In fact, if the hash code is long and the hash function
    is high-quality (e.g., 64+ bits of a properly constructed MD5 digest), two keys
    with the same hash code are almost certainly the same value. Your computer is
    then more likely to get a wrong answer from a cosmic ray hitting it than from
    a hash code collision.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 高质量的哈希函数可能很昂贵。如果相同的值被重复哈希，一个技巧是预先计算它们的哈希码并将其与值一起存储。哈希表还可以存储值的完整哈希码，这使得快速扫描一个桶变得快速。实际上，如果哈希码很长且哈希函数是高质量的（例如，64位以上的正确构造的MD5摘要），具有相同哈希码的两个密钥几乎可以肯定是相同的值。那么你的计算机更有可能因为宇宙射线击中它而得到错误答案，而不是因为哈希码碰撞。
