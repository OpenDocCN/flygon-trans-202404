["```\n # https://github.com/pytorch/examples/blob/master/mnist/main.py\nfrom __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\n# Training settings\nbatch_size = 64\n\n# MNIST Dataset\ntrain_dataset = datasets.MNIST(root='./data/',\n                               train=True,\n                               transform=transforms.ToTensor(),\n                               download=True)\n\ntest_dataset = datasets.MNIST(root='./data/',\n                              train=False,\n                              transform=transforms.ToTensor())\n\n# Data Loader (Input Pipeline)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False)\n\nclass InceptionA(nn.Module):\n\n    def __init__(self, in_channels):\n        super(InceptionA, self).__init__()\n        self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n\n        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n        self.branch5x5_2 = nn.Conv2d(16, 24, kernel_size=5, padding=2)\n\n        self.branch3x3dbl_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n        self.branch3x3dbl_2 = nn.Conv2d(16, 24, kernel_size=3, padding=1)\n        self.branch3x3dbl_3 = nn.Conv2d(24, 24, kernel_size=3, padding=1)\n\n        self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size=1)\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n\n        branch5x5 = self.branch5x5_1(x)\n        branch5x5 = self.branch5x5_2(branch5x5)\n\n        branch3x3dbl = self.branch3x3dbl_1(x)\n        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n\n        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n        branch_pool = self.branch_pool(branch_pool)\n\n        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n        return torch.cat(outputs, 1)\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(88, 20, kernel_size=5)\n\n        self.incept1 = InceptionA(in_channels=10)\n        self.incept2 = InceptionA(in_channels=20)\n\n        self.mp = nn.MaxPool2d(2)\n        self.fc = nn.Linear(1408, 10)\n\n    def forward(self, x):\n        in_size = x.size(0)\n        x = F.relu(self.mp(self.conv1(x)))\n        x = self.incept1(x)\n        x = F.relu(self.mp(self.conv2(x)))\n        x = self.incept2(x)\n        x = x.view(in_size, -1)  # flatten the tensor\n        x = self.fc(x)\n        return F.log_softmax(x)\n\nmodel = Net()\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        # sum up batch loss\n        test_loss += F.nll_loss(output, target, size_average=False).data[0]\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\nfor epoch in range(1, 10):\n    train(epoch)\n    test() \n```"]