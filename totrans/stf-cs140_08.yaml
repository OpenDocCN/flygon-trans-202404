- en: Scheduling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lecture Notes for CS 140
  prefs: []
  type: TYPE_NORMAL
- en: Spring 2014
  prefs: []
  type: TYPE_NORMAL
- en: John Ousterhout
  prefs: []
  type: TYPE_NORMAL
- en: 'Readings for this topic from *Operating Systems: Principles and Practice*:
    Chapter 7 up through Section 7.2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Resources fall into two classes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Non-preemptible: once given, it can''t be reused until thread gives it back.
    Examples are file space, terminal, and maybe memory.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Preemptible: processor or I/O channel. Can take resource away, use it for something
    else, then give it back later.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OS makes two related kinds of decisions about resources:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Allocation: who gets what. Given a set of requests for resources, which processes
    should be given which resources in order to make most efficient use of the resources?'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scheduling: how long can they keep it. When more resources are requested than
    can be granted immediately, in which order should the requests be serviced? Examples
    are processor scheduling (one processor, many threads), memory scheduling in virtual
    memory systems.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reminder of thread states for dispatching/scheduling:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ready: waiting for a core to become available'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Blocked: waiting for some other event (disk I/O, incoming network packet, etc.)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple Scheduling Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First-come-first-served (FCFS) scheduling (also called FIFO or non-preemptive):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep all of the ready threads in a single list called the *ready queue*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When a thread becomes ready, add it to the back of the ready queue.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the first thread on the queue until it exits or blocks.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Problem: one thread can monopolize a core.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Solution: limit maximum amount of time that a thread can run without a context
    switch. This time is called a *time slice*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Round robin scheduling: run thread for one time slice, then return to back
    of ready queue. Each thread gets equal share of the cores. Most systems use some
    variant of this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Typical time slice values: 10-100ms'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The length of a time slice is also called the *time quantum*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we decide whether a scheduling algorithm is good?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make users happy (minimize response time).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use resources efficiently:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Full utilization: keep cores and disks busy'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Low overhead: minimize context switches'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fairness (distribute CPU cycles equitably)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Is round-robin better than FCFS?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Optimal scheduling: STCF (Shortest Time to Completion First); also called SJF
    (Shortest Job First)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the thread that will finish most quickly, run it without interruptions.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another advantage of STCF: improves overall resource utilization.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppose some jobs CPU-bound, some I/O-bound.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: STCF will give priority to I/O-bound jobs, which keeps the disks/network as
    busy as possible.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Key idea: can use past performance to predict future performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Behavior tends to be consistent
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a process has been executing for a long time without blocking, it's likely
    to continue executing.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Priority-Based Scheduling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Priorities: most real schedulers support a priority for each thread:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always run the thread with highest priority.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In case of tie, use round-robin among highest priority threads
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use priorities to implement various scheduling policies (e.g. approximate STCF)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exponential Queues (or Multi-Level Feedback Queues): attacks both efficiency
    and response time problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One ready queue for each priority level.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Lower-priority queues have larger time slices (time slice doubles with each
    reduction in priority)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Newly runnable thread starts in highest priority queue
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If it reaches the end of its time slice without blocking it moves to the next
    lower queue.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Result: I/O-bound threads stay in the highest-priority queues, CPU-bound threads
    migrate to lower-priority queues'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the problems with this approach?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '4.4 BSD Scheduler (for first project):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep information about recent CPU usage for each thread
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Give highest priority to thread that has used the least CPU time recently.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Interactive and I/O-bound threads will use little CPU time and remain at high
    priority.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: CPU-bound threads will eventually get lower priority as they accumulate CPU
    time.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiprocessor Scheduling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multiprocessor scheduling is mostly the same as uniprocessor scheduling:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Share the scheduling data structures among all of the cores.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Run the k highest-priority threads on the k cores.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When a thread becomes runnable, see if its priority is higher than the lowest-priority
    thread currently running. If so, preempt that thread.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: However, a single ready queue can result in contention problems if there are
    lots of cores.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '2 special issues for multiprocessors:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Processor affinity:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once a thread has been running on a particular core it is expensive to move
    it to a different core (hardware caches will have to be reloaded).
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiprocessor schedulers typically try to keep a thread on the same core as
    much as possible to minimize these overheads.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gang scheduling:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the threads within a process are communicating frequently, it won''t make
    sense to run one thread without the others: it will just block immediately on
    communication with another thread.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Solution: run all of the threads of a process simultaneously on different cores,
    so they can communicate more efficiently.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This is called *gang scheduling.*
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Even if a thread blocks, it may make sense to leave it loaded on its core, on
    the assumption that it will unblock in the near future.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Scheduling algorithms should not affect the behavior of the system (same results
    regardless of schedule).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the algorithms do impact the system's efficiency and response time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best schemes are adaptive. To be optimal, we'd have to predict the future.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
