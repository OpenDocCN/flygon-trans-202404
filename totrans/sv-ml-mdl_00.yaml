- en: Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Machine learning is the hottest thing in software engineering today. There are
    a lot of publications on machine learning appearing daily, and new machine learning
    products are appearing all the time. [Amazon](http://bit.ly/what-is-amazon-ml),
    [Microsoft](http://bit.ly/azure-ml-modules), [Google](http://bit.ly/google-cloud-ml),
    [IBM](http://bit.ly/IBM-ml), and others have introduced machine learning as managed
    cloud offerings.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是当今软件工程中最热门的事物。每天都会出现大量关于机器学习的出版物，新的机器学习产品也不断出现。[亚马逊](http://bit.ly/what-is-amazon-ml)、[微软](http://bit.ly/azure-ml-modules)、[谷歌](http://bit.ly/google-cloud-ml)、[IBM](http://bit.ly/IBM-ml)等公司已经推出了作为托管云服务的机器学习产品。
- en: However, one of the areas of machine learning that is not getting enough attention
    is model serving—how to serve the models that have been trained using machine
    learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，机器学习中一个未受到足够关注的领域是模型服务——如何为使用机器学习训练的模型提供服务。
- en: The complexity of this problem comes from the fact that typically model training
    and model serving are responsibilities of two different groups in the enterprise
    who have different functions, concerns, and tools. As a result, the transition
    between these two activities is often nontrivial. In addition, as new machine
    learning tools appear, it often forces developers to create new model serving
    frameworks compatible with the new tooling.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的复杂性源于企业中通常模型训练和模型服务是由两个不同职能、关注点和工具的群体负责。因此，这两个活动之间的过渡通常并不简单。此外，随着新的机器学习工具的出现，通常会迫使开发人员创建与新工具兼容的新模型服务框架。
- en: This book introduces a slightly different approach to model serving based on
    the introduction of standardized document-based intermediate representation of
    the trained machine learning models and using such representations for serving
    in a stream-processing context. It proposes an overall architecture implementing
    controlled streams of both data and models that enables not only the serving of
    models in real time, as part of processing of the input streams, but also enables
    updating models without restarting existing applications.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书介绍了一种略有不同的模型服务方法，基于训练的机器学习模型的标准化基于文档的中间表示的引入，并在流处理上下文中使用这种表示进行服务。它提出了一个实现数据和模型的受控流的整体架构，不仅能够实时提供模型作为处理输入流的一部分，还能够在不重新启动现有应用程序的情况下更新模型。
- en: Who This Book Is For
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合谁？
- en: This book is intended for people who are interested in approaches to real-time
    serving of machine learning models supporting real-time model updates. It describes
    step-by-step options for exporting models, what exactly to export, and how to
    use these models for real-time serving.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适用于对支持实时模型更新的机器学习模型进行实时服务方法感兴趣的人。它逐步描述了导出模型的选项，要导出的内容以及如何使用这些模型进行实时服务。
- en: The book also is intended for people who are trying to implement such solutions
    using modern stream processing engines and frameworks such as Apache Flink, Apache
    Spark streaming, Apache Beam, Apache Kafka streams, and Akka streams. It provides
    a set of working examples of usage of these technologies for model serving implementation.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书还适用于那些试图使用现代流处理引擎和框架（如Apache Flink、Apache Spark Streaming、Apache Beam、Apache
    Kafka Streams和Akka Streams）实现这些解决方案的人。它提供了一组使用这些技术进行模型服务实现的实际示例。
- en: Why Is Model Serving Difficult?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么模型服务如此困难？
- en: 'When it comes to machine learning implementations, organizations typically
    employ two very different groups of people: data scientists, who are typically
    responsible for the creation and training models, and software engineers, who
    concentrate on model scoring. These two groups typically use completely different
    tools. Data scientists work with R, Python, notebooks, and so on, whereas software
    engineers typically use Java, Scala, Go, and so forth. Their activities are driven
    by different concerns: data scientists need to cope with the amount of data, data
    cleaning issues, model design and comparison, and so on; software engineers are
    concerned with production issues such as performance, maintainability, monitoring,
    scalability, and failover.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习实施方面，组织通常雇佣两组非常不同的人员：数据科学家，他们通常负责创建和训练模型，以及软件工程师，他们专注于模型评分。这两组通常使用完全不同的工具。数据科学家使用R、Python、笔记本等工具，而软件工程师通常使用Java、Scala、Go等工具。他们的活动受到不同的关注：数据科学家需要处理大量数据、数据清洗问题、模型设计和比较等问题；软件工程师关注生产问题，如性能、可维护性、监控、可扩展性和故障转移。
- en: These differences are currently fairly well [understood](http://bit.ly/spark-ml-lab-to-prod)
    and result in many “proprietary” model scoring solutions, for example, [Tensorflow
    model serving](https://tensorflow.github.io/serving/) and [Spark-based model serving](http://bit.ly/2xy47wV).
    Additionally all of the managed machine learning implementations ([Amazon](http://bit.ly/what-is-amazon-ml),
    [Microsoft](http://bit.ly/azure-ml-modules), [Google](http://bit.ly/google-cloud-ml),
    [IBM](http://bit.ly/IBM-ml), etc.) provide model serving capabilities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 目前对这些差异有相当深入的了解，并导致许多“专有”模型评分解决方案，例如[Tensorflow模型服务](https://tensorflow.github.io/serving/)和[基于Spark的模型服务](http://bit.ly/2xy47wV)。此外，所有托管的机器学习实施（[亚马逊](http://bit.ly/what-is-amazon-ml)、[微软](http://bit.ly/azure-ml-modules)、[谷歌](http://bit.ly/google-cloud-ml)、[IBM](http://bit.ly/IBM-ml)等）都提供模型服务功能。
- en: Tools Proliferation Makes Things Worse
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具的泛滥使情况变得更糟
- en: In his recent [talk](http://bit.ly/ted-dunning-ffsf-2017), Ted Dunning describes
    the fact that with multiple tools available to data scientists, they tend to use
    different tools to solve different problems (because every tool has its own sweet
    spot and the number of tools grows daily), and, as a result, they are not very
    keen on tools standardization. This creates a problem for software engineers trying
    to use “proprietary” model serving tools supporting specific machine learning
    technologies. As data scientists evaluate and introduce new technologies for machine
    learning, software engineers are forced to introduce new software packages supporting
    model scoring for these additional technologies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在他最近的[演讲](http://bit.ly/ted-dunning-ffsf-2017)中，Ted Dunning描述了数据科学家有多种工具可供选择，他们倾向于使用不同的工具来解决不同的问题（因为每个工具都有其独特的优势，而且工具数量每天都在增加），因此他们对工具标准化并不感兴趣。这给试图使用支持特定机器学习技术的“专有”模型服务工具的软件工程师带来了问题。随着数据科学家评估和引入新的机器学习技术，软件工程师被迫引入支持这些额外技术的模型评分的新软件包。
- en: One of the approaches to deal with these problems is the introduction of an
    [API gateway](https://github.com/ucbrise/clipper) on top of the proprietary systems.
    Although this hides the disparity of the backend systems from the consumers behind
    the unified APIs, for model serving it still requires installation and maintenance
    of the actual model serving implementations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这些问题的方法之一是在专有系统之上引入[API网关](https://github.com/ucbrise/clipper)。尽管这将后端系统的差异隐藏在统一的API背后，但对于模型服务仍需要安装和维护实际的模型服务实现。
- en: Model Standardization to the Rescue
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型标准化来拯救
- en: 'To overcome these complexities, the [Data Mining Group](http://dmg.org/) has
    introduced two model representation standards: [Predictive Model Markup Language
    (PMML)](http://dmg.org/pmml/v4-1/GeneralStructure.html) and [Portable Format for
    Analytics (PFA)](http://dmg.org/pfa/)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要克服这些复杂性，[数据挖掘组织](http://dmg.org/)引入了两种模型表示标准：[预测模型标记语言（PMML）](http://dmg.org/pmml/v4-1/GeneralStructure.html)和[分析便携格式（PFA）](http://dmg.org/pfa/)
- en: '[The Data Mining Group Defines PMML](http://dmg.org/pmml/pmml-v4-3.html) as:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据挖掘组织定义PMML](http://dmg.org/pmml/pmml-v4-3.html)为：'
- en: is an [XML](http://www.w3.org/TR/REC-xml/)-based language that provides a way
    for applications to define statistical and data-mining models as well as to share
    models between PMML-compliant applications.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 是一种基于[XML](http://www.w3.org/TR/REC-xml/)的语言，为应用程序提供了定义统计和数据挖掘模型以及在符合PMML的应用程序之间共享模型的方式。
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PMML provides applications a vendor-independent method of defining models so
    that proprietary issues and incompatibilities are no longer a barrier to the exchange
    of models between applications. It allows users to develop models within one vendor’s
    application, and use other vendors’ applications to visualize, analyze, evaluate
    or otherwise use the models. Previously, this was very difficult, but with PMML,
    the exchange of models between compliant applications is now straightforward.
    Because PMML is an XML-based standard, the specification comes in the form of
    an [XML Schema](http://dmg.org/pmml/v4-3/pmml-4-3.xsd).
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: PMML为应用程序提供了一种独立于供应商的定义模型的方法，因此专有问题和不兼容性不再是应用程序之间交换模型的障碍。它允许用户在一个供应商的应用程序中开发模型，并使用其他供应商的应用程序来可视化、分析、评估或以其他方式使用这些模型。以前，这是非常困难的，但有了PMML，符合标准的应用程序之间的模型交换现在变得简单。由于PMML是基于XML的标准，规范以[XML
    Schema](http://dmg.org/pmml/v4-3/pmml-4-3.xsd)的形式呈现。
- en: '[The Data Mining Group describes PFA](http://dmg.org/pfa/) as'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据挖掘组描述PFA](http://dmg.org/pfa/)如下：'
- en: 'an emerging standard for statistical models and data transformation engines.
    PFA combines the ease of portability across systems with algorithmic flexibility:
    models, pre-processing, and post processing are all functions that can be arbitrarily
    composed, chained, or built into complex workflows. PFA may be as simple as a
    raw data transformation or as sophisticated as a suite of concurrent data mining
    models, all described as a JSON or YAML configuration file.'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 是统计模型和数据转换引擎的新兴标准。PFA结合了跨系统易于移植性和算法灵活性：模型、预处理和后处理都是可以任意组合、链接或构建成复杂工作流程的函数。PFA可以简单到原始数据转换，也可以复杂到一套并发数据挖掘模型，所有这些都可以描述为JSON或YAML配置文件。
- en: 'Another de facto standard in machine learning today is [TensorFlow](https://www.tensorflow.org/)--an
    open-source software library for Machine Intelligence. Tensorflow can be defined
    as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 今天在机器学习中另一个事实上的标准是[TensorFlow](https://www.tensorflow.org/)——一个用于机器智能的开源软件库。Tensorflow可以定义如下：
- en: At a high level, TensorFlow is a Python library that allows users to express
    arbitrary computation as a graph of data flows. Nodes in this graph represent
    mathematical operations, whereas edges represent data that is communicated from
    one node to another. Data in TensorFlow are represented as tensors, which are
    multidimensional arrays.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在高层次上，TensorFlow是一个允许用户将任意计算表示为数据流图的Python库。图中的节点代表数学运算，而边代表从一个节点传递到另一个节点的数据。在TensorFlow中，数据被表示为张量，即多维数组。
- en: TensorFlow was released by Google in 2015 to make it easier for developers to
    design, build, and train deep learning models, and since then, it has become one
    of the most used software libraries for machine learning. You also can use TensorFlow
    as a backend for some of the other popular machine learning libraries, for example,
    [Keras](https://keras.io/). TensorFlow allows for the exporting of trained models
    in protocol buffer formats (both text and binary) that you can use for transferring
    models between machine learning and model serving. In an attempt to make TensorFlow
    more Java friendly, [TensorFlow Java APIs](http://bit.ly/tensorflow-java-apis)
    were released in 2017, which enable scoring TensorFlow models using any Java Virtual
    Machine (JVM)–based language.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow于2015年由Google发布，旨在使开发人员更容易设计、构建和训练深度学习模型，自那时起，它已成为最常用的机器学习软件库之一。您还可以将TensorFlow用作其他流行机器学习库的后端，例如[Keras](https://keras.io/)。TensorFlow允许以协议缓冲区格式（文本和二进制）导出训练好的模型，您可以将其用于在机器学习和模型服务之间传输模型。为了使TensorFlow更加友好于Java，于2017年发布了[TensorFlow
    Java APIs](http://bit.ly/tensorflow-java-apis)，这使得可以使用任何基于Java虚拟机（JVM）的语言对TensorFlow模型进行评分。
- en: All of the aforementioned model export approaches are designed for platform-neutral
    descriptions of the models that need to be served. Introduction of these model
    export approaches led to the creation of several software products dedicated to
    “generic” model serving, for example, [Openscoring](http://openscoring.io/) and
    [Open Data Group](https://www.opendatagroup.com/).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所有上述的模型导出方法都是为需要提供服务的模型设计的平台中立描述。引入这些模型导出方法导致了几个专门用于“通用”模型服务的软件产品的创建，例如，[Openscoring](http://openscoring.io/)
    和 [Open Data Group](https://www.opendatagroup.com/)。
- en: 'Another result of this standardization is the creation of open source projects,
    building generic “evaluators” based on these formats. [JPMML](https://github.com/jpmml/jpmml-evaluator)
    and [Hadrian](https://github.com/opendatagroup/hadrian) are two examples that
    are being adopted more and more for building model-serving implementations, such
    as in these example projects: [ING](http://bit.ly/erik-de-noojj-ffsf-2017), [R
    implementation](http://fastdatageek.blogspot.com/2014/03/), [SparkML support](https://github.com/jpmml/jpmml-evaluator-spark),
    [Flink support](https://github.com/FlinkML/flink-jpmml), and so on.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这种标准化的另一个结果是创建基于这些格式的通用“评估器”的开源项目。[JPMML](https://github.com/jpmml/jpmml-evaluator)
    和 [Hadrian](https://github.com/opendatagroup/hadrian) 是两个越来越多被采用用于构建模型服务实现的例子，比如这些示例项目：[ING](http://bit.ly/erik-de-noojj-ffsf-2017),
    [R implementation](http://fastdatageek.blogspot.com/2014/03/), [SparkML support](https://github.com/jpmml/jpmml-evaluator-spark),
    [Flink support](https://github.com/FlinkML/flink-jpmml)，等等。
- en: Additionally, because models are represented not as code but as data, usage
    of such a model description allows manipulation of models as a special type of
    data that is fundamental for our proposed solution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，因为模型不是表示为代码而是表示为数据，使用这种模型描述允许对模型进行操作，作为我们提出的解决方案的基础的一种特殊类型的数据。
- en: Why I Wrote This Book
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么写这本书
- en: This book describes the problem of serving models resulting from machine learning
    in streaming applications. It shows how to export trained models in TensorFlow
    and PMML formats and use them for model serving, using several popular streaming
    engines and frameworks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本书描述了在流式应用程序中为机器学习产生的模型提供服务的问题。它展示了如何将训练好的模型导出为 TensorFlow 和 PMML 格式，并在几个流行的流式引擎和框架中使用它们进行模型服务。
- en: 'I deliberately do not favor any specific solution. Instead, I outline options,
    with some pros and cons. The choice of the best solution depends greatly on the
    concrete use case that you are trying to solve, more precisely:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我故意不偏袒任何特定解决方案。相反，我概述了一些优缺点的选项。选择最佳解决方案在很大程度上取决于您试图解决的具体用例，更准确地说：
- en: The number of models to serve. Increasing the number of models will skew your
    preference toward the use of the key-based approach, like Flink key-based joins.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要提供服务的模型数量。增加模型数量将使您更倾向于使用基于键的方法，比如 Flink 基于键的连接。
- en: The amount of data to be scored by each model. Increasing the volume of data
    suggests partition-based approaches, like Spark or Flink partition-based joins.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个模型要评分的数据量。增加数据量建议使用基于分区的方法，比如 Spark 或 Flink 基于分区的连接。
- en: The number of models that will be used to score each data item. You’ll need
    a solution that easily supports the use of composite keys to match each data item
    to multiple models.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将用于对每个数据项进行评分的模型数量。您需要一个能够轻松支持使用复合键将每个数据项与多个模型匹配的解决方案。
- en: The complexity of the calculations during scoring and additional processing
    of scored results. As the complexity grows, so will the load grow, which suggests
    using streaming engines rather than streaming libraries.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评分过程中的计算复杂性以及评分结果的额外处理。随着复杂性的增加，负载也会增加，这表明应该使用流式引擎而不是流式库。
- en: Scalability requirements. If they are low, using streaming libraries like Akka
    and Kafka Streams can be a better option due to their relative simplicity compared
    to engines like Spark and Flink, their ease of adoption, and the relative ease
    of maintaining these applications.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性要求。如果要求较低，使用像 Akka 和 Kafka Streams 这样的流式库可能是一个更好的选择，因为相对于 Spark 和 Flink
    这样的引擎，它们相对简单，易于采用，并且相对容易维护这些应用程序。
- en: Your organization’s existing expertise, which can suggest making choices that
    might be suboptimal, all other considerations being equal, but are more comfortable
    for your organization.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您组织现有的专业知识，这可能表明在其他所有考虑因素相等的情况下，可能会做出次优选择，但对于您的组织来说更为舒适。
- en: I hope this book provides the guidance you need for implementing your own solution.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这本书能为您实现自己解决方案提供所需的指导。
- en: How This Book Is Organized
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书的组织方式
- en: 'The book is organized as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本书组织如下：
- en: '[Chapter 1](ch01.html#proposed_implementation) describes the overall proposed
    architecture.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 1 章](ch01.html#proposed_implementation) 描述了整体提议的架构。'
- en: '[Chapter 2](ch02.html#exporting_models) talks about exporting models using
    examples of TensorFlow and PMML.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 2 章](ch02.html#exporting_models) 讨论了使用 TensorFlow 和 PMML 示例导出模型。'
- en: '[Chapter 3](ch03.html#implementing_model_scoring) describes common components
    used in all solutions.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 3 章](ch03.html#implementing_model_scoring) 描述了所有解决方案中使用的常见组件。'
- en: '[Chapter 4](ch04.html#apache_flink_implementation) through [Chapter 8](ch08.html#akka_streams_implementation)
    describe model serving implementations for different stream processing engines
    and frameworks.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 4 章](ch04.html#apache_flink_implementation) 到 [第 8 章](ch08.html#akka_streams_implementation)
    描述了不同流处理引擎和框架的模型服务实现。'
- en: '[Chapter 9](ch09.html#monitoring) covers monitoring approaches for model serving
    implementations.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 9 章](ch09.html#monitoring) 涵盖了模型服务实现的监控方法。'
- en: A Note About Code
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有关代码的说明
- en: 'The book contains a lot of code snippets. You can find the complete code in
    the following Git repositories:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 该书包含许多代码片段。您可以在以下 Git 存储库中找到完整的代码：
- en: '[Python examples](https://github.com/typesafehub/fdp-tensorflow-python-examples)
    is the repository containing Python code for exporting TensorFlow models described
    in [Chapter 2](ch02.html#exporting_models).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 示例](https://github.com/typesafehub/fdp-tensorflow-python-examples)
    是包含导出 TensorFlow 模型代码的 Python 代码的存储库，描述在 [第 2 章](ch02.html#exporting_models) 中。'
- en: '[Beam model server](https://github.com/typesafehub/fdp-beam-modelServer) is
    the repository containing code for the Beam solution described in [Chapter 5](ch05.html#apache_beam_implementation).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Beam 模型服务器](https://github.com/typesafehub/fdp-beam-modelServer) 是包含 [第 5
    章](ch05.html#apache_beam_implementation) 中描述的 Beam 解决方案代码的存储库。'
- en: '[Model serving](https://github.com/typesafehub/fdp-modelserver) is the repository
    containing the rest of the code described in the book.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型服务](https://github.com/typesafehub/fdp-modelserver) 是包含书中描述的其余代码的存储库。'
- en: Acknowledgments
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: 'I would like to thank the people who helped me in writing this book and making
    it better, especially:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢那些在撰写本书和改进书籍方面帮助我的人，特别是：
- en: Konrad Malawski, for his help with Akka implementation and overall review
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Konrad Malawski，对 Akka 实现和整体审查的帮助
- en: Dean Wampler, who did a thorough review of the overall book and provided many
    useful suggestions
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dean Wampler，对整本书进行了彻底审查并提供了许多有用的建议
- en: Trevor Grant, for conducting a technical review
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trevor Grant，进行技术审查
- en: The entire Lightbend Fast Data team, especially Stavros Kontopoulos, Debasish
    Ghosh, and Jim Powers, for many useful comments and suggestions about the original
    text and code
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整个 Lightbend Fast Data 团队，特别是 Stavros Kontopoulos、Debasish Ghosh 和 Jim Powers，对原始文本和代码提出了许多有用的评论和建议
