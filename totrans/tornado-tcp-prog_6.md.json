["```\ndef sig_handler(sig, frame):\n    logger.warning('Caught signal: %s', sig)\n    ioloop.IOLoop.instance().add_callback(shutdown)\n\ndef shutdown():\n    io_loop = ioloop.IOLoop.instance()\n    server.stopFactory() ##\u81ea\u5df1\u53bb\u505a\u4e00\u4e9b\u5904\u7406\uff0c\u4fdd\u8bc1\u5165\u5e93\u7b49\u3002\n\n    deadline = time.time() + 5\n\n    def stop_loop():\n        now = time.time()\n        if now < deadline and io_loop._callbacks:\n            io_loop.add_timeout(now + 1, stop_loop)\n        else:\n            io_loop.stop() # \u5904\u7406\u5b8c\u73b0\u6709\u7684 callback\u540e\uff0c\u7ed3\u675fioloop\u5faa\u73af\n    stop_loop()\n\ndef start():\n    log_initialize()\n    global server\n    server = RPCServer(('localhost', 5700))\n    server.start()\n\n    signal.signal(signal.SIGTERM, sig_handler)\n    signal.signal(signal.SIGINT, sig_handler) \n```", "```\ncollect.py\n\n#1.\u7b2c\u4e00\u79cd\u65b9\u6cd5\u4e5f\u6bd4\u8f83\u50bb\uff0c\u9002\u5408rpc\u6587\u4ef6\u8f83\u5c11\u7684\u60c5\u51b5\nimport rpc1\n\nDICT = {}\n\nfor name in dir(rpc1):\n    if name.startswith(\"__\") or name.endswith(\"__\"):\n        continue\n    DICT[name] = getattr(rpc1, name)\n\nrpc1.py\n\n#\u88ab\u8c03\u7528\u51fd\u6570\ndef func():\n    return 1 \n```", "```\n#\u7b2c\u4e8c\u79cd\u76f8\u5bf9\u667a\u80fd\u4e00\u4e9b\n\u5c06\u6240\u6709\u53ef\u88ab\u8c03\u7528\u51fd\u6570\u7684\u6587\u4ef6\u5199\u5165\u56fa\u5b9a\u6587\u4ef6\u5939\u4e2d\uff0c\u6bd4\u5982\u53d6\u540d\u4e3ahandler\u7684\u6587\u4ef6\u5939\u3002\u76f4\u63a5\u5c06\u6a21\u5757import\u6216\u8005\u4e5f\u53ef\u4ee5\u5199\u5165\u4e00\u4e2a\u5b57\u5178\u4e2d\n#name\u4e3a\u5f53\u524d\u6587\u4ef6\u4e0ehandler\u7684\u76f8\u5bf9\u8def\u5f84\n_imported = []\nfor f in os.listdir(name + \"/handler\"):\n    if f.find('.pyc') > 0:\n        _subfix = '.pyc'\n    elif f.find('.pyo') > 0:\n        _subfix = '.pyo'\n    elif f.find('.py') > 0:\n        _subfix = '.py'\n    else:\n        continue\n\n    fname, _ = f.rsplit(_subfix, 1)\n    if fname and fname not in _imported:\n        _handlers_name = '%s.%s' % (module, fname)\n        __import__(_handlers_name)\n        _imported.append(fname) \n```", "```\n#1.mysql\u7b97\u662f\u6700\u5e38\u7528\u7684\u6570\u636e\u5e93\u4e4b\u4e00\u4e86,\u4e0d\u8981\u94b1,\u529f\u80fd\u9f50\u5168,\u6027\u80fd\u4f18\u826f\u3002\u8fd9\u91cc\u4e3b\u8981\u4f7f\u7528tornado\u7684\u4e00\u6b3eapi,\n#tornado_mysql\u3002\n\nfrom tornado_mysql      import pools\nfrom tornado            import gen\nfrom tornado            import ioloop\nfrom tornado.concurrent import Future\nfrom pool               import threadpool\n\nimport functools\n\nSYNC, ROW, DATASET = range(3)\n\n__pool = None\n\nioloop = ioloop.IOLoop.current()\n\ndef init(**conf):\n    global __pool\n\n    if not __pool:\n        __pool = pools.Pool(conf, max_idle_connections=5, max_recycle_sec=3)\n\n@gen.coroutine\ndef execute(sql, value=None, operator=SYNC):\n    assert __pool is not None\n\n    result = None\n    if value is None:\n        cur = yield __pool.execute(sql)\n    else:\n        yield __pool.execute(sql, value)\n    if operator == ROW:\n        result = cur.fetchone()\n    elif operator == DATASET:\n        result = cur.fetchall()\n    raise gen.Return(result)\n\nfetchone = functools.partial(execute, operator=ROW)\nfetchall = functools.partial(execute, operator=DATASET)\n#\u5bf9\u51e0\u79cd\u7b80\u5355\u7684\u6570\u636e\u5e93\u64cd\u4f5c\u8fdb\u884c\u4e86\u7b80\u5355\u7684\u5c01\u88c5,\u4fbf\u4e8e\u5f00\u53d1\u4e2d\u7684\u4f7f\u7528\u3002 \n```", "```\n#2.redis\u7b97\u662f\u6bd4\u8f83\u5e38\u7528\u7684\u6570\u636e\u5e93\u4e4b\u4e00\uff0c\u4e00\u822c\u4f7f\u7528\u6765\u505acache,\u4e5f\u6709\u505a\u6d88\u606f\u961f\u5217\u7684\u3002\u8fd9\u91cc\u7528\u7684\u662f\n#tornadoredis\u8fd9\u6b3eapi\u3002\n\nimport tornadoredis\nfrom tornado import gen\nfrom tornado.concurrent import Future\n\npool = None\n\ndef init():\n    global pool\n\n    if not pool:\n        CONNECTION_POOL = tornadoredis.ConnectionPool(max_connections=500, wait_for_available=True)\n        pool = tornadoredis.Client(connection_pool=CONNECTION_POOL, selected_db=12) \n\n@gen.coroutine\ndef close():\n    if pool:\n        yield pool.disconnect()\n\n@gen.coroutine\ndef batch(commands):\n    assert pool is not None\n    result = None\n    try:\n        pipe = pool.pipeline()\n\n        for _cmd in commands:\n            _op   = _cmd[0]\n            _args = _cmd[1]\n\n            if len(_cmd) > 2:\n                _kwargs = _cmd[2]\n            else:\n                _kwargs = {}\n\n            getattr(pipe, _op)(*args, **kwargs)\n\n        result = yield gen.Task(pipe.execute)\n    except Exception as e:\n        print e\n\n    raise Return(result)\n\ndef execute(cmd, *args, **kwargs):\n    assert pool is not None\n    f = Future()\n    def onResult(result):\n        f.set_result(result)\n\n    result = None\n    _func  = getattr(pool, cmd)\n    _func(callback=onResult, *args, **kwargs)\n    return f\n\n#\u5bf9redis\u7684\u64cd\u4f5c\u8fdb\u884c\u4e86\u7edf\u4e00\u5c01\u88c5,\u76f4\u63a5\u4f7f\u7528execute\u5c31\u53ef\u4ee5, \u5c06\u547d\u4ee4\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u3002\u591a\u4e2a\u547d\u4ee4\u7684\u6267\u884c\u53ef\u4ee5\u4f7f\u7528batch\u6765\u6267\u884c, \u4f7f\u7528pipe\u63d0\u9ad8\u6267\u884c\u6548\u7387\u3002 \n```", "```\nEXECUTOR = ThreadPoolExecutor(max_workers=4)\uff03\u6700\u5927\u7ebf\u7a0b\u6570\n\ndef unblock(f):\n    @tornado.web.asynchronous\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        self = args[0]\n        def callback(future):\n            self.write(future.result())#\u5c06f\u7ed3\u679c\u5199\u56de\u7ed9client\n            self.finish()\n\n        EXECUTOR.submit(\n                partial(f, *args, **kwargs)#\u542f\u7528\u591a\u7ebf\u7a0b\n                ).add_done_callback(#\u56e0\u4e3a\u662f\u5f02\u6b65\u6267\u884c\uff0c\u6240\u4ee5\u8fd4\u56de\u503c\u662ffuture\n                        lambda future: tornado.ioloop.IOLoop.instance().add_callback(\n                            partial(callback, future)))#\u6700\u540e\u5199\u56declient\u7684\u6b65\u9aa4\u8981\u5728\u4e3b\u7ebf\u7a0b\u4e2d\u5b8c\u6210\uff0c\u5426\u5219\u4f1a\u51fa\u9519\uff0c\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u56de\u8c03\u6765\u5c06f\u8fd4\u56de\u7684future\u8fd4\u56de\u5230\u4e3b\u7ebf\u7a0b\u4e2d\u3002\n    return wrapper\n\nclass MainHandler(tornado.web.RequestHandler):\n    @unblock\n    def get(self):\n        sleep(3)\n        #self.write(\"ff\")\n        return \"ff\" \n```", "```\nfrom celery import Celery, task\n\nc = Celery()\n\n\u8fd9\u662f\u6700\u57fa\u672c\u7684\u7528\u6cd5\u3002\n\n\u6211\u4eec\u60f3\u8981\u5b9a\u4e49\u4e00\u4e2a\u4efb\u52a1\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5199\u4e00\u4e2a\u5f88\u666e\u901a\u7684\u65b9\u6cd5\uff0c\u6bd4\u5982\n\n@task\ndef mytask(a):\n    print 1111\n\n\u53ea\u8981\u52a0\u4e0a@task\u8fd9\u6837\u4e00\u4e2a\u88c5\u9970\u5668\uff0c\u5b83\u5c31\u4f1a\u6807\u8bc6\u4e3a\u4e00\u4e2acelery\u7684task\u3002\u6211\u4eec\u5c31\u53ef\u4ee5\u8c03\u7528\u4ed6\u4e86\u3002\n\n\u9996\u5148\u6211\u4eec\u8981\u542f\u52a8celery\uff0c\u4e0b\u9762\u662f\u6211\u7684\u542f\u52a8\u547d\u4ee4\ncelery -A my.utils.async_task worker -P gevent -c 2 -l info -n 'my.worker.%%h.%(ENV_USER)s'\n\n\u76f8\u5173\u53c2\u6570\u5b98\u65b9\u6587\u6863\u4e2d\u90fd\u53ef\u4ee5\u67e5\u5230\uff0c\u8fd9\u91cc\u5c31\u4e0d\u4e00\u4e00\u8be6\u8ff0\u4e86\u3002\n\n\u8c03\u7528\u7684\u65f6\u5019\uff0c\u6211\u4eec\u8981\u8fd9\u6837\n\nv = mytask.apply_async(111, countdown=1)\n\u4ed6\u7684\u8fd4\u56de\u503c\u662f\u4ed6\u7684\u4efb\u52a1id\uff0c\u901a\u8fc7\u4efb\u52a1id\uff0c\u6211\u4eec\u53ef\u4ee5\u53d6\u6d88\u4efb\u52a1,countdown\u4ee3\u8868\u591a\u5c11\u79d2\u4ee5\u540e\u6267\u884c\n\nrevoke\u51fd\u6570\u5c31\u662f\u53d6\u6d88\u4efb\u52a1\u7684\uff0crevoke(task_id) \n```"]