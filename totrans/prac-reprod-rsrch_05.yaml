- en: The Basic Reproducible Workflow Template
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本可重复工作流程模板
- en: The Basic Reproducible Workflow Template
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本可重复工作流程模板
- en: Justin Kitzes
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Justin Kitzes
- en: The core of this book consists of a set of thirty-one contributed case studies,
    each showing an example of a scientific workflow that was designed, at least in
    part, to achieve the goal of reproducibility. These case studies are concerned
    mainly with the goal of computational reproducibility, the ability of a second
    researcher to receive a set of files, including data, code, and documentation,
    and to recreate or recover the outputs of a research project, including figures,
    tables, and other key quantitative and qualitative results.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的核心是一组三十一个案例研究，每个案例研究都展示了一个科学工作流程的例子，该工作流程至少在某种程度上是为了实现可重复性而设计的目标。这些案例研究主要涉及计算可重复性的目标，即第二个研究者能够接收一组文件，包括数据、代码和文档，并重新创建或恢复研究项目的输出，包括图表和其他关键的定量和定性结果。
- en: The thirty-one case studies in this volume describe a wide variety of research
    projects, disciplines, methods, and tools. Behind this diversity, however, all
    of the case studies share many key principles and practices in common. In this
    chapter, we describe what we view as the basic, underlying reproducible research
    workflow that any scientist should master before continuing on to the complexities
    described in the case study chapters.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本卷中的三十一个案例研究描述了各种各样的研究项目、学科、方法和工具。然而，在这种多样性背后，所有案例研究都有许多共同的关键原则和实践。在本章中，我们描述了我们认为是任何科学家在继续阅读案例研究章节中描述的复杂性之前应该掌握的基本、潜在的可重复研究工作流程。
- en: 'To demonstrate this basic workflow, this chapter walks through a complete,
    concrete example of perhaps the simplest realistic data-intensive research project:
    a regression analysis of a single tabular data set. This example is designed to
    provide useful background for understanding the case studies later in this book.
    It will also provide a self-contained introduction to the practice of reproducible
    research for beginning readers looking for a template to adapt to their own research
    needs. We particularly encourage beginning readers to work along interactively
    with the example in this chapter to get a feel for how a reproducible workflow
    can be implemented.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这个基本工作流程，本章通过一个完整的、具体的例子走过了一个可能是最简单的现实数据密集型研究项目：对单个表格数据集进行回归分析。这个例子旨在为理解本书后面描述的案例研究提供有用的背景。它还将为寻找适应自己研究需求的模板的初学者提供一个独立的可重复研究实践介绍。我们特别鼓励初学者与本章中的示例互动工作，以了解可重复工作流程如何实现。
- en: We begin this chapter with a general overview of three key practices that are
    needed to make any research project, no matter how simple, computationally reproducible.
    This is followed by a high-level overview of the basic reproducible research workflow.
    We then provide an extended example of how this workflow can be implemented in
    a simple research project. We conclude with some additional considerations that
    arise when transitioning from this simple workflow template to more complex workflows,
    such as those described in the contributed case study chapters.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从介绍使任何研究项目，无论多么简单，都能计算上可重复所需的三个关键实践开始本章。接下来是基本可重复研究工作流程的高层次概述。然后，我们提供了如何在一个简单的研究项目中实现这个工作流程的扩展示例。最后，我们总结了从这个简单工作流程模板转换到更复杂工作流程时涉及的一些额外考虑因素，比如那些在案例研究章节中描述的。
- en: Three Key Practices
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 三个关键实践
- en: 'Chapter 2 described a set of questions that can be used to assess, at a relatively
    fine grained level, the extent to which a research project is reproducible. At
    a higher level, we can summarize these recommendations in three general practices
    that arise repeatedly throughout all stages of a research project:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第二章描述了一组问题，可用于相对细粒度地评估研究项目的可重复性程度。在更高的层次上，我们可以总结这些建议为三个通用实践，这些实践在研究项目的所有阶段都反复出现：
- en: Clearly separate, label, and document all data, files, and operations that occur
    on data and files
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清晰地分离、标记和记录所有数据、文件和对数据和文件的操作
- en: Document all operations fully, automating them as much as possible, and avoiding
    manual intervention in the workflow when feasible
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完全记录所有操作，尽可能自动化，并在可行时避免手动干预工作流程
- en: Design a workflow as a sequence of small steps that are glued together, with
    intermediate outputs from one step feeding into the next step as inputs
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将工作流程设计为一系列小步骤的序列，这些步骤通过一个步骤的中间输出作为下一个步骤的输入而粘合在一起。
- en: At a beginning level, the first of these practices largely involves placing
    files in a clear directory structure and creating metadata to describe them. The
    second is met by writing code, or scripts, to perform each step automatically,
    or where this is not possible, documenting all manual steps needed to complete
    a task at a level that would allow a second researcher to unambiguously repeat
    them. The third is met through the overall workflow design, especially a clear
    conceptualization of the different operations that need to occur sequentially
    and how they support each other.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在初级阶段，第一项实践主要涉及将文件放置在清晰的目录结构中，并创建元数据来描述它们。第二项实践是通过编写代码或脚本来自动执行每个步骤，或者在不可能的情况下，记录完成任务所需的所有手动步骤，以便第二个研究人员可以明确地重复它们。第三项实践是通过整体工作流程设计来实现，特别是清晰地概念化需要按顺序发生的不同操作以及它们如何相互支持。
- en: Although not described in the example below, most of the contributed case studies
    in this book use version control software as a tool for following the first two
    practices above. In short, version control is used to capture a snapshot of all
    of a project's files at any moment in time, allowing a researchers to easily review
    the history of the project and to manage future changes. Version control also
    provides a means of documenting and tracking changes to project files in a systematic
    and transparent manner.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管下面的示例中没有描述，但本书中大多数贡献的案例研究都使用版本控制软件作为遵循上述前两项实践的工具。简而言之，版本控制用于在任何时刻捕获项目所有文件的快照，使研究人员能够轻松地查看项目的历史并管理未来的更改。版本控制还提供了一种系统和透明地记录和跟踪项目文件更改的方法。
- en: In our experience, however, many beginners find version control more difficult
    to learn than the other steps described below, and thus we have chosen not to
    include it in this basic workflow template. However, once you feel comfortable
    with this basic workflow, we recommend that you progress to one of the many online
    tutorials that can help you learn to use version control systems. We particularly
    recommend the tutorials on `git` available from Software Carpentry.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，根据我们的经验，许多初学者发现版本控制比下面描述的其他步骤更难学习，因此我们选择不在此基本工作流程模板中包含它。然而，一旦您对这个基本工作流程感到舒适，我们建议您进一步学习使用版本控制系统的许多在线教程之一。我们特别推荐软件工坊提供的关于`git`的教程。
- en: The Stages of the Basic Reproducible Workflow
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本可重现工作流程的阶段
- en: 'The basic reproducible research workflow can be divided into three main stages:
    data acquisition, data processing, and data analysis. These three stages are preceded
    by activities related to system setup, and are succeeded by steps that automate
    the entire workflow as much as possible. While steps such as project brainstorming
    and publication may also be a key part of a research workflow, the tasks that
    relate to ensuring a project''s reproducibility fall primarily within these stages.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 基本可重现研究工作流程可以分为三个主要阶段：数据获取、数据处理和数据分析。这三个阶段之前的活动涉及系统设置，之后的步骤尽可能自动化整个工作流程。虽然项目头脑风暴和出版等步骤也可能是研究工作流程的关键部分，但与确保项目可重现性相关的任务主要在这些阶段内。
- en: Before beginning a data-intensive computational research project, a computer
    system with the tools necessary to complete the analysis must be located and set
    up. These activities can be more or less involved, depending primarily on the
    researchers level of access to the computer and the programming language that
    will be used for the analysis.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始数据密集型计算研究项目之前，必须找到并设置具有完成分析所需工具的计算机系统。这些活动可能更多或更少地涉及，主要取决于研究人员对计算机的访问级别以及将用于分析的编程语言。
- en: The first stage of the basic workflow is data acquisition, input, or creation.
    This stage commonly consists of collecting data from a primary source, such as
    field observation, experimental research, or surveys. However, it also may include
    acquiring data from an existing source, through web-scraping or communication
    with other researchers, or generating data via simulation. Regardless of the method,
    the end result of this first stage is raw data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 基本工作流的第一个阶段是数据获取、输入或创建。这个阶段通常包括从主要来源收集数据，比如野外观察、实验研究或调查。然而，它也可能包括通过网络抓取或与其他研究人员交流获取现有来源的数据，或通过模拟生成数据。无论采用何种方法，这个第一阶段的最终结果都是原始数据。
- en: The second stage involves processing or cleaning of the data produced in the
    first stage. Depending on the tools used and the author's strategies, this stage
    may include tasks such as manual data entry, visual data review, or systematic
    data manipulation or filtering using scripts or other software. At the completion
    of this second stage, the relevant data is digitized, cleaned, and fully prepared
    for analysis. Although this stage is often treated as minor, or less important,
    than the other two stages surrounding it, we have found that this stage often
    requires as much intellectual energy, and as many difficult decisions, as the
    other stages in this workflow.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段涉及对第一阶段产生的数据进行处理或清洗。根据所使用的工具和作者的策略，这个阶段可能包括手动数据输入、视觉数据审查，或使用脚本或其他软件进行系统数据操作或过滤等任务。在完成第二阶段后，相关数据被数字化、清洗，并完全准备好进行分析。尽管这个阶段通常被视为次要的，或者比其周围的其他两个阶段不那么重要，但我们发现，这个阶段通常需要与其他阶段一样多的智力能量和同样多的困难决策。
- en: The third stage is data analysis. The most common form of data analysis is formal
    statistics, but other activities in this stage include data visualization, assessing
    the performance of particular algorithms, and extending the data to address a
    hypothesis or draw a scientific conclusion. The defining attribute of this stage
    is that it analyzes, in some manner, the clean data produced in the second stage,
    and produces the desired scientific products of the research, generally quantitative
    results in the form of figures and tables that are incorporated into manuscripts,
    talks, and other forms of communication.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第三阶段是数据分析。数据分析最常见的形式是形式统计，但该阶段的其他活动还包括数据可视化、评估特定算法的性能，并扩展数据以解决假设或得出科学结论。该阶段的定义属性是以某种方式分析第二阶段产生的干净数据，并生成所需的科学研究产品，通常是数量化结果，以图表的形式呈现在手稿、演讲和其他形式的交流中。
- en: Finally, following the three central stages, the reproducibility of a project
    can be greatly enhanced through the creation of a single controller script that
    can automatically execute all three stages to produce a finished result. When
    this type of "push button" workflow is unrealistic or impossible to achieve due
    to project constraints, detailed documentation of all non-automated steps should
    be created.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在三个核心阶段之后，通过创建一个可以自动执行所有三个阶段以生成最终结果的单个控制脚本，可以极大地增强项目的可重现性。当由于项目约束而无法实现或不切实际的"一键式"工作流时，应创建所有非自动化步骤的详细文档。
- en: Setup
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置
- en: The setup activities that precede the three core stages of a reproducible workflow
    consist first of gaining access to a computer, or several computers, to use for
    a project. For this simple example, we will presume that the entire analysis will
    occur on a personal computer for which the researcher has full administrator access.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在可重现工作流的三个核心阶段之前，设置活动首先包括获取计算机或多台计算机以用于项目。对于这个简单的示例，我们假设整个分析将在一台研究人员具有完全管理员权限的个人计算机上进行。
- en: There are generally three classes of tools that must be installed at this stage.
    The first of these is a shell or terminal program that allows access to the command
    line. The second is a plain text editor or a development environment that can
    be used to write code in a chosen language. The third is software allowing the
    user to write and execute code in a chosen a programming language. Alternatively,
    researchers may choose to use an integrated workflow program, such as [VisTrails](http://www.vistrails.org),
    [Taverna](https://taverna.incubator.apache.org/), or [Kepler](https://kepler-project.org/),
    although this approach will not be discussed here.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在此阶段必须安装三类工具。其中之一是允许访问命令行的 shell 或终端程序。第二个是纯文本编辑器或可用于以选择的语言编写代码的开发环境。第三个是允许用户在选择的编程语言中编写和执行代码的软件。或者，研究人员可以选择使用集成的工作流程程序，例如[VisTrails](http://www.vistrails.org)，[Taverna](https://taverna.incubator.apache.org/)或[Kepler](https://kepler-project.org/)，尽管这种方法在此不讨论。
- en: For the basic workflow that follows, Mac or Linux users can use the pre-installed
    Terminal program on their systems, while Windows users can work at the Command
    Prompt. All users should install a plain text editor, of which many are available
    for each platform. Finally, the examples below will make use of the R language,
    and users should download and install a recent version of [R](https://www.r-project.org/).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于随后的基本工作流程，Mac 或 Linux 用户可以使用其系统上预安装的 Terminal 程序，而 Windows 用户可以在命令提示符下工作。所有用户都应安装一个纯文本编辑器，每个平台都有许多可用。最后，下面的示例将使用
    R 语言，并且用户应下载并安装最新版本的[R](https://www.r-project.org/)。
- en: More detailed information on the above installation steps, as well as basic
    tutorials on how to use these tools, can be found in the [Software Carpentry lessons](http://software-carpentry.org/lessons/).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有关上述安装步骤的更详细信息，以及如何使用这些工具的基本教程，请参阅[软件 Carpentry 课程](http://software-carpentry.org/lessons/)。
- en: 'Stage 1: Data Acquisition'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阶段 1：数据采集
- en: The first stage in most data-intensive workflows involves the acquisition of
    raw data. For this example, we'll imagine a study in which we have collected field
    data on tomatoes being grown as part of an agricultural experiment.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据密集型工作流程的第一阶段涉及原始数据的获取。在本例中，我们将想象进行了一项研究，我们在其中收集了关于作为农业实验的一部分种植的番茄的田间数据。
- en: Table 1 reports hypothetical measurements of the total yield of tomatoes, in
    kilograms per plant, produced by four plants in each of three fields having no
    management after planting (N), conventional management with fertilizers and pesticides
    (C), or organic management (O). The third column indicates whether substantial
    insect damage was noted on the plant leaves at the time of harvest. Of the fifteen
    plants marked for sampling, two of them, denoted with `NA` in the mass column,
    were killed before bearing fruit.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1 报告了三个田地中每个田地四株植物的总产量的假设测量结果，单位为每株植物的千克，种植后不进行管理（N），常规管理，包括肥料和杀虫剂（C），或有机管理（O）。第三列指示是否在收获时注意到植物叶子上有大量昆虫损害。在标记为`NA`的质量列中，15
    株植物中有两株在结果之前被杀死。
- en: 'Table 1: Sample tomato data set'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：样本番茄数据集
- en: '| Field | Weight | Insect |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 重量 | 昆虫 |'
- en: '| --- | --- | --- |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| N | 5.8 | Y |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| N | 5.8 | Y |'
- en: '| N | 5.9 | N |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| N | 5.9 | N |'
- en: '| N | 1.6 | Y |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| N | 1.6 | Y |'
- en: '| N | 4.0 | Y |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| N | 4.0 | Y |'
- en: '| N | 2.9 | Y |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| N | 2.9 | Y |'
- en: '| C | 12.4 | N |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| C | 12.4 | N |'
- en: '| C | 11.5 | N |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| C | 11.5 | N |'
- en: '| C | 9.3 | N |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| C | 9.3 | N |'
- en: '| C | NA | N |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| C | NA | N |'
- en: '| C | 12.1 | N |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| C | 12.1 | N |'
- en: '| O | 9.9 | N |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| O | 9.9 | N |'
- en: '| O | 6.7 | N |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| O | 6.7 | N |'
- en: '| O | 10.6 | Y |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| O | 10.6 | Y |'
- en: '| O | 3.7 | Y |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| O | 3.7 | Y |'
- en: '| O | NA | N |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| O | NA | N |'
- en: This data should be entered into a spreadsheet program and saved as a CSV file.
    CSV files are a commonly used plain text format for storing tabular data, in which
    each row of a table is on a separate line and data for each column are separated
    by a comma. Plain text formats are often preferable to program-specific formats,
    such as XLSX, as they are more easily readable by a variety of software and by
    other researchers who may wish to work with this data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据应输入电子表格程序并保存为 CSV 文件。CSV 文件是一种常用的纯文本格式，用于存储表格数据，其中表的每一行都在单独的一行上，每列的数据由逗号分隔。纯文本格式通常优于特定于程序的格式，例如
    XLSX，因为它们更容易被各种软件和其他可能希望使用此数据的研究人员阅读。
- en: Once this file is created, it should be given a name and saved in a useful location.
    Naming conventions vary widely between researchers, but in small projects such
    as this one, we recommend using names that usefully describe a file's contents,
    even if these are somewhat long. This table, for example, might be saved as `raw_yield_data.csv`.
    To avoid the possibility of errors later in the workflow, spaces, periods, and
    slashes should not be used in file names.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建此文件后，应给它一个名称并保存在一个有用的位置。命名约定在研究人员之间差异很大，但在像这样的小项目中，我们建议使用能够有用地描述文件内容的名称，即使这些名称有些冗长。例如，这个表格可能被保存为`raw_yield_data.csv`。为了避免后续工作流程中出现错误的可能性，文件名不应使用空格、句点和斜杠。
- en: At the same time that data are saved, a metadata file should also be created
    and saved with it. The purpose of the metadata file is to document the source
    of the data and any relevant information about it. While many disciplines have
    standards for metadata, a minimal metadata file consists of a simple text file
    that describes, in plain English, where the data came from and what it describes.
    Such a file, which we can save as `README.txt` alongside the data file, might
    contain information like the following.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 数据保存的同时，还应创建并保存一个元数据文件。元数据文件的目的是记录数据的来源和任何相关信息。虽然许多学科都有元数据标准，但最小的元数据文件由一个简单的文本文件组成，以纯英语描述数据的来源和描述。这样一个文件，我们可以将其保存在与数据文件相邻的`README.txt`中，可能包含如下信息。
- en: Data collected by undergraduate assistants to Prof John Smith at the Berkeley
    Field Station. All plants were located in Field 3 and chosen for measurement when
    approximately 12" tall. Yields were recorded in August 2015.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 约翰·史密斯教授在伯克利野外站的本科助理收集的数据。所有植物均位于第3田地，并在约12英寸高时选择进行测量。产量记录于2015年8月。
- en: ''
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Field codes indicate no treatment (N), conventional (C), and organic (O). Yield
    is in kg, with NA indicating a plant that died prior to yield measurement. Insect
    damage assessed visually, Y indicates more than 25% loss of leaf area.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 田间代码表示无处理（N）、传统（C）和有机（O）。产量以千克为单位，NA表示在产量测量前死亡的植物。通过目测评估昆虫损伤，Y表示叶面积损失超过25%。
- en: The question then arises of where these two files, as well as all of the subsequent
    files that will be part of the project, should be saved. A common convention is
    to place all project files in a single directory, with a single layer of subdirectories
    for different types of files, such as data, source code, analysis results, etc.
    A structure such as the below, with all files and subfolders contained in a single
    folder called `tomato_project`, provides a useful starting point for simple projects.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随之而来的问题是这两个文件，以及将成为项目一部分的所有后续文件应该保存在哪里。一种常见的惯例是将所有项目文件放在单个目录中，其中包括不同类型文件的一个子目录，如数据、源代码、分析结果等。像下面这样的结构，所有文件和子文件夹都包含在一个名为`tomato_project`的单个文件夹中，为简单项目提供了一个有用的起点。
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Stage 2: Data Processing'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第二阶段：数据处理
- en: Once raw data has been collected and placed in a project directory, it nearly
    always requires some form of processing or cleaning before it can be used in an
    analysis. This step may involve removing invalid data, subsetting the original
    data, removing outliers, and other similar steps. The best approach for processing
    a raw data set is, of course, dependent on the questions that a researcher hopes
    to answer with this data and the particular type of analysis planned for Stage
    3.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦收集到原始数据并放置在项目目录中，几乎总是需要对其进行某种形式的处理或清理，以便在分析中使用。此步骤可能涉及删除无效数据、子集原始数据、删除异常值和其他类似的步骤。处理原始数据集的最佳方法当然取决于研究人员希望用这些数据回答的问题以及计划用于第三阶段的特定类型的分析。
- en: In this example, inspection of the raw data table revealed two plants without
    yield measurements, which we may wish to remove from the data before any further
    analysis. Given a goal of eventually conducting a two-sample t-test comparing
    the conventional to the organic yields, we also know that we can remove the no
    treatment plants from the table at this stage. For a small table such as this
    one, removing these rows is not strictly necessary, although such subsetting can
    improve the efficiency of subsequent analysis of larger data sets.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，检查原始数据表格发现两株未进行产量测量的植物，我们可能希望在进一步分析之前从数据中删除这些植物。考虑到最终进行传统和有机产量比较的两样本t检验的目标，我们也知道可以在这个阶段从表格中删除无处理的植物。对于像这样的小表格，删除这些行并不是绝对必要的，尽管这样的子集操作可以提高对更大数据集的后续分析的效率。
- en: To make this stage fully reproducible, every step taken to process the data
    must be recorded with detail fine enough that only one processed data set could
    result from the combination of the raw data and the set of instructions. The simplest
    and the recommended way to accomplish this is to encode the instructions for data
    processing as computer code, in a script, that will read in the raw data, execute
    various processing and cleaning operations, and save the resulting processed data
    as a new file.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要使这个阶段完全可重现，必须记录处理数据的每一步骤，细节足够精细，以至于只有一个处理后数据集可以从原始数据和一系列指令的组合中产生。实现这一点的最简单和推荐的方法是将数据处理的指令编码为计算机代码，即在一个脚本中，读取原始数据，执行各种处理和清洗操作，并将生成的处理后数据保存为新文件。
- en: Particularly for small tabular data, it can be tempting to skip this coding
    step, and instead open the file in a graphical editor, such as a spreadsheet program,
    delete the rows or columns that are not needed, and save the resulting file. In
    some instances, particularly where data files are stored in a proprietary format
    that can only be opened by certain programs, this manual approach may be the only
    option. Manual data processing, however, is prone to error and makes the "push
    button" automated workflow described later impossible.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小型表格数据，可能会诱人地跳过这个编码步骤，而是在图形编辑器中打开文件，如电子表格程序，删除不需要的行或列，并保存生成的文件。在某些情况下，特别是数据文件存储在只能被某些程序打开的专有格式中时，这种手动方法可能是唯一的选择。然而，手动数据处理容易出错，并使后面描述的“一键式”自动化工作流程变得不可能。
- en: As is the case with all research tasks, if this step must be done manually,
    ensure that the processed data file is accompanied by a very detailed human readable
    description, saved in a text file like the metadata file, that describes every
    operation performed on the raw data, to the level of what menu was selected and
    what button clicked in what order. Remember that if someone who you have never
    met cannot exactly, with 100% accuracy, reproduce the processed data file from
    the raw data and instructions, then this step is not fully reproducible. In many
    ways, this instruction file is itself similar to code, although it is intended
    to be executed by a human reader rather than by a computer.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有研究任务一样，如果这一步必须手动完成，请确保处理后的数据文件附有非常详细的人类可读描述，保存在类似元数据文件的文本文件中，描述对原始数据执行的每个操作，直到选择了哪个菜单并按照什么顺序点击了哪个按钮。请记住，如果一个你从未见过的人无法准确地、100%地从原始数据和指令中重现处理后的数据文件，那么这一步就不是完全可重现的。在许多方面，这个指令文件本身类似于代码，尽管它是为人类读者而不是计算机执行的。
- en: For this tomato yield data, we can readily write a short script that will read
    the raw table, remove the rows with `NA` yields and those with a field code of
    `N`, and save the resulting processed data. The following R commands will perform
    these operations.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个番茄产量数据，我们可以轻松地编写一个简短的脚本，读取原始表格，删除具有`NA`产量和字段代码为`N`的行，并保存生成的处理后数据。以下的R命令将执行这些操作。
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: While exploring the data, the commands above can be entered interactively into
    an interpreter window. Once a procedure for data processing has been identified,
    however, all of these commands should be placed in a separate file that when executed,
    will read the raw data, process it, and save the resulting processed data file.
    This ensures definitively that all necessary steps to reproduce this stage of
    the workflow were recorded properly and can be easily repeated at will.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索数据时，上述命令可以交互式地输入到解释器窗口中。然而，一旦确定了数据处理的程序，所有这些命令都应该放在一个单独的文件中，当执行时，将读取原始数据，处理它，并保存生成的处理后数据文件。这确保了所有必要的步骤都被正确记录下来，并且可以轻松地随意重复。
- en: In the simple directory structure described earlier, scripts and other code
    are saved in the `src` subfolder. To ensure that a script in the `src` directory
    will locate and save the appropriate files in the appropriate folders, we can
    modify the code above to the below, which modifies the locations where the files
    are read and written. Note that we have also added comments describing what each
    line of code is intended to do.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面描述的简单目录结构中，脚本和其他代码保存在`src`子文件夹中。为了确保`src`目录中的脚本能够定位并保存适当的文件到适当的文件夹中，我们可以修改上面的代码如下，修改文件读取和写入的位置。请注意，我们还添加了描述每行代码意图的注释。
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The commands above, when saved as a script `clean_data.R` in the `src` subfolder,
    will read the table `raw_yield_data.csv` from the `data_raw` subfolder, clean
    it, and save the resulting cleaned table as `clean_yield_data.csv` in the `data_clean`
    subfolder. The cleaned data are placed in a different subfolder from the raw data
    to ensure that the original, raw data are never confused with any derived data
    products. Ideally the raw data files should never be altered, with all changes
    and modifications saved to a separate file. This will ensure that you can always
    go back to the original data if you make a data processing decision that you regret.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令保存为 `clean_data.R` 脚本后，放在 `src` 子文件夹中，将从 `data_raw` 子文件夹中读取表格 `raw_yield_data.csv`，对其进行清理，并将清理后的结果保存为
    `clean_yield_data.csv`，放在 `data_clean` 子文件夹中。清理后的数据被放置在不同的子文件夹中，以确保原始的、未经处理的数据不会与任何派生的数据产品混淆。理想情况下，不应更改原始数据文件，所有的更改和修改都应保存在单独的文件中。这将确保如果做出导致后悔的数据处理决策，您仍然可以回到原始数据。
- en: To execute this script, navigate to the `src` subfolder in a terminal window
    and run the command `r clean_data.R`. For more information on working at the command
    line, see the [Software Carpentry shell tutorial](http://software-carpentry.org/lessons/).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行此脚本，请在终端窗口中导航到 `src` 子文件夹，并运行命令 `r clean_data.R`。有关在命令行中工作的更多信息，请参阅[软件加工shell教程](http://software-carpentry.org/lessons/)。
- en: The project directory should now look like the following.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 项目目录现在应该是这样的。
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Stage 3: Data Analysis'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第三阶段：数据分析
- en: Once data are checked in and processed, the third stage of the basic reproducible
    workflow is data analysis. There are, of course, many different types of analyses
    that may be employed here and many different types of outputs that can result,
    including text-based results, tables, and figures. For this example, we'll perform
    an unpaired two sample t-test to determine whether the mean tomato yield per plant
    is significantly different in the conventional and organic fields.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据经过检查和处理，基本可再现工作流程的第三阶段就是数据分析。当然，在这里可能会使用许多不同类型的分析方法，可能会得到许多不同类型的输出，包括基于文本的结果、表格和图形。在这个例子中，我们将执行一个非配对的双样本
    t 检验，以确定传统和有机田间每株番茄产量的平均值是否有显著差异。
- en: As with data processing, data analysis may be done manually using graphical
    tools, such as a spreadsheet program. This is not recommended due to the difficulty
    of accurately capturing all of the minute details needed to allow a second researcher
    to exactly repeat the analysis without errors. Data analysis may also be performed
    interactively, with code entered into a "live" interpreter window until a final
    result is reached and saved. This step is often important as a means of exploration
    to determine what commands should be used for the analysis. Once interactive tools
    have been used to explore possible approaches, however, we strongly recommend
    that all commands needed to perform the data analysis be placed in separate file
    that will save the results when executed.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据处理类似，数据分析可以通过图形工具手动完成，比如电子表格程序。由于准确捕捉所有细节以便让第二个研究人员能够完全重复分析而没有错误的困难，这种方法并不推荐。数据分析也可以交互式地进行，将代码输入到一个“活”解释器窗口中，直到达到最终结果并保存。这一步通常很重要，因为它是探索的手段，可以确定用于分析的命令。然而，一旦交互式工具用于探索可能的方法，我们强烈建议将执行数据分析所需的所有命令放在单独的文件中，在执行时保存结果。
- en: The code below should be saved in a script titled `analysis.R` in the `src`
    directory. When run, it will read the cleaned data table, perform the desired
    t-test, and save the summarized results of the test in the `results` subfolder
    as a plain text file `test_results.txt`. Although not applicable here, any other
    results, such as tables and figures, should also be saved in the `results` subfolder.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码应该保存在 `src` 目录中名为 `analysis.R` 的脚本中。运行时，它将读取清理过的数据表，执行所需的 t 检验，并将测试结果的摘要保存在
    `results` 子文件夹中，保存为纯文本文件 `test_results.txt`。虽然这里不适用，但任何其他结果，如表格和图形，也应保存在 `results`
    子文件夹中。
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that several comments describing the analysis steps are included in the
    code above. Although the relatively simple commands here do not require extensive
    explanation, comments should be used liberally in all code files, as we have demonstrated
    in the examples here. While the code itself describes *what* operation is performed,
    comments should be used to describe *why*, and in a larger sense *how*, a desired
    analysis is being conducted. While the code itself is designed to reproduce the
    quantitative results of an analysis, code comments and other documentation are
    designed to help another researcher reproduce the thought process that went into
    structuring and writing code in a particular way.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，上面的代码中包含了描述分析步骤的几条注释。尽管这里的相对简单的命令不需要详细的解释，但在所有代码文件中应该大量使用注释，就像我们在这里的示例中所演示的那样。虽然代码本身描述了执行的*操作*是什么，但注释应该用来描述*为什么*，以及在更大的意义上*如何*进行所需的分析。虽然代码本身旨在重现分析的定量结果，但代码注释和其他文档旨在帮助另一个研究人员重现构建和编写代码的思维过程。
- en: At the conclusion of this stage, after the script `analysis.R` has been run
    in the same manner as the previous `clean_data.R` script, the project directory
    will appear as follows.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段结束时，当脚本`analysis.R`像之前的`clean_data.R`脚本一样运行后，项目目录将如下所示。
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `test_results.txt` file indicates that there is no detectable significant
    difference between the yields in the conventional and organic fields (p = 0.104).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`test_results.txt`文件表明，在传统田地和有机田地的产量之间没有显著差异（p = 0.104）。'
- en: Automation
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动化
- en: At this stage, the reproducible workflow is essentially complete. We have written
    code that, when executed, will read and process our raw data table and save both
    a cleaned data table and the final results of our analysis. Most importantly,
    the final result of our analysis, the p-value for the comparison of the conventional
    and organic yields, can be reproduced by any researcher who has access to the
    original data and the code that we have written.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，可重现的工作流基本上已经完成。我们编写了一段代码，当执行时，将读取和处理我们的原始数据表，并保存清洁的数据表和我们分析的最终结果。最重要的是，任何有原始数据和我们编写的代码访问权限的研究人员都可以重现我们的分析结果，即传统和有机产量比较的p值。
- en: 'To make this workflow even easier to reproduce, a controller or driver script
    can be added to execute, in one step, all of the various subcomponents of the
    entire workflow. In this simple example, our workflow has only two steps that
    can be performed automatically: executing `clean_data.R` to generate the cleaned
    data table, and then executing `analysis.R` to perform the statistical test.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个工作流更容易重现，可以添加一个控制器或驱动脚本来执行整个工作流的各个子组件。在这个简单的示例中，我们的工作流只有两个可以自动执行的步骤：执行`clean_data.R`生成清洁的数据表，然后执行`analysis.R`执行统计测试。
- en: To create a single entry point that will perform our entire analysis, we can
    create a shell script, `runall.sh`, that we can save in the `src` directory. For
    this simple example, the script only contains two lines.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个执行整个分析的单一入口点，我们可以创建一个shell脚本`runall.sh`，并将其保存在`src`目录中。对于这个简单的示例，脚本只包含两行。
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To test out this controller script, delete the contents of the `data_clean`
    and the `results` directory to simulate giving a colleague only your raw data
    and code. From the command line, navigate to the `src` directory and run the command
    `sh runall.sh` to see the intermediate and final results of the workflow regenerate.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试这个控制器脚本，删除`data_clean`和`results`目录的内容，以模拟向同事只提供原始数据和代码。从命令行中，导航到`src`目录并运行命令`sh
    runall.sh`，以查看工作流程的中间和最终结果重新生成。
- en: In addition to supporting reproducibility, the creation of a "push button" workflow
    like this has a second related side benefit, which is ensuring that any generated
    results are linked directly back to specific known data sets and analysis parameters.
    We and many of our colleagues have been known to finish working on real projects,
    delete all results precisely as described above, and rerun the entire workflow
    using a controller script. This final step ensures that all results used in subsequent
    interpretation and presentation were, in fact, generated from the latest data
    and code in the project directory.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 除了支持可重复性外，创建类似于“一键式”工作流程还有一个相关的第二个好处，就是确保任何生成的结果直接链接到特定的已知数据集和分析参数。我们和许多同事已经知道，完成真实项目的工作后，会按照上述精确的步骤删除所有结果，并使用控制器脚本重新运行整个工作流程。这最后一步确保所有在后续解释和展示中使用的结果实际上都是从项目目录中的最新数据和代码生成的。
- en: Conclusion
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: While some real world workflows are nearly as simple as the one shown here,
    many projects will be more complex, perhaps substantially so. The most immediate
    extension of the template shown here would be the need to accommodate a greater
    variety of file types, including many types of code files, several categories
    of results, binary executables, and documentation. From an organizational perspective,
    an additional level of subfolders can be be created within folders such as `src`
    and `results` to organize these additional files. Subfolders such as `doc` and
    `bin` within the main project directory can be used to house files related to
    documentation, including manuscripts, and compiled binaries.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些真实世界的工作流程几乎和这里显示的一样简单，但许多项目会更加复杂，甚至可能大不相同。这里显示的模板的最直接扩展将是需要适应更多种类的文件类型，包括许多类型的代码文件、几个类别的结果、二进制可执行文件和文档。从组织角度来看，在诸如`src`和`results`等文件夹内可以创建额外的子文件夹，以组织这些附加文件。主项目目录中的子文件夹，如`doc`和`bin`，可用于存放与文档相关的文件，包括手稿和已编译的二进制文件。
- en: Beyond the addition of more project files, more complex projects will require
    more complex workflows that allow, for example, files to be shared across multiple
    projects, the same analysis to be run on multiple data sets or parameter combinations,
    analyses to be run on remote computers, etc. Many of these additional complexities
    are discussed in the contributed case studies in this volume.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 除了添加更多的项目文件之外，更复杂的项目将需要更复杂的工作流程，允许例如文件在多个项目之间共享，相同的分析在多个数据集或参数组合上运行，分析在远程计算机上运行等。这些额外的复杂性中的许多都在本卷中的案例研究中进行了讨论。
- en: When moving beyond the tools and techniques described above, we first recommend
    that you learn to integrate version control software into your workflow. Tutorials
    for software such as `git` are readily available online.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当超越上述描述的工具和技术时，我们首先建议您学习将版本控制软件整合到您的工作流程中。诸如`git`等软件的教程在网上很容易找到。
- en: A second possible direction would be to try using a literate programming approach.
    This approach involves creating a single source document in a language such as
    Markdown or LaTeX, or using a "notebook" interface such as one provided by Sage
    or Jupyter, that contains text describing the analysis directly alongside code,
    figures, tables and other results of our report. In this framework, the single
    source document can be executed to run the code and obtain results alongside narrative
    description and documentation. This approach provides a self-contained file of
    text and code that is convenient for circulating to other readers by email or
    submitting for publication.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种可能的方向是尝试使用文学编程方法。这种方法涉及创建一个单一的源文档，使用诸如Markdown或LaTeX之类的语言，或者使用像Sage或Jupyter提供的“笔记本”界面，其中包含直接描述分析的文本以及代码、图表、表格和我们报告的其他结果。在这个框架中，可以执行单一的源文档来运行代码并获取结果，同时进行叙述描述和文档编写。这种方法提供了一个包含文本和代码的自包含文件，方便通过电子邮件传播给其他读者或提交出版。
- en: In closing, we note once again that the structure of this basic reproducible
    workflow, particularly the division of the workflow into the three core stages
    plus setup and automation, underlies all of the more complex case studies described
    in this volume. We encourage researchers, both beginning and advanced, to use
    the template in this chapter as a basic foundational framework for understanding,
    organizing, and creating reproducible workflows as part of real world research
    projects in the data-intensive sciences.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们再次注意到，这个基本可重复的工作流程的结构，特别是将工作流程划分为三个核心阶段加上设置和自动化，构成了本卷描述的所有更复杂案例研究的基础。我们鼓励初学者和高级研究人员都将本章模板作为理解、组织和创建可重复工作流程的基本框架，作为数据密集型科学研究项目的一部分。
