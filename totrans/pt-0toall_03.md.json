["```\n import torch\nfrom torch.autograd import Variable\n\nx_data = [1.0, 2.0, 3.0]\ny_data = [2.0, 4.0, 6.0]\n\nw = Variable(torch.Tensor([1.0]),  requires_grad=True)  # Any random value\n\n# our model forward pass\n\ndef forward(x):\n    return x * w\n\n# Loss function\n\ndef loss(x, y):\n    y_pred = forward(x)\n    return (y_pred - y) * (y_pred - y)\n\n# Before training\nprint(\"predict (before training)\",  4, forward(4).data[0])\n\n# Training loop\nfor epoch in range(10):\n    for x_val, y_val in zip(x_data, y_data):\n        l = loss(x_val, y_val)\n        l.backward()\n        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n        w.data = w.data - 0.01 * w.grad.data\n\n        # Manually zero the gradients after updating weights\n        w.grad.data.zero_()\n\n    print(\"progress:\", epoch, l.data[0])\n\n# After training\nprint(\"predict (after training)\",  4, forward(4).data[0]) \n```"]