- en: Appendix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: Introduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'On this chapter we will learn the basics topics to better understand the book.
    The following topics will be presented:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习基础知识，以更好地理解本书。将介绍以下主题：
- en: Lua, Torch
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lua，Torch
- en: Tensorflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tensorflow
- en: Python, numpy
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python，numpy
- en: Matlab
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matlab
- en: Lua and Torch
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lua和Torch
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On this book I stressed out the importance of knowing how to write your own
    deep learning/artificial intelligence library. But is also very important specially
    while researching some topic, to understand the most common libraries. This chapter
    will teach the basics on Torch, but before that we're going also to learn Lua.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我强调了了解如何编写自己的深度学习/人工智能库的重要性。但特别是在研究某个主题时，理解最常见的库也非常重要。本章将教授Torch的基础知识，但在此之前我们也将学习Lua。
- en: Lua language
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lua语言
- en: '* * *'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Lua was first created to be used on embedded systems, the idea was to have a
    simple cross-platform and fast language. One the main features of Lua is it's
    easy integration with C/C++.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Lua最初是为嵌入式系统而创建的，其想法是拥有一个简单的跨平台和快速的语言。Lua的主要特点之一是它与C/C++的轻松集成。
- en: Lua was originally designed in 1993 as a language for extending software applications
    to meet the increasing demand for customization at the time.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Lua最初于1993年设计为一种用于扩展软件应用程序的语言，以满足当时对定制的增加需求。
- en: This extension means that you could have a large C/C++ program and, some parts
    in Lua where you could easily change without the need to recompile everything.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此扩展意味着您可以在一个大型的C/C++程序中，某些部分使用Lua，而无需重新编译所有内容。
- en: Torch
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Torch
- en: '* * *'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Torch is a scientific computing framework based on Lua with CPU and GPU backends.
    You can imagine like a Numpy but with CPU and GPU implementation. Some nice features:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Torch是一个基于Lua的科学计算框架，具有CPU和GPU后端。您可以将其想象成带有CPU和GPU实现的Numpy。一些很棒的功能：
- en: Efficient linear algebra functions with GPU support
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有效的线性代数函数，支持GPU
- en: Neural Network package, with automatic differentiation (No need to backpropagate
    manually)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络包，带有自动微分（无需手动反向传播）
- en: Multi-GPU support
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多GPU支持
- en: First contact with Lua
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与Lua的初次接触
- en: '* * *'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Bellow we have some simple examples on Lua just to have some contact with the
    language.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们将看到一些关于Lua的简单示例，只是为了对这种语言有一些接触。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Lua datatypes
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Lua数据类型
- en: '* * *'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The language offer those basic types:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该语言提供了这些基本类型：
- en: Numbers(Float)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字（浮点数）
- en: string
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串
- en: boolean
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔值
- en: table
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Doing some math
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进行一些数学运算
- en: '* * *'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Normally we will rely on Torch, but Lua has some math support as well.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们会依赖Torch，但Lua也具有一些数学支持。
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Lua include (require)
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Lua包含（require）
- en: '* * *'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The lua statement to include other lua files is the "require", as usual it is
    used to add some library
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 包含其他Lua文件的Lua语句是"require"，通常用于添加一些库。
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](pedestrianSign.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](pedestrianSign.png)'
- en: Conditionals
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 条件语句
- en: '* * *'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Just the simple if-then-else. Lua does not have switch statement.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 仅是简单的if-then-else。Lua没有switch语句。
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Loops
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 循环
- en: '* * *'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Lua have while, repeat and for loops. For loops has also a "for-each" extension
    to iterate on tables.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Lua具有while、repeat和for循环。for循环还有一个“for-each”扩展，用于在表上进行迭代。
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Functions
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数
- en: '* * *'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Defining functions in Lua is quite easy, it's syntax reminds matlab.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在Lua中定义函数非常简单，其语法类似于matlab。
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Tables
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 表
- en: '* * *'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'On Lua we use tables for everything else (ie: Lists, Dictionaries, Classes,
    etc...)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在Lua中，我们使用表来表示其他所有内容（例如：列表、字典、类等）
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Object oriented programming
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面向对象编程
- en: '* * *'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Lua does not support directly OOP, but you can emulate all it's main functionalities
    (Inheritance, Encapsulation) with tables and metatables
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Lua不直接支持面向对象编程，但您可以使用表和元表模拟所有其主要功能（继承、封装）。
- en: 'Metatable tutorial: Used to override operations (metamethods) on tables.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 元表教程：用于在表上覆盖操作（元方法）。
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: File I/O
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文件I/O
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Run console commands
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行控制台命令
- en: '[PRE19]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: First contact with Torch
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与Torch的初次接触
- en: '* * *'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On this section we're going to see how to do simple operations with Torch, more
    complex stuff will be dealt latter.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何使用Torch进行简单操作，更复杂的内容将在后面处理。
- en: 'One of the torch objectives is to give some matlab functionality, an usefull
    cheetsheat can be found here:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Torch的一个目标是提供一些matlab功能，可以在这里找到一个有用的速查表：
- en: '[PRE21]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Some Matrix operations
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一些矩阵运算
- en: '[PRE23]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Doing operations on GPU
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在GPU上执行操作
- en: '[PRE25]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Plotting
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 绘图
- en: '[PRE27]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](SimplePlotItorch.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](SimplePlotItorch.png)'
- en: Starting with nn (XOR problem)
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从nn开始（XOR问题）
- en: '[PRE28]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Define the loss function
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 定义损失函数
- en: '* * *'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On torch the loss function is called criterion, as on this case we're dealling
    with a binary classification, we will choose the Mean Squared Error criterion
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在torch中，损失函数称为criterion，因为在这种情况下，我们处理的是二元分类，我们将选择均方误差准则
- en: '[PRE29]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Training Manually
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 手动训练
- en: '* * *'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here we're going to back-propagate our model to get the output related to the
    loss gradient ![](9a616dbf.png) then use gradient descent to update the parameters.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将反向传播我们的模型，以获得与损失梯度相关的输出 ![](9a616dbf.png)，然后使用梯度下降来更新参数。
- en: '[PRE30]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Test the network
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测试网络
- en: '[PRE31]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Trainning with optimim
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用优化进行训练
- en: '* * *'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Torch provides a standard way to optimize any function with respect to some
    parameters. In our case, our function will be the loss of our network, given an
    input, and a set of weights. The goal of training a neural net is to optimize
    the weights to give the lowest loss over our training set of input data. So, we
    are going to use optim to minimize the loss with respect to the weights, over
    our training set.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Torch提供了一种标准的方法来优化任何函数关于一些参数。在我们的情况下，我们的函数将是网络的损失，给定一个输入和一组权重。训练神经网络的目标是优化权重，以在我们的训练数据集上给出最低的损失。因此，我们将使用optim来最小化相对于权重的损失，在我们的训练集上。
- en: '[PRE33]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Test the network
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测试网络
- en: '[PRE36]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Tensorflow
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tensorflow
- en: Tensorflow
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tensorflow
- en: Introduction
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: On this chapter we're going to learn about tensorflow, which is the goolge library
    for machine learning. In simple words it's a library for numerical computation
    that uses graphs, on this graph the nodes are the operations, while the edges
    of this graph are tensors. Just to remember tensors, are multidimensional matrices,
    that will flow on the tensorflow graphs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习关于tensorflow的知识，这是谷歌用于机器学习的库。简单来说，它是一个用于数值计算的库，使用图形，图中的节点是操作，而图的边缘是张量。只是为了记住张量，是多维矩阵，将在tensorflow图中流动。
- en: '![](tensors_flowing.gif)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](tensors_flowing.gif)'
- en: '![](Tensorflow_Graph_0.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](Tensorflow_Graph_0.png)'
- en: 'After this computational graph is created it will create a session that can
    be executed by multiple CPUs, GPUs distributed or not. Here are the main components
    of tensorflow:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 创建这个计算图后，它将创建一个会话，可以由多个CPU、GPU分布式或非分布式执行。这里是tensorflow的主要组件：
- en: 'Variables: Retain values between sessions, use for weights/bias'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 变量：在会话之间保留值，用于权重/偏差
- en: 'Nodes: The operations'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 节点：操作
- en: 'Tensors: Signals that pass from/to nodes'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 张量：从/到节点传递的信号
- en: 'Placeholders: Used to send data between your program and the tensorflow graph'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 占位符：用于在程序和tensorflow图之间发送数据
- en: 'Session: Place when graph is executed.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 会话：执行图形的地方。
- en: The TensorFlow implementation translates the graph definition into executable
    operations distributed across available compute resources, such as the CPU or
    one of your computer's GPU cards. In general you do not have to specify CPUs or
    GPUs explicitly. TensorFlow uses your first GPU, if you have one, for as many
    operations as possible.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow的实现将图定义转换为可执行操作，分布在可用的计算资源上，例如CPU或计算机的GPU卡。一般来说，您不必明确指定CPU或GPU。如果有GPU，TensorFlow将尽可能多地使用您的第一个GPU执行操作。
- en: Your job as the "client" is to create symbolically this graph using code (C/C++
    or python), and ask tensorflow to execute this graph. As you may imagine the tensorflow
    code for those "execution nodes" is some C/C++, CUDA high performance code. (Also
    difficult to understand).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 作为“客户端”的工作是使用代码（C/C++或python）符号地创建这个图，并要求tensorflow执行这个图。正如您可能想象的那样，这些“执行节点”的tensorflow代码是一些C/C++、CUDA高性能代码。（也很难理解）。
- en: For example, it is common to create a graph to represent and train a neural
    network in the construction phase, and then repeatedly execute a set of training
    ops in the graph in the execution phase.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在构建阶段通常会创建一个图来表示和训练神经网络，然后在执行阶段重复执行一组训练操作。
- en: '![](Tensorflow_Graph_1.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](Tensorflow_Graph_1.png)'
- en: Installing
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装
- en: '* * *'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you have already a machine with python (anaconda 3.5) and the nvidia cuda
    drivers installed (7.5) install tensorflow is simple
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经有一个安装了python（anaconda 3.5）和nvidia cuda驱动程序（7.5）的机器，安装tensorflow很简单
- en: '[PRE38]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: If you still need to install some cuda drivers refer [here](https://www.youtube.com/watch?v=cVWVRA8XXxs)
    for instructions
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您仍然需要安装一些cuda驱动程序，请参考[这里](https://www.youtube.com/watch?v=cVWVRA8XXxs)获取说明
- en: Simple example
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单示例
- en: '* * *'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Just as a hello world let's build a graph that just multiply 2 numbers. Here
    notice some sections of the code.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 就像一个hello world，让我们构建一个仅乘以2个数字的图。在这里注意代码的一些部分。
- en: Import tensorflow library
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入tensorflow库
- en: Build the graph
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建图
- en: Create a session
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个会话
- en: Run the session
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行会话
- en: Also notice that on this example we're passing to our model some constant values
    so it's not so useful in real life.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，在这个例子中，我们向模型传递了一些常量值，所以在现实生活中并不那么有用。
- en: '![](Tensorflow_Graph_2.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](Tensorflow_Graph_2.png)'
- en: Exchanging data
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交换数据
- en: '* * *'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Tensorflow allow exchanging data with your graph variables through "placeholders".
    Those placeholders can be assigned when we ask the session to run. Imagine placeholders
    as a way to send data to your graph when you run a session "session.run"
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Tensorflow 允许通过 "placeholders" 与图中的变量交换数据。当我们运行会话 "session.run" 时，这些 placeholders
    可以被赋值。想象 placeholders 就像是在运行会话时向图发送数据的一种方式。
- en: '[PRE39]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Linear Regression on tensorflow
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 tensorflow 上的线性回归
- en: '* * *'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now we're going to see how to create a linear regression system on tensorflow
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看看如何在 tensorflow 上创建一个线性回归系统
- en: '[PRE40]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![](Dataset_Linear_Regression.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](Dataset_Linear_Regression.png)'
- en: Now we're going to implement a graph with a function ![](6e6dbcfc.png), a loss
    function ![](b403dde9.png). The loss function will return a scalar value with
    the mean of all distances between our data, and the model prediction.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将实现一个包含函数 ![](6e6dbcfc.png) 和损失函数 ![](b403dde9.png) 的图。损失函数将返回一个标量值，表示我们的数据与模型预测之间所有距离的平均值。
- en: '[PRE41]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: With the graph built, our job is create a session to initialize all our graph
    variables, which in this case is our model parameters. Then we also need to call
    a session x times to train our model.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 构建好图后，我们的工作是创建一个会话来初始化所有图中的变量，这在这种情况下就是我们的模型参数。然后我们还需要调用会话 x 次来训练我们的模型。
- en: '[PRE42]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![](Dataset_Linear_Regression_Result.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](Dataset_Linear_Regression_Result.png)'
- en: Loading data
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据
- en: '* * *'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Is almost entirely up to you to load data on tensorflow, which means you need
    to parse the data yourself. For example one option for image classification could
    be to have text files with all the images filenames, followed by it''s class.
    For example:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在 tensorflow 中几乎完全由你自己来加载数据，这意味着你需要自己解析数据。例如，图像分类的一个选项可能是有包含所有图像文件名及其类别的文本文件。例如：
- en: trainingFile.txt
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: trainingFile.txt
- en: '[PRE43]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: A common API to load the data would be something like this.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据的常见 API 可能是这样的。
- en: '[PRE44]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Tensorboard
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tensorboard
- en: '* * *'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Tensorflow offers a solution to help visualize what is happening on your graph.
    This tool is called Tensorboard, basically is a webpage where you can debug your
    graph, by inspecting it's variables, node connections etc...
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Tensorflow 提供了一个解决方案来帮助可视化图中发生的事情。这个工具叫做 Tensorboard，基本上是一个网页，你可以通过检查变量、节点连接等来调试你的图。
- en: '![](TensorBoardScreenhsot.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](TensorBoardScreenhsot.png)'
- en: 'In order to use tensorboard you need to annotate on your graph, with the variables
    that you want to inspect, ie: the loss value. Then you need to generate all the
    summaries, using the function tf.merge_all_summaries().'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 tensorboard，你需要在图上注释你想要检查的变量，即：损失值。然后你需要生成所有摘要，使用函数 tf.merge_all_summaries()。
- en: Optionally you can also use the function "tf.name_scope" to group nodes on the
    graph.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，你还可以使用函数 "tf.name_scope" 来将图中的节点分组。
- en: 'After all variables are annotated and you configure your summary, you can go
    to the console and call:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有变量都被注释并配置好摘要后，你可以去控制台调用：
- en: '[PRE45]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Considering the previous example here are the changes needed to add information
    to tensorboard.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到前面的例子，这里需要做出改变以向 tensorboard 添加信息。
- en: 1) First we annotate the information on the graph that you are interested to
    inspect building phase. Then call merge_all_summaries(). On our case we annotated
    loss (scalar) and W,b(histogram)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 首先我们在感兴趣的图上注释信息，以便在构建阶段进行检查。然后调用 merge_all_summaries()。在我们的情况下，我们注释了损失（标量）和
    W、b（直方图）。
- en: '[PRE46]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 2) During our session creation we need to add a call to "tf.train.SummaryWriter"
    to create a writer. You need to pass a directory where tensorflow will save the
    summaries.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 在创建会话期间，我们需要添加一个调用 "tf.train.SummaryWriter" 来创建一个写入器。你需要传递一个目录，tensorflow
    将在其中保存摘要。
- en: '[PRE47]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 3) Then when we execute our graph, for example during training we can ask tensorflow
    to generate a summary. Of course calling this every time will impact performance.
    To manage this you could call this at the end of every epoch.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 然后当我们执行我们的图时，例如在训练期间，我们可以要求 tensorflow 生成一个摘要。当然，每次调用这个函数都会影响性能。为了管理这个问题，你可以在每个
    epoch 结束时调用这个函数。
- en: '[PRE48]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Results on tensorboard
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 tensorboard 上的结果
- en: '* * *'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here we can see our linear regression model as a computing graph. ![](GraphLinearRegTensorflow.png)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到我们的线性回归模型作为一个计算图。![](GraphLinearRegTensorflow.png)
- en: Bellow we can see how the loss evolved on each iteration.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们可以看到损失在每次迭代中的演变。
- en: '![](LossLinearRegTensorflow.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](LossLinearRegTensorflow.png)'
- en: Sometimes ipython hold versions of your graph that create problems when using
    tensorboard, one option is to restart the kernel, if you have problems.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 有时 ipython 会保存您的图的版本，当使用 tensorboard 时会出现问题，解决方法之一是重新启动内核，如果出现问题。
- en: Using GPUs
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GPU
- en: '* * *'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Tensorflow also allows you to use GPUs to execute graphs or particular sections
    of your graph.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Tensorflow 还允许您使用 GPU 执行图形或图形的特定部分。
- en: On common machine learning system you would have one multi-core CPU, with one
    or more GPUs, tensorflow represent them as follows
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在常见的机器学习系统上，你可能会有一个多核 CPU，配备一个或多个 GPU，tensorflow 将它们表示如下
- en: '"/cpu:0": Multicore CPU'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"/cpu:0": 多核 CPU'
- en: '"/gpu0": First GPU'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"/gpu0": 第一个 GPU'
- en: '"/gpu1": Second GPU'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"/gpu1": 第二个 GPU'
- en: Unfortunately tensorflow does not have an official function to list the devices
    available on your system, but there is an unofficial way.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，tensorflow 没有官方函数来列出系统上可用的设备，但有一种非官方的方法。
- en: '[PRE49]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Fix graph to a device
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将图固定到设备
- en: '* * *'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Use the "with tf.device('/gpu:0')" statement on python to lock all nodes on
    this graph block to a particular gpu.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中使用 "with tf.device('/gpu:0')" 语句将此图块上的所有节点锁定到特定的 GPU。
- en: '[PRE52]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Multiple Gpus and training
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多 GPU 和训练
- en: '* * *'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now we will explain how training is one on a multiple GPU system.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将解释如何在多 GPU 系统上进行训练。
- en: '![](multipleGpu_Train.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](multipleGpu_Train.png)'
- en: 'Baiscally the steps for multiple gpu training is this:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 多 GPU 训练的基本步骤如下：
- en: Separate your training data in batches as usual
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练数据像往常一样分成批次
- en: Create a copy of the model in each gpu
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个 GPU 中创建模型的副本
- en: Distribute different batches for each gpu
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个 GPU 分配不同的批次
- en: Each gpu will forward the batch and calculate it's gradients
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个 GPU 将转发批次并计算其梯度
- en: Each gpu will send the gradients to the cpu
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个 GPU 将梯度发送到 CPU
- en: The cpu will average each gradient, and do a gradient descent. The model parameters
    are updated with the gradients averaged across all model replicas.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU 将平均每个梯度，并进行梯度下降。模型参数将根据所有模型副本上平均的梯度进行更新。
- en: The cpu will distribute the new model to all gpus
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU 将新模型分发到所有 GPU
- en: the process loop again until all training is done
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次循环该过程，直到所有训练完成
- en: Multi Layer Perceptron MNIST
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多层感知器 MNIST
- en: Multi Layer Perceptron MNIST
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多层感知器 MNIST
- en: Load tensorflow library and MNIST data
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载 tensorflow 库和 MNIST 数据
- en: '[PRE54]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Neural network parameters
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络参数
- en: '[PRE56]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Build graph
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建图
- en: '[PRE57]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Initialize weights and construct the model
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始化权重并构建模型
- en: '[PRE59]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Define Loss function, and Optimizer
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义损失函数和优化器
- en: '[PRE61]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Launch graph
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动图
- en: '[PRE62]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Convolution Neural Network MNIST
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络 MNIST
- en: Convolution Neural Network MNIST
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络 MNIST
- en: SkFlow
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SkFlow
- en: SkFlow
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SkFlow
- en: Introduction
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: In order to make the use of tensorflow simpler to experiment machine learning,
    google offered a library that stays on top of tensorflow. Skflow make life easier.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使使用 tensorflow 更简单地进行机器学习实验，谷歌提供了一个位于 tensorflow 之上的库。Skflow 让生活更轻松。
- en: Import library
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入库
- en: '[PRE64]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Load dataset
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 加载数据集
- en: '[PRE65]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Linear classifier
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性分类器
- en: '[PRE66]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Multi layer perceptron
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多层感知器
- en: '[PRE68]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Using Tensorboard
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Tensorboard
- en: It's much easier to monitor your model with tensorboard through skflow. Just
    add the parameter "model_dir" to the classifier constructor.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 skflow，使用 tensorboard 更容易监视您的模型。只需将参数 "model_dir" 添加到分类器构造函数中。
- en: 'After running this code, type on your server console:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，在服务器控制台上输入：
- en: '[PRE70]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
