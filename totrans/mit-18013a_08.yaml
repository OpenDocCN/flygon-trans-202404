- en: 'Chapter 7: Computation of Derivatives from their Definition'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discuss ways to compute derivatives on a spreadsheet, with emphasis on repeating
    the symmetric approximation with exponentially decreasing d and extrapolating
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: Topics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '7.1  [Introduction: the Obvious Approximation: f''(x) ~ (f(x+d) - f(x))/d](section01.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 7.2  [Round off Errors and the Derivative](section02.html)
  prefs: []
  type: TYPE_NORMAL
- en: '7.3  [The Symmetric Approximation: f''(x) ~ (f(x+d) - f(x-d)/(2d)](section03.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 7.4  [Extrapolating the Sequence of Answers](section04.html)
  prefs: []
  type: TYPE_NORMAL
- en: '7.1 Introduction: the Obvious Approximation: f ''(x) ~ (f(x+d) - f(x)) / d'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose we have a given function, f, and we seek its **derivative at argument
    x[0]**.
  prefs: []
  type: TYPE_NORMAL
- en: One way to estimate it is to evaluate f at two points, x[1] and x[2],�and examine
    the slope of the line from (x[1], f(x[1])) to (x[2], f(x[2])). But what should
    we use for x[1] and x[2] and what will we learn about f '(x[0])?
  prefs: []
  type: TYPE_NORMAL
- en: The choice that first occurs to people is to set x[1] = x[0], and x[2] = x[0]
    + d for some very small d. So one can compute
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/793c3c78de3c67d36d482f95fb2f0dce.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is not a horrible thing to do, but it is not very good, as we shall see.
  prefs: []
  type: TYPE_NORMAL
- en: '**What''s wrong with it?**'
  prefs: []
  type: TYPE_NORMAL
- en: Well, if d is too big, the linear approximation won't be accurate and if d is
    too small, the inaccuracy of your calculation tools may screw up your answer.
    And the transition from being too big to too small may be difficult to find.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Round off Errors and the Derivative
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**How can d being too small cause problems?**'
  prefs: []
  type: TYPE_NORMAL
- en: Usually computations on a calculator or computer or by hand are not performed
    to perfect accuracy. There are very small errors. Normally, these very small errors
    (called **round off errors**) can be ignored because the "noise" they represent
    in your evaluation is extremely small compared to the signal, which consists of
    the value of f itself. (A notable exception occurs when your answer is 0; then
    the machine's answer will be only the error it has created.)
  prefs: []
  type: TYPE_NORMAL
- en: In general, if you take two very similar numbers, like f(x[0] + d) and f(x[0])
    and take their difference, that difference will be very much smaller than either
    term and the information in the signal represented by the difference will therefore
    be much smaller than the signal represented by either, while the noise level usually
    remains about the same for the terms and the difference.
  prefs: []
  type: TYPE_NORMAL
- en: Taking the result of the subtraction and dividing by a very small d (which is
    the same as multiplying by a huge ![](../Images/84022c37d90e8ab197207e722f94b5d9.jpg)),
    amplifies the signal and noise together. The net result is that you get the expected
    answer plus a large amount of noise, and the smaller you make d, the larger that
    noise will be, and the more this effect will make your computation inaccurate.
  prefs: []
  type: TYPE_NORMAL
- en: If you make d smaller than the accuracy of your machine's computation, your
    answer will typically be off by more than 1, or your program will accuse you of
    dividing by 0 when you divide by d.
  prefs: []
  type: TYPE_NORMAL
- en: The spreadsheet allows you to perform a very large number of calculations of
    this kind for a wide choice of d values with essentially *no more work than is
    involved in one such calculation.* This usually gives you the power to look for
    yourself and see where round off error is causing significant error.
  prefs: []
  type: TYPE_NORMAL
- en: You will then be troubled by this effect only when the answer you are computing
    is too far from the correct answer for d values at which this effect becomes noticeable.
    In consequence we try to make use of techniques that will allow us to get accurate
    estimates for as large d values as possible.
  prefs: []
  type: TYPE_NORMAL
- en: '**How?**'
  prefs: []
  type: TYPE_NORMAL
- en: Set up a computation using one d value on one line of the spreadsheet, then
    on the next line set d = the old ![](../Images/5bed3bab8b6a256cff949af84df0e88d.jpg),
    and copy the results downward as far as you like. You will get your computation
    repeated with d replaced by ![](../Images/5bed3bab8b6a256cff949af84df0e88d.jpg),
    then ![](../Images/44dd85ce3c3ae17d41407ba36afd592a.jpg) then ,..., until the
    resulting value is so small your machine won't recognize it as other than 0.
  prefs: []
  type: TYPE_NORMAL
- en: If your estimate of the derivative were to home in on a value and stay there,
    that would probably be the derivative you seek. Alas this does not always happen.
    The estimates tend to home in then start to move away again, as the effects of
    round off error make themselves felt.
  prefs: []
  type: TYPE_NORMAL
- en: (Fortunately modern computers keep greater accuracy in their computations than
    they display on the screen, so that you can tolerate some amount of loss of accuracy
    due to round-off error, without even noticing it.)
  prefs: []
  type: TYPE_NORMAL
- en: However there is something much better that generally does home in on a value
    that is recognizable as the derivative you seek, and it takes no more work! Instead
    of computing ![](../Images/daf9b480149ce21283a0b5714f358bf6.jpg) Try this yourself.
  prefs: []
  type: TYPE_NORMAL
- en: '7.3 The Symmetric Approximation: f ''(x) ~ (f(x+d) - f(x-d)) / (2d)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Using this formula for the "d-approximation" to the derivative is much more
    efficient than using the naïve formula ![](../Images/605702ab33c4882de2ce9d693026161f.jpg)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Why is it better?**'
  prefs: []
  type: TYPE_NORMAL
- en: The answer is that the "symmetric formula" is exactly right if f is a quadratic
    function, which means that the error made by it is proportional to d² or less
    as d decreases. The naïve formula is wrong for quadratics and makes an error that
    is proportional to d.
  prefs: []
  type: TYPE_NORMAL
- en: How come?
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose f is a quadratic: f(x) = ax² + bx + c.'
  prefs: []
  type: TYPE_NORMAL
- en: Then we get
  prefs: []
  type: TYPE_NORMAL
- en: f(x + d) = a(x + d)² + b(x + d) + x
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df6882577e1fe02ade4d1d452c2dc7a2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: On the other hand, we get
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b70f5a1a7eaf73d94c5185fda3430619.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This means that the symmetric approximation is exact for any value of d for
    any quadratic; no need to make d small; and this is not true for the asymmetric
    formula.
  prefs: []
  type: TYPE_NORMAL
- en: In general, if our function being differentiated, f(x + d), can be expanded
    in a power series in d, the first error in our symmetric formula comes from cubic
    terms, and will be proportional to d².
  prefs: []
  type: TYPE_NORMAL
- en: The reason this happens is that the d² term in f(x + d) - f(x - d) cancels itself
    out, being the same in both terms. The same things happens for all even power
    terms, by the way; the errors in this approximation to the derivative all come
    from odd power terms in the power series expansion of f about x.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, if we replace d by ![](../Images/5bed3bab8b6a256cff949af84df0e88d.jpg),
    the error in the symmetric approximation will decline by a factor of 4, while
    the asymmetric formula has error which declines only by a factor of 2 when we
    divide d by 2.
  prefs: []
  type: TYPE_NORMAL
- en: And so, the symmetric formula approaches the true answer for the derivative
    much faster than the naïve asymmetric one does, as we decrease d.
  prefs: []
  type: TYPE_NORMAL
- en: '**Now we ask: can we get even faster convergence?**'
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Extrapolating the Sequence of Answers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Yes!** By extrapolating it!'
  prefs: []
  type: TYPE_NORMAL
- en: Extrapolation is a procedure for anticipating where a sequence is going based
    on a few terms, and creating a new sequence that consists at each stage of your
    best guess at the answer given the information in the terms of the sequence so
    far.
  prefs: []
  type: TYPE_NORMAL
- en: A nifty trick for doing this which can eliminate terms in a sequence that decline
    by a fixed factor from term to term is as follows. Suppose, for example, we have
    a sequence and want to eliminate from it terms which decline by a factor of 4
    from term to term in the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Then if you take 4 times any particular term in the sequence, and subtract the
    previous term, any contribution which goes down by a factor of 4 from term to
    term will cancel out between the two; of course you will get the right answer
    4-1 or 3 times.
  prefs: []
  type: TYPE_NORMAL
- en: Thus in a sequence s[1], s[2],... in each of which there are error terms which
    decrease by a factor of 4, the new sequence whose j-th term is![](../Images/436ea69366291dd399a5dbdb7efda7bf.jpg)
    will kill off the error term that decreases by a factor of 4\. (In the general
    case in which the leading error term in ![](../Images/b851390a95f8a4616dcbc35cb2442b56.jpg)
    declines by a factor of k, the analogous formula is ![](../Images/9614099743c6a90f17bf1ad0cc98a29d.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we can do the following. Compute the symmetric approximation to
    the derivative, and let d decrease by a factor of two from row to row. Then the
    leading error in the symmetric approximation will decrease by a factor of 4 from
    row to row. If we apply the extrapolation formula above to the quadratic approximation,
    we eliminate that leading term, and the leading term that is left will go down
    by a factor of 16 (coming from the d⁵ term in f(x + d)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Is that the best we can do?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**No!** We can use the k = 16 extrapolation formula to replace 16 here by 64,
    and then use the k = 64 extrapolation to do even better.'
  prefs: []
  type: TYPE_NORMAL
- en: A nice feature of this is that every step, from forming the symmetric approximation
    to producing the extrapolations indicated, is very easy to do on a spreadsheet,
    and need only be done in one row, and copied down into subsequent rows.
  prefs: []
  type: TYPE_NORMAL
- en: Another nice feature is that if you set this up sensibly, you can change the
    argument at which you are differentiating by changing only one entry in the spreadsheet.
    You can change the function being differentiated by entering the new function
    exactly once, and copying it appropriately. Everything else including extrapolations
    need be performed only once and it will work for almost all standard functions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**7.1 Set up a a spreadsheet differentiator as described in the discussion
    above, that uses the symmetric form of difference with two levels of� extrapolation.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**7.2 What value of** **d do you need to get the computation as accurate as
    your machine will show in doing the derivative of (sin x)² at x = 2?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**7.3 Make a spreadsheet that keeps** **d fixed (at say .001) and allows x
    to vary. Use it to plot both f and f '' vs x for f = sin x in the range -3.5 to
    3.5, using the xy chart feature of the spreadsheet.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**7.4 Can you find a function for which this method fails? What and where?
    Can you fix it?**'
  prefs: []
  type: TYPE_NORMAL
