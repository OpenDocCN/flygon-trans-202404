["```\nobject DataProcessorKeyed {\n def apply() = new DataProcessorKeyed\n...\n}\nclass DataProcessor extends\nCoProcessFunction[WineRecord, ModelToServe, Double]\nwith CheckpointedFunction\nwith CheckpointedRestoring[List[Option[Model]]] {\n\n var currentModel : Option[Model] = None\n var newModel : Option[Model] = None\n @transient private var checkpointedState:\n   ListState[Option[Model]] = null\n\noverride def\n  snapshotState(context: FunctionSnapshotContext): Unit = {\n checkpointedState.clear()\n checkpointedState.add(currentModel)\n checkpointedState.add(newModel)\n}\n\noverride def initializeState(context:\n  FunctionInitializationContext): Unit = {\n val descriptor = new ListStateDescriptor[Option[Model]] (\n   \"modelState\",new ModelTypeSerializer)\n\n checkpointedState = context.getOperatorStateStore.\n   getListState (descriptor)\n\n if (context.isRestored) {\n   val iterator = checkpointedState.get().iterator()\n   currentModel = iterator.next()\n   newModel = iterator.next()\n }\n}\n\noverride def restoreState(state: List[Option[Model]]): Unit = {\n currentModel = state(0)\n newModel = state(1)\n}\n\n override def processElement2(model: ModelToServe, ctx:\n   CoProcessFunction[WineRecord,ModelToServe, Double]#Context,\n   out: Collector[Double]): Unit = {\n\n import DataProcessorKeyed._\n\n println(s\"New model - $model\")\n newModel = factories.get(model.modelType) match {\n   case Some(factory) => factory.create (model)\n   case _ => None\n }\n}\n\n override def processElement1(record: WineRecord, ctx:\n   CoProcessFunction[WineRecord,ModelToServe, Double]#Context,\n   out: Collector[Double]): Unit = {\n\n   // See if we have update for the model\n   newModel match {\n     case Some(model) => {\n       // Clean up current model\n       currentModel match {\n         case Some(m) => m.cleanup()\n         case _ =>\n       }\n       // Update model\n       currentModel = Some(model)\n       newModel = None\n     }\n     case _ =>\n   }\n   currentModel match {\n     case Some(model) => {\n       val start = System.currentTimeMillis()\n       val quality = model.score(record.asInstanceOf[AnyVal]).\n         asInstanceOf[Double]\n       val duration = System.currentTimeMillis() - start\n       modelState.update(modelState.value()\n         .incrementUsage(duration))\n       println(s\"Calculated quality - $quality\")\n     }\n     case _ => println(\"No model available - skipping\")\n   }\n }\n}\n```", "```\nobject ModelToServe {\n def fromByteArray(message: Array[Byte]): Try[ModelToServe] = Try{\n   val m = ModelDescriptor.parseFrom(message)\n   m.messageContent.isData match {\n     case true => new ModelToServe(m.name, m.description,\n       m.modeltype, m.getData.toByteArray, m.dataType)\n     case _ => throw new Exception(\"Not yet supported\")\n   }\n }\n}\n\ncase class ModelToServe(name: String, description: String,\n  modelType: ModelDescriptor.ModelType,\n  model : Array[Byte], dataType : String) {}\n```", "```\nobject DataRecord {\n\n def fromByteArray(message: Array[Byte]): Try[WineRecord] = Try {\n   WineRecord.parseFrom(message)\n }\n}\n```", "```\nclass ModelTypeSerializer extends TypeSerializer[Option[Model]] {\n ...\n\n override def serialize(record: Option[Model],\n   target: DataOutputView): Unit = {\n   record match {\n     case Some(model) => {\n       target.writeBoolean(true)\n       val content = model.toBytes()\n       target.writeLong(model.getType)\n       target.writeLong(content.length)\n       target.write(content)\n     }\n     case _ => target.writeBoolean(false)\n   }\n }\n\n ...\n\n override def deserialize(source: DataInputView): Option[Model] =\n   source.readBoolean() match {\n     case true => {\n       val t = source.readLong().asInstanceOf[Int]\n       val size = source.readLong().asInstanceOf[Int]\n       val content = new Array[Byte] (size)\n       source.read (content)\n       Some(factories.get(t).get.restore(content))\n     }\n     case _ => None\n   }\n...\n```", "```\nclass ModelSerializerConfigSnapshot[T <: Model]\n  extends TypeSerializerConfigSnapshot{\n\n...\n\n override def write(out: DataOutputView): Unit = {\n   super.write(out)\n   // write only the classname to avoid Java serialization\n   out.writeUTF(classOf[Model].getName)\n }\n\n override def read(in: DataInputView): Unit = {\n   super.read(in)\n   val genericTypeClassname = in.readUTF\n   try\n     typeClass = Class.forName(genericTypeClassname, true,\n       getUserCodeClassLoader).asInstanceOf[Class[Model]]\n   catch {\n     ...\n   }\n }\n...\n```", "```\nobject ModelServingKeyedJob {\n...\n // Build execution Graph\n def buildGraph(env : StreamExecutionEnvironment) : Unit = {\n   env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)\n   env.enableCheckpointing(5000)\n   // Configure Kafka consumer\n   val dataKafkaProps = new Properties\n   dataKafkaProps.setProperty(\"zookeeper.connect\",\n     ModelServingConfiguration.LOCAL_ZOOKEEPER_HOST)\n   dataKafkaProps.setProperty(\"bootstrap.servers\",\n     ModelServingConfiguration.LOCAL_KAFKA_BROKER)\n   dataKafkaProps.setProperty(\"group.id\",\n     ModelServingConfiguration.DATA_GROUP)\n   dataKafkaProps.setProperty(\"auto.offset.reset\", \"latest\")\n   val modelKafkaProps = new Properties\n   modelKafkaProps.setProperty(\"zookeeper.connect\",\n     ModelServingConfiguration.LOCAL_ZOOKEEPER_HOST)\n   modelKafkaProps.setProperty(\"bootstrap.servers\",\n      ModelServingConfiguration.LOCAL_KAFKA_BROKER)\n   modelKafkaProps.setProperty(\"group.id\",\n      ModelServingConfiguration.MODELS_GROUP)\n   modelKafkaProps.setProperty(\"auto.offset.reset\", \"latest\")\n   // Create a Kafka consumer\n   val dataConsumer = new FlinkKafkaConsumer010[Array[Byte]](...\n   val modelConsumer = new FlinkKafkaConsumer010[Array[Byte]](...\n\n   // Create input data streams\n   val modelsStream = env.addSource(modelConsumer)\n   val dataStream = env.addSource(dataConsumer)\n   // Read data from streams\n   val models = modelsStream.map(ModelToServe.fromByteArray(_))\n     .flatMap(BadDataHandler[ModelToServe]).keyBy(_.dataType)\n   val data = dataStream.map(DataRecord.fromByteArray(_))\n     .flatMap(BadDataHandler[WineRecord]).keyBy(_.dataType)\n\n   // Merge streams\n   Data\n.connect(models)\n.process(DataProcessor())\n }\n}\n```", "```\nclass ByteArraySchema extends DeserializationSchema[Array[Byte]]\n  with SerializationSchema[Array[Byte]] {\n\n override def isEndOfStream(nextElement:Array[Byte]):Boolean = false\n override def deserialize(message:Array[Byte]):Array[Byte] = message\n override def serialize(element: Array[Byte]): Array[Byte] = element\n override def getProducedType: TypeInformation[Array[Byte]] =\n   TypeExtractor.getForClass(classOf[Array[Byte]])\n}\n```", "```\nclass DataProcessorMap\n  extends RichCoFlatMapFunction[WineRecord, ModelToServe, Double]\n  with CheckpointedFunction\n  with CheckpointedRestoring[List[Option[Model]]] {\n ...\n\n override def flatMap2(model: ModelToServe, out: Collector[Double]):\n   Unit = {\n   import DataProcessorMap._\n   println(s\"New model - $model\")\n   newModel = factories.get(model.modelType) match{\n     case Some(factory) => factory.create(model)\n     case _ => None\n   }\n }\n override def flatMap1(record: WineRecord, out: Collector[Double]):\n   Unit = {\n   // See if we need to update\n   newModel match {\n     case Some(model) => {\n       // Close current model first\n       currentModel match {\n         case Some(m) => m.cleanup();\n         case _ =>\n       }\n       // Update model\n       currentModel = Some(model)\n       newModel = None\n     }\n     case _ =>\n   }\n   currentModel match {\n     case Some(model) => {\n       val start = System.currentTimeMillis()\n       val quality = model.score(record.asInstanceOf[AnyVal])\n         .asInstanceOf[Double]\n       val duration = System.currentTimeMillis() - start\n     }\n     case _ => println(\"No model available - skipping\")\n   }\n }\n}\n```", "```\n// Read data from streams\nval models = modelsStream.map(ModelToServe.fromByteArray(_))\n .flatMap(BadDataHandler[ModelToServe]).broadcast\nval data = dataStream.map(DataRecord.fromByteArray(_))\n .flatMap(BadDataHandler[WineRecord])\n// Merge streams\nData\n .connect(models)\n .flatMap(DataProcessorMap())\n```"]