["```\n# Lab 3 Minimizing Cost\nimport tensorflow as tf\ntf.set_random_seed(777)  # for reproducibility\n\nx_data = [1, 2, 3]\ny_data = [1, 2, 3]\n\n# Try to find values for W and b to compute y_data = W * x_data\n# We know that W should be 1\n# But let's use TensorFlow to figure it out\nW = tf.Variable(tf.random_normal([1]), name='weight')\n\nX = tf.placeholder(tf.float32)\nY = tf.placeholder(tf.float32)\n\n# Our hypothesis for linear model X * W\nhypothesis = X * W\n\n# cost/loss function\ncost = tf.reduce_mean(tf.square(hypothesis - Y))\n\n# Minimize: Gradient Descent using derivative: W -= learning_rate * derivative\nlearning_rate = 0.1\ngradient = tf.reduce_mean((W * X - Y) * X)\ndescent = W - learning_rate * gradient\nupdate = W.assign(descent)\n\n# Launch the graph in a session.\nsess = tf.Session()\n# Initializes global variables in the graph.\nsess.run(tf.global_variables_initializer())\n\nfor step in range(21):\n    sess.run(update, feed_dict={X: x_data, Y: y_data})\n    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n\n'''\n0 1.93919 [ 1.64462376]\n1 0.551591 [ 1.34379935]\n2 0.156897 [ 1.18335962]\n3 0.0446285 [ 1.09779179]\n4 0.0126943 [ 1.05215561]\n5 0.00361082 [ 1.0278163]\n6 0.00102708 [ 1.01483536]\n7 0.000292144 [ 1.00791216]\n8 8.30968e-05 [ 1.00421977]\n9 2.36361e-05 [ 1.00225055]\n10 6.72385e-06 [ 1.00120032]\n11 1.91239e-06 [ 1.00064015]\n12 5.43968e-07 [ 1.00034142]\n13 1.54591e-07 [ 1.00018203]\n14 4.39416e-08 [ 1.00009704]\n15 1.24913e-08 [ 1.00005174]\n16 3.5322e-09 [ 1.00002754]\n17 9.99824e-10 [ 1.00001466]\n18 2.88878e-10 [ 1.00000787]\n19 8.02487e-11 [ 1.00000417]\n20 2.34053e-11 [ 1.00000226]\n''' \n```"]