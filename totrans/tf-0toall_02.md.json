["```\n# Lab 2 Linear Regression\nimport tensorflow as tf\ntf.set_random_seed(777)  # for reproducibility\n\n# X and Y data\nx_train = [1, 2, 3]\ny_train = [1, 2, 3]\n\n# Try to find values for W and b to compute y_data = x_data * W + b\n# We know that W should be 1 and b should be 0\n# But let TensorFlow figure it out\nW = tf.Variable(tf.random_normal([1]), name='weight')\nb = tf.Variable(tf.random_normal([1]), name='bias')\n\n# Our hypothesis XW+b\nhypothesis = x_train * W + b\n\n# cost/loss function\ncost = tf.reduce_mean(tf.square(hypothesis - y_train))\n\n# Minimize\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\ntrain = optimizer.minimize(cost)\n\n# Launch the graph in a session.\nsess = tf.Session()\n# Initializes global variables in the graph.\nsess.run(tf.global_variables_initializer())\n\n# Fit the line\nfor step in range(2001):\n    sess.run(train)\n    if step % 20 == 0:\n        print(step, sess.run(cost), sess.run(W), sess.run(b))\n\n# Learns best fit W:[ 1.],  b:[ 0.]\n\n'''\n0 2.82329 [ 2.12867713] [-0.85235667]\n20 0.190351 [ 1.53392804] [-1.05059612]\n40 0.151357 [ 1.45725465] [-1.02391243]\n...\n\n1920 1.77484e-05 [ 1.00489295] [-0.01112291]\n1940 1.61197e-05 [ 1.00466311] [-0.01060018]\n1960 1.46397e-05 [ 1.004444] [-0.01010205]\n1980 1.32962e-05 [ 1.00423515] [-0.00962736]\n2000 1.20761e-05 [ 1.00403607] [-0.00917497]\n''' \n```"]