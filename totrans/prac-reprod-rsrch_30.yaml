- en: Enabling Astronomy Image Processing With Cloud Computing Using Apache Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用Apache Spark实现云计算的天文图像处理
- en: Enabling Astronomy Image Processing With Cloud Computing Using Apache Spark
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用Apache Spark实现云计算的天文图像处理
- en: Zhao Zhang
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 赵张
- en: My name is Zhao Zhang, I am a joint postdoctoral researcher at AMPLab and Berkeley
    Institute for Data Science, University of California, Berkeley. The theme of my
    research is to enable data-driven science with computer systems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我的名字是赵张，我是加州大学伯克利分校AMPLab和伯克利数据科学研究所的联合博士后研究员。我的研究主题是利用计算机系统实现数据驱动科学。
- en: This case study describes the process of building Kira, a distributed astronomy
    image processing pipeline in the cloud environment. The idea of the Kira project
    is to explore the applicability of cloud computing based software stack in supporting
    scientific applications. Specifically, we use the SEP (Source Extraction Python)
    library for domain computation. We choose Apache Spark and Hadoop to build the
    infrastructure of distributed processing and data storage.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例研究描述了在云环境中构建Kira，一个分布式天文图像处理管道的过程。Kira项目的理念是探索基于云计算软件堆栈支持科学应用的适用性。具体来说，我们使用SEP（Source
    Extraction Python）库进行领域计算。我们选择Apache Spark和Hadoop构建分布式处理和数据存储的基础设施。
- en: Workflow
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作流程
- en: '![Diagram](zzhang.png) We use LaTeX and Slides to track the merit evaluation:
    why do we need a new system for astronomy image processing, what makes it a better
    system, and what lessons we can we learn from this research.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![图表](zzhang.png) 我们使用LaTeX和Slides跟踪评估的优点：为什么我们需要一个新的天文图像处理系统，什么使其成为一个更好的系统，以及我们可以从这项研究中学到什么教训。'
- en: We use a private GitHub repository to keep track of solutions for technical
    barriers such as I/O processing, Spark interaction with C program, Spark system
    parameter configurations and many others.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用私人GitHub存储库跟踪解决技术障碍的解决方案，如I/O处理、Spark与C程序的交互、Spark系统参数配置等。
- en: The whole system is built with multiple programming languages and tools. At
    the programming language level, we use Scala, Java, Python, Bash, and C. At the
    system level, we use Spark for task coordination, HDFS for persistent storage,
    and the SEP library for actual computation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 整个系统是用多种编程语言和工具构建的。在编程语言层面上，我们使用Scala、Java、Python、Bash和C。在系统层面上，我们使用Spark进行任务协调，HDFS进行持久存储，SEP库进行实际计算。
- en: The source code of the project is kept in a public GitHub repository to make
    it open source.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 项目的源代码保存在公共GitHub存储库中，以便开源。
- en: The manuscript is being kept in a private GitHub repository since it is under
    review.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 由于正在审阅中，手稿保存在私人GitHub存储库中。
- en: In system design phase, we decided to use three datasets four development, testing
    and performance measurements. But we end up with four datasets. A trivial dataset
    that contains only a few image files is used for development and testing. A small
    dataset (12GB) is used for quick verification at scales. A large dataset (65GB)
    is used for large scale performance measurement. A fourth dataset (1TB) is used
    to show the data processing capacity of the Kira system as we put up the paper.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统设计阶段，我们决定使用三个数据集进行开发、测试和性能测量。但最终我们使用了四个数据集。一个包含少量图像文件的微不足道的数据集用于开发和测试。一个小型数据集（12GB）用于快速验证规模。一个大型数据集（65GB）用于大规模性能测量。第四个数据集（1TB）用于展示Kira系统的数据处理能力，我们将其发表在论文中。
- en: All these datasets come from the Sloan Digital Sky Survey. Some of them are
    from Data Release 2 while some are from Data Release 7\. We choose them arbitrarily
    as we care more about the system capacity rather than the science in this research.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些数据集都来自斯隆数字天空调查。其中一些来自数据发布2，而另一些来自数据发布7。我们随意选择它们，因为在这项研究中，我们更关心系统容量而不是科学。
- en: 'Our collaborators are: Kyle Barbary, Oliver Zahn, Saul Perlmutter are astronomers.
    Frank Nothaft, Evan Sparks, Michael Franklin, David Patterson are experts about
    Spark and cloud computing in general. Zhao Zhang has rich experience in HPC community
    and some experience in cloud computing as well as a bit astronomy background.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的合作者是：Kyle Barbary、Oliver Zahn、Saul Perlmutter是天文学家。Frank Nothaft、Evan Sparks、Michael
    Franklin、David Patterson是Spark和云计算方面的专家。赵张在HPC社区有丰富的经验，也��一些云计算经验以及一点天文学背景。
- en: We use private GitHub repository for manuscript management and public GitHub
    repository for project management.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用私人GitHub存储库进行手稿管理，使用公共GitHub存储库进行项目管理。
- en: We have summaries for Team Brainstorming and Merit Evaluation phase. System
    Design's output is in the form of figures and is kept in GitHub repository. Solutions
    for Technical Barriers are kept in a private GitHub repository. Documents, Source
    code, system configurations as the products of coding/testing/tuning/measurements
    are kept in a public GitHub repository. The paper draft is kept in a private GitHub
    repository.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对团队头脑风暴和成果评估阶段进行了总结。系统设计的输出以图表形式保存在GitHub存储库中。解决技术障碍的方案保存在私人GitHub存储库中。作为编码/测试/调整/测量的产品的文档、源代码、系统配置保存在公共GitHub存储库中。论文草稿保存在私人GitHub存储库中。
- en: Before explaining the details of the diagram, I will first briefly review the
    software and systems that are used in this case study.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释图表的细节之前，我将首先简要回顾一下在这个案例研究中使用的软件和系统。
- en: FITS (Flexible Image Transport System) is a widely adopted image format in the
    astronomy and cosmology community. It is a fixed format with the image metadata
    as text and the actual image as binary format.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FITS（灵活图像传输系统）是天文学和宇宙学社区广泛采用的图像格式。它是一个固定格式，其中图像元数据为文本，实际图像为二进制格式。
- en: SEP (Source Extraction Python) is the software that detects light source objects
    from images. It rewrites the SEXtractor software by exposing primitive functionalities
    through a library interface with both C and Python.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SEP（源提取Python）是从图像中检测光源对象的软件。它通过一个库接口暴露基本功能，同时支持C和Python。
- en: Apache Spark is a popular distributed computing framework in cloud computing.
    It offers implicit parallelism and the lineage-based fault tolerance through the
    Resilient Distributed Dataset (RDD) abstraction. Spark is built using the Scala
    programming language which compiles a program that is executable on Java Virtual
    Machine (JVM).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Spark是云计算中流行的分布式计算框架。通过弹性分布式数据集（RDD）抽象，它提供了隐式并行性和基于血统的容错性。Spark是使用Scala编程语言构建的，它编译一个可在Java虚拟机（JVM）上执行的程序。
- en: JNI (Java Native Interface) provides a method to call existing C libraries inside
    a Java/Scala program. C and Java/Scala data structures can be used to exchange
    information between the two runtimes.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JNI（Java本机接口）提供了一种在Java/Scala程序内调用现有C库的方法。C和Java/Scala数据结构可用于在两个运行时之间交换信息。
- en: Amazon EC2 (Elastic Compute Cloud) is a public cloud service provided by Amazon.
    Users can request a number of compute nodes with various hardware and software
    combination.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon EC2（弹性计算云）是亚马逊提供的公共云服务。用户可以请求具有各种硬件和软件组合的计算节点。
- en: Amazon S3 is a data storage service provided by Amazon. Users can host there
    dataset on S3.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon S3是亚马逊提供的数据存储服务。用户可以在S3上托管其数据集。
- en: NERSC (National Energy Research Scientific Computing Center) is a high performance
    computing facility operated by Lawrence Berkeley National Lab. It hosts a few
    supercomputers and clusters.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NERSC（国家能源研究科学计算中心）是由劳伦斯伯克利国家实验室运营的高性能计算设施。它托管了一些超级计算机和集群。
- en: SDSS (Sloan Digital Sky Survey) is a large scale sky survey, its data is publicly
    available online.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SDSS（斯隆数字天文巡天）是一个大规模的天文巡天项目，其数据可以在网上公开获取。
- en: Thread safety is an operating system concept that describes the concurrent execution
    of multiple threads safely manipulating shared data structures.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程安全是一个操作系统概念，描述了多个线程并发执行时安全地操作共享数据结构。
- en: The process begins with team brainstorming of how modern computer software and
    hardware can accelerate the astronomy image processing pipeline. This requires
    a wide and also deep understanding of the state-of-the-art research and technical
    solution. In this research, we gather domain expertise (astronomers), cloud computing
    expertise and high performance computing expertise. We review the existing work
    and we think using cloud computing software-hardware stack can improve the overall
    application performance, but we have no idea by how much it can improve. The research
    is an exploratory process to implement the idea and quantitatively measure the
    improvements if there is any.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程始于团队头脑风暴，思考现代计算机软件和硬件如何加速天文图像处理流水线。这需要对最新研究和技术解决方案有广泛而深入的理解。在这项研究中，我们汇集了领域专业知识（天文学家）、云计算专业知识和高性能计算专业知识。我们审查了现有工作，我们认为使用云计算软件-硬件堆栈可以提高整体应用性能，但我们不知道它可以提高多少。这项研究是一个探索性过程，用于实施这一想法，并在有必要时定量衡量改进。
- en: 'The Team Brainstorming and Merit Evaluation phase happened back and forth as
    we keep asking why are we building such a project. Detail questions include: What
    are the existing solutions? How does the new project make difference in terms
    of performance and usability? Who are the potential users? This procedure lasts
    for about two weeks, all members of the Kira project are involved in the discussion.
    The pros and cons of each existing solution was documented, and later used in
    the paper.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 团队头脑风暴和优点评估阶段反复进行，因为我们一直在问为什么要构建这样一个项目。详细问题包括：现有解决方案是什么？新项目在性能和可用性方面有何不同？谁是潜在用户？这个过程持续约两周，Kira
    项目的所有成员都参与了讨论。对每个现有解决方案的利弊进行了记录，并后来用于论文中。
- en: 'The System Design phase lays out the programming interface of Kira, the modules
    and interactions between the modules. In this phase, we also identify some technical
    barriers of this project. I am listing them below, feel free to contact me if
    this is hard to understand:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 系统设计阶段规划了 Kira 的编程接口、模块和模块之间的交互。在这个阶段，我们还确定了这个项目的一些技术障碍。我在下面列出了它们，如果这难以理解，请随时联系我：
- en: Kira I/O, how to make Spark read FITS images
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kira I/O，如何使 Spark 读取 FITS 图像。
- en: Calling C library in Spark, how to make Spark work with existing C code in the
    SEP library
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Spark 中调用 C 库，如何使 Spark 与 SEP 库中现有的 C 代码一起工作。
- en: Setting up compilation environment, set Maven to automatically build Kira
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置编译环境，将 Maven 设置为自动构建 Kira。
- en: 'As we progress with the code, we notice a few other technical barriers:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们不断进行代码编写，我们注意到了一些其他技术障碍：
- en: Thread safety, neither the jFITS library nor the SEP library is thread safe
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线程安全性，jFITS 库和 SEP 库都不是线程安全的。
- en: Load imbalance, scheduler tuning for this particular workload
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 负载不平衡，调度程序调整适用于这个特定工作负载。
- en: 'For each of these technical barriers, we seek solutions for them. The solutions
    come from three sources: colleague expertise, google, and documents. By isolating
    the barriers, we were able to focus on a single barrier each time and can quickly
    verify the solution. The resulting code is stored in GitHub, and later merged
    into the project. This process takes about two weeks.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 针对每一个技术障碍，我们寻找解决方案。这些解决方案来自三个来源：同事的专业知识，Google 和文档。通过隔离障碍，我们能够每次专注于一个障碍，并快速验证解决方案。得到的代码存储在
    GitHub 中，并随后合并到项目中。这个过程大约需要两周的时间。
- en: The Software Coding and Testing phase takes about three weeks, we managed to
    integrate the SEP library through Java Native Interface with Spark, thus finally
    implement Kira. I implemented the code, and wrote the documents to make it convenient
    for my self to repeatedly run experiments. In the meantime, I prepared four datasets
    for performance measurements. A 24MB (4 files) dataset for sanity check, a 12GB
    (2,310 files) dataset for small scale test, a 65GB (111,50 files) for medium scale
    test and a 1TB (176,938 files) for large scale tests. The datasets were initially
    stored in NERSC shared file system, later I made a mirroring on EC2 S3 service,
    as most experiments were run on EC2 where S3 has a better transfer bandwidth to.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 软件编码和测试阶段大约需要三周的时间，我们通过 Java Native Interface 将 SEP 库与 Spark 集成，从而最终实现 Kira。我编写了代码，并编写了文档，以便我自己反复运行实验。同时，我为性能测量准备了四个数据集。一个
    24MB（4 个文件）的数据集用于健全性检查，一个 12GB（2,310 个文件）的数据集用于小规模测试，一个 65GB（111,50 个文件）的数据集用于中等规模测试，一个
    1TB（176,938 个文件）的数据集用于大规模测试。这些数据集最初存储在 NERSC 共享文件系统中，后来我在 EC2 S3 服务上进行了镜像，因为大多数实验是在
    EC2 上运行的，S3 的传输带宽更好。
- en: 'Performance Measurements and Performance Tuning come in pair and we go back
    and forth frequently. The key thing in these two steps is that we need a reasonable
    expected performance before the measurements. If the measurement does not match
    with our expectation, we need to analyze the reason and tune the system. Our methodology
    is like this: we started on 1 core on a single machine. We compare the Kira performance
    against the equivalent implementation to understand the slowdown introduced by
    Spark and JVM. Then we started to scale up with more cores on the same node, and
    observe the scaling curve. By doing that we understand the bounding factor of
    the performance on a single node. Later on, we scale out on multiple nodes by
    doubling the number of compute nodes in each step and observe the performance
    scaling. Since Spark hide the scalability complexity in the system, all we need
    to do here for different scale is to set relevant parameters in the configuration
    files. The code and documents are kept in GitHub, and the dataset is kept in Amazon
    S3 service.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 性能测量和性能调整是一对，我们经常来回进行。在这两个步骤中的关键是我们需要在测量之前有一个合理的预期性能。如果测量结果与我们的期望不符，我们需要分析原因并调整系统。我们的方法是这样的：我们从单核单机开始。我们将Kira的性能与等效实现进行比较，以了解Spark和JVM引入的减速情况。然后，我们开始在同一节点上使用更多核心，并观察缩放曲线。通过这样做，我们了解了在单节点上性能的限制因素。之后，我们通过每一步将计算节点数量加倍来扩展到多个节点，并观察性能的扩展情况。由于Spark隐藏了系统中的可扩展性复杂性，因此我们在不同规模下所需要做的一切就是在配置文件中设置相关参数。代码和文档保存在GitHub上，数据集保存在Amazon
    S3服务中。
- en: With all of the scripts from Merit Evaluation, System Design, and Source code,
    we put together the paper. Writing the paper is a collaborative process. We used
    a private GitHub repository to host the paper, and using Pull Request to manage
    everybody's editing.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将Merit Evaluation、System Design和Source code的所有脚本汇总起来，我们撰写了论文。写论文是一个协作过程。我们使用一个私有的GitHub存储库来托管论文，并使用Pull
    Request来管理每个人的编辑。
- en: Pain points
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 痛点
- en: (reproducible results) For the results to be reproducible, the readers should
    be able to tell and access the computers with the same hardware, the code base
    used particularly for the experiments, the dataset that was used for performance
    measurements.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可重现的结果）为了使结果可重现，读者应该能够识别和访问具有相同硬件的计算机，特别是用于实验的代码库，以及用于性能测量的数据集。
- en: 1.1 Hardware access. Since we are using Amazon EC2 resources, the same computer
    hardware is mostly accessible unless Amazon upgrades the hardware. It happens
    every few years. A second risk is that for large scale test, the reader might
    contact Amazon to increase the hardware limit which Amazon uses to limit the quantity
    of resources each user can posses at the same time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1 硬件访问。由于我们正在使用Amazon EC2资源，因此相同的计算机硬件基本上是可以访问的，除非Amazon升级硬件。这种情况每隔几年会发生一次。第二个风险是，对于大规模测试，读者可能会联系Amazon来增加硬件限制，Amazon使用这些限制来限制每个用户同时拥有的资源数量。
- en: 1.2 Code base. We maintain our code under a public GitHub repository, so it
    is accessible to all. However, the pain point is that the software evolves and
    the performance might change with the software evolution. Thus it is important
    that the authors should let the readers know which version of the software is
    related to the results that readers care about.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 1.2 代码库。我们将我们的代码保存在一个公共的GitHub存储库中，因此所有人都可以访问。然而，痛点在于软件在演进，性能可能随着软件演变而改变。因此，重要的是作者应该让读者知道与读者关心的结果相关的软件版本是哪个。
- en: 1.3 Dataset. The astronomy image dataset we use is Sloan Digital Sky Survey
    Data Release 7, which is publicly accessible. As long as the data hosting service
    is up running, the dataset is available. We also make a copy of the dataset we
    used in Amazon S3 service with public accessible permission. The pain point is
    that we have to pay Amazon for maintaining the 1TB dataset, and eventually we
    will run out of funding, so instead we have to publish the dataset file list as
    a text file in the code base.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 1.3 数据集。我们使用的天文图像数据集是Sloan数字天空调查数据发布7，它是公开可访问的。只要数据托管服务在运行，数据集就可用。我们还在Amazon
    S3服务中以公开访问权限备份了我们使用的数据集。痛点在于我们必须支付Amazon来维护1TB数据集，最终我们会耗尽资金，所以我们不得不将数据集文件列表发布为代码库中的文本文件。
- en: Key benefits
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键优势
- en: 'I break this question down to two: non-usable workflow and non-reproducible
    workflow.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我将这个问题分解成两个部分：不可用的工作流程和不可重现的工作流程。
- en: Non-usable workflow. I have seen a couple of projects in astronomy, where the
    authors conducted study on applying new tools to solve the old problems, but the
    authors failed to publish their source code along with the paper. This gives up
    the opportunity for people to build solutions upon their work. For Kira, we make
    the source code available on GitHub, so people can extend this code base for more
    functionalities.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不可用的工作流程。我见过一些天文学项目，作者进行了应用新工具解决旧问题的研究，但作者没有在论文中发布他们的源代码。这使得人们无法基于他们的工作构建解决方案。对于
    Kira，我们在 GitHub 上提供了源代码，因此人们可以扩展这个代码库以获得更多功能。
- en: Non-reproducible workflow. There was one experiment I read in a paper that I
    would like to reproduce, and design a new solution for it. However, the experiment
    was not reproducible due to the software version evolution. During the Kira building
    process, we particularly care about this issue, we documented the hardware, code
    base and dataset that are used for the performance measurement, so any user that
    follow the documented instructions should be able to reproduce the results.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不可复现的工作流程。有一个实验我在一篇论文中读到，我想重现，并设计一个新的解决方案。然而，由于软件版本的演进，该实验无法重现。在 Kira 的构建过程中，我们特别关注这个问题，我们记录了用于性能测量的硬件、代码库和数据集，因此任何按照记录的说明操作的用户都应该能够重现结果。
- en: Key tools
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键工具
- en: GitHub for code management, and Amazon S3 service for data hosting. We built
    Kira with Apache Spark which is a highly active open source project, so that we
    do not have the concern of the computing framework is out of maintenance if our
    academic funding ends.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 用于代码管理，亚马逊 S3 服务用于数据托管。我们使用 Apache Spark 构建了 Kira，这是一个高度活跃的开源项目，所以如果我们的学术资金结束，我们就不用担心计算框架是否已不再维护。
- en: Questions
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题
- en: What does "reproducibility" mean to you?
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对你来说，“可复现性”意味着什么？
- en: In the context of my case study, reproducibility has several levels of meanings.
    The very baseline is that users can compile the source code and pass the tests.
    Secondly, users should be able to configure the computer cluster so the can reproduce
    the performance in the documents. Since it is impossible to reproduce the exact
    performance measurement for every single run, a statistical repetition should
    be fine (average performance with bounded variation). Generally for computer system
    research that involves data, a public available data source is necessary for the
    performance to be reproducible.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的案例研究中，“可复现性”有几个层次的含义。最基本的是用户能够编译源代码并通过测试。其次，用户应该能够配置计算机集群，以便能够重现文档中的性能。由于不可能对每次运行进行精确的性能测量重现，统计重复应该是可以接受的（平均性能有界变化）。通常情况下，涉及数据的计算机系统研究需要有一个公开的数据来源，以便能够重现性能。
- en: Why do you think that reproducibility in your domain is important?
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 你为什么认为在你的领域中可复现性很重要？
- en: As computer system researchers, we build systems assuming people will use them.
    So it is important that people can follow the instructions in the documents to
    reproduce the state in which the system works. And it is important that users
    can reproduce the improvements over existing systems we describe in the paper
    or documents so they are more likely to adopt our systems. As paper reviewers,
    it is more convincing if they can reproduce the results in the paper as these
    are the evidence of the paper's idea.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作为计算机系统研究人员，我们构建系统时假设人们会使用它们。因此，重要的是人们能够按照文档中的说明重现系统工作的状态。重要的是，用户能够重现我们在论文或文档中描述的对现有系统的改进，这样他们更有可能采用我们的系统。作为论文审稿人，如果他们能够重现论文中的结果，那将更具有说服力，因为这些是论文观点的证据。
- en: How or where did you learn about reproducibility?
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 你是怎么学习到可复现性的？
- en: I learned the reproducible practices since the first time I submitted my homework
    project in college and ever since. I need to write a README file along with my
    code so the teaching assistant could compile and run my code to test if my solution
    is right. The later research experience follows the same path.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我自从大学第一次提交作业项目以来就学习了可复现性实践，并且一直如此。我需要在我的代码中写一个 README 文件，以便助教可以编译并运行我的代码，测试我的解决方案是否正确。后来的研究经验也是如此。
- en: What do you see as the major challenges to doing reproducible research in your
    domain, and do you have any suggestions?
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 你认为在你领域进行可复现研究的主要挑战是什么？你有什么建议吗？
- en: I used to design systems on supercomputers, where many people including paper
    reviewers have no access to. Thus, it is impossible for the research to be reproducible.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经设计过超级计算机上的系统，其中包括审稿人在内的许多人无法访问。因此，这项研究不可能是可重复的。
- en: Another major pitfall is due to software version evolving. At the time of writing
    the paper, some features of a piece of software was working, and the researchers
    measured and published the numbers. But these numbers are no longer reproducible
    after a few versions.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个主要的陷阱是由于软件版本的演变。在撰写论文时，某个软件的一些功能正在运行，研究人员进行了测量并发布了数字。但是几个版本之后，这些数字就无法再现了。
- en: What do you view as the major incentives for doing reproducible research?
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 您认为进行可重复研究的主要动机是什么？
- en: I break this down to reproducible results and reproducible research process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我将这分解为可重复结果和可重复研究过程。
- en: 4.1\. (reproducible results) The systems I build are usually to facilitate scientific
    research. The systems either expedite the execution of computer programs or provide
    novel functionalities (e.g. failure diagnosis). To make sense about my research,
    users should be able to see the performance improvement I documented in the paper
    or documents. They should be able to use the novel functionalities to ease their
    research. So reproducibility of the systems is the key to prove the system actually
    works.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 4.1\. （可重复结果）我建立的系统通常是为了促进科学研究。这些系统要么加快计算程序的执行，要么提供新功能（例如故障诊断）。为了理解我的研究，用户应该能够在论文或文档中看到我记录的性能改进。他们应该能够使用新功能来简化他们的研究。因此，系统的可重复性是证明系统实际工作的关键。
- en: '4.2\. (reproducible research process) As a whole process, this particular research
    case is exploratory. We only have a conjecture about the performance before the
    implementation and measurement. I am not familiar with the tools I am using also
    (Apache Spark, Scala, Java Native Library, SEP library, Source Extractor C program).
    I think (not quite sure) the incentive for the reproducible research progress
    is helpful in my future projects. Once again, if I am facing such situation, I
    know where to start to tackle a complicated problem. My methodology particularly
    for this research is: 1) a more-or-less valid hypothesis, 2) a performance profile
    of the existing solution, 3) isolating the technical barriers, 4) solving the
    technical barriers, 5) build the new solution, 6) performance measurement and
    tuning.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 4.2\. （可重复研究过程）作为一个整体过程，这个特定的研究案例是探索性的。在实施和测量之前，我们只对性能有一个猜想。我对我正在使用的工具也不熟悉（Apache
    Spark，Scala，Java Native Library，SEP library，Source Extractor C program）。我认为（不太确定）可重复研究进展对我未来的项目有帮助。再次，如果我面对这样的情况，我知道从哪里开始解决一个复杂的问题。我特别针对这项研究的方法是：1）一个或多或少有效的假设，2）现有解决方案的性能概况，3）隔离技术障碍，4）解决技术障碍，5）构建新解决方案，6）性能测量和调整。
- en: Are there any best practices that you'd recommend for researchers in your field?
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 你能推荐给你领域的研究者任何最佳实践吗？
- en: I would recommend for open source software and related publications. The authors
    should maintain a version of the software for readers to reproduce the results
    in the paper. These versions and repository should be included in the paper.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我会推荐开源软件和相关出版物。作者应该维护一份软件版本，以便读者能够在论文中重现结果。这些版本和存储库应该包含在论文中。
- en: Would you recommend any specific resources for learning more about reproducibility?
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 你会推荐学习更多关于可重复性的特定资源吗？
- en: I can only think of GitHub for code management and Amazon S3 for data management
    right now.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我目前只能想到GitHub用于代码管理和Amazon S3用于数据管理。
